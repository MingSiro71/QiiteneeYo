[{"url":"https://qiita.com/miyuki_samitani/items/dc4639d186716841db3e","title":"IAM Access Analyzer とは","body":"## 勉強前イメージ\n\nIAMのアクセスした分析見れる的な？\n\n## 調査\n\n### IAM Access Analyzer とは\n\nリソースのポリシーを確認して、意図せぬ公開設定などがされていないか\n検出し、可視化する機能になります。\n\n### 対応しているリソース\n\n- s3\n- IAMロール\n- KMSキー\n- lambda関数・レイヤー\n- SQSキュー\n- Secrets Managerシークレット\n\n※2021/03/29時点\n詳細は [AWS Identity and Access Management のユーザガイド](https://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/what-is-access-analyzer.html) をご確認ください\n\n### 設定方法\n\n- マネジメントコンソールから確認\n\nIAM > アクセスレポート > Access Analyzer から設定することが出来ます\n\n![2021-03-29 IAM Management Console - Google Chrome 2021-03-29 15.44.10.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/129517/153f5c2e-05f9-e05f-9521-0c981929efb6.png)\n\n- 設定内容\n\n以下が設定内容になります。\n名前だけ指定するだけでアナライザーを作成できます。\n\n![2021-03-29 IAM Management Console - Google Chrome 2021-03-29 15.57.48.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/129517/f4c648c3-7b0e-e136-8bd1-6ded4e6684cb.png)\n\n\n### 費用\n\nIAM Access Analyzer の利用費用は、追加料金無しに使用できるので\n設定し、確認するのが良いかと思います。\n\n### 注意点\n\n- サポートされているリソースが限定される\n\nすべてのリソースがサポートされているわけではないので、\nこれを有効にするだけで大丈夫、とはならないです\n\n- リージョン単位の設定\n\n複数リージョン利用する際は、リージョンごとに設定を有効にする必要があります。\n\n## 勉強後イメージ\n\nなんかAWS config とか似たようなことしてなかったっけ・・？\nまた今度気が向いたら勉強します。\nとりあえずそんな機能があるってことを知った。\n\n## 参考\n\n- [IAM Access Analyzerと既存の機能を比較してどう使っていくか考察してみた #reinvent](https://dev.classmethod.jp/articles/iam-access-analyzer-vs-config-rules/)\n- [【はじめてのAWS】AWS IAM Access Analyzer を設定しよう](https://blog.serverworks.co.jp/tech/2020/07/01/iam_access_analyzer-2/)\n- [AWS IAM Access Analyzer を使用する](https://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/what-is-access-analyzer.html)\n","user":"miyuki_samitani","created_at":"2021-03-29T16:13:07+09:00","updated_at":"2021-03-29T16:13:07+09:00"},{"url":"https://qiita.com/kenjiuno/items/7678a27834a7b3b5773c","title":"QR コード サンプル集","body":"# QR コードのサンプルです\n\nzbarimg の動作確認目的で作りました。\n\n半角英数字\n\n![han.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/364126/195a6764-1752-4efd-a05c-b9d670dbbe0f.png)\n\n`\"%01%02%03\"` のような特殊コードを含む\n\n![010203.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/364126/4cfea95c-909e-6e75-1397-a41daa8c5bde.png)\n\nXML の CDATA セクションで使用できない文言 `]]>` を含む\n\n![nocdata.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/364126/9071dafe-090e-994b-8bce-26e40241ca87.png)\n\n※ [libqrencode](https://github.com/fukuchi/libqrencode/) ([QRCodeActiveXControl](https://github.com/HiraokaHyperTools/QRCodeActiveXControl) と Microsoft Excel) を使用して生成\n","user":"kenjiuno","created_at":"2021-03-29T16:12:52+09:00","updated_at":"2021-03-29T16:12:52+09:00"},{"url":"https://qiita.com/tomoxxx/items/594c4676a9d102068e33","title":"オブジェクト指向が分からない…乃木坂・櫻坂・日向坂に頼ってみた","body":"#オブジェクト指向の定義に入る前に…\n\n**明確な定義はない!**\nということを頭の隅に入れておいてください。\n\n例えば、愛とは？恋とは？乃木坂の良さとは？\nって言われてもその答えは人それぞれで、一つに定まらないのと同じです。\n\nなので、**ざっくり雰囲気を理解すること**が大事だということを覚えてください!\n\n\n#オブジェクト指向とは？\n**概念・考え方の一つです!**\n(目に見えない・触れない。つまり無体物なのです！)\n\n## どんな概念・考え方？\nいかに**効率よく**開発を行うかを突き詰めた考え方!\n\n例えば、エンジニアチームがプロジェクトを行うときは、**\"オブジェクト指向に基づいてプログラムを作成しましょう!\"**と言って作業に取り掛かります。\n\n## 効率の良い考え方とは？\n### ①カプセル化\n\n**他のプログラムから干渉されないようにする考え方!**\n\n乃木坂・櫻坂・日向坂のOFFICIAL WEB SITEを作る際に、\n乃木坂のサイトのプログラムと櫻坂のサイトのプログラムと日向坂のサイトのプログラムがそれぞれ独立した環境にすること!\n(**互いに\"干渉\"を受けない**ようにすること!)\n\n\n\n\n### ②継承\n\n同じようなプログラムは**\"共通化\"**して使う考え方！\n\n乃木坂・櫻坂・日向坂のOFFICIAL WEB SITEのベースとして\n個人の**名前・生年月日・身長など**の情報が共通して存在しています。\n\nであれば、\n**初めに乃木坂のOFFICIAL WEB SITEを作った際**に、櫻坂・日向坂でも共通化できる部分は同じコードを書かないで、継承しようという考え方です。\n\n\n\n<img width=\"200\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449715/f0c782b4-8bde-a3bd-1466-7615a09b739b.png\" class=\"img\" alt=\"自然言語処理の流れ\"><img width=\"200\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449715/bcdfe94f-2dc8-f645-3898-958baa2f8722.png\" class=\"img\" alt=\"自然言語処理の流れ\"><img width=\"200\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449715/daad79e4-2a0d-aa63-bb7b-b4367227eccb.png\" class=\"img\" alt=\"自然言語処理の流れ\">\n\n\n\n\n\n\n\n\n### ③ポリモーフィズム\n\n汎用的な形に出来るようにしましょうという考え方！\n**\"②継承\"**によってベースを作成した後に、\n独自に派生したプログラムを追加・修正出来るようにする考え方!\n\n例えば、\n**【変更前】**   >>>>>>>>>>>>>>>>>>>>>**【変更後】**\n<img width=\"300\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449715/230d4d9d-4b54-9661-8cda-744d6ed3db53.png\" class=\"img\" alt=\"自然言語処理の流れ\"><img width=\"300\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/449715/02cfc6cd-7b92-699d-73d2-2312dcb971c5.png\" class=\"img\" alt=\"自然言語処理の流れ\">\n\n\n\n\n","user":"tomoxxx","created_at":"2021-03-29T16:06:09+09:00","updated_at":"2021-03-29T16:06:09+09:00"},{"url":"https://qiita.com/Ryo9597/items/6ddc7e834e18bf348d9f","title":"Laravel6 チートシート","body":"# はじめに\nLaravel触り始めたばかりの初心者です。\nいちいち調べるのもめんどくさくなってきたので基本的な部分をまとめてみました。\n自分用のチートシートにはなりますが、Laravel6で開発中の初心者の方も参考にしてください。\n開発環境に関しては、MAMPで構築しています。\n\n## Laravelのインストールから初期設定\n### Laravelのインストール\nLaravelのインストールはcomposerコマンドで行います。\n\n```terminal:ターミナル\ncomposer create-project laravel/laravel （フォルダ名） --prefer-dist \"6.0.*\"\n```\n\n`composer create-project`には2つのオプションがあります。\n1. --prefer-dist\n2. –prefer-source \n\n`--prefer-dist`は、zipファイルでダウンロードします、こっちのほうが高速なのでこちらを採用。\n`--prefer-source`は、git cloneでソースを落とします。\n\n### Laravelの動作確認\nLaravelのインストールが正常に行われたかを確認するために開発サーバーを起動します。\n\n```terminal:ターミナル\nphp artisan serve\n```\n\n### 初期設定\nLaravelでやっておくべき初期設定は以下の7つです。\n\n1. タイムゾーン\n2. 言語設定\n3. DBの文字コード\n4. デバッグバー\n5. DB設定\n6. エラーメッセージの日本語訳\n7. HTMLにCSRFトークンの設置\n\n#### タイムゾーン\nタイムゾーンを日本時間に変更します。\n\n```php:config/app.php(70行目あたり)\n'timezone' => 'Asia/Tokyo'\n```\n\n#### 言語設定\n言語設定を日本語に変更します。\n\n```php:config/app.php(83行目あたり)\n'locale' => 'ja'\n```\n\n#### DBの文字コード\n文字コードをUTF-8に変更します。\n\n```php:config/database.php(55行目~56行目あたり)\n'charset' => 'utf8',\n'collation' => 'utf8_unicode_ci'\n```\n\n#### デバッグバー\nデバッグ用にデバッグバーを表示させます。\n\n```terminal:ターミナル\ncomposer require barryvdh/laravel-debugbar\n```\n\n現時点での設定では本番環境でもデバッグバーが表示されます。\nDBなどの値がユーザーに見えてしまうため本番環境ではデバッグバーを非表示にする必要があります。\n\n```env:.env\nAPP_DEBUG=false\n```\n\n#### DB設定\n.envファイルのDBに関する記載の部分を修正していきます。\n\n```env:.env\nDB_CONNECTION=mysql //DB種類\nDB_HOST=127.0.0.1 //ホスト\nDB_PORT=3306 //ポート\nDB_DATABASE=laravel //データベース名\nDB_USERNAME=root //ユーザー名\nDB_PASSWORD= //パスワード\n```\n\n##### 接続確認\n\n```terminal:ターミナル\nphp artisan migrate\n```\n\n###### エラー発生\n修正すべきポイントは3つです。\n\n①.envのDB_HOSTを修正\n\n```env:.env\nDB_HOST=localhost\n```\n\n②config/database.phpのunix_socketを修正\n\n```php:config/database.php(54行目あたり)\n'unix_socket' =>  '/Applications/MAMP/tmp/mysql/mysql.sock'\n```\n\n③ターミナルでキャッシュクリア\n\n```terminal:ターミナル\nphp artisan cache:clear\nphp artisan config:cache\n```\n\n#### エラーメッセージの日本語訳\n`resources/lang/en`内にエラーメッセージのファイルがあるがこれらすべて英語となっています。\nそのため、日本語訳するために以下のサイトからダウンロードします。\n\nhttps://github.com/minoryorg/laravel-resources-lang-ja\n\n\nダウンロードしたファイルを`resources/lang/ja`内に格納します。\n\n##### 任意修正箇所\n\nエラーメッセージが一部英語で表示されます。\n\n![スクリーンショット 2021-03-29 12.46.06.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/838372/bd6e1cff-e9db-6279-1032-f1d7f10bc3f7.png)\n\nエラーメッセージの変更は以下のように行います。\n\n```php:resources/lang/ja/validation.php\n\"attributes\" => [\n  \"password\" => \"パスワード\"\n]\n```\n\n![スクリーンショット 2021-03-29 12.48.11.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/838372/ad7f5562-cc7b-8eab-6ca1-650af8e4e5f0.png)\n\n\n#### HTMLにCSRFトークンの設置\nこちらを入れておかないとフォームが必ずエラーとなります。\nHTMLのheadタグ内の共通レイアウトbladeファイルを作り、そこに記載します。\n\n```php:resources/views/layout.blade.php(レイアウトファイル)\n<meta name=\"csrf-token\" content=\"{{ csrf_token() }}\">\n```\n\n## フロントエンドでVue.jsを使うとき\nLaravel6ではインストールが必要となりました。\n\n```terminal:ターミナル\n// laravel/uiをインストール\ncomposer require laravel/ui:^1.0 --dev\n\n//　どちらかを選択\n// ①auth機能あり\nphp artisan ui vue --auth\n// ②auth機能なし\nphp artisan ui vue\n\n// コンパイルとインストール\nnpm install && npm run dev\n```\n\n### npm run devでエラーが発生した場合\nエラーメッセージは以下の通りです。\n\n```\nERROR  Failed to compile with 2 errors                                                             \n\n error  in ./resources/sass/app.scss\n```\n\n#### 【原因】\nsass-loaderのバージョンの互換性がない。\n\n#### 【対応】\nバージョンの変更を行う\n\n```terminal:ターミナル\n// sass-loaderをアンインストール\nnpm uninstall --save-dev sass-loader\n\n// sass-loaderをインストール\nnpm install --save-dev sass-loader@7.1.0\n\n// 実行\nnpm run dev\n```\n\n## MVCアーキテクチャ\n大きく分けて2つの動きが考えられます。\n\n**①DBの情報を必要としないとき**\nクライアント → ルーティング → コントローラー → ビュー\n\n**②DBの情報を必要とするとき**\nクライアント → ルーティング → (コントローラー ⇄ モデル ⇄ DB) → ビュー\n\n### ルーティング\n<details>\n<summary>フォルダ</summary>\nroutes/web.php\n`api`の場合は、routes/api.php\n</details>\n\n```php:routes/web.php\n// ①直接Viewに移動\n// Viewのwelcome\nRoute::get(\"/\", function() {\n  return view(\"welcome\");\n}\n\n// ②Controllerに移動\n// ControllerのUserControllerのindexメソッドに移動\nRoute::get(\"/user\", \"UserController@index\");\n```\n\n### コントローラー\n<details>\n<summary>フォルダ</summary>\napp/Http/Controllers\n</details>\n\n#### コントローラーの作成方法\n\n```terminal:ターミナル\nphp artisan make:controller UserController\n```\n\n#### リソースコントローラー（RESTful）\n1行のコードで典型的なCRUDルートをコントローラーで作成できます。\n\n```terminal:ターミナル\nphp artisan make:controller PhotoController --resource\n```\n\n| 動詞　　　　 | URI                 | アクション     | ルート名          |\n|:-----------|:--------------------|:------------|:----------------|\n| GET        | /tests              | index       | Tests.index     |\n| GET        | /tests/create       | create      | Tests.create    |\n| POST       | /tests              | store       | Tests.store     |\n| GET        | /tests/{test}       | show        | Tests.show      |\n| GET        | /tests/{test}/edit  | edit        | Tests.edit      |\n| PUT/PATCH  | /tests/{test}       | update      | Tests.update    |\n| PUT/PATCH  | /tests/{test}       | destroy     | Tests.destroy   |\n\n##### RestFulでよく使われる書き方\n**認証がされているときに表示する**\n\n```php:routes/web.php\nRoute::group([\"prefix\" => \"photos\", \"middleware\" => \"auth\"], function() {\n   Route::get(\"index\", \"PhotosController@index\")->name(Photos.index);\n   Route::get(\"create\", \"PhotosConroller@create\")->name(Photos.create);\n   Route::posts(\"store\", \"PhotosController@store\")->name(Photos.store);\n   Route::get(\"show/{id}\", \"PhotosController@show\")->name(Photos.show);\n   Route::get(\"edit/{id}\", \"PhotosController@edit\")->name(Photos.edit);\n   Route::post(\"update/{id}\", \"PhotosController@update\")->name(Photos.update);\n   Route::post(\"destroy/{id}\", \"PhotosController@destroy\")->name(Photos.destroy);\n})\n```\n\n**`id`の値をどのようにして取ればいいのか？**\n\n```php:resources/views/show.blade.php\n<form action=\"{{ route('test.edit', [ \"id\" => $test->id ]) }}\" method=\"GET\">\n</form>\n```\n\n#### 値の取り出し方\n値の取り出し方は2通りあります。\n①Viewのフォーム経由から値を受け取る\n②ModelでDBから値を受け取る\n\n##### View経由\n\n```php:app/Http/Controllers/UserController\nuse App\\Models\\User;\n\npublic function store(Request $request) {\n    // 値を取得する\n    // $email = $request->input(\"email\");\n    // $password = $request->input(\"password\");\n\n    // 正しく取得できているか確認\n    // dd($email);\n\n    // Modelを呼び出すだけでOK\n    $user = new User;\n    \n    // インスタンス化したものに保存\n    $user->email = $request->input(\"email\");\n    $user->password = $request->input(\"password\");\n    \n    // DBに保存\n    $user->save();\n\n    // リダイレクト\n    return redirect(\"user/index\");\n}\n```\n\n**`POST`がうまくいかないとき**\n一旦キャッシュをすべてクリアしてみましょう。\n\n```terminal:ターミナル\nphp artisan optimize:clear\n```\n\n##### Model経由\n\n```php:app/Http/Controller/UserController.php\n// ModelsのUserを読み込み\nuse App\\Models\\User\n\n// クエリビルダーを使うためのおまじない\nuse Illuminate\\Support\\Facades\\DB\n\n// ①Eloquent\n// all() = すべてのデータを取得する\n$values = User::all();\n\n// find() = 引数の値のidのデータを取得する\n$value = User::find($id);\n\n// where() = 条件指定(categoryカラムがPHPのデータを取得する)\n$value = User::where(\"category\", \"PHP\")->get();\n\n// ②クエリビルダー\n// get() = 条件にあったデータのすべてを取得する\n$values = DB::table(\"users\")->get();\n\n// first() = 最初の１件を取得する\n$value = DB::table(\"users\")->first();\n\n// SELECT = 取得するカラムを指定する\n$values = DB::table(\"users\")->select(\"name\", \"email\")->get();\n\n// user.indexのViewに移動し、$valuesの値を渡す\nreturn view(\"user.index\", compact(\"values\"));\n```\n\nhttps://www.ritolab.com/entry/120\n\nhttps://www.ritolab.com/entry/93\n\n### モデル\n<details>\n<summary>フォルダ</summary>\napp/Models\n</details>\n\n#### モデルの作成方法\n同時にマイグレーションファイルを作成すると便利\n\n```terminal:ターミナル\nphp artisan make:model Models/Post --migration\n```\n\n##### マイグレーションとは？\nマイグレーションとは、DBテーブルの履歴を管理する仕組みです。\n<details>\n<summary>フォルダ</summary>\ndatabase/migrations\n</details>\n\n###### マイグレーションの頻出カラムタイプ\n\n```php:database/migrations/XXXX_XX_XXXXXX_create_users_table.php\npublic function up()\n    {\n        Schema::create('registers', function (Blueprint $table) {\n            // 符号なしBIGINTを使用した自動増分ID\n            $table->bigIncrements('id')->comment('id');\n            // 20文字以内の文字列\n            $table->string('name', 20)->comment('名前');\n            // 255文字以内で独自の文字列\n            $table->string('email', 255)->unique('email')->comment('メールアドレス');\n            // 日付\n            $table->date('birthday')->comment('生年月日');\n            // 0~255までの整数値で符号なし\n            $table->tinyInteger('gender')->unsigned()->comment('1:男性 2:女性');\n            // 最大65535文字で未記入可\n            $table->text('memo', 65535)->nullable()->comment('メッセージ');\n            $table->timestamps();\n        });\n    }\n```\n\n**テーブルにカラムを作成する**\n\n```terminal:ターミナル\nphp artisan migrate\n```\n\n###### マイグレーションを修正する\n\n**①migrationファイルを新規に作成する**\n`--table`オプションでテーブル名を指定します。\nファイル名は何をするかをわかりやすくするのがおすすめです。\n下記の場合、「usersテーブルにemailを追加する」です。\n\n```terminal:ターミナル\nphp artisan make:migration add_email_users_table --table=users\n```\n\n**②migrationファイルを修正**\n\n```php:database/migrations/XXXX_XX_XXXXXX_add_email_users_table.php\npublic function up()\n    {\n        Schema::table('users', function (Blueprint $table) {\n             $table->string('email');  //カラム追加\n        });\n    }\n\npublic function down()\n    {\n        Schema::table('users', function (Blueprint $table) {\n            $table->dropColumn('email');  //カラムの削除\n        });\n    }\n```\n\n**③migration**\n\n```terminal:ターミナル\nphp artisan migrate\n```\n\n### ビュー\n<details>\n<summary>フォルダ</summary>\nresources/views\n</details>\n\n#### assetsヘルパー\nBladeファイル内にCSSやJSを記述すると可読性が著しく落ちるので別ファイルに保存します。\n\n```\npublic \n  |__ css\n  |__ js\n  |__ img\n```\n\n```php:resources/views/index.blade.php\n<!-- css -->\n<link rel=\"stylesheet\" href=\"{{ asset('/css/style.css') }}\">\n\n<!-- js -->\n<script src=\"{{ asset('/js/index.js') }}\"></script>\n\n<!-- img -->\n<img alt=\"ロゴ\" src=\"{{ asset('/img/logo.jpg') }}\">\n```\n\n## ダミーデータ\n### Factory & Faker\n<details>\n<summary>フォルダ</summary>\ndatabase/factories\n</details>\n\n```terminal:ターミナル\nphp artisan make:factory PostFactory\n```\n\n**ここで修正が必要です**\n\n```php:database/factories/PostFactory.php\n// これは誤り\n// use App\\Model\n\n// こちらが正しい\nuse App\\Models\\Post\n\n// ModelではなくPostのためこちらも誤り\n/* $factory->difine(Model::class, function (Faker $faker) {\n    return [\n    \n    ];\n} */\n\n//こちらが正しい\n$factory->define(Post::class, function (Faker $faker) {\n    return [\n        \"name\" => $faker->name,\n        \"title\" => $faker->realText(50),\n        \"email\" => $faker->unique()->email,\n        \"tel\" => $faker->phoneNumber,\n        \"password\" => $faker->password,\n        \"url\" => $faker->url,\n        \"gender\" => $faker->randomElement([\"0\", \"1\"]),\n        \"age\" => $faker->numberBetween($min = 1, $max = 6),\n        \"contact\" => $faker->realText(200)\n    ];\n});\n```\n\nその他のFakerに関しては以下を確認してください。\n\nhttps://shingo-sasaki-0529.hatenablog.com/entry/how_to_use_php_faker\n\n\n#### 作成手順\n##### ①config/app.phpの修正\n\n```php:config/app.php(109行目あたり)\n\"faker_locale\" => \"ja_JP\"\n```\n\n##### ②シーダの作成\n\n```terminal:ターミナル\nphp artisan make:seeder PostSeeder\n```\n\n```php:PostSeeder.php\nuse App\\Models\\Post\n\npublic function run() {\n    // 200個作成\n    factory(Post::class, 200)->create();\n}\n```\n\n##### ③データベースシーダーに追記\n```php:database/seeds/DatabaseSeeder.php\npublic function run()\n{\n    $this->call([\n        // ここに付け足していく\n        UsersTableSeeder::class,\n        PostsSeeder::class,\n    ]);\n}\n```\n\n###### ④ターミナル\n\n```terminal:ターミナル\n// Composerのオートローダーを再生成する\ncomposer dump-autoload\n\n// データベースに入っている値を初期化し入力する場合\nphp artisan migrate:fresh --seed\n```\n\n## バリデーション\n<details>\n<summary>フォルダ</summary>\napp/Http/Requests\n</details>\n\n```terminal:ターミナル\nphp artisan make:request StoreBlogPost\n```\n\n\n```php:app/Http/Requests/StoreBlogPost.php\n// ①trueに変更（これをしないとうまく作用しない）\npublic function authorize() {\n    return true;\n}\n\npublic function rules() {\n    return [\n        // 【必須】最大20文字\n        \"name\" => \"required|string|max:20\",\n        // 【必須】最大255文字のメールアドレスであり被りがあってはならない\n        \"email\" => \"required|email|unique:users|max:255\",\n        // 【必須】8文字以上で確認用と同じパスワード\n        \"password\" => \"required|confirmed|min:8\",\n        // 【任意】\n        \"hobby\" => \"nullable\",\n    ]\n}\n```\n\n```php:app/Http/Controllers/StoreBlogPostController\n// ファイルを読み込む\nuse App\\Http\\Requests\\StoreBlogPost;\n\n// これで自動的にバリデーションができるようになる\npublic function store(StoreBlogPost $request) {\n}\n```\n\n```php:resources/views/blogpost.blade.php\n// ①それぞれ書く\n@error(\"email\")\n    <span>\n        <strong>{{ $message }}</strong>\n    </span>\n@enderror\n\n// ②まとめて書く\n@if ($errors->any())\n    <div>\n        <ul>\n            @foreach($errors->all() as $error)\n                <li>{{ $error }}</li>\n            @endforeach\n        </ul>\n    </div>\n@endif\n```\n","user":"Ryo9597","created_at":"2021-03-29T16:03:56+09:00","updated_at":"2021-03-29T16:03:56+09:00"},{"url":"https://qiita.com/usk2000/items/80fa533f842844a46596","title":"[iOS14]UITableViewCellに置いたボタンが押せなくなった","body":"かなり昔に書かれたObjective-Cソースコードで、iOS14になってから発生したバグについてです。\n\n## 何が起きたか\n\nUITableViewCellサブクラスの実装で、コードでレイアウトしていたソースがありました。\nこんな感じです。\n\n```objc\n- (void)awakeFromNib {    \n    [super awakeFromNib];\n\n    UIButton *button = [[UIButton alloc] init];\n    [button addTarget:self action:@selector(doSomething:) forControlEvents:UIControlEventTouchUpInside];\n    [self addSubView: button];\n\n}\n\n```\n\nこのボタンが、iOS14ではなぜか押せなくなりました。\n\n## 原因\n\niOS14からは、UITableViewCell.contentView(UITableViewCellContentView)がUITableViewCellの大きさになっており、かつ一番手前に来るようになりました。\nなので、上記のソースでは`UITableViewCell`自体に`addSubView`していたため、UIButtonよりも前面に`UITableViewCellContentView`が来てしまい、UIButtonが押せなくなりました。\n\n## 解決方法\n\n```objc\n    //[self addSubView: button];\n    [self.contentView addSubView: button];\n```\n\nこれで押せるようになります。\n\n## 参考資料\n\nhttps://stackoverflow.com/questions/63932279/an-extra-uitableviewcellcontentview-overlay-appears-in-a-tableview-on-ios-14-pre\n","user":"usk2000","created_at":"2021-03-29T16:00:25+09:00","updated_at":"2021-03-29T16:00:25+09:00"},{"url":"https://qiita.com/maskot1977/items/dc82e00b46209e0d527a","title":"ScikitAllStars: 主要なscikit-learnの教師あり機械学習法を全部Optunaでチューニングしてスタッキングまでやっちゃうツール","body":"教師あり機械学習法はたくさんありますが、scikit-learn に入ってるもののうち主なものを全部使って、optunaでハイパーパラメーターチューニングして、できたモデルをさらにstackingしてしまうという一連の作業をまとめて行うライブラリ ScikitAllStars を作りました。\n\nなぜこんなツールを作ったかって？めんどいからです。\n\nまた、ScikitAllStars の特徴として、教師あり機械学習が「回帰問題」なのか「分類問題」なのかという違いをほとんど意識せずに使えるというところもあります。\n\n以下のコードは全て Google Colaboratory 上で動作を確認済みです。\n\n# 必要なツールのインストール\n\n\n```python\n# Optuna のインストール\n!pip install optuna\n```\n\n\n\n```python\n# ScikitAllStars のインストール\n!pip install git+https://github.com/maskot1977/scikitallstars.git\n```\n\n\n\n# データの用意\n\n下記は Numpy array 形式のデータを用いていますが、Pandas DataFrame 形式のデータでも使えるはずです。\n\nまず、分類用データを使ってみましょう。\n\n\n```python\nimport sklearn.datasets\n\ndataset = sklearn.datasets.load_breast_cancer() # 分類用データ例\n#dataset = sklearn.datasets.load_diabetes() # 回帰用データ例\n```\n\n訓練データ・テストデータへ分割を行います。\n\n\n```python\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=.4) # 訓練データ・テストデータへのランダムな分割\n```\n\n# AllStarsモデルの学習\n\n次のようにして、ScikitAllStarsに登録してある全ての手法に対してoputunaでチューニングしながら学習を行います。feature_selection=True とすることで、RandomForestによる特徴選択を事前に行ないます。\n\n\n```python\nfrom scikitallstars import allstars, depict\n\nallstars_model = allstars.fit(X_train, y_train, timeout=1000, n_trials=100, feature_selection=True)\n```\n\n    feature selection: X_train (341, 30) -> (341, 9)\n    \n   \n\n\nfeature_selection=True とした場合は、次のようにすると、重要な特徴量についての知見が得られます。\n\n\n```python\ndepict.feature_importances(allstars_model)\n```\n\n![scikitallstars_basic_usage2_10_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/29a3f4d7-62ba-86bc-531c-a18311427748.png)\n\n    \n    \n\n\n次のようにして、学習経過のサマリーが得られます。\n\n\n```python\ndepict.training_summary(allstars_model)\n```\n\n![scikitallstars_basic_usage2_12_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/14f85caa-8f9f-47ff-76e3-366497b41b9d.png)\n\n    \n    \n\n\n次のようにして、手法ごとのベストモデルの性能を確認できます。\n\n\n```python\ndepict.best_scores(allstars_model)\n```\n\n![scikitallstars_basic_usage2_14_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/4e94e218-2840-5ea2-5140-7218227154cb.png)\n\n   \n    \n\n\n\n```python\ndepict.all_metrics(allstars_model, X_train, y_train)\n```\n\n![scikitallstars_basic_usage2_15_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/b27fcf15-79fa-badd-44a9-2a8bcca586e1.png)\n\n    \n\n    \n\n\n\n```python\ndepict.all_metrics(allstars_model, X_test, y_test)\n```\n\n![scikitallstars_basic_usage2_16_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/7567e515-5f6b-201d-adc3-35fd0b733737.png)\n\n    \n    \n\n\nAllStarsモデル全体でのベストモデルの性能は次のようにして確認できます。\n\n\n```python\nallstars_model.score(X_train, y_train), allstars_model.score(X_test, y_test)\n```\n\n\n\n\n    (0.9976689976689977, 0.9690721649484537)\n\n\n\n\n```python\ndepict.metrics(allstars_model, X_train, y_train, X_test, y_test)\n```\n\n![scikitallstars_basic_usage2_19_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/dd539bf8-eaa6-31ea-67f6-51cc8121d17f.png)\n\n    \n\n    \n\n\nベストモデルを用いた新規予測は次のようにして行えます。\n\n\n```python\nallstars_model.predict(X_test)\n```\n\n\n\n\n    array([1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n           1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n           0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n           1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n           1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n           1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n           1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n           1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n           1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n           1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n           1, 1, 0, 1, 1, 1, 1, 1])\n\n\n\n# スタッキングモデルの学習\n\n上記のようにして学習した AllStars モデルを用いて、下記のようなコードでスタッキングモデルを組んでハイパラチューニングしながら学習することができます。\n\n\n```python\nstacking_model = allstars.get_best_stacking(allstars_model, X_train, y_train, timeout=1000, n_trials=100)\n```\n\n\n\n得られたスタッキングのベストモデルの性能は次のようにして確認できます。\n\n\n```python\nstacking_model.score(X_train, y_train), stacking_model.score(X_test, y_test)\n```\n\n\n\n\n    (0.9882697947214076, 0.9517543859649122)\n\n\n\n\n```python\ndepict.metrics(stacking_model, X_train, y_train, X_test, y_test)\n```\n\n![scikitallstars_basic_usage2_26_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/75bf4b9e-9784-04ce-8a7c-83c2f12f97ac.png)\n\n    \n\n    \n\n\nAllStarsベストモデルと比較してみましょう。\n\n\n```python\ndepict.metrics(allstars_model, X_train, y_train, X_test, y_test)\n```\n\n![scikitallstars_basic_usage2_28_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/32ba9f9b-2d34-19e9-7917-45fe929d0cf3.png)\n\n    \n\n    \n\n\nスタッキングのベストモデルにおける、各機械学習手法の重要度が次のようにして確認できます。\n\n\n```python\ndepict.model_importances(stacking_model)\n```\n\n![scikitallstars_basic_usage2_30_0.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/211162/c245a550-50b6-b050-009c-394ab71ccb44.png)\n\n    \n\n    \n\n\nスタッキングのベストモデルによる新規予測は次のようにして得られます。\n\n\n```python\nstacking_model.predict(X_test)\n```\n\n\n\n\n    array([1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0,\n           1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n           0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n           1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n           1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n           1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n           1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n           1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n           1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n           1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n           1, 1, 0, 1, 1, 1, 1, 1])\n\n\n# 分類モデル、回帰モデルの切り替え\n\nScikitAllStars では、取り扱う問題が分類なのか回帰なのかという違いをほとんど意識せずに使える設計を心がけています。なぜって？めんどいからです。\n\n上記のコードのうち、データの部分だけを次のように書き換えるだけで、自動的に「回帰問題」だと認識して回帰モデルを全部やっちゃってくれます。他の部分は書き換える必要がありません。\n\n```python\nimport sklearn.datasets\n\n#dataset = sklearn.datasets.load_breast_cancer() # 分類用データ例\ndataset = sklearn.datasets.load_diabetes() # 回帰用データ例\n```\n\n結果は省略。気になる方は、各自試してみてくださいね。\n\n\n# 今後\n\n細かい設定が色々あるんですが、最小限の動作は上記のコードを参考に行えると思います。詳しくは https://github.com/maskot1977/scikitallstars.git のコードを読んでみてください。\n","user":"maskot1977","created_at":"2021-03-29T16:00:23+09:00","updated_at":"2021-03-29T16:00:23+09:00"},{"url":"https://qiita.com/Bkyr79/items/8a0cf62e8562af8707c7","title":"SUBSTRING関数で右端の文字から何文字か抽出したい時","body":"SUBSTRING関数で右端の文字から何文字か抽出したい時\n→LENGTH関数を利用\n\n例えば、\n$hoge=hogehoge@yahoo.co.jpのjpを抽出したい場合は\nSUBSTRING($hoge, LENGTH($hoge)-1, 2)とでとれる\n","user":"Bkyr79","created_at":"2021-03-29T15:58:49+09:00","updated_at":"2021-03-29T15:58:49+09:00"},{"url":"https://qiita.com/ryamamoto0406/items/6c52f7eb2615e2c0d479","title":"Global Forecast System (GFS) のデータ概要","body":"# はじめに\n全球の気象データを提供している NOAA/GFS について、少し調べたので備忘録として記録しておく。専門外の人間が調べた結果を書いているので、もし理解に間違いがあれば是非コメント下さい！\n\n# 予報データの入手先\nこちらのページ([https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs](https://www.ncdc.noaa.gov/data-access/model-data/model-datasets/global-forcast-system-gfs))の中段の「GFS Forecast」からデータをダウンロードできる。モデルは0.5度の分解能のもの（004）と、1度の分解能のもの（003）の二種類がある。表の右側の「Data Access Links」からHTTPS, TDS, AIRS の好きな方法でダウンロードできる。\n\n以下、HTTPS を選択した場合、年月のディレクトリ（YYYYMM/）が表示される。それをクリックすると次は年月日のディレクトリ（YYYYMMDD/）が表示される。それをクリックすると、大量のファイルが表示される。\n\n※因みに「GFS Analysis」は再解析データなので、今回は割愛する。\n\n# ファイル名の意味\nファイル名は\n\n- mode：3=1度の予報データ、4=0.5度の用法データ\n- Y：予報を発表した年\n- M：予報を発表した月\n- D：予報を発表した日\n- h：予報を発表した時\n- m：予報を発表した分\n- f：予報を発表した時刻から何時間後\n\nとすると、命名ルールは、\n\ngfs_mode_YYYYMMDD_hhmm_fff.grb2\n\nとなる。つまり、2021年3月26日の12時に発表した、分解能1度の9時間後の予報データは、\n\ngfs_3_20210329_1200_009.grb2\n\nとなる。予報は6時間ごとに発表され、予報時間は0時間後から384時間後まで3時間ごとにデータがある状況である。因みに、\n\n- 拡張子が.grb2：実際の予報データが格納されているファイル\n- 拡張子が.grb2.inv：予報項目が含まれているヘッダファイル\n\nである。\n\n# データの項目について\n含まれている予報値（データ項目）は、ファイルごとによって変わる。例えば、gfs_3_20210329_1200_009.grb2 の中身を wgrib2 で確認すると、\n\n```bash\n$ wgrib2 gfs_3_20210326_1200_009.grb2\n1:0:d=2021032612:PRMSL:mean sea level:9 hour fcst:\n2:75246:d=2021032612:CLMR:1 hybrid level:9 hour fcst:\n3:86296:d=2021032612:ICMR:1 hybrid level:9 hour fcst:\n---中略---\n741:45317259:d=2021032612:HGT:PV=-2e-06 (Km^2/kg/s) surface:9 hour fcst:\n742:45396668:d=2021032612:PRES:PV=-2e-06 (Km^2/kg/s) surface:9 hour fcst:\n743:45473804:d=2021032612:VWSH:PV=-2e-06 (Km^2/kg/s) surface:9 hour fcst:\n```\n\n743 項目のデータがあることが確認できる。データ項目の意味は、[https://www.nco.ncep.noaa.gov/pmb/products/gfs/](https://www.nco.ncep.noaa.gov/pmb/products/gfs/)の各項目のページに書いてある。例えば、gfs_3_20210329_1200_009.grb2 の場合は、[https://www.nco.ncep.noaa.gov/pmb/products/gfs/gfs.t00z.pgrb2.1p00.f003.shtml](https://www.nco.ncep.noaa.gov/pmb/products/gfs/gfs.t00z.pgrb2.1p00.f003.shtml)に書いてある。\n\n# おわりに\nこれでGFSの予報データから必要な情報を取り出して扱うことができる。今のところ他の記事では地表面の気温（\"TMP:surface\"）しか使用してないが、他の項目（例えば、雲のデータ、降水量、気圧etc...）も調べて使っていきたい。\n","user":"ryamamoto0406","created_at":"2021-03-29T15:57:52+09:00","updated_at":"2021-03-29T15:57:52+09:00"},{"url":"https://qiita.com/yumenomatayume/items/aeb05f34cd8a0749b8c6","title":"Vagrantのゴミを削除する","body":"## ゴミを削除する方法まとめ\n\n1. `vagrant global-status`で、ゴミを確認する\n2. `vagrant global-status —-prune`で、vagrant上のゴミを削除する\n3. `VBoxManage unregistervm ${VM}`で、VMを削除する\n\n## はじめに\n\nVagrantを使っていると、使わなくなったものを放置して、そのままディレクトリを削除してしまうことがよくあります。\n\n`vagrant destroy`を実行してVMを削除しないと、VagrantやVirtualboxの中にゴミが残ってしまいます。\nディレクトリを復活させれば`vagrant destroy`コマンドが実行できるようになりますが、それが出来ない場合はゴミだけを消します。\n\n## 実行環境\n\n- MacOS: 10.15.7\n- Vagrant: 2.2.9\n- virtualbox: 6.1.8\n\nMacにvirtualboxとvagrantを入れて使用しています。詳細環境は以下になります。\n\n```bash\n$ sw_vers\nProductName:\tMac OS X\nProductVersion:\t10.15.7\nBuildVersion:\t19H524\n\n$ vagrant --version\nVagrant 2.2.9\n\n$ VBoxManage --version\n6.1.8r137981\n```\n\n## Vagrantのゴミを削除\n\n`vagrant global-status`コマンドを実行すると、Macにある全てのVagrant VMを確認することが出来ます。これにはゴミも含まれます。\n\n```bash\n$ vagrant global-status\n \nid       name    provider   state    directory                                                    \n--------------------------------------------------------------------------------------------------\nd032dbc  web     virtualbox running  /var/tmp/web/vagrant            # ゴミ\n5186e88  default virtualbox running  /var/tmp/vagrant-centos8-sample # ゴミ\n33fbe44  web     virtualbox poweroff /opt/webserver                  \n\nThe above shows information about all known Vagrant environments\non this machine. This data is cached and may not be completely\nup-to-date (use \"vagrant global-status --prune\" to prune invalid\nentries). To interact with any of the machines, you can go to that\ndirectory and run Vagrant, or you can use the ID directly with\nVagrant commands from any directory. For example:\n\"vagrant destroy 1a2b3c4d\"\n```\n\n`vagrant global-status --prune`を実行すると、ゴミのVM情報が削除されて、vagrantで管理されているVMのみ表示することができます。\n\nこれ以降は既にゴミが削除されているので、—pruneオプションを外してもゴミは表示されません。\n\n```bash\n$ vagrant global-status --prune\n \nid       name    provider   state    directory                                                    \n--------------------------------------------------------------------------------------------------\n33fbe44  web     virtualbox poweroff /opt/webserver                  \n\nThe above shows information about all known Vagrant environments\non this machine. This data is cached and may not be completely\nup-to-date (use \"vagrant global-status --prune\" to prune invalid\nentries). To interact with any of the machines, you can go to that\ndirectory and run Vagrant, or you can use the ID directly with\nVagrant commands from any directory. For example:\n\"vagrant destroy 1a2b3c4d\"\n```\n\nしかし、virtualbox上にあるゴミのVM自体は削除されません。\n\nまた、出力例にある通り`vagrant destroy ${id}`とすることで、指定のディレクトリに移動しなくても1つずつVMを削除することができます。\n\n`vagrant global-status`には出力されなくなりますが、\nそもそもディレクトリが存在しない場合は、以下の様にVM自体削除することが出来ません。\n\n```bash\n$ vagrant destroy 89363d2\nThe working directory for Vagrant doesn't exist! This is the\nspecified working directory:\n```\n\n## virtualboxのゴミを削除\n\n普通にGUIかコマンドから削除すればOKです。\n\nコマンドの場合、`VBoxManage list vms`コマンドでvirtualboxにあるVM一覧が表示されるので、`VboxManage unregistervm ${VM名}`コマンドを実行して削除することができます。\n\n```bash\n$ VBoxManage list vms\n\"webserver_web_1609474127863_21675\" {b7796093-c127-4f5c-b84b-70bc2500c73f}\n\"minikube\" {c2febc29-b21c-44c7-8cd5-4d0738b6a708}\n\"GNS3 VM\" {59b55fc5-3af4-4010-b7a7-7339d767edb3}\n\"trash\" {9a3abb30-524b-4929-8d06-060813521796}\n\n$ VboxManage unregistervm trash\n```\n\n## Reference\n\n- [Vagrantで起動しているVMを一覧する - Qiita](https://qiita.com/ringo/items/e30761b89fb6c9a1c45d)\n- [使ってないVagrant Boxを削除する - Qiita](https://qiita.com/mochizukikotaro/items/52f4434c3f69c4ba1f54)\n- [不要な Vagrant 仮想マシンを削除する (vagrant destroy) | まくまくVagrantノート](https://maku77.github.io/vagrant/destroy-vm.html)\n- [VirtualBoxのよく使うコマンドまとめ - ほたてメモ](http://hotatekun.hatenablog.com/entry/2016/07/11/095218)\n","user":"yumenomatayume","created_at":"2021-03-29T15:55:06+09:00","updated_at":"2021-03-29T15:55:45+09:00"},{"url":"https://qiita.com/arata0520/items/64071b84e3e72fee4ed0","title":"備忘録 - Withステートメント 【VBA】","body":"##目的\n繰り返し記述するオブジェクトをまとめることで、コードの簡素化・高速化を図る\n\n##文法\n全体をWith - End Withで挟み、各処理はドットから文を始める\n\n```vb\nWith オブジェクト\n.プロパティ = 値　（又は .メソッド）\n.プロパティ = 値　（又は .メソッド）\n.プロパティ = 値　（又は .メソッド）\nEnd With\n```\n#実例\nA10セルからA15セルまでの文字のフォントをYu Gothic、文字サイズ15に、太文字に変える処理\n\n```vb\n    Dim TestRange As Range\n    Set TestRange = Range(\"A10:A15\")\n    With MyRange.Font\n        .Name = \"Yu Gothic\"\n        .Size = 15\n        .Bold = True\n    End With\n```\n\n","user":"arata0520","created_at":"2021-03-29T15:53:42+09:00","updated_at":"2021-03-29T15:53:42+09:00"},{"url":"https://qiita.com/hanhnh/items/50a682a8fdb510f3762b","title":"DX とは","body":"テクノロジーの発展現代では、確か「デジタルトランスフォーメーション（DX：Digital transformation）」という言葉をよく聞かれているでしょう。ITの進化にともなって、新たなサービスやビジネスモデルを展開することでコストを削減し、働き方改革や社会そのものの変革につなげる施策を総称したものです。\nしかし、DX以外では、「デジタル化（Digitization）」という定義もよく語られています。デジタルトランスフォーメーションの内容や、日本で定められている定義を見ると、デジタル化とそう変わらないように見えるかもしれません。多くの方がこれらの定義を迷っているでしょう。\nただし、デジタル化とデジタルトランスフォーメーションは、デジタルで行う範囲や考え方が違います。それらの関係を時系列で並べると、デジタル化からデジタルトランスフォーメーションまでの順序です。「デジタル化」は「[デジタルトランスフォーメーション](https://kaopiz.com/ja-news-about-digital-transformation/)」を目標としたときの手段といった関係性です。\n簡単にまとめると、デジタル化は作業や過程であり、デジタルトランスフォーメーションは、社会全体を変えようとする概念です。デジタル化は、デジタルトランスフォーメーションを進める過程の一部であるともいえます。\nこのように、デジタルトランスフォーメーションは、ただデジタル化を進めるだけではありません。 企業や社会全体の考え方を変えるような、大きな変革です。\n","user":"hanhnh","created_at":"2021-03-29T15:53:29+09:00","updated_at":"2021-03-29T15:53:29+09:00"},{"url":"https://qiita.com/kuroitu/items/64ff33944b9486546ccf","title":"CNN高速化シリーズ ~Overlap-Add法とOverlap-Save法~","body":"#概要\n[前回の記事](https://qiita.com/kuroitu/items/fd6843a13843256a07bf)で述べましたが、FCNNの畳み込みは非常にメモリ効率が悪いことが知られています。\nそこでOverlap-Add: OVAまたはOLA: 重畳加算法の導入が提案されました。これによりフィルタサイズと入力サイズとを揃える必要がなくなり、メモリ効率が大幅に向上しました。\nこの手法はもともと信号処理での畳み込み演算に利用されている手法ですが、同じ畳み込み(仮)ですのでCNNにも適用することができます。\n本記事ではそのOVA法と、ついでにOVA法と類似のOverlap-Save: OVSまたはOLS: 重畳保留法について触れています。\n\n何かの役に立てばぜひLGTM、ストック、コメントしていただけると励みになります。\n\n\n#目次\n- [Overlap-Add法](#overlap-add法)\n- [Overlap-Save法](#overlap-save法)\n- [CNNに適用する](#cnnに適用する)\n- [FCNNに適用する](#fcnnに適用する)\n- [おわりに](#おわりに)\n\n\n#Overlap-Add法\nOVerlap-Add: OVA法はもともと信号処理の分野で非常に長い入力信号に対して随時畳み込みをかけることで結果的に高速に全体を畳み込みするための手法です。まずは1次元でのアルゴリズムを見てみましょう。\n入力の長さ$I$、フィルタサイズ$F$とすると\n\n1. 入力をブロック長$F$のブロックに重複なく分割する\n2. フィルタと分割ブロックとを線形畳み込みする\n3. 各ブロックを$F-1$だけ重ねて、重なっている部分を足し算しつつブロックを繋げる\n\nとなります。シンプルですね〜\n実際に図を交えながら詳細に見ていきましょう。\n\n入力を$(x_1, x_2, \\ldots, x_9)$、フィルタを$(w_1, w_2, w_3)$とします。\nまずは入力をフィルタと同サイズのブロックに分割します。\n![ova_block.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/640911/05759a5d-4b8b-2360-28ec-4b1aee7287db.png)\nこの分割それぞれとフィルタとを**線形畳み込み**で畳み込みます。\n![OVA_linear_conv.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/640911/ebb4fe83-b0e4-86c7-f0b6-f93171140a3d.gif)\nこうして計算された出力を、$F-1$だけ重ね合わせて配置し、重なっている部分は足し算することで最終的な出力を得ることができます。\n![OVA_Add.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/640911/e92de885-cb5e-2969-74f4-bacf226571be.png)\nしっかり線形畳み込みの結果になっていますね！\n\n\n#Overlap-Save法\n続いてOverlap-Save: OVS法について紹介します。こちらはちょっとわかりづらい＆あまり解説しているサイトが見当たらなかったので間違っている部分もあるかもしれません...\n\n先ほどと同じように定数を設定します。また、ブロック長を$N$とします。この$N$は任意数です。ただし$N$は入力長$I$の倍数になっている方がパディングする必要もなくていいかもしれません。\n各ブロック$F-1$だけ重ねてブロック長$N$となるように分割します。\n![ovs_block.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/640911/cc5d2e5d-ba3d-a681-8218-a6c5f40d99c9.png)\n続いてこの各ブロックとフィルタとを**循環畳み込み**で畳み込みます。\n![OVS_circle_conv.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/640911/4f5d44e0-0765-4c62-fb9c-34f3dfeb7a97.gif)\nこのように計算された出力の、$F-1$だけ破棄したものを結合することで最終的な出力を得ることができます。\n![OVS_join.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/640911/d211c42d-f752-3b02-7b2f-4ef7f7459614.png)\n\n#CNNに適用する\nここまででOVA法、OVS法の1次元での動作を見てきました。ここからはCNNに適用することを考えます。\nといっても、ただ単に2次元に拡張してあげればOKです。\nまた、色々と調べている中でFCNNにおいてOVS法を使用している例は見つからなかったため、OVA法のみ載せます。\n![OVA_CNN.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/640911/48ed7898-a22f-0b44-83bb-ffb2afe40682.png)\nまあシンプルな線形畳み込みです。CNNでの畳み込みとは微妙に異なりますが、周囲$(F_h-1, F_w-1)$だけカットすればCNNでの畳み込みと同等になりますね。もちろん添字を反転させる必要もあります。詳しくは[前回の記事](https://qiita.com/kuroitu/items/fd6843a13843256a07bf#cnn%E3%81%A7%E3%81%AE%E7%95%B3%E3%81%BF%E8%BE%BC%E3%81%BF)参照。\n\n\n#FCNNに適用する\nさて、Fourier CNNに適用しましょう。どうやって適用するのか、色々な論文などを流し読みしてみたりしましたが、どれもこれも微妙...流し読みしてるせいかもしれませんが笑\nということで自分で色々考えて試しに手計算してみたりしたのですが、結局以下のようにするしかなさそうという結論になりました。\n![OVA_FCNN.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/640911/c05d3696-3519-6b10-5c56-e817fedd5929.png)\n図中のFFT,IFFTは高速フーリエ変換と高速逆フーリエ変換を意味しています。\nまた、流石にきちんと図中に記述するのは無理だったのでフーリエ変換結果などは省略して大文字で表してあります。\nメモ代わりに少しだけ計算式を載せておきます。\n\n```math\nX^{(0)}_{m,n} = \\sum_{k=0}^{F_h-1}{\\sum_{l=0}^{F_w-1}{x_{k,l}e^{i\\frac{2\\pi}{F_h}km}e^{i\\frac{2\\pi}{F_w}ln}}} \\\\\nW_{m,n} = \\sum_{k=0}^{F_h-1}{\\sum_{l=0}^{F_w-1}{w_{k,l}e^{i\\frac{2\\pi}{F_h}km}e^{i\\frac{2\\pi}{F_w}ln}}} \\\\\ny^{(0)}_{m,n} = \\frac{1}{F_h}\\sum_{k=0}^{F_h-1}{\\frac{1}{F_w}\\sum_{l=0}^{F_w-1}{X^{(0)}_{k,l}W_{k,l}e^{-i\\frac{2\\pi}{F_h}km}e^{-i\\frac{2\\pi}{F_w}ln}}}\n```\n\nこのように分割した部分ごとにフーリエ変換→要素積→逆フーリエ変換とした後でOVA法に則って計算していけば、**省メモリを実現しつつ求めたい畳み込み演算結果を得ることができる**わけです。\n\n\n#計算量の比較\n1. ただの線形畳み込み\n2. OVA法を利用した線形畳み込み\n3. 高速フーリエ変換を利用した線形畳み込み\n4. OVA法と高速フーリエ変換を利用した線形畳み込み\n\nについて、それぞれ時間計算量・空間計算量を調べてみます。\nただし、簡略化のために入力、フィルタ、出力の形状は全て正方形であるとします。\n\nなお様々な参考資料を独自解釈して考えているため、間違いがある可能性があります。\nまた、オーダ記法$\\mathcal{O}$はできる限り採用していません。\n\n##1. ただの線形畳み込み\n- 時間計算量：$2O^2F^2$\n- 空間計算量：$I^2+F^2+O^2$\n\nただの線形畳み込みは以下の数式で表すことができます。\n\n```math\ny_{m,n} = \\sum_{k=0}^{F-1}{\\sum_{l=0}^{F-1}{x_{m-k,n-l}w_{k,l}}}\n```\n\nこの部分の時間計算量は$F^2$回の足し算と$F^2$回の掛け算であり、これが出力サイズの回数分だけ実行されるため、$2O^2F^2$が最終的な時間計算量となります。\nストライド1、パディング0の場合なら$O=I-F+1$などと計算できますね。\n空間計算量については、もともとの入力$I^2$と重み$F^2$、出力の$O^2$を足し合わせたものになります。\n\n##2. OVA法を利用した線形畳み込み\n- 時間計算量：$\\frac{I^2}{F^2}-1 + 2(F+1)^2F^2 + 2 \\left( \\frac{I}{F}-1 \\right)O(F-1) + \\frac{1}{2}\\frac{I}{F} \\times \\frac{1}{2}\\frac{I}{F}(F-1)^2$\n- 空間計算量：$I^2+F^2+O^2$\n\nOVA法についての正確な計算量の導出は不明なのですが、とりあえず独自解釈を交えて考えてみます。\n間違っていればご指摘ください。\n\nまず、アルゴリズムを再掲します。\n\n1. 入力をブロック長$F$のブロックに重複なく分割する\n2. 重みと分割ブロックとを線形畳み込みする\n3. 各ブロックを$F-1$だけ重ねて、重なっている部分を足し算しつつブロックを繋げる\n\n一つずつ考えてみましょう。ただし、簡略化のためにパディング不要などの色々といい感じの条件下でのことにします。\n\n1. 入力を分割する回数は$$\\frac{I^2}{F^2}-1回$$生成されるブロックのサイズは$F \\times F$\n2. それぞれを線形畳み込みするのに必要な計算回数は$$2(F+1)^2F^2回$$生成される出力ブロックは$o \\times o$\n3. ブロックの数は$\\frac{I}{F} \\times \\frac{I}{F}$個であり、先の図で言う色の濃い帯は$2 \\times \\left( \\frac{I}{F}-1 \\right)$本、帯の幅が$F-1$となるため、足し算の回数は$$2 \\left( \\frac{I}{F}-1 \\right)O(F-1)回$$ただし、$2\\times2$個のブロックセットにつき$(F-1)(F-1)$回ずつ、数えられていない足し算が存在するので、それら$\\frac{1}{2}\\frac{I}{F} \\times \\frac{1}{2}\\frac{I}{F}(F-1)^2$回も考慮した$$2 \\left( \\frac{I}{F}-1 \\right)O(F-1) + \\frac{1}{2}\\frac{I}{F} \\times \\frac{1}{2}\\frac{I}{F}(F-1)^2回$$\n\nよって、時間計算量はこれら全てを足し合わせた\n\n```math\n\\frac{I^2}{F^2}-1 + 2(F+1)^2F^2 + 2 \\left( \\frac{I}{F}-1 \\right)O(F-1) + \\frac{1}{2}\\frac{I}{F} \\times \\frac{1}{2}\\frac{I}{F}(F-1)^2\n```\n\nとなります。\n空間計算量については、あらかじめ出力サイズ$O \\times O$のメモリを確保しておき、ブロックごとの線形畳み込みによる出力ブロックをこのメモリの該当箇所に足し合わせていく、と考えれば$O^2$となります。\nもちろん入力、重みの空間計算量$I^2$と$F^2$も加算します。\n\n##3. 高速フーリエ変換を利用した線形畳み込み\n- 時間計算量：$2I^2\\log_2I + 2F^2\\log_2F + 2O^2\\log_2O + 6O^2$\n- 空間計算量：$6O^2$\n\n高速フーリエ変換を利用する場合、入力やフィルタを出力サイズに拡張しつつフーリエ変換を行う必要があります。このフーリエ変換に必要な時間計算量は、高速フーリエ変換の場合は入力、重みそれぞれについて$2I^2\\log_2I$と$2F^2\\log_2F$となります。\nそして入力と重みとの要素積を取るのですが、この時の要素積は複素数積であることに注意すると$$(a+bi)(c+di)=ac-bd+i(ad+bc)$$より積4回和1回差1回となり、通常の6倍の演算量であると見なすことができるので、$6O^2$となる。\n最後に出力を逆フーリエ変換する必要があるため、その計算量$2O^2\\log_2O$が加えられます。\n空間計算量については、入力及び重み、出力の3つがそれぞれ$O \\times O$必要で、さらに複素数として保持する必要があるため実数と比較して倍のメモリが必要となり、$6O^2$となります。\n\nちなみに高速フーリエ変換の時間計算量は厳密な計算量の出し方がわからなかったので、厳密なものではなくオーダです。\n\n##4. OVA法と高速フーリエ変換を利用した線形畳み込み\n- 時間計算量：$\\frac{I^2}{F^2}-1 + 2 \\left( \\frac{I^2}{F^2}+1 \\right)F^2\\log_2F + 6\\frac{I^2}{F^2}o^2 + 2\\frac{I^2}{F^2}o^2\\log_2o$\n- 空間計算量：$I^2 + 2 \\left( 1 + \\frac{I^2}{F^2} \\right)o^2 + O^2$\n\nOVA法を利用する場合のアルゴリズムは以下のようになります。\n\n1. 入力をブロック長$F$のブロックに重複なく分割\n2. 各入力ブロックと重みを高速フーリエ変換\n3. 重みと入力ブロックとを要素積\n4. 生成された出力ブロックを逆フーリエ変換\n5. 各ブロックを$F-1$だけ重ねて、重なっている部分を足し算しつつブロックを繋げる\n\n1と5は先の議論から$\\frac{I^2}{F^2}-1$回と$2 \\left( \\frac{I}{F}-1 \\right)O(F-1) + \\frac{1}{2}\\frac{I}{F} \\times \\frac{1}{2}\\frac{I}{F}(F-1)^2$回ですね。それ以外の部分を見ていきます。\n\n2. 各入力ブロックと重みはサイズ$F \\times F$なので、高速フーリエ変換の計算量は$2F^2\\log_2F$であり、全部で$\\frac{I}{F} \\times \\frac{I}{F} + 1$個あるため$$2 \\left( \\frac{I^2}{F^2}+1 \\right)F^2\\log_2F$$となります。また、生成されるブロックサイズを$o \\times o$としておきます\n3. 重みと入力ブロックの要素積に必要な計算回数は、複素数積であることを考慮すると$6o^2$であり、これが$\\frac{I}{F} \\times \\frac{I}{F}$回行われるので$$6\\frac{I^2}{F^2}o^2回$$\n4. 出力ブロックのサイズは$o \\times o$で、それが$\\frac{I}{F} \\times \\frac{I}{F}$個あるため$$2\\frac{I^2}{F^2}o^2\\log_2o$$\n\n以上から、時間計算量は総じて\n\n```math\n\\frac{I^2}{F^2}-1 + 2 \\left( \\frac{I^2}{F^2}+1 \\right)F^2\\log_2F + 6\\frac{I^2}{F^2}o^2 + 2\\frac{I^2}{F^2}o^2\\log_2o\n```\n\nとなります。\n空間計算量については、入力の$I^2$と出力$O^2$はもちろん、重みや入力ブロックごとに$2o^2$必要となります。\n\n\n#おわりに\nGIFアニメーションの手抜きっぷりよ...気が向いたらもう少しマシなの作ります。\n\n\n#CNN高速化シリーズ\n- [CNN高速化シリーズ ~FCNN: Fourier Convolutional Neural Networkの導入~](https://qiita.com/kuroitu/items/fd6843a13843256a07bf)\n","user":"kuroitu","created_at":"2021-03-29T15:46:02+09:00","updated_at":"2021-03-29T15:46:02+09:00"},{"url":"https://qiita.com/mumucochimu/items/b92ddb1de05df92d17ed","title":"コンピュータのメモリについて","body":"コンピュータの成り立ちとか、基礎とか理解できればこれから先どんなことをやるにしても理解が早いのではないかと思い勉強を始めました。\n[キタミ式イラストIT塾 基本情報技術者](https://www.amazon.co.jp/%E3%82%AD%E3%82%BF%E3%83%9F%E5%BC%8F%E3%82%A4%E3%83%A9%E3%82%B9%E3%83%88IT%E5%A1%BE-%E5%9F%BA%E6%9C%AC%E6%83%85%E5%A0%B1%E6%8A%80%E8%A1%93%E8%80%85-%E4%BB%A4%E5%92%8C03%E5%B9%B4-%E3%81%8D%E3%81%9F%E3%81%BF%E3%82%8A%E3%82%85%E3%81%86%E3%81%98/dp/4297117819)で勉強させていただいております。\n\nまとめます！\n\n\n## メモリの分類\n\nメモリには大きく分けてRAMとROMが存在します。\nCPUが命令を実行するためにデータを読み出す際に利用します。\n\n#### RAM\n\nRAMはRamdom Access Memoryの略で、`ランダムに読み書きできるメモリ`のことを言います。\n電源を切ると中身が消える揮発性の性質を持ちます。\n\n以下の2種類があります。\n\n| 名前               | 概要                                                                       |\n|:-----------------:|:---------------------------------------------------------------------------|\n| DRAM(Dynamin RAM) | 主記憶装置に用いられるメモリ。CPUが命令を取り出して記憶しておく装置。定期的なリフレッシュが必要。  |\n| SRAM(Static RAM)  | 小容量のキャッシュメモリとして用いられるメモリ。リフレッシュの必要なし。                        |\n\n\n#### ROM\n\nROMはRead Only Memoryの略で`読み出しだけのメモリ`のことを言います。\n電源を切っても中身が消えない不揮発性の性質を持ちます。\n\nここで私は「読み出しだけということは書き込みできないの？」と疑問に思いました。\n何故ならSDカードなどのメモリはROMという認識で、書き込みできるメモリだから。\n\n本の解説では以下の2種類があるとのことでした。\n\n| 名前                    | 概要                                                                 |\n|:----------------------:|:---------------------------------------------------------------------|\n| マスクROM                | 読み出し専用のメモリ。製造時にデータを書き込み以降は読み出しのみの利用。書き換えは不可。 |\n| PROM(Programmable ROM) | ユーザーの手で書き換えることができるROMでさらに以下の3種類がある。                  |\n\nなるほど。\n私がROMと理解していたのはPROMの方で、元々ROMと言えばマスクROMを指していたということですね。\nマスクROMで分かりやすい例としては家電製品など。\nあらかじめ決まった内容をROMに書き込んでおき、それを読み出してCPUが処理をすると考えれば分かりやすかったです。\n\nさらにPROMは下記のような種類があります。\n\n| 名前                        | 概要                                                          |\n|:--------------------------:|:--------------------------------------------------------------|\n| EPROM(Erasable PROM)       | 紫外線でデータを消去して書き換えることができる。                          |\n| EEPROM(Electrically EPROM) | 電気的にデータを消去して書き換えることができる。                          |\n| フラッシュメモリ(SDカード等)       | EEPROMの一種。全消去ではなくブロック毎にデータを消去して書き換えることができる。 |\n\n\n## キャッシュメモリ\n\nよく聞く`キャッシュ`について。\n私の認識では`一度アクセスした機能はキャッシュとして残しておくことでその機能へのアクセス時に時間や通信量を節約できる`という感じでした。\n\n内容は大体合っているのですが、何故それが必要かというと\n\n`CPUは動作に必要なデータやプログラムをメモリから取り出しているけど、メモリはCPUと比べて処理が遅いのでそれを補うためにキャッシュメモリを配置している`\n\nとのことです。\nCPUがメモリからデータを読み込む際にキャッシュメモリにも同じようにデータを読み込ませておき、\nまた同じデータが必要になったらメモリから読み出しするのではなくキャッシュメモリから読み出すことで動作を早くしているという動きになるということですね。\n\nで、そのキャッシュメモリは1つではなく外部にもキャッシュを置いておくことで容量を大きくできます。その役割をしているのがSRAMです。\n\n以上です。\n","user":"mumucochimu","created_at":"2021-03-29T15:43:55+09:00","updated_at":"2021-03-29T15:43:55+09:00"},{"url":"https://qiita.com/seshat/items/614e74b39a560eb579c1","title":"Ubuntu上でC言語やC#を各種エディタで書いてみる","body":"Linuxは、狭義にはLinuxカーネル、広義にはそれをカーネルとして用いたオペレーティングシステムを指します。LinuxはUnix系オペレーティングシステム (OS) の1つと言えます。\nUbuntuはLinuxディストリビューションの1つです。初心者からベテランまで、幅広く利用されています。\n\n本稿では、C言語やC#のプログラムを各種エディタを用いて作成します。\n\n### 参考URL\nVirtualBox上にUbuntu 20.04をインストールする方法は、以下のリンクが参考になると思います。\n[プログラマーのためのUbuntu](https://daimaohsx.dip.jp/wordpress/2020/04/23/ubuntu4programmer/)\n\n## C言語のコンパイル環境を構築しよう\n\n端末を起動し、以下を実行します。\n\n```bash\nsudo apt update\nsudo apt install build-essential\n```\n\n## geditでC言語を編集してみる\n\ngeditはUbuntu標準のエディタで、初心者向けと言えます。ディスクトップ最上段の「アクティビティ」をクリックし、「ged」と入力してgeditを起動します。\n\n![無題のドキュメント-1-gedit_004.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1185720/c8196414-6603-2ef2-af39-06123bfe6a99.png)\n\n\nまず、geditの下の「なし」をクリックし、メニューから「C」を選択します。そして次のコードを入力します。\n\n```c:sample01.c\n#include <stdlib.h>\nint main()\n{\n  system(\"/bin/cat /etc/lsb-release\");\n}\n```\n\nすると、エディタ上のコードはシンタックスハイライトされて表示されます。\n次に、gedit上部の保存ボタンをクリックし、「sample01.c」として保存します。そして次のコマンドでコンパイルし、実行してみます。\n\n```bash\ngcc -o sample01 sample01.c\n./sample01\n```\n\n下記のように、Ubuntuのバージョン情報が表示されれば成功です。\n\n```bash:実行結果\nDISTRIB_ID=Ubuntu\nDISTRIB_RELEASE=20.04\nDISTRIB_CODENAME=focal\nDISTRIB_DESCRIPTION=”Ubuntu 20.04 LTS”\n```\n\n## C#の編集と実行に挑戦してみる\n\nまず、C#をインストールします。\n\n```bash:C#のインストール\nsudo apt install mono-devel\n```\n\n今度はnanoというエディタを使ってみます。nanoはGUIを持たない、CUIベースのエディタです。リモートログインして作業するなど、GUIが使用できない環境でも使用できる利点があります。\n\n```bash:nanoの起動\nnano sample02.cs\n```\n\n以下のコードを入力します。\n\n```c#:sample02.cs\nusing System;\nusing System.IO;\nusing System.Text;\nclass FileRead1 {\n  static void Main() {\n    StreamReader sr = new StreamReader(\n                      　　　　　　\"/etc/lsb-release\");\n    string text = sr.ReadToEnd();\n    sr.Close();\n    Console.Write(text);\n  }\n}\n```\n\nCtrl+Oで”sample02.cs”という名称でファイルに書き込みます。次にCtrl+Xで終了します。nanoを終了したら、コンパイルします。\n\n```bash:C＃のコンパイル\nmcs sample02.cs\n```\n\nコンパイルが完了すると、”sample02.exe”というファイルが生成されています。”sample02.exe”を実行してみてください。\n\n```bash:sample02の実行\n./sample02.exe\n```\n\n先ほどのC言語のプログラムと同じ、Ubuntuのバージョン情報が出力されます。\n\n## Visual Studio Codeのインストール\n\n最後に、人気のVisual Studio Codeのインストール方法を紹介します。Ubuntu20.04ではsnapを用いてインストールできます。\n\n```bash:VScodeのインストール\nsudo snap install --classic code\ncode\n```\n\n![Welcome-Visual-Studio-Code_005.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1185720/a2563a0f-3762-9747-35ab-a70a0b903fc9.png)\n\n## さいごに\nWindows10の環境であれば、WSL（Windows Subusystem for Linux）のUbuntuから実行するのが手っ取り早いでしょう。\nWSLのUbuntuを構築する方法は、よければ以下のリンクを参考にしてみてください。\n\n[LinuxとWindowsの欲張りな環境を手にする](https://daimaohsx.dip.jp/wordpress/2020/05/10/linux-windows-wsl2-ubuntu2004/)\n","user":"seshat","created_at":"2021-03-29T15:42:03+09:00","updated_at":"2021-03-29T15:42:03+09:00"},{"url":"https://qiita.com/H-Toshi/items/da900322244410f32b79","title":"PHP fopenでファイルを開いて使用する","body":"#fopenの例\n\n##読み込み・追加の処理\n####txt.txt\n\n```\nabcdefg\none,two,three\n12345\nアイウエオ\n```\n\n####fopen.php\n\n```php\n<?php \n//$変数名(ファイルポインタ) = fopen (“開きたいファイル名”, “オープンモード”);\n\n// 読み込みモードでファイルを開く\n$fp = fopen(\"txt.txt\", \"r\");\n\n// ファイルを1行ずつ取得する\nwhile ($line = fgets($fp)) {\n  echo \"$line\";\n}\n\n// ファイルを閉じる\nfclose($fp);\n\n//結果\n/*\nabcdefg\none,two,three\n12345\nアイウエオ\n*/\n\n//追加の記述（末尾に追加される）\n$fa = fopen('txt.txt','a');\nfwrite($fa,\"\\n\".'5行目に追加');\nfclose($fa);\n\n$fr = fopen('txt.txt','r');\nwhile($line = fgets($fr)){\n    echo $line;\n}\n/*\n//結果\n/*\nabcdefg\none,two,three\n12345\nアイウエオ\n5行目に追加\n*/\n```\n\n##上書きの処理\nさらにこの記述の後に以下のコードを実行すると上書きされる。\n\n```php\n$fw = fopen('txt.txt','w');\nfwrite($fw,'上書きして1行になります');\nfclose($fw);\n\n$fr = fopen('txt.txt','r');\nwhile($line = fgets($fr)){\n    echo $line;\n}\nfclose($fr);\n//結果\n//上書きして1行になります\n```\n\n\n\n###fopen()の第二引数について\n以下の用途で指定する\n[参考：phpドキュメント](https://www.php.net/manual/ja/function.fopen.php)\n![スクリーンショット 2021-03-29 15.33.16.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/670884/731d5161-afe2-685a-d976-8ab127667938.png)\n\n\n","user":"H-Toshi","created_at":"2021-03-29T15:37:55+09:00","updated_at":"2021-03-29T16:19:06+09:00"},{"url":"https://qiita.com/IntenF/items/5851fdebfc95c4880181","title":"【pysen README和訳】: あの「Preferred Networks」が作ったpython linter/formatter 管理アプリ「pysen」のREADMEを和訳してみた","body":"github: https://github.com/pfnet/pysen\n\n# はじめに\npysenはpreferred networksが公開するpython用のlinter/formatterの管理用アプリです。\n複数人でコードを作成するとき、ある程度の可読性を確保するためにコーディングの約束を決めるものですが、それを自動的に判定/整形しようというのがlinter/formatterです。しかし、python用のlinter/formatterは複数あり、プロジェクトごとに様々で、linter/formatterの整備自体が形骸化するのが問題でした。そこで、preferred networksではlinter/formatterの管理用アプリを作って統合しようと作ったのが**pysen**です。\n\nただ、preferred networksの[github](https://github.com/pfnet/pysen)のREADME.mdには英語のドキュメントしかなかったので、和訳したのが以下です。（執筆時 2021/03/29）\n\n[参考](https://tech.preferred.jp/ja/blog/pysen-is-the-new-sempai/)\n\n![イメージ](https://github.com/pfnet/pysen/raw/main/assets/imgs/pysen.gif?raw=true)\n\n# pysen って何？\n\n「pysenは日々の開発用のツールを統合すること」を目標に提供されるツールです。\n次のように使うことを想定しています。\n\n- `pysen run lint`, `pysen run format`を実行することで、プロジェクト内のすべてのコードをチェックして、フォーマットする\n- `pyproject.toml`内での数行書くことで標準化用のコードスタイルを定義する\n\npysenは各々のチームが蓄積した知見やコード、特にpythonのlinterについて中央集権的に共有します。実行はsetup.pyと私たちのコマンドラインツールのどちらからでも実行可能です。現在、以下のツールの設定ファイルを管理可能です。\n\n- linter\n    - flake8\n    - isort\n    - mypy\n    - black\n- utility\n    - (2021/03/29現在:予定)protoc\n\n# pysenで「できない」こと\n\n- pysen自体はlinterではありません。`pysen run lint`は複数のpythonのlinterをpysenのより抽象的な設定ファイルに則って自動的に各々のlinterの設定を構築します。\n- pysenはあなたの環境の依存性やパッケージを管理するものではありません。**パッケージマネージャには`pipenv`や`poetry`を使い、pysenが使うツール（isort, mypy, flake8, blackなど)のバージョンを固定することを推奨します**。pysenが対応するバージョンは`setup.py`内の[extra_requires/lint](https://github.com/pfnet/pysen/blob/102a6bd67644faa5ef3f766ea74cc8415988cac3/setup.py#L44)を確認してください。`pip install pysen[lint]`によるlinterのバージョン管理は**非推奨**です。\n- pysenはlintだけに限って作られたものではありません。是非、「[プラグイン](https://github.com/pfnet/pysen/blob/main/README.md#create-a-plugin-to-customize-pysen)」を見て詳細を確認してみてください。\n\n# インストール方法\n[訳注]以下のいずれかを使用してください。ただし、pipは非推奨です。\n\n```bash\n# pip\npip install \"pysen[lint]\"\n# pipenv\npipenv install --dev \"pysen[lint]==0.9.1\"\n# poetry\npoetry add -D pysen==0.9.1 -E lint\n```\n\n# クイックスタート: pysenでのlinterの管理方法\nまずは、あなたのpythonパッケージ内で、以下の設定をpysenの設定ファイル`pyproject.toml`に記入してみてください。\n\n```toml\n[tool.pysen]\nversion = \"0.9\"\n\n[tool.pysen.lint]\nenable_black = true\nenable_flake8 = true\nenable_isort = true\nenable_mypy = true\nmypy_preset = \"strict\"\nline_length = 88\npy_version = \"py37\"\n[[tool.pysen.lint.mypy_targets]]\n  paths = [\".\"]\n```\n次に、次のコマンドを実行します。\n\n```bash\n$ pysen run lint\n$ pysen run format  # ここでformatter(black, isort)を使ったコードの自動修正を試みます\n```\n\nこれでお終りです！\n\npysenは特定のlinter（black, isort, mypy, flake8）の設定ファイルを生成し、適切に実行します。`pyproject.toml`に関して、より詳細を知りたい場合は`pysen/pyproject_model.py`を参照してください。\n\nセットアップ用のコマンドはあなたのpythonのパッケージに追加することも可能です。次のコードを、あなたのパッケージ内の`setup.py`に追記して、実行してみてください。\n\n```python\nimport pysen\nsetup = pysen.setup_from_pyproject(__file__)\n```\n\n```bash\n$ python setup.py lint\n```\nまた、設定をカスタマイズしたり、pysenを拡張するためのPythonインターフェースも提供しています。詳しい内容は以下を参照してください。\n- Pythonを使った設定例：`examples/advanced_example/config.py` [訳注] 3/29現在このファイルは存在しません。おそらく`lint.py`のこと\n- pysenのプラグイン例: `examples/plugin_example/plugin.py`\n\n# どう動いているか？: 設定ファイルのディレクトリ\n水面下では、pysenが動くときはlinterに使われるファイルを一時的に生成しています。もし、このファイルをディスクに取っておきたい場合（例えば、エディタで使いたいときなど）、以下のコマンドを実行して保存先を指定してください。\n\n```bash\n$ pysen generate [保存先ディレクトリ]\n```\n`pysen run`実行時に、pysenの使用する設定ディレクトリを指定することも可能です。次のセクションを`pyproject.toml`に追加してください。\n\n```toml\n[tool.pysen-cli]\nsettings_dir = \"path/to/generate/settings\"\n```\n\n指定したディレクトリが既に設定ファイルを含んでいた場合、pysenはマージします。よって、`settings_dir`を指定しなかった時と異なる挙動になるかもしれません。\n\nこのオプションはpysenのCLIを介して使用する場合のみ適用されることに注意してください。pre-commitやsetuptoolsを使用する場合は、引数に`settings_dir`を指定する必要があります。\n\n# Tips: IDE/テキストエディタ との統合\n[訳注] 私がvimやemacsに明るくないので訳がおかしな箇所があるかもしれません。分かりづらい箇所あれば[原文](https://github.com/pfnet/pysen#tips-ide--text-editor-integration)をお読みください（修正歓迎です)\n## vim\npysenの出力するエラーはクイックフィックスウィンドウに次のコードで加えることができます\n\n`:cex system(\"pysen run_files lint --error-format gnu \".expand('%:p'))`\n\n他にも、pysenを`makeprg`に設定する方法もあります　\n\n`set makeprg=pysen\\ run_files\\ --error-format\\ gnu\\ lint\\ %`\n\nそして、`:make`を実行するとクイックフィックスウィンドウにエラーを表示できます。これは、`:Dispatch`の代わりに`:Make`を呼び出す限り、`vim-dispatch`でも動作します。\n\n実行結果は以下のようになります。\n![vim pysen](https://github.com/pfnet/pysen/raw/main/assets/imgs/pysen_vim.gif?raw=true)\n\n## Emacs\n[Comliation mode](https://www.gnu.org/software/emacs/manual/html_node/emacs/Compilation-Mode.html)を参照してください。\n以下はpythonのフックの例です。\n\n```emacs-lisp\n(add-hook 'python-mode-hook\n    (lambda ()\n        (set (make-local-variable 'compile-command)\n            (concat \"pysen run_files lint --error-format gnu  \" buffer-file-name))))\n```\n\n## VSCode\n[設定例](https://github.com/pfnet/pysen/blob/main/assets/vscode/tasks.json)のjsonを参考にしてみてください。実行すると、PROBLEMSウィンドウに以下のようなエラーが表示されます。\n![vscode エラー](https://github.com/pfnet/pysen/blob/main/assets/imgs/pysen_vscode.jpg?raw=true)\n\n**※注意※**\nVSCodeの拡張機能からflake8のようなlinterを別途導入していた場合、重複してエラーが出力される可能性があります。pysenはすべてのファイルをチェックし時間がかかる可能性があります。よって、大規模なプロジェクトにおいて、ファイルの変更をトリガーにしてpysenを実行することは推奨しておりません。\n\n\n# pysenの設定\n\npysenを設定するための方法は2つあります。\n\n- 1つ目の方法は、`project.toml`の`[tool.pysen.lint]`セクションに書く方法です。この方法は最もシンプルな方法ですが、設定できる事項は限定的です。\n- 2つ目の方法は、pysenを直接設定するpythonのスクリプトを書く方法です。もし、pysenのコマンドライン引数やpysenの挙動、pysenの生成する設定ファイルをカスタマイズしたい場合、この方法を使うことを推奨します。より詳しい例は[`pysen/examples`](https://github.com/pfnet/pysen/tree/main/examples)を参照してください。\n\n## pyproject.toml で設定する場合\n最新のものは`pysen/pyproject_model.py`を参照してください。[訳注]3/29現在、参照先がありませんでした。[`pysen/project.toml`](https://github.com/pfnet/pysen/blob/main/pyproject.toml)を参照すれば良いと思います。\n\n以下は、基本的な設定例になります。\n\n```toml\n[tool.pysen]\nversion = \"0.9\"\n\n[tool.pysen.lint]\nenable_black = true\nenable_flake8 = true\nenable_isort = true\nenable_mypy = true\nmypy_preset = \"strict\"\nline_length = 88\npy_version = \"py37\"\nisort_known_third_party = [\"numpy\"]\nisort_known_first_party = [\"pysen\"]\nmypy_ignore_packages = [\"pysen.generated.*\"]\nmypy_path = [\"stubs\"]\n[[tool.pysen.lint.mypy_targets]]\n  paths = [\".\", \"tests/\"]\n\n[tool.pysen.lint.source]\n  includes = [\".\"]\n  include_globs = [\"**/*.template\"]\n  excludes = [\"third_party/\"]\n  exclude_globs = [\"**/*_grpc.py\"]\n\n[tool.pysen.lint.mypy_modules.\"pysen.scripts\"]\n  preset = \"entry\"\n\n[tool.pysen.lint.mypy_modules.\"numpy\"]\n  ignore_errors = true\n```\n\n## プラグインを設計して、pysenをカスタマイズしよう\n内製のツールや設定ファイルの管理、セットアップ用コマンドなどのためにプラグイン用インターフェースを用意しています。\nより詳しい内容は、[`pysen/examples/plugin_example`](https://github.com/pfnet/pysen/tree/main/examples/plugin_example)を参照してください。\n\n# 開発\n私たちの開発環境を運用したい場合は`pipenv`が必要になります.\n\n- 環境構築\n\n```bash\n# setup your environment\n$ pipenv sync\n# activate the environment\n$ pipenv shell\n```\n\n- `Pipfile.lock`の依存関係の更新\n\n```bash\n$ pipenv lock --pre\n```\n\n- 全テストの実行\n\n```bash\n$ pipenv run tox\n```\n\n# Contributing\npysenの公開レポジトリはPreferred Networksのプライベートレポジトリのミラーです。現在、いかなるプルリクエストも受ける予定はありません。意欲のある開発者様はフォークしてからパッチを適用されることを推奨いたします。\n\nまた、私たちの人的リソースにも限りがあるため、Preferred Networks特有の要求を満たす開発を優先せざるを得ないときがあります。そのため、Issueを当面の間、閉鎖致します。心苦しいことではありますが、すべての質問、トラブルシューティング、feature request、バグレポートはすべて`dev/null`にダイレクトします。\n","user":"IntenF","created_at":"2021-03-29T15:34:13+09:00","updated_at":"2021-03-29T15:34:13+09:00"},{"url":"https://qiita.com/Hkingyo/items/ce1c0cd042ead8cc68e7","title":"更新ファイルのリスト取得","body":"基本的なことだと思いますが、苦労したので、備忘録として書きます。\n間違っているものなどありましたらご指摘いただけますと幸いです。\n\n\nディレクトリ配下の全ファイルの中から、今日更新されたもの、もしくは、今さっき更新されたものの一覧を取得します。\n\n##今日の更新ファイル一覧\n\n\n```\n\nfind ディレクトリ名 -type f -mtime 0 -ls\nls -lrt ディレクトリ名 `find -type f -mtime 0` \n```\n\n##10分以内の更新ファイル一覧\n\n```\n\nfind ディレクトリ名 -type f -mmin -10 -ls\nfind ディレクトリ名 -type f -mmin -10 | xargs -r ls -lrt \n```\n\n時間を変更するときは、-10のところをいじってください。\n\n|-mminの引数|意味|\n|:------:|:------:|\n|-100|　現在から100分以内|\n|+10|　10分より前（10分以内の逆）|\n\n\n##注意点\nディレクトリ名を省略した場合、カレントディレクトリ以下の検索になります。\n一番上の階層でこのコマンドを入力すると、このサーバ、PCで更新されたすべてのファイルリストを取得できます。\n\n-lrtや、-lsは個人的に見やすくするために使用しているだけなので、適宜変更できます。\n\n\n","user":"Hkingyo","created_at":"2021-03-29T15:29:54+09:00","updated_at":"2021-03-29T15:46:11+09:00"},{"url":"https://qiita.com/jc-0527/items/f691bc4255785ba0ca74","title":"javacコマンドでコンパイルするソースファイルを指定する方法（※ソースファイル内に、パッケージ宣言のクラスが参照されている場合）","body":"#概要\nパッケージ宣言のクラスが参照されているソースファイルを\nコンパイルする際にエラーが起き、\nコンパイルが出来なかったので、その時の健忘録である。\n\n```terminal:フォルダ階層\n. #①\n├── logics #②\n│   └── CalcLogic.java #③\n└── main #④\n    └── Calc.java #⑤\n\n```\n\n```java:Calc.java\npackage calcapp.main;\n\npublic class Calc{\n  public static void main(String[] args){\n    int a = 10;\n    int b = 2;\n    int total = calcapp.logics.CalcLogic.tasu(a, b);\n    int delta = calcapp.logics.CalcLogic.hiku(a, b);\n    System.out.println(\"足すと\" + total + \"、引くと\" + delta);\n  }\n}\n```\n\n```java:CalcLogic.java\npackage calcapp.logics; // ⑥\n\npublic class CalcLogic{\n  \n  public static int tasu(int a, int b){\n    return (a + b);\n  }\n  \n  public static int hiku(int a, int b){\n    return (a - b);\n  }\n\n}\n```\n\n④の階層で下記のコマンドを実行。「NG①」\n\n```terminal\njavac Calc.java \n```\n\nしかし、以下のエラーメッセージが表示され、コンパイルできなかった。\n\n```terminal\nCalc.java:7: エラー: パッケージcalcapp.logicsは存在しません\n    int total = calcapp.logics.CalcLogic.tasu(a, b);\n                              ^\nCalc.java:8: エラー: パッケージcalcapp.logicsは存在しません\n    int delta = calcapp.logics.CalcLogic.hiku(a, b);\n                              ^\nエラー2個\n```\n\n\n#解決策\n\njavacコマンドを正しいディレクトリの中で実行する。（階層①で実行する）\n\n```terminal\n# ①のディレクトリで実行\njavac calcapp/main/Calc.java\n```\n\njavacコマンドは、実行したディレクトリ「直下」にあるパスを検索して、\nパッケージ名と同じディレクトリがあれば、それを辿って目的のファイルを見つけるようだ。\nもし、なければ、javacコマンドはコンパイルすべきファイルを見つけることができない。\n\n「NG①」で、パッケージを見つけることができなかった理由としては、\n階層④でjavacコマンドを実行しても、\njavacコマンドは、階層④「直下」にあるパスから、\n「./calcapp/logics」探そうとしていたからである。\n\n\n#備考\nちなみに、今、問題となっているのは、\n**Calc.javaをコンパイルする際に、パッケージが記載されたクラスが使われていた（パッケージが記載されたクラスの記載があった）場合である。**\n（Calc.javaのソースファイルに記載されているパッケージ宣言（※⑥の表記）の事ではない。）\n\nつまり、パッケージとjavaファイルを探す際に、Javacコマンドを実行するディレクトリとパッケージに対応するディレクトリを正常に配置していないと、Javacコマンドが該当ファイルを見つけることができないのである。）\n\n実際、Calc.javaがたとえ、calcapp.mainパッケージに属していたとしても、そのパッケージ内で、パッケージが参照されていなければ、階層④でjavacコマンドを実施しても、正常にクラスファイルが作成される。\nただし、その場合も、javaコマンドを実行する際には、\n同じように、実行ディレクトリ（※Javaコマンドをどのディレクトリで実行するか）と\nパッケージに対応するディレクトリから該当classファイルを見つけていくので、\njavaコマンドを実行するディレクトリと、パッケージに対応するディレクトリの構成を\n正しくしておかなければ、クラスファイルを見つけることができない。（プログラムが起動しない。）\n\n\n\n\n","user":"jc-0527","created_at":"2021-03-29T15:24:49+09:00","updated_at":"2021-03-29T15:24:49+09:00"},{"url":"https://qiita.com/tani__san929/items/f08e8ce7f39c7f8f2b4c","title":"userがadminの新規登録をさせない方法","body":"\n#adminの新規登録を防ぐ\n\n単純にadminの設定をしたままだと、\nroutesを見てもわかる通り、adminの新規会員登録ができてしまいます。\n\nつまり、**管理権限を持たない一般ユーザーでも管理者アカウントを作成できてしまいます。**\nセキュリティーとして問題大です。\n\n\n解決方法としては、下記を実施。\n\n#解決方法\n\n方法は、至って簡単です。\n**adminモデルファイルから:resisterableを削除**\n\n```rb:models/admin\n:registerable, =>  #削除しましょう。\n```\n\n下記が、削除後の記述になります。\n\n```rb:models/admin\nclass Admin < ApplicationRecord\n  # Include default devise modules. Others available are:\n  # :confirmable, :lockable, :timeoutable, :trackable and :omniauthable\n  devise :database_authenticatable,:recoverable, :rememberable, :validatable\nend\n```\n\n\n\n#結果\n\nルーティングからregitrationが消えたと思います。\n\n```rb:terminal\n             Prefix Verb   URI        Pattern                    Controller#Action\n        new_admin_session GET    /admin/sign_in(.:format)        admin/sessions#new\n            admin_session POST   /admin/sign_in(.:format)        admin/sessions#create \n    destroy_admin_session DELETE /admin/sign_out(.:format)       admin/sessions#destroy\n       new_admin_password GET    /admin/password/new(.:format)   admin/passwords#new\n      edit_admin_password GET    /admin/password/edit(.:format)  admin/passwords#edit\n           admin_password PATCH  /admin/password(.:format)       admin/passwords#update\n                          PUT    /admin/password(.:format)       admin/passwords#update\n                          POST   /admin/password(.:format)       admin/passwords#create\n```\n\nあとは、routesからもregitrationsを消しておきましょう。\n特に影響はないと思いますが、不要な記述は削除しておくべきかと思います。\n\n```rb:routes\n  registrations: 'admin/registrations' => #削除しましょう。\n```\n\n下記が、削除後のルーティングになります。\n\n```rb:routes\nRails.application.routes.draw do\n  devise_for :admin, controllers: {\n  sessions:      'admin/sessions',\n  passwords:     'admin/passwords',\n  }\n```\n\n\n\n以上、たにーでした。\n\n#参考文献\n\nhttps://qiita.com/WallyNegima/items/8e7021fa949805de112e\n\nhttps://qiita.com/iguchi1124/items/bb25cf650348f31ea37e\n","user":"tani__san929","created_at":"2021-03-29T15:17:41+09:00","updated_at":"2021-03-29T15:17:41+09:00"},{"url":"https://qiita.com/azumak/items/bbe04d26d1c75050cede","title":"Windows10にLaravel 8.xの環境を構築する","body":"Windows10にLaravel 8.*の環境を作成するにあたっての備忘録です。\nLaravel 7まではcomposerで環境を構築できていましたが、\nLaravel 8~ではDocker上に環境を構築するようです。\nWindows10に環境を作成するにあたっての備忘録。\n\n## Docker Desktopをインストール\nダイアログに従って普通にインストール。\nDocker Desktop\nhttps://www.docker.com/products/docker-desktop\n\n## Windows Subsystem for Linux 2（WSL2）インストール\n以下URLの「Manual Installation Steps」を参考に。\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10\n\n#### PowerShellを管理者権限で起動\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/147857/c5431477-5209-254e-3416-d7ac693dcb66.png)\n\n#### Windows SubsystemforLinuxオプション機能の有効化\nWindowsでLinuxサブシステムを使えるようにするための設定。\nPowerShell上で次のコマンドを実行し、マシンを再起動する。\n\n```\ndism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n```\n#### 仮想マシン機能の有効化\n仮想マシン利用を有効にするための設定。\nPowerShellで次のコマンドを実行し、マシンを再起動。\n\n```\ndism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n```\n\n#### WSL2 Linuxカーネルアップデートパッケージをダウンロード\nリンク先の「WSL2 Linux kernel update package for x64 machines」から\nダウンロードしてインストール。\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10\n\n#### WSL2をデフォルトバージョンとして設定\nこれからインストールするLinuxサブシステムで、WSL2をデフォルトとして使用するための設定。\nPowerShell上で次のコマンドを実行。\n```\nwsl --set-default-version 2 \n```\n## Linuxサブシステムのインストールと設定\n\n#### サブシステムのインストール\n\nWindows上で動作するLinuxサブシステムをインストールする。\n色々あるが、今回は深く考えずにKali-linuxをインストールした。\n\n[MicrosoftStore](https://aka.ms/wslstore)から、\n各Linuxサブシステムをダウンロード＆インストール。\n各サブシステムへのリンクは下記リンクの「Step 6 - Install your Linux distribution of choice」参照。\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10\n\n#### サブシステムのユーザー、パスワードを設定\nサブシステムをインストールし、初回起動すると\nユーザー名とパスワードの設定を求められるので、設定する。\n\n以上でWindows上にLinuxサブシステムがセットアップされる。\n\nPowerShell上から次のコマンドを打ってみて、エラーなどが出なければ正しくセットアップされているはず。\n\nLinuxサブシステムに割り当てられているWSLの確認\n\n```\nwsl --list --verbose\n```\n\n## Docker Desktopの設定\nDockerがWSL2をベースに動き、またインストールしたLinuxサブシステムを認識するための設定。\n\nDocker Desktopを起動し、メニューバーの「Settings」（歯車のアイコン）をクリック。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/147857/b4235381-b676-e767-022d-6ad136b9c0a0.png)\n\n左メニューの「General」が選択された状態で、\n「Use the WSL 2 based engine」が有効になっていることを確認。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/147857/166ba941-bd3b-1b58-b638-78f66f0ce4e8.png)\n\n左メニューの「Resources」→「WSL INTEGRATION」で、\nインストールしたLinuxサブシステムにチェックを入れ（自分の場合はkaki-linuxです）、\nApply ＆ RestartをクリックしてDockerを再起動。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/147857/eb213928-f87d-9dc5-30c0-d9b1c279cebe.png)\n\nPowerShellでLinuxサブシステムを起動する。\n自分の場合はkali-linuxの起動コマンド「kali」。\n\n```\nPS C:\\Users\\azumak> kali\n```\n\n起動したLinuxサブシステム上で、「docker -v」などと打ってみて\nDockerを認識しているか確認する。\n\n## Laravelインストール\nLinuxサブシステム上で、以下コマンドを実行してLaravel最新版をインストールする。\n\n```\n sudo curl -s https://laravel.build/<プロジェクト名>| bash\n```\n\nここで、「Docker is not running」と表示されて先に進まないようであれば、\nDockerが起動していないか、LinuxサブシステムがDockerを認識していない・・・かも。\n自分の場合はDockerとkali-linuxの関連付けができていなかった。\n\nうまくいけば、指定したフォルダにLaravel最新版がインストールされる。\n\n#### Laravel Sail起動\nインストールが成功すると指定したフォルダにLaravelプロジェクトが作成されるので、\nプロジェクトフォルダに移動してSailコマンドを実行する。\n\n```\ncd <プロジェクト名>\n./vendor/bin/sail up\n```\n\n初回はとても時間がかかる。\nbuild成功のログが出たらhttp://localhostにアクセスし、\nLaravelのTOページが表示されれば成功！\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/147857/847ceecd-62ec-8a2a-748b-65de8501be2b.png)\n\n## 参考\nhttps://readouble.com/laravel/8.x/ja/installation.html\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","user":"azumak","created_at":"2021-03-29T15:13:19+09:00","updated_at":"2021-03-29T15:13:19+09:00"},{"url":"https://qiita.com/kahirokunn/items/bad36409e13dbb757cf1","title":"自分用メモ Lambdaやクロージャの実態","body":"lambdaやクロージャは静的型付け言語では基本糖衣構文的な実装になっていて(コンパイラの実装次第)、インタプリタ言語では関数オブジェクトがプリミティブで用意されている場合だと都度生成になっている感じぽい\n\n参考文献\nhttps://t.co/ttU8TxuFCs?amp=1\nhttps://koturn.hatenablog.com/entry/2013/08/06/223805\nhttps://gist.github.com/koturn/5013105\n","user":"kahirokunn","created_at":"2021-03-29T15:10:12+09:00","updated_at":"2021-03-29T15:10:12+09:00"},{"url":"https://qiita.com/ozk009/items/86c9a20842efeb50e2f6","title":"WordPressの引っ越し（CentOS7→Amazon Linux 2）","body":"# 概要\n<font color='red'>個人の備忘録メインのため、不備が多いかと思います。よろしければご指摘ください。</font>\nこれまで自宅サーバー（CentOS7）でWordPressのブログを運営してきましたが、EC2に引っ越ししてみます。\nついでにWebサーバーをApacheからNginxに変更してみます（ただの興味）。\n\n# EC2\nインスタンスの起動、Elastic IPの割り当て、セキュリティグループ設定は割愛します。\n\n## 初期設定\n基本、ルート権限で作業します。\n\n```\n$ sudo -s\n```\n\n### 1. ホスト名の変更\n\n```\n# vi /etc/hostname\n```\n### 2. タイムゾーンの設定\n\n```\n# rm -f /etc/localtime; ln -sf /usr/share/zoneinfo/Japan /etc/localtime\n# vi /etc/sysconfig/clock\nZONE=\"UTC\"のUTCをAsia/Tokyoに変更\n```\n\n### 3. 日本語対応\n\n```\n# vi /etc/sysconfig/i18n\nLANG=en_US.UTF-8のen_US.UTF-8をja_JP.UTF-8に変更\n# source /etc/sysconfig/i18n\n```\n\n### 4. 再起動\n\n```\n# reboot\n```\n\n参考URL\nhttps://qiita.com/2no553/items/e166c00790c3397acf2d\nhttp://mktktmr.hatenablog.jp/entry/2016/12/07/154736\n\n## Nginx、PHPインストール\n\n```\n# amazon-linux-extras\n…\n 38  nginx1                   available    [ =stable ]\n…\n 42  php7.4                   available    [ =stable ]\n…\n# amazon-linux-extras install nginx1 php7.4\n…\n# systemctl start nginx\n# systemctl enable nginx\n…\n# yum install php-mbstring\n```\n\n## MariaDBインストール\n### 1. yumでインストール\n\n```\n# yum install mariadb-server\n```\n\n### 2. 文字コード設定\n```\n# vi /etc/my.cnf.d/server.cnf\n…\n[mysqld]\ncharacter-set-server = utf8 ← 追記\n…\n```\n\n### 3. 起動\n```\n# systemctl start mariadb\n# systemctl enable mariadb\n```\n\n### 4. 初期設定\n```\n# mysql_secure_installation\n…\nEnter current password for root (enter for none): ← 空Enter\n…\nSet root password? [Y/n] ← 空Enter\nNew password: ← rootパスワード\nRe-enter new password: ← rootパスワード\n…\nRemove anonymous users? [Y/n] ← 空Enter\n…\nDisallow root login remotely? [Y/n] ← 空Enter\n…\nRemove test database and access to it? [Y/n] ← 空Enter\n…\nReload privilege tables now? [Y/n] ← 空Enter\n…\n```\n\n参考URL\nhttps://centossrv.com/mariadb.shtml\n\n# WordPress用の設定\n## MariaDB\n以下の設定とする。\nデータベース名：wordpress\nユーザー名：wordpress\n\n```\n# mysql -u root -p\n> create database wordpress;\n> grant all privileges on wordpress.* to wordpress@localhost identified by '(任意のパスワード)';\n```\n\n## PHP-FPM\n```\n# vi /etc/php-fpm.d/www.conf\n…\nuser = nginx ← apacheから変更\ngroup = nginx ← 〃\n…\n# systemctl restart php-fpm\n# systemctl enable php-fpm\n```\n\n# 旧サーバーからのデータ移動\n## 1. 旧サーバー処理\n旧サーバーのディレクトリは以下にある。\n/var/www/wordpress\n\n```\n### WordPress ###\n# cd /var/www\n# tar cvf wordpress.tar.gz wordpress\n# mv wordpress.tar.gz （ユーザーのホームディレクトリ）\n\n### MariaDB ###\n# mysqldump wordpress -u wordpress -p > dump.sql\n```\n\n## 2. 新サーバー処理\n新サーバーのディレクトリは以下にする。\n/usr/share/nginx/html/blog\n\n```\n### データコピー ###\n# sftp （ユーザー名）@（旧サーバーのアドレス）\n> get wordpress.tar.gz\n> get dump.sql\n> quit\n\n### WordPress ###\n# tar zxvf wordpress.tar.gz\n# mv wordpress /usr/share/nginx/html/blog\n# chown -R nginx. /usr/share/nginx/html/blog\n\n### MariaDB ###\n# mysql -u wordpress -p -D wordpress < dump.sql\n```\n\n# HTTPS対応\n## Let's Encrypt導入\n```\n# amazon-linux-extras install epel\n# yum install certbot-nginx\n# certbot --nginx\n…\nEnter email address (used for urgent renewal and security notices)\n (Enter 'c' to cancel): ← メールアドレスを入力してEnter\n…\n(Y)es/(N)o: ← 1回目ライセンス関連：Yを入力してEnter\n…\n(Y)es/(N)o: ← 2回目メールアドレスの共有：YかNを入力してEnter\n…\nname(s) (comma and/or space separated)  (Enter 'c' to cancel): fugiters.net ← ホスト名を入力してEnter\n…\n```\n\n参考URL\nhttps://qiita.com/ntm718/items/37d1d0a7de2d1edb4e7c\n\n## Nginx設定\n設定ファイル（/etc/nginx/nginx.conf）の「Settings for a TLS enabled server.」の下の設定をコメントを外し、\n\n```\n# vi /etc/nginx/nginx.conf\n…\n    server {\n        listen       443 ssl http2;\n        listen       [::]:443 ssl http2;\n        server_name  fugiters.net; ← ホスト名\n        root         /usr/share/nginx/html;\n\n        ssl_certificate \"/etc/letsencrypt/live/fugiters.net/cert.pem\"; ← 証明書\n        ssl_certificate_key \"/etc/letsencrypt/live/fugiters.net/privkey.pem\"; ← 秘密鍵\n        ssl_session_cache shared:SSL:1m;\n        ssl_session_timeout  10m;\n#        ssl_ciphers PROFILE=SYSTEM; ← 不明\n        ssl_prefer_server_ciphers on;\n\n        # Load configuration files for the default server block.\n        include /etc/nginx/default.d/*.conf; ← これが無いとPHP動かず（ここでハマった）\n\n        error_page 404 /404.html;\n            location = /40x.html {\n        }\n\n        error_page 500 502 503 504 /50x.html;\n            location = /50x.html {\n        }\n    }\n…\n# systemctl restart nginx\n```\n\n# 参考URL\nhttps://ja.wordpress.org/support/article/nginx/\nhttps://note.com/hiroki_hachisuka/n/nc1d5342c3a9b\n","user":"ozk009","created_at":"2021-03-29T15:05:54+09:00","updated_at":"2021-03-29T15:05:54+09:00"},{"url":"https://qiita.com/sho_yamamoto/items/19bee257e86ff55590e8","title":"railsのfile_fieldにおける画像アップロードボタンのデザインの変更方法","body":"#環境\nruby 2.6.5\nrails 6.0.0\n\n#やりたいこと\n画像をアップロードする際に，アイコンをクリックするとファイル選択に移るようにしたい\n\n#実装\n```ruby\n<%= f.label :image, class: \"far fa-image\" do %>\n  <%= f.file_field :image, style:\"display:none;\" %>\n<% end %>\n```\n\n上記のコードを任意のforループの中に挿入する．このときid値は同様のものにしておく必要がある．\n\n#あとがき\nlabelについての理解が浅いことがわかって良かったです．\n\n#参考文献\n[railsのfile_fieldで画像クリックによりアップロード](\"https://qiita.com/zukakosan/items/41ed95fea2323cf458a9\")\n[Railsのfile_fieldで画像クリックでアップロードしてプレビューを差し替える](\"https://qiita.com/hirogw/items/b4937dbb0ea5f0b60085\")\n","user":"sho_yamamoto","created_at":"2021-03-29T15:04:57+09:00","updated_at":"2021-03-29T15:04:57+09:00"},{"url":"https://qiita.com/rasukaru1006/items/8a5bd12c136fe634a680","title":"AWSで「●●ができないんですが！」って言われたときに気にするところ","body":"良く障害調査とか起きた時に\n”この辺怪しいな”って経験則に基づくアレ、あるじゃないですか\n備忘(まあ忘れないけど)のために書いておこうかなと。\n\n  \n## なんかわからないけど「つながりません！」って言われる\n1. SG\n1. ネットワークACL\n1. ルートテーブル  \n1. 接続先のインスタンスが起動してない\n\nだいたいこの辺。ほとんど1。\n\nその次に多いのが4。\nいつも動いてる時間に止まってたりすると…仕方ない。\n\n\n\n## 「S3にアクセスできません！」って言われる\n1. そもそもSG\n1. IAMポリシー\n1. S3のバケットポリシー\n\nVPC エンドポイントがS3とDynamoDBはGatewayタイプなので\n443のpl-XXXXみたいなのを追加しなきゃいけない。\n（私もたまに忘れます。）\n\n2と3に関しても誤記載はよく耳にします。\ns3://test-bucket/\"\\*\"　　最後の\"\\*\"忘れはよく聞く。\n\n\n\n\n\n## あとはのちのち編集します\n\n","user":"rasukaru1006","created_at":"2021-03-29T15:03:04+09:00","updated_at":"2021-03-29T15:03:04+09:00"},{"url":"https://qiita.com/taka_yayoi/items/8ce4f36a155317318fa1","title":"Databricksにおけるディザスターリカバリー","body":"[Disaster recovery — Databricks Documentation](https://docs.databricks.com/administration-guide/disaster-recovery.html)の翻訳(2021/3/17時点)です。\n\nDatabricksにようなクラウドネイティブのデータ分析プラットフォームにおいては、明確なディザスターリカバリーパターンは重要となります。ハリケーン、地震などによって地域レベルの災害が起きた結果、地域レベルでのクラウドサービスの停止が仮に起きたとしても、いくつかの企業においては、データチームがDatabricksを使い続けられるようにすることは重要となります。\n\nDatabricksが、上流のデータ投入サービス(バッチ、ストリーミング)、AWS S3のようなクラウドネイティブストレージ、下流のインテリジェンスアプリケーションなのどのツール、サービス、そしてオーケストレーションツールを含む多数のサービスのエコシステムのコアとなることはよくあることです。いくつかのユースケースにおいては、地域レベルの障害に対して特に敏感になるかもしれません。\n\n本書では、Databricks統合分析プラットフォームにおけるディザスターリカバリーの概念とベストプラクティスを説明します。組織によって状況は異なりますので、ご自身のソリューションをデプロイする際に疑問があれば、Databricks担当者にお問い合わせください。\n\n# ディザスターリカバリー概論\n\nディザスターリカバリーには、自然災害あるいは人為的な災害に対して、重要なインフラストラクチャ、システムの継続及び復旧を可能とする一連のポリシー、ツール、手順が含まれます。多数の顧客にサービスを提供しているAWSのような大規模なクラウドサービスは、単一の障害に対するビルトインの防御策を講じています。例えば、単一の電源の障害が地域全体に波及しないように、地域にあるそれぞれの建物は異なる電源に接続されています。しかし、クラウドの地域レベルの障害は起こり得るものですし、障害の規模及び組織への影響度合いは組織によって異なります。\n\nディザスターリカバリープランを実装する前に、[ディザスターリカバリー](https://en.wikipedia.org/wiki/Disaster_recovery)(DR)と[高可用性](https://en.wikipedia.org/wiki/High_availability)(HA)を理解することが重要です。\n\n高可用性はシステムの回復特性です。高可用性は、一貫性のある稼働時間あるいは稼働時間の割合によって定義される稼働パフォーマンスの最低限のレベルを定めるものです。高可用性は主系システムの機能として設計され(主系システムと同じ地域に)実装されるものです。例えば、AWSのようなクラウドサービスは、AWS S3のような高可用性サービスを持っています。高可用性はDatabricksのユーザーに対して特別な準備を求めません。\n\n一方、ディザスターリカバリープランは、重要なシステムの地域レベルの障害に対応するために、それぞれの組織に対してソリューション及び意思決定を求めるものです。本書では、一般的なディザスターリカバリーに関する用語、一般的なソリューション、Databricksにおけるディザスターリカバリープランのベストプラクティスを説明します。\n\n# 用語\n\n## 地域に関する用語\n\n本書では地域に関する以下の用語を用います：\n\n- **プライマリリージョン：** 典型的な日々のインタラクティブ、自動化データ分析作業を行うリージョン\n- **セカンダリリージョン:** プライマリリージョンでの障害の期間一時的にデータ分析作業を行うリージョン\n\n## デプロイメント(配備)ステータスに関する用語\n\n本書ではデプロイメントステータスに関する以下の用語を用います：\n\n- **アクティブデプロイメント:** ユーザーはDatabricksワークスペースのアクティブデプロイメントに接続し、作業を行うことができます。Databricksのスケジューラや他の機構を用いてジョブが定期的に実行されます。このデプロイメントでは、データのストリーミングも実行できます。いくつかの文書ではホットデプロイメントとも呼ばれます。\n- **パッシブデプロイメント:** パッシブデプロイメントではプロセスは実行されません。ITチームは、コード、設定などのDatabricksのオブジェクトを、パッシブデプロイメントに自動的にデプロイするように設定することができます。アクティブデプロイメントがダウンした時にのみ、パッシブデプロイメントはアクティブになります。いくつかの文書ではコールドデプロイメントとも呼ばれます。\n\n> **重要!**\nプロジェクトによっては、リージョンでの障害に対してさらなる選択肢を加えるために、異なるリージョンに複数のパッシブデプロイメントを持つこともあります。\n\n一般的には単一のアクティブデプロイメントを持ち、これはディザスターリカバリー戦略において[アクティブ・パッシブ](#アクティブパッシブソリューション戦略)デプロイメントと呼ばれます。同時に二つのアクティブデプロイメントが存在する[アクティブ・アクティブ](#アクティブアクティブソリューション戦略)デプロイメントもありますが、あまり一般的ではありません。\n\n## ディザスターリカバリー分野における用語\n\nディザスターリカバリーにおいては、理解すべき二つの用語があります。\n\n- **リカバリーポイント目標:** [目標リカバリーポイント(RPO)](https://en.wikipedia.org/wiki/Disaster_recovery#Recovery_Point_Objective)は、ITサービスが重大な障害によってデータ(トランザクション)が喪失する最長の目標期間となります。あなたのDatabricksデプロイメントは主要な顧客情報を格納しません。顧客情報は、AWS S3のようにあなたの制御下にある別のシステムに格納されます。Databricksのコントロールプレーンはジョブやノートブックなどのオブジェクトを格納します。DatabricksにおけるRPOは、最大でどのくらいの期間のジョブ、ノートブックの変更が失われるのかということになります。加えて、AWS S3などあなたの制御下にあるデータソースにある顧客データのRPOを定義するのはあなたの責任となります。\n- **リカバリータイム目標：** [目標リカバリータイム(RTO)](https://en.wikipedia.org/wiki/Disaster_recovery#Recovery_Time_Objective)は、災害からビジネスプロセスが復旧するまでの時間とサービスレベルの目標値となります。\n  ![](https://docs.databricks.com/_images/disaster-recovery-rpo-rto.png)\n\n## ディザスターリカバリーとデータ破損\n\nDatabricksのディザスターリカバリーシナリオは以下のようになります：\n\n1. プライマリーリージョンで重要なサービスに障害が発生します。これは、データソースのサービスかもしれませんし、Databricksデプロイメントに影響を与えるネットワークかもしれません。\n1. あなたはクラウドプロバイダーとともに調査を行います。\n1. プライマリーリージョンでの復旧を待てないとあなたの組織が判断した場合には、セカンダリリージョンへのフェイルオーバーを決断します。\n1. セカンダリーリージョンで同様の問題が起きていないことを検証します。\n1. セカンダリーリージョンにフェイルオーバーします。\n    1. ワークスペースでの活動を全て停止します。ユーザーも作業を止めます。可能であれば管理者は最近の変更のバックアップを取ります。障害によりジョブが止まっていない場合にはそれらを停止します。\n    1. セカンダリーリージョンでのリカバリー手順を開始します。リカバリー手順においては、セカンダリーリージョンへのネットワークトラフィック、接続名、ルーティングをアップデートします。\n    1. テストの後、セカンダリーリージョンの稼働を宣言します。プロダクションのワークロードを再開します。ユーザーはアクティブデプロイメントにログインできます。予定されていた、あるいは遅延したジョブを再実行します。\n1. Databricksにおける詳細な手順に関しては、[フェイルオーバーのテスト](#フェイルオーバーのテスト)を参照ください。\n1. ある時点で、プライマリーリージョンの問題が解決されたことを確認します。\n1. プライマリーリージョンに復帰(フェイルバック)します。\n    1. セカンダリーリージョンでの全ての作業を止めます。\n    1. プライマリリージョンでのリカバリー手順をスタートします。リカバリー手順においては、プライマリーリージョンへのネットワークトラフィック、接続名、ルーティングをアップデートします。\n    1. 必要であればプライマリーリージョンにデータをコピーします。複雑にしないためには、コピーするデータを最小限にしたほうがいいかもしれません。例えば、あるジョブがセカンダリーリージョンで読み取りしか行わなかったのであれば、それらをプライマリーリージョンにコピーする必要はないかもしれません。しかし、プライマリーリージョンにデータをコピーして実行するプロダクションのジョブもあるかもしれません。\n    1. プライマリーリージョンでテストを行います。\n    1. プライマリーリージョンがアクティブデプロイメントであり稼働状態になったことを宣言します。プロダクションワークロードを再開します。\n1. 詳細な手順に関しては、[復旧(フェイルバック)のテスト](#復旧フェイルバックのテスト)を参照ください。\n\n> **重要!**\nこれらのステップにおいてはいくつかのデータ損失が起こりえます。あなたの組織では、どの程度のデータ損失を許容できるのか、データ損失をどのように防ぐのかを定義する必要があります。\n\n# ステップ1: ビジネス要件を理解する\n\n最初に行うことはビジネス要件を理解し定義することです。どのデータサービスが重要で、期待すべき[RPOとRTO](https://en.wikipedia.org/wiki/Disaster_recovery#Recovery_Point_Objective)が何であるかを定義します。\n\n個々のシステムに対してどの程度許容できるのかを実例を調査します。フェイルオーバー、フェイルバックにはコストを要し、他のリスクも含むことを理解する必要があります。他のリスクとしては、データ破損、誤ったストレージロケーションに書き込むことによるデータ重複、誤ったワークスペースにログインしてしまい変更を加えてしまう、などが挙げられます。\n\nビジネスに影響を及ぼすDatabricksのコンポーネントを全てマッピングします：\n\n- あなたのディザスターリカバリーソリューションは、インタラクティブなプロセス、あるいは自動化プロセスと調整を行う必要がありますか？\n- どのサービスを使用していますか？いくつかはオンプレミスかもしれません。\n- 入力データはどのようにクラウドに投入されますか？\n- 誰がデータを使用しますか？下流のどのプロセスがデータを使用しますか？\n- ディザスターリカバリーの変更に留意すべきサードパーティサービスは存在しますか？\n\nディザスターリカバリープランをサポートするコミュニケーション、ツールに対する戦略を決定します：\n\n- 迅速にネットワーク設定を変更するためにどのようなツールを使いますか？\n- ディザスターリカバリーソリューションが自然かつ維持可能な形で、設定を事前定義し、モジュール化することができますか？\n- ディザスターリカバリーにおけるフェイルオーバー、フェイルバックの変更を、どのようなコミュニケーションツール、チャネルを用いて内部チーム、サードパーティに通知しますか？\n- どのようなツール、特別なサポートが必要になりますか？\n- 完全に復旧するまでにシャットダウンするサービスは存在しますか？\n\n# ステップ2: ビジネス要件に合致するプロセスを選択する\n\nあなたのソリューションは両方のコントロールプレーン、データプレーン、データソースにあるデータを正しく複製しなくてはなりません。異なるリージョンにある異なるコントロールプレーンに対して、ディザスターリカバリーのために冗長化されたワークスペースをマッピングする必要があります。[同期ツールあるいはCI/CDワークフロー](#ツールの選択)による、スクリプトベースのソリューションを用いて定期的にデータを同期する必要があります。\n\nカスタマーマネージドVPCを使用しているのであれば、[Terraform](https://docs.databricks.com/dev-tools/terraform/index.html)のようなテンプレートベースのツールを用いて、両方のリージョンのネットワークに一貫性を持ってデプロイを行うことができます。\n\n加えて、あなたはデータソースが両方のリージョンで複製されていることを確認する必要があります。\n![](https://docs.databricks.com/_images/disaster-recovery-what-to-replicate-aws.png)\n\n## 一般的なベストプラクティス\n\nディザスターリカバリープランにおける一般的なディザスターリカバリープランには以下が含まれます：\n\n1. どのプロセスがビジネスにおいて重要で、ディザスターリカバリーにおいても実行すべきであるのかを理解します。\n1. どのサービスが必要で、どのデータが処理され、どのデータフローが必要で、どこに格納されるのかを明確にします。\n1. 可能な限りサービスとデータを分離します。例えば、ディザスターリカバリー専用のクラウドストレージを作成し、災害時にDatabricksオブジェクトを移動します。\n1. Databricksコントロールプレーンに格納されない他のオブジェクトについては、あなたがプライマリー、セカンダリーで整合性が保たれていることに対して責任を持つ必要があります。\n1. データソースに対しては、可能であれば、ディザスターリカバリーリージョンにデータを複製するネイティブのAWSツールを使うことをお勧めします。\n\n> **警告!**\nワークスペースのDBFSルートとして使われているAWS S3にデータを格納しないのがベストプラクティスとなります。DBFSルートのストレージはプロダクションの顧客データをサポートしていません。しかし、ライブラリ、設定ファイル、initスクリプトなどのデータを格納しても構いません。これらのオブジェクトを複製するプロセスを自動化するか、セカンダリーデプロイメントに手動で複製する手順を確立します。\n\n## リカバリーソリューション戦略を選択します\n\n典型的なディザスターリカバリーソリューションは二つ(あるいはそれ以上)のワークスペースを内包します。選べる戦略はいくつかあります。潜在的な障害の期間(数時間あるいは１日)、ワークスペースが完全に復旧するのに必要な作業、プライマリーリージョンに復旧(フェイルバック)する作業を検討します。\n\n### アクティブ・パッシブソリューション戦略\n\nアクティブ・パッシブソリューションは最も一般的で容易なソリューションであり、本書がフォーカスしているものです。アクティブ・パッシブソリューションは、アクティブデプロイメントからパッシブデプロイメントにデータとオブジェクトの変更を同期します。必要であれば、異なるリージョンで複数のパッシブデプロイメントを持つことも可能です。ディザスターリカバリーの際には、セカンダリーリージョンでのパッシブデプロイメントがアクティブデプロイメントとなります。\n\nこの戦略には二つの派生形があります：\n\n- 統合(企業規模)ソリューション: 組織全体をサポートするアクティブ・パッシブのセットを一つ持ちます。\n- プロジェクト、部署ごとのソリューション: それぞれの部署、プロジェクトが分離したディザスターリカバリーのソリューションを持ちます。いくつかの組織においては、部門ごとに異なるディザスターリカバリーの詳細手順を持ち、それぞれのチームの要求に応じたプライマリー、セカンダリーリージョンを持ちたいケースがあります。\n\nパッシブデプロイメントを読み取り専用にするような他の派生形もあります。\nクエリなどワークロードが読み取りのみである場合、それらがノートブックやジョブなどのDatabricksオブジェクトを更新しないのであればパッシブソリューションを常に稼働させることができます。\n\n### アクティブ・アクティブソリューション戦略\n\nアクティブ・アクティブソリューションにおいては、常に全てのデータプロセスを両方のリージョンで並行で動作させます。あなたの組織のオペレーションチームは、両方のリージョンで処理が成功した場合にのみ、ジョブのようなプロセスが完了とマークされることを保証する必要があります。プロダクションにあるオブジェクトは更新されず、必ずデベロップメント・ステージングからプロダクションへの厳密なCI/CDプロモーションに従う必要があります。\n\n両方のリージョンでジョブが実行されるため、アクティブ・アクティブソリューションは最も複雑な戦略であり、追加のコストも発生します。\n\nアクティブ・パッシブ戦略と同様に、企業全体のソリューションあるいは部署単位のソリューションとして実装できます。\n\nワークフローによっては、全てのワークスペースがセカンダリーのシステムに複製される必要がないかもしれません。例えば、デベロップメント、ステージングのワークスペースは複製の必要がないかもしれません。適切に設計された開発パイプラインがあれば、必要に応じてこれらのワークスペースを容易に再構築できる場合があります。\n\n## ツールの選択\n\nプライマリー、セカンダリーリージョンでワークスペースの同期をとるためのツールに関しては、大きく二つのアプローチがあります：\n\n- **プライマリーからセカンダリーにコピーを行う同期クライアント:** 同期クライアントはプロダクションのデータと資産をプライマリーリージョンからセカンダリーリージョンにコピーを行います。\n- **並列デプロイメントのためのCI/CDツール:** プロダクションのコード、資産に対して、両方のリージョンに同時にプロダクションの変更を反映する[CI/CDツール](https://docs.databricks.com/dev-tools/terraform/index.html)を使用します。例えば、ステージング、デベロップメントからプロダクションにコードや資産がプッシュされる際、CI/CDシステムは同時に両方のリージョンに変更を反映します。根本となる考え方は、Databricksワークスペースにおける全ての成果物をインフラストラクチャ・アズ・コードとして取り扱うというものです。いくつかの成果物はディザスターリカバリー後にのみデプロイされる必要がありますが、ほとんどの成果物はプライマリー、セカンダリー両方に同時にデプロイされます。ツールに関しては、[自動化ツール、サンプル、プロトタイプ](#自動化スクリプトサンプルプロトタイプ)を参照ください。\n\n以下の図は二つのアプローチを比較したものとなっています。\n![](https://docs.databricks.com/_images/disaster-recovery-tooling-options.png)\n\n必要に応じて、これらのアプローチを組み合わせることができます。例えば、ノートブックに対してCI/CDを使用し、プールやアクセス制御の設定に関しては同期を行うなどです。\n\n以下の表では、それぞれのツールで、どのようなタイプのデータが取り扱えるかをまとめています。\n\n| 説明 | CI/CDツールでの取り扱い | 同期ツールでの取り扱い |\n|:--|:--|:--|\n|ソースコード：ノートブックのソース、ライブラリパッケージのソースコード   |プライマリー、セカンダリー両方にデプロイ   |プライマリーからセカンダリーにソースコードを同期   |\n|ユーザー、グループ   |Gitでメタデータを管理。あるいは、両方のワークスペースに同じIDプロバイダ(IdP)を使用する。プライマリー、セカンダリー両方にユーザー、グループデータをデプロイ   |両方のリージョンで[SCIM](https://docs.databricks.com/dev-tools/api/latest/scim/index.html)あるいは他の自動化ツールを使用する   |\n|プール設定   |Gitにテンプレートを保存する。プライマリー、セカンダリー両方にデプロイする。しかし、セカンダリーの`min_idle_instances`は、ディザスターリカバリーが発生するまで0にしておくこと   |APIあるいはCLIを使ってセカンダリーに同期された際には任意のmin_idle_instancesでのプールが作成される   |\n|ジョブ設定   |Gitにテンプレートを保存する。プライマリーでのデプロイでは、そのままの状態とする。セカンダリーでのデプロイでは、同時実行数をゼロにする。これによりジョブは実行されなくなる。セカンダリーデプロイメントがアクティブになった際には同時実行数を変更する   |ジョブが<インタラクティブ>クラスターで実行されている場合には、同期クライアントは対応するcluster_idにマッピングを行う必要がある   |\n|アクセス制御リスト(ACL)   |Gitにテンプレートを保存する。ノートブック、フォルダー、クラスターに対するACLをプライマリー、セカンダリーに設定する。ジョブに関するものに関しては、ディザスターリカバリーが発生するまで待つこと。   |[Permissions API](https://docs.databricks.com/dev-tools/api/latest/permissions.html)により、クラスター、ジョブ、プール、ノートブック、フォルダーのアクセス権を設定できる。同期クライアントはオブジェクトのIDをセカンダリーワークスペースにマッピングする必要がある。アクセス権を複製する前に、プライマリーからセカンダリーへのオブジェクトIDのマッピングを作成することを推奨する  |\n|ライブラリ   |ソースコード、クラスター、ジョブテンプレートに含める   |集中管理されたリポジトリ、DBFSあるはマウント可能なクラウドストレージからカスタムライブラリを同期する   |\n|[クラスターinitスクリプト](https://docs.databricks.com/clusters/init-scripts.html)   |必要ならソースコードに含める   |単純な同期に関しては、initスクリプトをプライマリーのワークスペースの単一あるいは数個のフォルダーに格納する   |\n|マウントポイント   |ノートブックベースのジョブあるいは[Command API](https://docs.databricks.com/dev-tools/api/1.2/index.html)で作成された場合にはソースコードに含める   |ジョブを使う。ワークスペースのリージョンが異なる場合には、ストレージのエンドポイントが変化する場合があることに注意する。これはあなたのデータのディザスターリカバリー戦略に依存する   |\n|テーブルメタデータ   |ノートブックベースのジョブあるいは[Command API](https://docs.databricks.com/dev-tools/api/1.2/index.html)で作成された場合にはソースコードに含める。これは内部Databricksメタストア、外部メタストア両方に適用される   |  [Spark Catalog API](https://github.com/apache/spark/blob/master/python/pyspark/sql/catalog.py)あるいはノートブック、スクリプトでShow Create Tableを使ってメタデータ定義を比較する。利用しているストレージによってはテーブルがリージョン依存となりメタストアインスタンス間でテーブルが異なるケースがあることに注意する |\n|シークレット   |ノートブックベースのジョブあるいは[Command API](https://docs.databricks.com/dev-tools/api/1.2/index.html)で作成された場合にはソースコードに含める。いくつかのシークレットはプライマリーとセカンダリーで異なる場合があることに注意する   |APIを通じて両方のワークスペースにシークレットが作成される。いくつかのシークレットはプライマリーとセカンダリーで異なる場合があることに注意する   |\n|クラスター設定 |Gitでテンプレートにする。プライマリー、セカンダリー両方にデプロイする。セカンダリーのクラスターはディザスターリカバリーが発生するまで停止しておくこと |API、CLIを用いてセカンダリーワークスペースに同期された後にクラスターが生成される。自動停止設定によっては、必要であれば明示的にクラスターは停止される |\n|ノートブック、ジョブ、フォルダのアクセス権|Gitでテンプレートにする。プライマリー、セカンダリー両方にデプロイする。|[Permissions API](https://docs.databricks.com/dev-tools/api/latest/permissions.html)を用いて複製する|\n\n## セカンダリーワークスペースのリージョンの選択\n\nあなたには、ディザスターリカバリーを実行するためのフルコントロールが必要です。あなたはあらゆる理由、あらゆるタイミングで実行をスタートできます。フェイルバックモード（通常状態）での再起動を行う前に、ディザスターリカバリーの安定性に対してあなたは責任を持つ必要があります。すなわち、ディザスターリカバリー、プロダクションの要件に応じて、あなたは複数のDatabricksワークスペースを作成し、セカンダリーのフェイルオーバーリージョンを選択する必要があります。\n\nAWSにおいては、あなたはセカンダリーリージョンにおいてフルコントロールを有します。EC2のようなリソース、製品が利用可能であることを確認してください。いくつかのDatabricksは、特定のリージョンでのみ利用可能です。あなたのDatabricksアカウントがE2バージョンであれば、E2バージョンのプラットフォームをサポートしているAWSリージョンを選択する必要があります。\n\n# ステップ3: ワークスペースを準備しワンタイムコピーを行う\n\nワークスペースがプロダクション環境である場合には、アクティブデプロイメントとパッシブデプロイメントで同期を行う際には**ワンタイムコピー**を行うのが一般的です。\n\n最初の**ワンタイムコピー**の実行後は、以降のコピー、同期操作は高速となり、ツールのログは、どのような変更がいつ発生したのかのログにもなります。\n\n# ステップ4: データソースを準備する\n\nDatabricksはバッチ処理、ストリーミング処理を通じて流入する様々な種類のデータを取り扱うことができます。\n\n## データソースに対するバッチ処理\n\nバッチでデータが処理される際、他のリージョンに容易に複製できるデータソースを用いるのが一般的です。\n\n例えば、データはクラウドストレージに定期的にアップロードされます。セカンダリーリージョンにディザスターリカバリーする際には、セカンダリーリージョンのストレージにファイルがアップロードされていることを確認する必要があります。ワークロードはセカンダリーリージョンのストレージを読み取り、セカンダリーリージョンのストレージに書き込みを行う必要があります。\n\n## データストリーム\n\nデータストリームを処理することはさらなるチャレンジとなります。ストリーミングデータは様々なソースから投入され、処理後にストリーミングソリューションに送信されます：\n\n- Kafkaのようなメッセージキュー\n- データベース変更データキャプチャストリーム\n- ファイルベースの継続的処理\n- ファイルベースのスケジュール処理\n\nこれら全てのケースで、ディザスターリカバリーモードで、セカンダリーリージョンでのデプロイメントを利用するために、データソースを設定する必要があります。\n\nストリームライターは、処理された地点を管理するチェックポイントを格納します。このチェックポイントは、ストリームが再開した際に正しくデータを更新するために、データの場所(一般的にはクラウドストレージ)を保持します。例えば、チェックポイント配下のsourceサブフォルダーはファイルベースのクラウドフォルダーを格納します。\n\nこのチェックポイントは遅延なく複製される必要があります。[こちらの例](https://docs.databricks.com/spark/latest/rdd-streaming/developing-streaming-applications.html#good-stream-example)を参照ください。\n\nチェックポイントの更新はライターの機能であり、データストリームの投入、処理、別のストリーミングソースへの格納にも適用できます。\n\nストリーミングのワークローにおいては、障害復旧時から適切にワークロードを再開できるように、チェックポイントがセカンダリーリージョンのお客様管理のストレージに複製されることを確認する必要があります。\n\n# ステップ5: ソリューションを実装しテストする\n\nディザスターリカバリーが適切に設定されているのかを定期的にテストします。必要となった時に利用できないのであれば、ディザスターリカバリーソリューションを維持することに価値はありません。いくつかの企業では、数ヶ月おきにリージョンを切り替えています。定期的にリージョンを切り替えることは、仮説とプロセスを検証でき、復旧要件を満たしているかどうかをテストできます。また、これにより自身の組織で緊急事態のポリシーと手順を訓練することができます。\n\n> **重要!**\n実世界の環境で定期的にディザスターリカバリーソリューションをテストしてください。\n\nオブジェクトあるいはテンプレートが足りず、プライマリーワークスペースに蓄積されている情報に依存しなくてはならないことが明らかになったら、これらの障害を取り除き、セカンダリーシステムに情報が複製されるようにしてください。\n\n設定、プロセスに対する組織変更をテストしてください。あなたのディザスターリカバリープランはデプロイメントパイプラインに影響を及ぼしますので、あなたのチームは何が同期されるべきかを知ることが重要です。ディザスターリカバリーワークスペースをセットアップした後で、あなたのインフラストラクチャ(手順書、コード)、ジョブ、ノートブック、ライブラリ、その他のワークスペースのオブジェクトがセカンダリーリージョンで利用できることを検証してください。\n\n変更を全てのワークスペースに反映するために、あなたのチームと、どのように標準作業プロセス、設定パイプラインを拡張するのかを議論してください。全てのワークスペースでユーザIDを管理してください。ジョブの自動化、新規のワークスペースをモニタリングするツールを設定することを忘れないでください。\n\n設定ツールに対する変更をテストする計画を立ててください：\n\n- 投入： データソースがどこにあるか、データソースはどこからデータを持ってくるのかを理解します。可能であれば、セカンダリーリージョンにおけるセカンダリーデプロイメントで作業するための設定テンプレートを持てるようにソースの部分をパラメータ化してください。フェイルオーバーのプランを立て、仮説を検証してください。\n- スケジューラーの変更: ジョブやアクションを実行するスケジューラーをもっているのであれば、セカンダリーデプロイメントで動作するようにスケジューラを設定する必要があります。フェイルオーバーのプランを立て、仮説を検証してください。\n- 相互接続性: JDBC/ODBCのような他のサービス、CLIツール、REST APIの利用において、リージョン障害によってどのような設定、認証、ネットワーク接続が影響を受けるのかを検討します。フェイルオーバーのプランを立て、仮説を検証してください。\n- オートメーションの変更: 全てのオートメーションツールに対して、フェイルオーバーのプランを立て、仮説を検証してください。\n- 出力: 出力データ、ログを生成する全てのツールに対して、フェイルオーバーのプランを立て、仮説を検証してください。\n\n## フェイルオーバーのテスト\n\nディザスターリカバリーは、様々なシナリオで発生します。予期されない障害によって引き起こされます。クラウドネットワーク、クラウドストレージなどいくつかの主要機能がダウンするかもしれません。安全にシステムをシャットダウンできずに、リカバリをトライしなくてはならないかもしれません。しかし、シャットダウンや計画停止、二つのリージョン間のアクティブデプロイメントの切り替えによっても引き起こされるかもしれません。\n\nフェイルオーバーをテストする際には、システムに接続しシャットダウンプロセスを実行してください。全てのジョブが停止し、クラスターが停止されたことを確認してください。\n\n同期クライアント(あるいはCI/CDツール)がセカンダリーワークスペースに適切なDatabrikcsオブジェクトを複製します。セカンダリーワークスペースを有効化するには、以下のいずれかあるいは全てのプロスが必要になります：\n\n1. プラットフォームが最新の状態にあることを確認するためにテストを実行します\n1. 障害のあるサービスが復旧した際に、プライマリーリージョンが新たなデータを処理し始めないようにプライマリーリージョンのクラスター、プールを停止しておきます\n1. 復旧プロセス：\n    1. 最新の同期データの日付を確認する。ディザスターリカバリー領域の用語を確認してください。このステップの詳細は、あなたがどのようにデータを同期するのか、ビジネス特有の要件によって変化します。\n    1. データソースを安定化させ、全てのデータが利用可能であることを確認します。これには、AWS RDSのような外部データソースに加え、Delta Lake、Parquet、その他のファイルが含まれます。\n    1. ストリーミングの回復ポイントを見つけます。その地点から処理を再開し、潜在的なデータ重複を排除します(Delta Lake箱の作業を容易にします)。\n    1. データフロープロセスを完了し、ユーザーに通知します。\n1. 適切な数のプールを起動(あるいはmin_idle_instancesを適切な数に増やします)します。\n1. (停止されていない場合には)適切な数のクラスターを起動します。\n1. ジョブに対する同時実行数を変更し、適切なジョブを実行します。これらは一度限りのものもあれば、定期実行のものもあります。\n1. Databricksワークスペースのドメイン名、URLを使う外部ツールに対して、新たなコントロールプレーンに更新します。例えば、REST APIのURLやJDBC/ODBC接続を更新します。コントロールプレーンが変更した際には、ユーザーが利用するDatabricksのウェブアプリケーションURLも変更になりますので、新たなURLをユーザーに通知します。\n\n## 復旧(フェイルバック)のテスト\n\nフェイルバックは容易にメンテナンス期間中に実行できます。このプランは以下のいずれか、あるいは全てを含みます：\n\n1. プライマリーリージョンが回復したことを確認します。\n1. 新たなデータを処理しないようにセカンダリーリージョンのプールとクラスターを停止します。\n1. セカンダリーワークスペースにおいて更新されたアセットをプライマリーデプロイメントに同期します。フェイルオーバースクリプトの設計によっては、セカンダリー(ディザスターリカバリー)からプライマリーリージョン(プロダクション)にコピーするために同じスクリプトを実行できるケースがあります。\n1. 新規データをプライマリーデプロイメントに更新します。データ損失を防ぐために監査ログとDeltaテーブルを活用できます。\n1. ディザスターリカバリーリージョンでの全てのワークロードを停止します。\n1. ジョブとユーザーのURLをプライマリーリージョンに切り替えます。\n1. プラットフォームが最新の状態にあることをテストします。\n1. 適切な数のプールを起動(あるいはmin_idle_instancesを適切な数に増やします)します。\n1. (停止されていない場合には)適切な数のクラスターを起動します。\n1. ジョブに対する同時実行数を変更し、適切なジョブを実行します。これらは一度限りのものもあれば、定期実行のものもあります。\n1. 必要であれば、将来の障害に備えてセカンダリーリージョンを再度ディザスターリカバリーとして利用できるように設定します。\n\n# 自動化スクリプト、サンプル、プロトタイプ\n\n同期プロセス開発を容易にするために[Databricks Terraform Provider](https://docs.databricks.com/dev-tools/terraform/index.html)を活用することをお勧めします。\n\n自動化のサンプル、プロトタイプのスクリプトに関しては[Databricks Workspace Migration Tools](https://github.com/databrickslabs/migrate)も参照ください。\n\n### Databricks 無料トライアル\n\n[Databricks 無料トライアル](https://databricks.com/jp/try-databricks)\n","user":"taka_yayoi","created_at":"2021-03-29T14:55:35+09:00","updated_at":"2021-03-29T14:55:35+09:00"},{"url":"https://qiita.com/toki_k/items/14cb5df53fce12e83b4b","title":"NestJS TypeORM postgres で環境構築 with docker(DBのみ)","body":"#記事の内容\nNestJS TypeORM postgresで環境構築します。\npostgresはDocker上で起動します。\n\nDockerについては、完全初心者です。\nただ、dbをローカルに作るのが嫌でしたので導入してみました。\n\n今回調べながらの環境構築なので\n間違っている所やこうした方がいい所、等があった場合\n教えていただけると嬉しいです。\n\n\n環境構築を終えたら、\nURLのアクセスからデータ操作までの流れを簡単に実装します。\n\nソースコードはこちら↓\nhttps://github.com/tokio-k/docker-nest-postgres-sample\n\n※Docker、yarnのインストールは前提で進めます。\n※調べればすぐできると思うのでよろしくお願いします。\n\n\n#プロジェクトの作成\n\n###フォルダ作成\nターミナルで今回作成していくフォルダを作成し、そのフォルダに移動します。\n(今回はdocker-nest-postgres-sampleというフォルダ)\n\n```terminal.\n# フォルダ作成\nmkdir docker-nest-postgres-sample\n# 移動\ncd docker-nest-postgres-sample\n```\n(terminal. の「.」は気にしないでください。普通にターミナルで実行しています。)\n\n###NestJSのプロジェクトを作成\nNest用CLIを用いて作成していきます。\nNest用CLIをインストールします。(既にインストールしてある場合は飛ばしてください。)\n\n```terminal.\nyarn global add @nestjs/cli\n```\n\n作成したフォルダの中に、Nestのプロジェクトを作成します。\n簡単に雛形を作成できます。\n\n```terminal.\n# Nestのプロジェクトを作成\nnpx nest new .\n```\n# ライブラリのインストール\nTypeORM関連やバリデーションのライブラリをインストールしておきます。\nDBにはpostgresを使用します。\n\n```terminal.\n#TypeORM関連\nyarn add @nestjs/typeorm typeorm pg\n\n#バリデーション\nyarn add class-transformer class-validator\n```\n\n#Dockerでpostgresの環境構築\n\n最初に作成したフォルダの中にdocker-compose.ymlを作成します。\nsrcフォルダやpackage.jsonと同じ階層です。\n\n```terminal.\ntouch docker-compose.yml\n```\n作成したdocker-compose.ymlの中に以下の記述をします。\nデータベース接続情報などは好きに書いてください。(environment)\n本当は、環境変数や.envファイルに記述し、参照する様にするみたいです。\nいつか書き換えればいいので、今は直接書きで。\n\n```docker-compose.yml\nversion: '3'\n\nservices:\n  postgres:\n    image: postgres:13.1\n    container_name: postgres\n    ports:\n      - 5432:5432\n    volumes:\n      - ./postgres_data:/var/lib/postgresql/data\n    environment:\n      POSTGRES_USER: root\n      POSTGRES_PASSWORD: password\n      POSTGRES_DB: test_db\n      POSTGRES_INITDB_ARGS: '--encoding=UTF-8'\n      TZ: 'Asia/Tokyo'\n    restart: always\n```\ndocker-composeに記載した内容で、\ndocker上にpostgresの環境を立ち上げます。\n\n```terminal.\ndocker-compose up -d\n```\npgAdmin4などで確認してみると、データベースが作成されていることが確認できます。\n\n#NestJSからTypeORMを使用\n\n###ormconfig.jsonを作成\n\nsrcフォルダやpackage.jsonと同じ階層にormconfig.jsonを作成します。\n\n```terminal.\ntouch ormconfig.json\n```\normconfig.jsonを編集していきます。\nデータベース情報は、先程設定したものと合わせてください。\n\n```ormconfig.json\n{\n    \"type\": \"postgres\",\n    \"host\": \"localhost\",\n    \"port\": 5432,\n    \"username\": \"root\",\n    \"password\": \"password\",\n    \"database\": \"test_db\",\n    \"entities\": [\"dist/entities/**/*.entity.js\"],\n    \"migrations\": [\"dist/migrations/**/*.js\"],\n    \"logging\": true,\n    \"synchronize\": false\n}\n```\n\n###app.module.tsを編集\napp.module.tsを編集します。\nこれで、TypeORMの機能を呼び出すことができる様になります。\n\n```app.module.ts\nimport { Module } from '@nestjs/common';\nimport { AppController } from './app.controller';\nimport { AppService } from './app.service';\nimport { TypeOrmModule } from '@nestjs/typeorm';//追加箇所\n\n@Module({\n  imports: [TypeOrmModule.forRoot()],//編集箇所\n  controllers: [AppController],\n  providers: [AppService],\n})\nexport class AppModule {}\n```\n\n# テーブル作成\nテーブルを作成していきます。\n\n###Entityの作成\nEntityを作成します。\nEntityでは、テーブルの構造を定義し、これを元にテーブルが作成されます。\n\nsrcフォルダの中にentitiesフォルダを作成します。\nentitiesフォルダの中にitem.entity.tsを作成します。\n\nitem.entity.tsを編集していきます。\n\n```item.entity.ts\nimport {\n  Entity,\n  Column,\n  PrimaryGeneratedColumn,\n  CreateDateColumn,\n  UpdateDateColumn,\n} from 'typeorm';\n\n@Entity()\nexport class Item {\n  @PrimaryGeneratedColumn()\n  readonly id: number;\n\n  @Column()\n  todo: string;\n\n  @Column('boolean', { default: false })\n  idDone: boolean;\n\n  @CreateDateColumn()\n  readonly createdAt?: Date;\n\n  @UpdateDateColumn()\n  readonly updatedAt?: Date;\n}\n```\nid,todo,isDone,createdAt,updatedAtがそれぞれテーブルのカラムになります。\n\n###マイグレーションファイルの作成/実行\n\nマイグレーションファイルを作成していきます。\n\n```terminal.\n# ビルド\nyarn build\n\n#マイグレーションファイルの作成\nyarn typeorm migration:generate -d src/migrations -n create-item\n```\n\nマイグレーションファイルを実行していきます。\n\n```terminal.\n# ビルド\nyarn build\n\n# マイグレーションファイルの実行　(DB作成)\nyarn typeorm migration:run\n```\n\npgAdmin4などで確認してみると、テーブルが作成されている事が確認できます。\n\n#module,controller,serviceの作成\n\nコマンドでそれぞれ作成していきます。\n\n```terminal.\n# module作成\nyarn nest g module item\n\n# controller作成\nyarn nest g controller item\n\n# service作成\nyarn nest g service item\n```\n\nコマンドで作成すると、読み込まれるように、app.module.tsやitem.module.tsに自動で追記されます。\napp.module.tsを編集します。\n\n```item.module.ts\nimport { Module } from '@nestjs/common';\nimport { TypeOrmModule } from '@nestjs/typeorm';//追加箇所\nimport { Item } from 'src/entities/item.entity';//追加箇所\nimport { ItemController } from './item.controller';\nimport { ItemService } from './item.service';\n\n@Module({\n  controllers: [ItemController],\n  imports: [TypeOrmModule.forFeature([Item])],//編集箇所\n  providers: [ItemService],\n})\nexport class ItemModule {}\n```\n\n#DTOの作成\n\n###DTOを作成します。\nデータのやり取りをするときにデータ構造を表す箱のようなものです。\nここでバリデーション(入力チェック)などができます。\n\n```item.dto.ts\nimport { IsNotEmpty, IsString } from 'class-validator';\n\nexport class CreateItemDTO {\n  @IsNotEmpty()\n  @IsString()\n  todo: string;\n}\n\n```\ntodoを必須+文字列に制限しました。\nデータ追加をするときに、このクラスを使ってデータのやり取りをします。\n\n###バリデーションを有効にする\nsrc/main.tsを編集して、バリデーションを有効にします。\n\n```main.ts\nimport { ValidationPipe } from '@nestjs/common';//追加箇所\nimport { NestFactory } from '@nestjs/core';\nimport { AppModule } from './app.module';\n\nasync function bootstrap() {\n  const app = await NestFactory.create(AppModule);\n  app.useGlobalPipes(new ValidationPipe());//追加箇所\n  await app.listen(3000);\n}\nbootstrap();\n```\n\n#APIの実装\nService,Controllerを実装していきます。\n\n###Serviceの実装\nServiceを実装していきます。\n\n```item.service.ts\nimport { Injectable } from '@nestjs/common';\nimport { InjectRepository } from '@nestjs/typeorm';\nimport { Item } from 'src/entities/item.entity';\nimport { InsertResult, Repository } from 'typeorm';\nimport { CreateItemDTO } from './item.dto';\n\n@Injectable()\nexport class ItemService {\n  constructor(\n    @InjectRepository(Item)\n    private readonly itemRepository: Repository<Item>,\n  ) {}\n\n  // 全データ検索\n  async findAll(): Promise<Item[]> {\n    return await this.itemRepository.find();\n  }\n\n  //データ追加\n  async create(item: CreateItemDTO): Promise<InsertResult> {\n    return await this.itemRepository.insert(item);\n  }\n}\n\n```\n\nconstructorの部分でRepositoryをInjectionしています。\nRepositoryに指示を出すことでテーブルのデータを変更できます。\n\n###Controllerの実装\n\n```item.controller.ts\nimport { Body, Controller, Get, Post } from '@nestjs/common';\nimport { Item } from 'src/entities/item.entity';\nimport { InsertResult } from 'typeorm';\nimport { CreateItemDTO } from './item.dto';\nimport { ItemService } from './item.service';\n\n@Controller('item')\nexport class ItemController {\n  constructor(private readonly service: ItemService) {}\n\n  // 全データ検索\n  @Get()\n  async getItemList(): Promise<Item[]> {\n    return await this.service.findAll();\n  }\n  //データ追加\n  @Post()\n  async addItem(@Body() item: CreateItemDTO): Promise<InsertResult> {\n    return await this.service.create(item);\n  }\n}\n```\n/itemにGetでアクセスがあった時に「getItemList()」\n/itemにPostでアクセスがあった時に「addItem(item)」が呼び出されます。\naddItem(item)の「item」が先程作成したCreateItemDTOの型には入ります。\n\nconstructorでは、先程作成したServiceがInjectionされています。\n\nとりあえず、実装は完成\n\n#動作確認\n\n###実行\n以下のコマンドで実行できます。\n\n```terminal.\nyarn start dev\n```\n###新規データの追加 (addItemを呼び出す)\n\nコマンドで以下を実行してデータを追加できます。\n\n```terminal.\ncurl http://localhost:3000/item -X POST -d \"todo=test\"\n```\n\n###ブラウザからアクセス (getItemListを呼び出す)\nブラウザから以下で検索すると、追加したデータが表示されます。\nhttp://localhost:3000/item\n\nこれで、全検索と追加のAPIが作成することができました。\n\n##参考記事\n[How To Set Up TypeORM With Postgres in NestJS](https://betterprogramming.pub/how-to-set-up-typeorm-with-postgres-in-nestjs-5575c949c05f)\n[NestJSの始め方](https://qiita.com/tobita0000/items/6705800853b2869fec80)\n[NestJSで簡単なtudoリストを実装するチュートリアル](https://taroosg.io/nestjs-tutorial)\n[Mac に Docker Desktop をインストール](https://docs.docker.jp/docker-for-mac/install.html)\n","user":"toki_k","created_at":"2021-03-29T14:55:11+09:00","updated_at":"2021-03-29T14:55:11+09:00"},{"url":"https://qiita.com/belre/items/0dc1736b70bf4cb79d45","title":"【C#⇔C++/CLI】ファイルまたはアセンブリ、またはその依存関係の1つが読めませんでした。【トラブルシューティング】","body":"\n# 概要\n\nWindows専用のアプリケーションなんて今更・・・という昨今ですが、\n\n未だに.NET Frameworkや.NET Coreで、C++のコードとC#のコードをまとめて使うときにC++/CLIというMicrosoftが開発した中間言語を使って、ネイティブコードを共存させたいという需要が狭い世界で存在します。\n\nC++/CLIは、現状C++用のラッパーとしてDLLとして作成する場合での運用でのみ、Microsoftからも推奨されています。\n\nそして、.NET FrameworkのC++/CLIの設定を誤ると、表題のエラーを見かけるようになります。\n\nこの狭い世界で何度か開発することがあったので、C++/CLI導入時のチェックリストみたいなのを用意しておこうと思います。\n\n# Windows Forms, WPF, UWPの場合\n\nC++/CLIで結合されているオブジェクトを参照すると、こんな感じのエラーが出てきます。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281173/c6c3d61f-c8c3-9d53-4415-d01e0361e276.png)\n\n## チェックするべき項目\n\n### 実行ファイル側が\"Any CPU\"になっていないこと\n### 実行されるDLLと実行ファイル側が\"x86/Win32\"または\"x64\"に統一されていること\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281173/783b3bca-c263-5e58-bef1-12f42c22fba5.png)\n\n基本的に、C++/CLIで作成されたDLLは、32bitで使用するか64bitで使用するかを指定する必要があります。\n両方のCPUで使えるような器用な仕様にはなっていません。\n従って、上のように\"Any CPU\"という設定が混在している場合は、\"x86/Win32\"または\"x64\"に設定を統一しましょう。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281173/38d3da22-1542-0c91-064e-4fe9d874e312.png)\n\n### 実行予定のDLLが、全く同じディレクトリに含まれていること\n\n① C++/CLI以外に、C++ネイティブDLLが混在する場合は、**ビルド時に自動的に実行ファイルのディレクトリ下に保存してくれません。**\nその場合は、ビルドイベントを使って、dllファイル、pdbファイルをコピーするようにしましょう。\n(**pdbファイルを入れ忘れると、ネイティブコードのデバッグが出来なくなるので注意すること。**)\n\n② もし依存関係が分からない場合は、Dependenciesをダウンロードして調べると、一目で理解できます。\n\nhttps://github.com/lucasg/Dependencies\n\n\n# ASP .NETの場合\n\nローカルサーバを立てた場合のデバッガの挙動\n大体こんな感じの画面になります。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281173/8c6e66df-5635-945f-9904-e71e2cd43734.png)\n\n## チェックするべき項目\n\n基本的には、上記のケースと同じですが、これ以外に下記の内容も確認しましょう。\n\n### IIS Expressが32ビット版、64ビット版に統一されているかを確認する\n\nツール>オプション>プロジェクトおよびソリューションを参照\n\n64bitのC++/CLIのDLLを使用する場合は、**Webサイトおよびプロジェクト用IIS Expressの64ビットバージョンを使用する**にチェックを入れます。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/281173/b6704237-e4ff-0fe2-897d-5a8a05ab209e.png)\n\n\n","user":"belre","created_at":"2021-03-29T14:52:14+09:00","updated_at":"2021-03-29T14:52:14+09:00"},{"url":"https://qiita.com/motoki0208/items/2d3e8e49349d8d59a133","title":"「AWS 認定データアナリティクス 専門知識」 取得に向けた学習まとめ","body":"\n## はじめに\n先日、AWS 認定データアナリティクス 専門知識の認定試験を受験し、無事合格しました。自分が実施した学習の流れとそれぞれの概要について、実施した順に記載をしています。「データアナリティクス 専門知識」に限らず、他の認定試験を受ける際に参考になる部分もあるかと思うので、良かったら読んでみてください。\n\n## 受験目的\n- 数ヶ月前にデータ分析やデータ活用をメインとして扱う会社に転職。\n- データ分析に関わるAWSサービスを体系的に学ぶべく、本認定試験を受験することに。\n\n## 前提\n- ソリューションアーキテクト・アソシエイトの資格は取得しており、AWSのサービスの基本は把握済。\n- テスト範囲のサービスの中には、自分が関わっているPJの中で使われているものもあったが、ゼロからの構築、設定経験はほぼ無し。\n\n## 学習手順\n### 試験ガイド\nまずはこの認定試験の試験内容を把握しましょう。試験の出題形式や、分野及び観点が記載されています。\n\n### 「AWS 認定試験に備える」ページ\n- https://aws.amazon.com/jp/certification/certification-prep/\n- AWSの各認定試験ごとに、学習すべきリソースへのリンクをまとめてくれています。\n- こちらの「データ分析 – 専門知識」項目における「AWSホワイトペーパーと、よくある質問を読む」を見ると、認定試験の出題対象となるサービスの一覧を確認することができます。\n    - 試験対象となるサービスについて、明示的に記載がある箇所はここ以外にないようなので(少なくとも私は見つけられませんでした)、ぜひ確認してみてください。\n\n### 書籍\n- 図解即戦力　ビッグデータ分析のシステムと開発がこれ1冊でしっかりわかる教科書\n    - https://www.amazon.co.jp/dp/429710881X\n    - ビッグデータ分析システムを構成する要素にどういったものがあるのか、概要を掴む上で非常に役立つ書籍かと思います。\n- AWSで始めるデータレイク\n    - https://www.amazon.co.jp/dp/491031301X\n    - こちらはよりAWSサービスに特化した書籍になります。各サービスの具体的なユースケースや利用手順が平易な文章で書かれていて、概要を理解するのにもってこいな書籍かと思います。\n    - AWSの中の人が書いている点と、最近出版されている点(2021/03/29執筆時点)からも、信頼のおける学習教材だと思います。\n\n### サンプル問題\n- https://d1.awsstatic.com/ja_JP/training-and-certification/docs-data-analytics-specialty/AWS-Certified-Data-Analytics-Specialty_Sample-Questions.pdf\n- ざっくりとデータ分析に関わるAWSサービスの概要を理解したタイミングで、公式が提供しているサンプル問題(無料)に取り組むのがおすすめです。先の試験ガイドに記載のあった観点が、どういった切り口で問われるのかを確認できます。意外と深掘りされるな、とか、同系統サービスの比較で問われることが多いな、とかを感じられるかなと思います。\n\n### 公式ドキュメント\n- やはり一番大事なのは公式ドキュメントです。当たり前ですが、ここの記載が認定試験における正解となります。各種サービスの公式ドキュメントに一通り目を通しましょう。\n- 基本的には日本語訳が整備されていますが、たまに不自然な表現に出くわすことがあります(目的語や主語が文末に突然現れるようなものなど。読んだことある方は分かっていただけるはずw)。英語が得意な方は英語の方が読みやすい部分もあるかもしれないです。\n    - ちなみに試験問題自体も日本語版が提供されているんですが、1, 2問ほど日本語訳が分かりづらいものがありました。英語の問題文も表示可能なので、不安に思った際にはそちらも試しに見てみるのもおすすめです。\n- 公式ドキュメントに簡単なチュートリアルがあるサービスもあります。触ってみることで、各種設定値の意味や設定タイミングなどを一気に理解しやすくなると思います。業務の中で触ったことのないサービスについては一度は触れてみることを強くおすすめします。\n    - ただし、課金には重々気をつけてください。笑 ものによっては無料利用枠のない場合があります。チュートリアルが終わってその後使わない場合はすぐにリソースを削除して、課金金額を最小限に抑えましょう。\n   \n### クラウドサービス活用資料集\n- AWS公式側が用意しているWebinarなどの発表資料です。プレゼン資料なので視覚的な情報を中心に分かりやすくまとまっています。公式ドキュメントを読むのに疲れた時にはこちらもおすすめです\n- https://aws.amazon.com/jp/aws-jp-introduction/https://www.slideshare.net/AmazonWebServicesJapan/presentations\n\n### ブログ\n- AWSのサービスに関する情報は公式以外にもWeb上に沢山あります。より具体的な利用事例や、触ってみた的な記事を見て、実利用のイメージを膨らますことができるかと思います。特にクラスメソッドさんが運営されているDevelopersIOは記事の速報性も高く、記事数も多いため、学習の上で非常に役立つソースの一つかなと思います(私はとてもお世話になりました、、!\n\n### 模擬試験\n- AWS公式が提供している20問の模擬試験の受験が可能です。\n- この時点で理解度不足を痛感する可能性もあるので、本試験受験日からある程度余裕を持たせて受験することをおすすめします。\n- 過去にAWS関連の認定試験に合格している場合は、一度だけ模擬試験を無料で受験することができます。ぜひ活用してみてください。\n    - https://level69.net/archives/25972\n- 注意点: 模擬試験の受験を終了した後、確認できるのは点数のみです。各問題の正誤及び正答は確認できませんのでご注意ください。\n\n### よくある質問\n- 実際に出た問題の中には、このよくある質問から出ていたものもありました。理解を深めるためにも役立つかと思うので、こちらにも目を通してみることをおすすめします。\n\n## 受験を終えての感想\n- 当たり前ではありますが、データ分析に関わる各AWSサービスの概要とユースケース、パフォーマンスやセキュリティ面での勘所を体系的に学ぶことができました。当初の目的は達成できたかなと思います。\n- 副次的なところで言うと、業務の中で不明点が出てきた時に、公式ドキュメントを抵抗なく読む習慣がつき、また理解するスピードも上がった気がします。\n- まだ業務で使用していないサービスについては、深いところまで理解しきれていない部分も多少あるとは思います。その点については、社内で機会があれば積極的に挑戦して、知識を実践に結びつけていきたいと思います。\n- AWSでしっかり基礎を身につけておけば、仮に他のクラウドを使うことになっても、キャッチアップしやすいんじゃないかなとは思っているので、適度に復習もしつつ、業務でも活用しつつ、さらなる知識の定着に努めたいなと思います。\n","user":"motoki0208","created_at":"2021-03-29T14:49:20+09:00","updated_at":"2021-03-29T14:59:56+09:00"},{"url":"https://qiita.com/hayato1130/items/f2cf00ab40babeabd61a","title":"Jupyter notebook でtqdmが使えない場合の対処法","body":"\n## 使い方\nJupyter notebook または　Jupyter lab では次のようにしてtqdmを用います。\n\n```python\n\nfrom tqdm.notebook import tqdm\n\ntotal = 0\nfor i in tqdm(range(1,11)):\n    total += i\n```\n\n## エラーと対処法\n\n次のようなエラーが出た場合、\n\n```shell\nHBox(children=(IntProgress(value=0, max=5), HTML(value='')))\n```\n\nJupyter notebook の拡張機能がインストールされていないことが原因のため、次の２つをshellで実行してインストールします。\n\n```shell\njupyter nbextension enable --py widgetsnbextension\n```\n\n```shell\njupyter labextension install @jupyter-widgets/jupyterlab-manager\n```\n\nインストール後にnotebookを再起動すれば、 下の図のようなプログレスバーを表示させることができます。\n\n![スクリーンショット 2021-03-29 14.46.55.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/328421/db4f04e9-a90a-1e97-214d-67ec1b736196.png)\n\n\n## 参考\n- https://stackoverflow.com/questions/57343134/jupyter-notebooks-not-displaying-progress-bars\n","user":"hayato1130","created_at":"2021-03-29T14:47:42+09:00","updated_at":"2021-03-29T14:47:42+09:00"},{"url":"https://qiita.com/motthy/items/d8c295bbcfd8073fa6ab","title":"JBrowse2を遺伝研スパコンで動かす","body":"# JBrowse2とは\n- 公式サイト https://jbrowse.org/jb2/\n- ゲノム配列と遺伝子の位置を可視化するツール\n- webアプリケーションとデスクトップ（オフライン）アプリケーションがある\n\n# バージョン1との違い\n公式サイトを和訳　https://jbrowse.org/jb2/features/\n\n**2でできるようになったこと**\n\n- トラック読み込み中のステータス更新（例：BAMインデックスをダウンロード中...）\n- BAM/CRAMタグによるソート、カラー、フィルター、その他の高度なオプション\n- トラックの解析とレンダリングにウェブワーカーを使用\n- アプリ内での設定のインタラクティブな編集をサポート\n- リニアビューを「フリップ」または逆に補完することが可能\n- Hi-Cデータのレンダリング\n- 複数の染色体を1つのビューで表示可能\n- アラインメントトラックでのリードパイルアップのソート\n- アラインメントトラックにソフトクリッピングを表示\n- データセットの表形式ビューを内蔵\n- UCSCトラックハブを開くことができる\n- スクリプトを実行せずにプラグインの追加と削除が可能\n- 管理者以外のユーザーがトラックを開き、他のユーザーと共有できる\n- NPMを使ってJavaScriptプロジェクトにエンベッディング可能\n- Reactアプリケーションに直接エンベッディング可能 \n\n**2ではできなくなったこと**（前のバージョンではできた）\n\n- 名前の検索 例：遺伝子名/IDを入力して検索する機能\n- URLクエリAPI \n    - 例: ブラウザのURLバーで ?loc=chr1:1-100 を指定する\n\nあれれ、これは地味に困る...？\nウェブサイトに組み込んでいる場合は単純に置き換えできなさそうなので注意が必要\n\n\n\n\n## JBrowse2をスパコン上で動かす\n- スパコン上で動かしてポートフォワードを利用してウェブブラウザから見る\n- bamなど大きいファイルをlocalにダウンロードせずに見えるんじゃないか（注1\n- 以前のバージョンではapacheが必要なので設定が面倒だった\n- 2はNode.jsで動くのでapacheの設定不要なのがうれしい\n\n注1 　この目論見はちょっと外れたっぽい（後述）\n\n# 手順\n## ツールのインストール \nNode.jsをcondaでインストール（必要なら仮想環境を作ってから）\n任意の場所に、GithubからJBrowse2のバイナリをダウンロードする\n\n```\n$ conda install -c conda-forge nodejs\n$ wget https://github.com/GMOD/jbrowse-components/releases/download/v1.0.4/jbrowse-web-v1.0.4.zip\n```\n\nnpmでserveをインストール\n\n```\n$ npm install -g serve\n```\n\nzipファイルを解凍して、できたディレクトリ`jbrowse2`に移動\n\n```\n$ gunzip jbrowse-web-v1.0.4.zip\n$ mv jbrowse-web-v1.0.4.zip jbrowse2\n$ cd jbrowse2\n```\n\nconfig.jsonのバックアップを取っておく\n\n## ゲノム配列とgffの追加\nなぜかvolvoxを入れてからでないとうまくいかなかった\n\n```\n$ jbrowse add-assembly http://jbrowse.org.s3.amazonaws.com/genomes/volvox/volvox.fa\n$ jbrowse add-assembly /your/genome/path/genome/nanikano.genome.fa --load copy --target data --name nanikanogenome\n$ jbrowse add-track /your/annotation/path/nanikano.gff.gz --load copy --name nanikanoannotation --trackID nanikanoannotation\n```\n\nconfig.jsonから手動でvolvoxを削除\n\n## 実行\nポート33770で動かす（ポート番号は任意、だが30000番台にしておくと他のタスクに邪魔にならなそう）\n\n```\n$ npx serve -l 33770\nERROR: Cannot copy to clipboard: Couldn't find the required `xsel` binary. On Debian/Ubuntu you can install it with: sudo apt install xsel\n\n  ┌────────────────────────────────────────────────────┐\n  │                                                    │\n  │ Serving!                                           │\n  │                                                    │\n  │   - Local:            http://localhost:33770       │\n  │   - On Your Network:  http://XXX.XX.XX.XXX:33770   │\n  │                                                    │\n  └────────────────────────────────────────────────────┘\n```\n(ネットワークのIPは伏せ字にした）\n\n外からはポートフォワード（gwノードを踏み台にする）で\nlocalのwebブラウザに`http://localhost:8888`で見える\n `xsel`がないというエラーが出ているけど、見えるからOK?\n (どうしたらエラーが解消されるのか、または無視していいのか、わかる人がいたらコメントください）\n\n他の人（スパコンアカウントを持っている人）も一緒に見ることができる\nターミナルに以下のように入力する\n`atXXX`のところはjbrowse2が動いているノード名を入力\n`youraccout`はスパコンのアカウント名を入力\n\n```\nssh -L 8888:atXXX:33770  youraccout@gw.ddbj.nig.ac.jp\n```\n\nlocalのwebブラウザに`http://localhost:8888`と入れるとゲノムブラウザが見えるはず\n\n## bamの追加\nシンボリックリンクだと表示できないので`--load copy`にする(ディスク容量注意）\n\n```\n$ jbrowse add-track /bam/path/nanika01.bam --load copy -n 01 \n$ jbrowse add-track /bam/path/nanika02.bam --load copy -n 02\n```\n\nみてみよう\n\n```\n$ npx serve -l 33770\n```\n\n見えるけどloadにめちゃくちゃ時間かかる...\n（Node.jsの設定まわりいじるとぬるぬる動くようになるかもしれない？）\n \n","user":"motthy","created_at":"2021-03-29T14:44:35+09:00","updated_at":"2021-03-29T14:44:35+09:00"},{"url":"https://qiita.com/Aotanit/items/826f444d74e0b259c847","title":"EKS workshop 触ってみる① -Introduction,Start the Workshop...,Launch using eksctl-","body":"## EKS workshop\n[EKS workshop](https://www.eksworkshop.com/)を通してEKSの使い方などを確認してみようとおもい備忘録も兼ねて記事化しました。\n今回は[Introduction](https://www.eksworkshop.com/010_introduction/)から[Start the Workshop...](https://www.eksworkshop.com/020_prerequisites/)、[Launch using eksctl](https://www.eksworkshop.com/030_eksctl/)を実施します。\n\nここまで実施して、準備完了。さぁ触ろうという感じです。\n\n## Introduction\n### Kubernetes(k8s) Basics\n導入部分。k8sを理解している人には飛ばして問題ない部分と思われる。\n\n- What is Kubernetes\n  - k8sを端的に紹介。[詳細はk8s公式ページ](https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/)を案内している。\n- Kubernetes Nodes\n  - nodeの説明。Master(Control Plane)とWorker(Data Plane)。\n- K8s Objects Overview\n  - k8s Objectsの簡単な説明。  \n  k8sは「現在の状態(current state)」を「望ましい状態(desired stat)」となるように動くもの。\n- K8s Objects Detail(1/2)\n  - Pod,DaemonSet,Deploymentを簡単に記載。  \n  詳細はそれぞれのドキュメントを参照となっている。\n      - [Pod](https://kubernetes.io/docs/concepts/workloads/pods/pod/)\n      - [DaemonSet](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)\n      - [Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)\n- K8s Objects Detail(2/2)\n  - ReplicaSet,Job,Service,Labelsを簡単に記載。  \n  詳細はそれぞれのドキュメントを参照となっている。\n      - [ReplicaSet](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/)\n      - [Job](https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/)\n      - [Service](https://kubernetes.io/docs/concepts/services-networking/service/)\n      - [Labels](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/)\n\n### Kubernetes Architecture\n\n- Architectural Overview\n  - コンポーネントとその相関を簡易的な図として表現していると思われる。\n- Control Plane\n  - Control Plane内のコンポーネントを簡単に説明。\n      - 詳細は[kubernetes公式ドキュメント(Control Plane)](https://kubernetes.io/docs/concepts/overview/components/#master-components)参照となっている。\n- Data Plane\n  - Data Plane内のコンポーネントを簡単に説明。\n      - 詳細は[kubernetes公式ドキュメント(Data Plane)](https://kubernetes.io/docs/concepts/overview/components/#node-components)参照となっている。\n- Kubernetes Cluster Setup\n  - EKSはSelf-Managed-k8sClusterのboostrapやconfigureも活用できる。と書いてる・・・はず。  \n  記載されているSelf-Managed-k8sClusteは下記。\n      - [Minikube](https://kubernetes.io/docs/setup/minikube/)\n      - [Kops](https://github.com/kubernetes/kops)\n      - [Kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n      - [Docker for Mac](https://docs.docker.com/docker-for-mac/#kubernetes)\n      - [Kubernetes IN Docker](https://github.com/kubernetes-sigs/kind)\n\n### Amazon EKS\n\n- EKS Cluster Creation Workflow\n  - 読んで字の如く。図が１枚あるのみ。\n- What happens when you create your EKS cluster\n  - `create cluster`実行後のフロー図が１枚。\n- EKS Architecture for Control plane and Worker node communication\n  - EKSアーキテクチャ図が１枚。\n- High Level\n  - `kubectl`を使ってEKSのk8s Clusterを操作できるよ！って書いてる感じ。\n- Amazon EKS!\n  - slackでいつでも質問とか受け付けてるぜ！って書いてある。\n\n## Start the Workshop...\n下記から選択。\n\n- …running the workshop on your own (in your own account)\n- …attending an AWS hosted event (using AWS provided hashes)\n\n片方はAWSイベント参加などで利用するものなので[...on your own](https://www.eksworkshop.com/020_prerequisites/self_paced/)を実施\n選ばなかった方の手順はスキップ。ページを送るとそのままattending on AWS・・・のページに飛ぶ\n\n- ...on your own\n  - Create an AWS account\n        - 記載内容に従ってIAMユーザを作成していく\n- Create a Workspace\n  - Cloud9 Environmentを手順に従い作成する\n  - 作成後も記載の指示に従って手順を進める\n- Install Kubernetes Tools\n  - 記載の手順に従いツールを導入していく\n- Create an IAM role for your Workspace\n  - 記載の手順に従いIAM roleを作成する\n- Attach the IAM role to your Workspace\n  - 手順に従いEC2インスタンスに作成したIAM roleを割り当てる\n- Update IAM settings for your Workspace\n  - 手順に従いIAM設定を更新する\n- Clone the Service Repos\n  - 手順の通りにGitからソースをCloneする\n- Create an AWS KMS Custom Managed Key (CMK)\n  - k8sのシークレット暗号化に利用するCMKを作成する\n\n## Launch using eksctl\n- Prerequisites\n  - eksctlコマンドを配置して利用可能にする\n- Launch EKS\n  - 記載の手順に従いEKS Clusterを作成する\n- Test the Cluster\n  - `kubectl get node`で作成されたnodeがReadyで表示されるか確認\n  - 問題なければ、Workshopを通じて利用するWorkerRoleNameを環境変数として入れる  \n下記のように確認することができる。\n\n```\n$ kubectl get nodes\nNAME                                                STATUS   ROLES    AGE     VERSION\nip-XXX-XXX-XXX-XXX.ap-northeast-1.compute.internal   Ready    <none>   4m27s   v1.17.12-eks-XXXXXX\nip-XXX-XXX-XXX-XXX.ap-northeast-1.compute.internal   Ready    <none>   4m32s   v1.17.12-eks-XXXXXX\nip-XXX-XXX-XXX-XXX.ap-northeast-1.compute.internal   Ready    <none>   4m31s   v1.17.12-eks-XXXXXX\n```\n\n- Console Credentials\n  - EKSコンソールでワークショップで作成したクラスターへのフルアクセスが必要な場合にこの手順を実施する\n\n## To Be Continued\nBeginner以降の内容を次回以降で実施していく予定です。\n\n利用しない時にEKS Clusterを停止する際には、AutoScalingグループを編集してキャパシティを０にすれば良さそうでした。\n![AutoScalingグループ](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/922657/20019775-6e70-030a-e94a-17d043ffbafa.png)\n","user":"Aotanit","created_at":"2021-03-29T14:42:18+09:00","updated_at":"2021-03-29T14:42:18+09:00"},{"url":"https://qiita.com/arata0520/items/ca4c713cf01e89eb141a","title":"備忘録 - セル・範囲の指定【VBA】","body":"##セルを指定\n\n```vb\nActiveRange '現在アクティブのセルを指定\nRange(\"セル名\") ' A1やB5など通常のエクセルのセル名で指定\nCells(行番号、列番号）\n\n'セルのアドレスを表示\nCells(行番号、列番号).Address\n```\n##範囲の指定\n\n```vb\nRange(\"セル名:セル名\")\n\n'空白のセルで囲まれた範囲を取得(表を取得したりするのに便利）\nRange(\"セル名\").CurrentRegion 'セルは範囲内のどこでも可\n```\n\n##シートにある行の数を計算\n\n```vb\nRows.Count\n```\n\n##シートにある列の数を計算\n```vb\nColumns.Count\n```\n##表の最終行を取得\n\n```vb\n'表の中から下に向かって指定する場合\nRange(\"セル名\").CurrentRegion.End(xlDown).Row\n\n'ワークシートの一番下から上へ範囲を特定する場合\nRange(\"列名\"&Rows.Count).End(xlUp).Row '列名は、表の中のどの列でも可\n\n'Cellsを使ってワークシートの一番下から上へ範囲を特定する場合\nCells(Rows.Count,行番号).End(xlUp).Row\n```\n\n##表の最終列を取得\n\n```vb\n'表の中から右に向かって指定する場合\nRange(\"セル名\").CurrentRegion.End(xlToRight).Column\n\n'ワークシートの一番右から左へ範囲を特定する場合\nCells(行番号,Columns.Count).End(xlToLeft).Column '行番号は、表の中のどの行でも可\n```\n\n##ワークシートの中で値が入っている最後の行を取得する\n```vb\n'セルの種類から特定する方法\nCells.SpecialCells(xlCellTypeLastCell).Row\n\n'ワークシートから特定する方法\nワークシート.UsedRange.Rows.Count\n```\n","user":"arata0520","created_at":"2021-03-29T14:38:46+09:00","updated_at":"2021-03-29T15:58:11+09:00"},{"url":"https://qiita.com/hayato1130/items/1c714fc5e7ed12128e0c","title":"pandas で文字コードがShift-JISであるcsvファイルを読み込む方法","body":"## 方法\n\n`codecs`というライブラリを用いることで、文字コードがShift-JISであるcsvファイルを読み込むことができます。\n\n```python\nimport pandas as pd\nimport codecs\n\nwith codecs.open('path_to_file', 'r', 'Shift-JIS', 'ignore') as file:\n        temp = pd.read_table(file, delimiter=\",\")\n```\n\n## 参考\n- https://qiita.com/niwaringo/items/d2a30e04e08da8eaa643\n","user":"hayato1130","created_at":"2021-03-29T14:36:27+09:00","updated_at":"2021-03-29T14:36:27+09:00"},{"url":"https://qiita.com/hiro-tech1192/items/e83e2453f361e5b427be","title":"AWSでControl Towerを使わずにマルチアカウントを実装してみた（④GuardDuty編）","body":"# はじめに\n前回記載した①概要編、②Organizations編、③CloudTrail編の続きとなります。今回はOrganizations内の全アカウント、全リージョンに対しGuardDutyを有効化する方法を記載します。\n今回の前提となるマルチアカウント環境の全体的な構成や、GuardDutyで何ができるか？については以下の概要編を参照ください。\n\nhttps://qiita.com/hiro-tech/items/b9f88efe542ac534637e\n\n\n# 全体構成\n概要図はこんな感じです。Organizations内に複数のアカウントがありますが、これらのアカウントのGuradDutyを有効化します。さらに、全リージョンに対してGuardDutyを適用します。\n\n![010_kouseizu.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/be8d02b2-cbbd-232a-c3bd-193c4099ee20.png)\n\n\n# 対応手順\n以下、対応手順を記載します。Organizationsコンソールは現時点では画面デザインが新しいものと古いものの両方を使えますが、今回は新しい方を使っていきます。\n\n## GuardDutyの委任（東京リージョン）\nまずはOrganizationsのメンバーアカウント（セキュリティアカウント）に対し、GuardDutyの権限を委任します。これにより、セキュリティアカウントで組織内のGuardDutyをコントロールできるようになります。以降の手順は管理アカウントで実施します。\n\n管理アカウントでコンソールにログイン後、東京リージョンに切り替えます。続いてGuardDutyコンソールを開きます。画面内の「今すぐ始める」をクリックします。\n![020.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/6d60fa23-6294-e22f-d065-8b98c30baa17.png)\n\n\n下記の画面が表示されるので、「委任された管理者アカウントID」にセキュリティアカウントのID（12桁の数字）を入力します。\n![030.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/4245253d-f06c-ea07-e087-71c79c943249.png)\n\n\n管理者の委任が完了しました。\n![040.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/9b04ad74-ce08-66cb-77a7-09080335a155.png)\n\n\n\n## GuardDuty有効化（東京リージョン）\nここからは委任先のセキュリティアカウントで操作を行います。\nセキュリティアカウントのAWSコンソールへログイン後、東京リージョンへ切り替えます。続いてGuardDutyコンソールを開き、左メニューの「設定→アカウント」をクリックします。画面上部に青いバーが出ていますので、「有効化」ボタンをクリックします。\n![050.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/40828c90-20a6-f3ee-ed9a-9fc689fba95a.png)\n\n\n無事有効化されました。この時点で、選択されている１リージョン（ここでは東京）に対し、Organizations内の全アカウントのGuardDutyが有効になります。\n![060.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/1cdd42ca-68ee-79ba-5421-bf8ebd3ee330.png)\n\n\n## GuardDutyの委任（その他リージョン）\nさて、この時点では東京リージョン以外のGuardDutyは無効化されている状態です。上でやったのと同じことを繰り返してもよいですが、ここでは委任操作をCLIで実施したいと思います。\n最近CloudShellという便利なサービスが出たのでこれを利用してみます。管理アカウントでAWSコンソールを開き、とりあえず東京リージョンを選択した状態でCloudShellコンソールを起動します。\n※下記は検索窓に「CloudShell」と打った状態です\n![070.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/cda55c34-4199-5088-fc4f-32cc879d0738.png)\n\n\nしばらく経つと以下の画面が表示されます。恐らくですが、裏で何がしかのコンテナが割り当てられて起動しているものと思われます。このコンソール上でAWS CLIの実行が可能です。ブラウザ上でCLI操作まで完結してしまうとは、何とも素晴らしい時代になったものです。。\n![080.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/7a03e48e-6bd3-ad18-01ed-dc4ca66968bc.png)\n\n\nというわけで全リージョン分の委任コマンドを実行します。委任先のアカウントIDには12桁の数字を入力してください。また下記のコマンドは東京リージョンも含めていますので、必要に応じ外してください。\n\n```\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"ap-northeast-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"ap-northeast-2\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"ap-northeast-3\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"ap-south-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"ap-southeast-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"ap-southeast-2\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"ca-central-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"eu-central-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"eu-north-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"eu-west-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"eu-west-2\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"eu-west-3\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"sa-east-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"us-east-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"us-east-2\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"us-west-1\"\naws guardduty enable-organization-admin-account --admin-account-id 委任先のアカウントID --region \"us-west-2\"\n```\n\n## GuardDuty有効化（その他リージョン）\nセキュリティアカウントのAWSコンソールへログイン後、上記東京リージョンで対応したのと同じ要領で、画面からGuardDutyを有効化していきます。手順は全く同じなので割愛します。\n\n\n# 最後に\n無事全リージョン、全アカウントでGuardDutyを有効化することができました。次回はAWS Configの有効化方法について書ければと思っています。\n\n今回の記事が誰かのお役に立てると幸いです。\n","user":"hiro-tech1192","created_at":"2021-03-29T14:34:04+09:00","updated_at":"2021-03-29T14:34:04+09:00"},{"url":"https://qiita.com/kurosuke1117/items/1b32e2e7944f1200a7cc","title":"Laravel PDF日本語化で一部文字化けが起きる時の対処","body":"# 環境\n\n* PHP 7.2\n* Laravel 6.x\n* Composer library\n    * `barryvdh/laravel-dompdf`\n\n# 事象\n前提の日本語対応済み。\n請求書のPDFで`ご請求金額`と表示されるはずが、`ご☒☒☒☒`といった感じで一部の日本語が文字化けを起こす。\n\n# 前提\n日本語対応\n\n1. `barryvdh/laravel-dompdf`ライブラリをインストール\n1. IPAからフォントダウンロード\n1. `storage/fonts/`配下に配置\n1. inline cssで`@font-face` `font-family`定義\n\n# 対処\n\n1. `storage/fonts`配下に自動生成されるファイル削除。\n    * dompdf_font_family_cache.php\n    * ipag-bold_*.ttf\n    * ipag-bold_*.ufm\n    * ipag-bold_*.ufm.php\n    * ipag-normal_*.ttf\n    * ipag-normal_*.ufm\n    * ipag-normal_*.ufm.php\n    * Times-Bold.afm.php\n    * Times-Roman.afm.php\n2. 念の為、キャッシュ一式クリアする\n    * `php artisan optimize:clear`\n\n","user":"kurosuke1117","created_at":"2021-03-29T14:33:19+09:00","updated_at":"2021-03-29T14:33:19+09:00"},{"url":"https://qiita.com/fukuhito/items/1ba179e47ca8bff31ced","title":"コンテナLambdaをデプロイしてみた（躓いたポイントとリソース削除）","body":"## はじめに\nAWS builders-flashにコンテナLambdaの記事が出ていたので試してみました。\n躓いたポイントと試した後に実行したリソース削除コマンドだけ書いておきます。\n\nhttps://aws.amazon.com/jp/builders-flash/202103/new-lambda-container-development/\n\n## 躓いたポイント\n\n##### awscli 2.1.6 未満だとコマンド実行エラーになる\n\n> aws lambda create-function \\\n     --function-name func1-container  \\\n     --package-type Image \\\n     --code ImageUri=\\${ACCOUNTID}.dkr.ecr.\\${REGION}.amazonaws.com/func1@\\${DIGEST} \\\n     --role ${ROLE_ARN}\n\nコンテナLambdaは新しくサポートされた機能なので、バージョンは最新化すべきですね。\n<details><summary>2.1.5と2.1.6の必須パラメータの違い</summary><div>\n\n```bash:bash\n\n#必須項目が変わっているので、2.1.5以前でコンテナLambda作成コマンドを叩くとエラーになります\n\ndocker run --rm -ti -v ~/.aws:/root/.aws amazon/aws-cli:2.1.5 lambda create-function help\n#コマンド結果抜粋\nSYNOPSIS\n    create-function\n  --function-name <value>\n  --runtime <value>\n  --role <value>\n  --handler <value>\n  [--code <value>]\n  [--description <value>]\n\ndocker run --rm -ti -v ~/.aws:/root/.aws amazon/aws-cli:2.1.6 lambda create-function help\n#コマンド結果抜粋\nSYNOPSIS\n    create-function\n  --function-name <value>\n  [--runtime <value>]\n  --role <value>\n  [--handler <value>]\n  [--code <value>]\n  [--description <value>]\n```\n\n</div></details>\n\n##### amazon/aws-cliでawsコマンドを実行していると環境変数が正しくセットされない\n\n> REGION=\\$(aws configure get region)\n> ACCOUNTID=\\$(aws sts get-caller-identity --output text --query Account)\n\n\namazon/aws-cliを利用した場合としない場合で出力結果が違うよう。\n<details><summary>ローカルのawscliとamazon/aws-cliの出力結果の違い</summary><div>\n\n```bash:bash\n#amazon/aws-cliを利用すると余計な内容が出力されているので、amazon/aws-cliの実行結果を直接環境変数に入れると、環境変数を使う際にコマンド実行エラーが起きる\n#amazon/aws-cliを使ってもよいやり方があるのかも知れないですが、今回はローカルにawscliを入れて実行しました。\n\nalias aws\n#aliasがない状態\naws sts get-caller-identity --output text --query Account | cat -e\n#コマンド結果\nXXXXXXXXXXXX$\n\nalias aws='docker run --rm -ti -v ~/.aws:/root/.aws amazon/aws-cli:2.1.32'\naws sts get-caller-identity --output text --query Account | cat -e\n#コマンド結果\n^[[?1h^[=^MXXXXXXXXXXXX^[[m^M$\n^M^[[K^[[?1l^[>%\n```\n\n</div></details>\n\n##### IAMRoleのポリシー不足で権限エラー\nできるだけ最小権限で実行したく、ポリシーを見直しました。まだ小さくできると思います。\n<details><summary>今回設定したポリシー</summary><div>\n\n```bash:bash\n\"ecr:BatchCheckLayerAvailability\"\n\"ecr:BatchDeleteImage\"\n\"ecr:BatchGetImage\"\n\"ecr:CompleteLayerUpload\"\n\"ecr:CreateRepository\"\n\"ecr:DeleteLifecyclePolicy\"\n\"ecr:DeleteRepository\"\n\"ecr:DeleteRepositoryPolicy\"\n\"ecr:DescribeImageScanFindings\"\n\"ecr:DescribeImages\"\n\"ecr:DescribeRepositories\"\n\"ecr:GetDownloadUrlForLayer\"\n\"ecr:GetLifecyclePolicy\"\n\"ecr:GetLifecyclePolicyPreview\"\n\"ecr:GetRepositoryPolicy\"\n\"ecr:InitiateLayerUpload\"\n\"ecr:ListImages\"\n\"ecr:ListTagsForResource\"\n\"ecr:PutImage\"\n\"ecr:PutImageScanningConfiguration\"\n\"ecr:PutImageTagMutability\"\n\"ecr:PutLifecyclePolicy\"\n\"ecr:ReplicateImage\"\n\"ecr:SetRepositoryPolicy\"\n\"ecr:StartImageScan\"\n\"ecr:StartLifecyclePolicyPreview\"\n\"ecr:UploadLayerPart\"\n\"iam:CreateRole\"\n\"iam:DeleteRole\"\n\"iam:PassRole\"\n\"lambda:CreateFunction\"\n\"lambda:DeleteFunction\"\n\"lambda:InvokeFunction\"\n```\n\n</div></details>\n\n## コンテナLambdaをデプロイしてみる\nここはAWS builders-flashと同じなので、ここには記載しません。\n\n## 不要リソースを削除\n試したあとはリソース削除しておきたいので削除コマンドを記載。\n\n```bash:bash\naws lambda delete-function --function-name func1\naws lambda delete-function --function-name func1-container\naws ecr delete-repository --repository-name func1 --force\naws iam delete-role --role-name lambda-ex\n```\n","user":"fukuhito","created_at":"2021-03-29T14:32:48+09:00","updated_at":"2021-03-29T14:35:44+09:00"},{"url":"https://qiita.com/H-Toshi/items/73a92ea5708953ae6851","title":"PHP 関数は同一ファイル内であれば宣言より前に記述しても呼び出し可能。呼び出しは大文字と小文字を区別しない。","body":"#関数の呼び出しについてのメモ\n\n例）\n\n```php\n<?php \n<?php \necho \"上です\\n\";\nhoge();\n\nfunction hoge(){\n    echo \"hogeですファイル内から呼べます\\n\";\n    echo \"関数は同一ファイルであれば宣言より前に記述しても呼べます\\n\";\n}\n\necho \"下です\\n\";\nhoge();\n\necho \"関数は大文字と小文字を区別しない\\n\";\nHOGE();\n\necho \"小文字と大文字を混ぜても平気\\n\";\nhoGe();\n\n/*\n上です\nhogeですファイル内から呼べます\n関数は同一ファイルであれば宣言より前に記述しても呼べます\n下です\nhogeですファイル内から呼べます\n関数は同一ファイルであれば宣言より前に記述しても呼べます\n関数は大文字と小文字を区別しない\nhogeですファイル内から呼べます\n関数は同一ファイルであれば宣言より前に記述しても呼べます\n小文字と大文字を混ぜても平気\nhogeですファイル内から呼べます\n関数は同一ファイルであれば宣言より前に記述しても呼べます\n*/\n\n```\n\n宣言の前後で関数が呼び出せていることを確認できる。\n","user":"H-Toshi","created_at":"2021-03-29T14:26:51+09:00","updated_at":"2021-03-29T14:31:36+09:00"},{"url":"https://qiita.com/RSdesign/items/34b1188b404a8c05fcf2","title":"スマホでも100vhを安定させる方法","body":"#はじめに\nコンテンツの高さを100vhで指定した時に、pcだと問題なくても、スマホだとレイアウトが崩れることがある。\n原因は、アドレスバーやキーボードなどがviewportの高さを圧迫してしまうから。\nこの記事では、スマホでも100vhを維持してレイアウトを崩さない方法をjsを使ってご紹介したいと思います。\n\n##ウィンドウの高さを取得して、min-heightで指定する\n`height:100vh;`では、高さが可変してしまいますが、**min-height**で指定してあげれば、それ以下のサイズになることはありません。\n\n```javascript:index.js\nlet sp_height = window.innerHeight;\ndocument.documentElement.style.setProperty(\"--sp_height\", `${sp_height}px`);\n```\nまず、１行目の記述でスマホの画面高を`window.innerHeight`で取得して、変数`sp_height`に代入します。取得した高さ`sp_height`は、２行目の記述で、scssの変数`--sp_height`に代入します。\n\n```scss:index.scss\n.sp_height{\n  height: 100vh;\n  min-height: var(--sp_height);\n}\n```\nscssで、`var(--sp_height);`とプロパティの値に記述することで、jsとリンクさせることができます。\n無事、min-heightが設定できました。\n#まとめ\n**min-height**を指定することで、アドレスバーやキーボードによってviewportが圧迫されたとしても、ウィンドウの高さ分はコンテンツの最低高として確保されるのでレイアウトが崩れる心配がありません。100vh指定は、スマホだと表示崩れなどが懸念されますが、回避策はいくつかあると思いますので今回記事で紹介した内容も一つの対策として、皆様の参考になれば幸いです。\n","user":"RSdesign","created_at":"2021-03-29T14:21:48+09:00","updated_at":"2021-03-29T14:21:48+09:00"},{"url":"https://qiita.com/H-Toshi/items/83540832341c9f17382d","title":"PHP unset(), implode(), explode(), in_arrayの使い方","body":"#各関数の意味\n###unset\n変数の割り当てを解除する\n###implode\n配列を引数に指定した文字で区切り文字列として結合する\n###explode\n文字列を指定した値を区切りにして配列に分割する\n###in_array\n配列の中から指定した値があるか確認する\n\n例）\n\n```php\n<?php \n\n\n//unset\n$foo = 'test';\necho $foo.\"\\n\";\nunset($foo);// 変数を削除する\necho 'hoge'.\"\\n\";\necho $foo.\"unset\\n\";\necho 'hoge2'.\"\\n\";\n\n/*\ntest\nhoge\nunset　//unset()によってtestunsetとならず「unset」のみがechoされている\nhoge2\n*/\n\n\n//implode\n$arr = [\"one\",\"two\",\"three\"];\necho implode($arr).\"\\n\";// onetwothre ←第一引数に分割する値を入れないと配列を単純に結合する。\necho implode(\",\", $arr).\"\\n\";// one,two,three ←引数を指定した事で第一引数の「,」を配列のインデックスごとに挿入して結合している\n\n\n//explode\n$str = \"one,two,three\"; // one,two,three\nvar_dump(explode(\",\", $str));\n/*\narray(3) {\n  [0]=>\n  string(3) \"one\"\n  [1]=>\n  string(3) \"two\"\n  [2]=>\n  string(5) \n  */\n//↑第一引数で指定した「,」で文字列を分割し配列を作っている\n\n\n$search_arr = ['remon','stroberry','apple'];\n\nif(in_array('apple',$search_arr)){\n    echo 'リンゴがあります';\n}else{\n    echo 'リンゴはありません';\n}\n//リンゴがあります\n//第一引数で指定した値が配列内にあればtrueを返す（なければfalseを返す）。\n```\n","user":"H-Toshi","created_at":"2021-03-29T14:18:30+09:00","updated_at":"2021-03-29T14:18:30+09:00"},{"url":"https://qiita.com/qjuliar/items/2a8c35a0ef64f321ee39","title":"Pandas 構文メモ","body":"## 目的\n\nたまに使う構文をさっと使えるようにメモ\n\n## \n\n### 特定の文字列を含む\n\nstrがないとエラーになる\n\n```\ndf['xxx'].str.contains('yyy')\n```\n\n","user":"qjuliar","created_at":"2021-03-29T14:12:08+09:00","updated_at":"2021-03-29T14:12:08+09:00"},{"url":"https://qiita.com/miriwo/items/1dcc55e16790a5d3f7b8","title":"リーダブルコードの読み方 ほぼ個人メモ","body":"# 目的\n\n- リーダブルコードという技術書を読んでみて自分に合った読み方を見つけたのでまとめておく\n\n# 詳細\n\n- 読んだ本\n    - リーダブルコード: [https://www.amazon.co.jp/dp/4873115655/ref=cm_sw_em_r_mt_dp_97MYJ3X5JEN95S49YD0P](https://www.amazon.co.jp/dp/4873115655/ref=cm_sw_em_r_mt_dp_97MYJ3X5JEN95S49YD0P)（アマゾンのリンクですがアフィリンクではないので安心してクリックしていただいて大丈夫です。）\n\n# この本の概要（ネタバレにならない程度の内容のまとめ記事を別途記載予定）\n\n1. 読みやすいソースコードの書き方が書いてある。\n1. 「初心者エンジニアはとりあえず読んだほうが良い技術書」として取り上げられる事が多い。\n1. 初心者エンジニアだけではなくベテランエンジニアさんも読んでいらっしゃる。\n1. もともと著者は海外の方で日本語訳されたものが多く出回っている。\n\n# 個人的におすすめの読み方（完全自分向け）\n\n- 章の題名を読む→章末に箇条書きにされているまとめを読む→内容を読む\n    - 必ず章末に箇条書きでその章のまとめが記載されている。先にそっちを呼んだほうが内容が入ってきやすかった。\n    - 内容がわかりにくいということではなく、単純に結論ファーストのほうが自分は理解しやすかった。\n    - 日本語訳されていると入っても元は海外の方が書いた本なので若干理解しにくい部分も合った。（主に言い回し的な意味）\n    - 自分の文章読解力が低い可能性も大いにあるので皆さんに合った読み取り方法を見つけてみてください。\n- 例文として記載されているソースはあんまり気にしなくていいかも\n    - 自分はPHPしかほぼ読めない。ただの本には例文としてJava、Python、Ruby、JavaScript、などなど様々なソースが乗っている。\n    - もちろんソースにからめて解説や実例が記載されているので重要ではあるが、自分も含めて初心者エンジニアの方はせいぜい1~2個くらいしかなれている言語はない。\n    - 真面目にあまり知らない言語の例文を読む必要はないと思う。\n    - 「あ、多分この辺こんな処理してそう」「その処理はたしかに一緒に書かないほうがいいかもね〜」くらいの軽い気持ちでスルーすれば良いかもしれない。\n    - こちらも自分の読解力と技術力が低い可能性は大いにある。\n- ちょっと苦手な部分はさっと読み飛ばして2週目を読む、今の自分に必要そうな部分だけ読むのもありかも\n    - 実際に実装してみないとイメージが沸かないことが結構あった。\n    - 少なからずソースを書いた経験がなくてこれから言語について学ぶ方は実感が沸かないかもしれない。\n    - 業務や自分の勉強と平行して一周目はさっと読み、実務で必要になったら必要そうな部分（変数の命名方とか、ネストの深さとか、ソースのコメントとか）をピンポイントで読み直すのもありかもしれない。\n    - 大切なのは自分が必要としている知識がリーダブルコードに記載されていることを知っていることなのかも。\n    - 一周目は「今時分が抱えている課題はリーダブルコードのこの辺に書いてあったかも」を知るためにざっと読むことが大切っぽい。\n","user":"miriwo","created_at":"2021-03-29T14:04:28+09:00","updated_at":"2021-03-29T14:04:28+09:00"},{"url":"https://qiita.com/ccaiueo/items/1d26ab3ae254bde883b0","title":"プロジェクトクリーン時のCheckstyleエラー","body":"## 事象\nCheckStyle使用環境下でクリーンした際に<font color=\"red\"> 'Got an exception - expecting xxx, found EOF'</font>エラーが出る\n\n`<module name=\"TreeWalker\"></module>` 間や\n`<module name=\"Checker\"></module>` 間に以下を追加しても直らない\n\n```\n<property name=\"charset\" value=\"UTF-8\"/>\n```\n\n## 原因\nCheckstyleプラグインのバージョンが古い\n\n\n## 解決方法\nCheckStyleのバージョンを上げる\n<br>\nHELP ＞ Install New Software ＞ Add\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/243523/07c21a11-86bc-f6ea-074c-fdf2fe12e375.png)\n`https://checkstyle.org/eclipse-cs/update`\n<br>\n※インストール時のエラー\nhttps://logroid.blogspot.com/2012/05/eclipse-no-repository-found-containing.html\n上記と同様のエラーが出たが何故か自分はプロキシ設定＆再起動してから実施解消した\n<br>\n\n### 再起動してバージョンが上がっていることを確認\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/243523/662e3f0e-8b06-a132-80c3-4e0476a273f0.png)\n\n### クリーン再実施\n以下のようなエラーが発生したが、参考URL実施で解消\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/243523/7f5c8308-3c6e-29c7-8b2c-f15e1c13b195.png)\n【参考】https://qiita.com/ponsuke0531/items/02d3761c83ec2e0681d0\n\n\n\n<br>\nわりと削除したり直したりしないといけなかった（左：修正後）\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/243523/42712a57-66d0-7646-fccb-1f753b9e5202.png)\n","user":"ccaiueo","created_at":"2021-03-29T14:03:40+09:00","updated_at":"2021-03-29T14:03:40+09:00"},{"url":"https://qiita.com/x87/items/9c8014524d903126ec29","title":"vimで連続した文字の周りを装飾する","body":"#概要\n`aiueoWWWpiyo`という文字列は`:%s/\\v((.)\\2+)/!\\1!`を実行すると`aiueo!WWW!piyo`になる。\n#詳細\n`\\v`はvimのvery magicという機能を使うという意味。\n\n`()`はグループ化で、マッチしたものを`\\1`のように参照できる。この番号は何個目の括弧かを記述する。\n\n```:vim\naiiiueo\n:%s/\\v(a)(iii)(ue)/\\1\\3\\2\n\naueiiio\n```\n\n`()`は`()`の中に入れられる。外側が1でそこから数える。\n\n```:vim\ngreeting\n:%s/\\v(([a-z])(ee))/\\3\\2\n\ngeerting\n```\n\n`\\1`は検索の段階で使用できる。\n\n```:vim\nthatthatthat\n:%s/\\v(that)\\1/this\n\nthisthat\n```\n\n連続した文字は`(.)\\1+`のようにするとマッチする。\n\n```:vim\napple book ddddc\n:%s/\\v(.)\\1+/m/g\n\namle bmk mc\n```\n\n\n\n\n","user":"x87","created_at":"2021-03-29T13:59:02+09:00","updated_at":"2021-03-29T14:00:51+09:00"},{"url":"https://qiita.com/REON/items/d3782b60918b362fb3f0","title":"【Swift】TargetedExtensionとは","body":"#はじめに\n僕のSwiftで最も好きな文法はExtensionです笑\nTargetedExtensionというものがあるらしいので、みていきましょう。\n\n#Extensionとは？\n詳細なエクステンションの説明は省きますが、エクステンションは以下のように構造体やクラス、プロトコルを拡張してメソッドなどを追加できます。\n例を見てみましょう。\n\n```swift\nextension Int {\n    var minus10: Self {\n        return self - 10\n    }\n    func plus100() -> Self {\n        return self + 100\n    }\n}\nprint(200.minus10) //190\nprint(200.plus100().plus100().minus10) //390\n```\nこちらも合わせてご覧ください([メソッドチェーン](https://qiita.com/REON/items/780f341b5b80ae4c9e6b))\n\n#TargetedExtensionとは?\n前項の例だといいのですが、命名によってはこのメソッドは既にあるものなのか、自分で作ったものなのかわからない場合がありますし、Xcodeの予測変換でメソッドやプロパティが自分で作った数だけ多くなるので、見辛くなってしまうかもしれません。できればXcodeの補完を汚さずに、自作のメソッドなどにアクセスしたいです。\nこのような時に役に立つのがTargetedExtensionです。\n前項のプログラムを修正していきましょう。\n\n```swift \nprotocol SomeComapatible {\n    associatedtype ComapatibleType\n    var own: ComapatibleType { get }\n}\n\nclass Some<T> {\n    private let base: T\n    init(_ base: T) {\n        self.base = base\n    }\n}\n\nextension SomeComapatible {\n    var own: Some<Self> {\n        return Some(self)\n    }\n}\n\nextension Int: SomeComapatible { }\n\nextension Some where T == Int {\n    var minus10: Int {\n        return base - 10\n    }\n    func plus100() -> Int {\n        return base + 100\n    }\n}\n```\n\nこうすることで、以下のように`own`を間に挟まないと`minus10`プロパティや`plus100`メソッドにアクセスできないようにできました。\n\n```swift \nprint(1000.minus10) //エラー\nprint(1000.own.plus100()) //1100\n```\n\n#解説\n###ステップ1\nこのプロトコルを採用したものは`own`プロパティを持つようにする。\n\n```swift\nprotocol SomeComapatible {\n    associatedtype ComapatibleType\n    var own: ComapatibleType { get }\n}\n```\n###ステップ2\n`Int`に先ほどのプロパティを準拠させます。しかし、`own`プロパティの実装がありませんので、次で実装しましょう。\n\n```swift \nextension Int: SomeComapatible { }\n```\n###ステップ3\n以下のように実装します。`Some<Self>`の`Self`はプロトコル`SomeComapatible`を準拠させた具体的な型なので、今回は`Int`ですね。\nそして、`return Some(self)`の`self`は`print(1000.own.plus100())`このように書いた時の`1000`のことです。\nこのように、ジェネリクスも用いてあげることで、`Int`だけでなく`String`などでも同じ`own`を利用する事ができます。\n\n```swift \nclass Some<T> {\n    private let base: T\n    init(_ base: T) {\n        self.base = base\n    }\n}\n\nextension SomeComapatible {\n    var own: Some<Self> {\n        return Some(self)\n    }\n}\n```\n###ステップ4\nでは、具体的にメソッドなどを定義していきます。\n\n```swift\nextension Some where T == Int {\n    var minus10: Int {\n        return base - 10\n    }\n    func plus100() -> Int {\n        return base + 100\n    }\n}\n```\nこの`minus10`と`plus100`は`T`が`Int`の時のみ使えると言う条件を付け足しました。\n`base`は`Int`なので、実際は`1000`などが入ってきます。\n\n#おわりに\n[メソッドチェーン](https://qiita.com/REON/items/780f341b5b80ae4c9e6b)はこのような考慮がかけています。ぜひ、この記事を参考に書き換えてみてください。\n","user":"REON","created_at":"2021-03-29T13:58:32+09:00","updated_at":"2021-03-29T14:05:12+09:00"},{"url":"https://qiita.com/beertmp/items/f1c80332ec2a55eeed42","title":"ゴジラvsコング","body":"\nゴジラvsコングフルムービーを見る\n\n見る http://bit.ly/Godzillavskong2021\n![7.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1251603/6b2f5854-3f73-8f82-30f1-5eba06398665.jpeg)\n\n\n","user":"beertmp","created_at":"2021-03-29T13:58:10+09:00","updated_at":"2021-03-29T13:58:10+09:00"},{"url":"https://qiita.com/k3ntar0/items/6193d6b8841132faaf82","title":"Flutter で pod install が失敗する [!] The 'Pods-Runner' target has transitive dependencies that include statically linked binaries","body":"\n## 出力されているエラー\n\n```sh\n$ pod install\nAnalyzing dependencies\ncloud_firestore: Using Firebase SDK version '6.33.0' defined in 'firebase_core'\nfirebase_analytics: Using Firebase SDK version '6.33.0' defined in 'firebase_core'\nfirebase_core: Using Firebase SDK version '6.33.0' defined in 'firebase_core'\nfirebase_messaging: Using Firebase SDK version '6.33.0' defined in 'firebase_core'\nfirebase_remote_config: Using Firebase SDK version '6.33.0' defined in 'firebase_core'\nDownloading dependencies\n[!] The 'Pods-Runner' target has transitive dependencies that include statically linked binaries: (/path-to/ios/Flutter/Flutter.framework)\n```\n\n## 解決方法\nPodfileの `use_frameworks!` をコメントアウトする\n\n```sh\ntarget 'Runner' do\n  👇 コメントアウト\n  # use_frameworks! \n  use_modular_headers!\n\n  flutter_install_all_ios_pods File.dirname(File.realpath(__FILE__))\nend\n```\n\n以上です\n\ncf. https://github.com/flutter/flutter/issues/20045#issuecomment-409492211\n","user":"k3ntar0","created_at":"2021-03-29T13:57:31+09:00","updated_at":"2021-03-29T13:57:31+09:00"},{"url":"https://qiita.com/toki_k/items/a95229217ec7ea9186c5","title":"Github 初push時のエラー ~ src refspec main does not main any","body":"githubで新しくプロジェクトを作成して、ローカルの物をpushしようとした時に遭遇するエラーの解決方法のメモです。\n\n#手順/エラー内容\n\ngithubで新しくプロジェクトを作成すると以下の表示が見つかります。\n\n```\n…or push an existing repository from the command line\ngit remote add origin git@github.com:.........\ngit branch -M main\ngit push -u origin main\n```\n従って実行すると、以下の様なエラーになってしまいます。\n\n###git branch -M main 時のエラー\n\n```\n$ git branch -M main\nerror: refname refs/heads/master not found\nfatal: Branch rename failed\n```\n\n###git push -u origin main 時のエラー\n\n```\n$ git push -u origin main\nerror: src refspec main does not main any\nerror: failed to push some refs to 'https://github.com/.../.git'\n```\n\n#解決方法\n\n###git branch -M main 時のエラー\ngit checkout -b でブランチを作れます。\n\n```\ngit checkout -b main\n``` \nこれでmainブランチに行けます。\n\n###git push -u origin main 時のエラー\n\ngit add して\n\n```\ngit add .\n```\nコミットします。\n\n```\ngit commit -m 'First Commit'\n```\n\nすると、無事にpushできる様になります。\n\n###参考資料\n[【Git】初プッシュ時にsrc refspec master does not match anyとエラーになる](https://www.mtioutput.com/entry/git-pusherror-refspec)\n","user":"toki_k","created_at":"2021-03-29T13:52:24+09:00","updated_at":"2021-03-29T13:52:24+09:00"},{"url":"https://qiita.com/d0ne1s/items/4bc26378c1eb7f9a19cc","title":"【Rails】SendGridでメール送信(2021年3月)","body":"SendGridの仕様がもろもろ変わったっぽいので改めて使い方をまとめる。\n\n## アカウント作成\nうろ覚えだけど、日本の代理店(構造計画研究所)を通して契約すると、「サービス提供者のドメインのメールアドレスから申し込まない」みたいな制約があった記憶。受託開発とかだと面倒。\nなので代理店を遠さずに、以下のURLからアカウントを作成した。\n\nhttps://sendgrid.com/\n\n確認用メールが届くのでリンクを踏んで有効化。\n\n## sender identity(差出人情報)の登録\nログイン後の画面。\n![ 2021-03-26 12.11.54.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/244893/e6bb4a75-3f91-5fae-4459-58451fbad654.png)\n\n指示の通り、sender identityの登録を登録する。\n「Create a single sender」「Authenticate a domain」の2つの方法があるけど、前者が推奨とのこと。\n\n![ 2021-03-26 12.13.53.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/244893/864dbd88-fae4-ad25-5214-f6ec3628a1b9.png)\n\n表示されるフォームに情報を入力する。\n![ 2021-03-26 12.15.37.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/244893/008b1c7c-f476-ad77-19e6-aa6260b92ab4.png)\n\n- From Name\n  - 受信者に表示される差出人名\n- From Email Address\n  - メール送信者のメールアドレスとして表示される\n  - このアドレスの持ち主かチェックするため、登録後このアドレスに確認メールが届く\n      - リンク踏めばログインしなくてもverifyできる\n- Reply to\n  - 受信者が返信する時の宛先にセットされるアドレス\n- Nickname\n  - 差出人情報を一意に識別するための名前\n  - この名前がメール受信者に表示されることはない\n\nなお、このページを再度表示したい時は`Marketing Campaigns` > `Senders`からアクセスできる。\n\nhttps://sendgrid.kke.co.jp/docs/Tutorials/B_Marketing_Mail/marketing_campaigns1.html\n\n## Railsアプリからメールを送信\n#### メール送信の2種類の方法\nSendGridを使ったメール送信には「Web API」「SMTP」の2種類の方法がある。公式はWeb APIを推奨している。\n\nhttps://sendgrid.kke.co.jp/blog/?p=5009\n\n注意点として、Web APIを使うと、ActionMailerを使ったメール送信が難しくなる。\nhttps://github.com/eddiezane/sendgrid-actionmailer\nhttps://techracho.bpsinc.jp/yamada/2018_12_22/67222\n上記のように、WebAPIを使いながらActionMailerで送信するgemや手法がいくつかヒットしたが、私のRails6の環境ではうまくいかなかった。\n\n今回は、Web APIを使い、Action Mailerは使わずにメールを送信することにした。\n\n#### APIキーを取得\n- `Email API` > `Integration Guide` > `Web API` > `Ruby`を選択\n- `2.Create an API key`にAPIキーの名前(なんでも良い)を入力し`Create key`をクリック\n- 表示されたAPIキーを環境変数に保存\n\n#### gemをインストール\n```rb:Gemfile\ngem 'sendgrid-ruby'\n```\n```zsh\n$ bundle install\n``` \n\n#### メール送信処理を実装\n```zsh\n$ touch app/models/send_email.rb\n```\n```rb:app/models/send_email.rb\nclass SendEmail\n  require 'sendgrid-ruby'\n  include SendGrid\n\n  def self.test_email\n    from = Email.new(email: 'dev@example.jp') # SendGridの管理画面でSenderに登録したアドレス\n    to = Email.new(email: 'hogehoge@gmail.com') # 送信したいアドレス\n    subject = 'テストホゲホゲ'\n    content = Content.new(type: 'text/plain', value: 'ハローハロー')\n    mail = Mail.new(from, subject, to, content)\n\n    sg = SendGrid::API.new(api_key: ENV['SENDGRID_WEB_API_KEY'])\n    response = sg.client.mail._('send').post(request_body: mail.to_json)\n  end\nend\n```\n\n#### 送信テスト\n```zsh\n$ rails c\n> SendEmail.test_email\n=> #<SendGrid::Response:0x00erererc9650\n @body=\"\",\n @headers=\n  {\"server\"=>[\"nginx\"],\n   \"date\"=>[\"Mon, 29 Mar 2021 02:47:15 GMT\"],\n   \"content-length\"=>[\"0\"],\n   \"connection\"=>[\"close\"]\n```\n\nメールが届くことを確認\n\n### その他\nメール送信のオプションは以下のAPI仕様書を確認\n\nhttps://sendgrid.kke.co.jp/docs/API_Reference/Web_API_v3/Mail/index.html\n\nメール内のリンクがsendgrid用に置換されるのが嫌な場合、`Settings` > `Tracking` > `Click Tracking`設定から無効化できる。\n\nhttps://support.sendgrid.kke.co.jp/hc/ja/articles/206253421-%E3%83%A1%E3%83%BC%E3%83%AB%E6%9C%AC%E6%96%87%E5%86%85%E3%81%AEURL%E3%81%8C%E5%8B%9D%E6%89%8B%E3%81%AB%E7%BD%AE%E6%8F%9B%E3%81%95%E3%82%8C%E3%81%A6%E3%81%97%E3%81%BE%E3%81%84%E3%81%BE%E3%81%99-%E8%A7%A3%E9%99%A4%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%99%E3%81%8B-\n","user":"d0ne1s","created_at":"2021-03-29T13:50:50+09:00","updated_at":"2021-03-29T14:12:41+09:00"},{"url":"https://qiita.com/hiro_koba_jp/items/c69bcde42d36d3842e8d","title":"Google SpreadsheetsのデータをAmazon Redshiftに自動同期して、Lookerで可視化してみる","body":"## 概要\n\nGoogle Spreadsheets(スプレッドシート)に集められたデータを分析にかけるとき、更新がない数十件程度のデータであれば、BIツール上に手作業でグラフを作成することができます。しかし、分析用のデータはたいてい常に更新があり、最新のグラフを維持し続けることは難しいものです。そこで、DWH（データウェアハウス）にデータを自動で統合することが必要になるでしょう。\n\n今回は[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)という分析基盤向けデータ統合サービスを利用してGoogle Spreadsheetsのデータを自動で抽出できるよう設定し、DWHへの統合・データポータルの可視化までをやってみます。\n\nデータの転送手段として採用する[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)は、Google Spreadsheetsの他にも、様々な広告・CRM・DBなどのデータソースに対応しています。\n[troccoの使い方まとめ（CRM・広告・データベース他）](https://qiita.com/hiro_koba_jp/items/2b2caa040804e402bda7)\n![Spreadsheets_to_Redshiftアイコン.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/c3b3a28c-04e7-411c-2899-4d59f789b2d4.png)\n\n\n\n\n## ゴール\n↓画像のようなデータから\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/b6a8ba6f-c333-d344-6b32-49aaa4d5c26a.png)\n\n\n\n\n\n↓画像のようなグラフをを30分くらいで作り上げます（作成後は自動で最新値に更新することも可能です）\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/537f48bb-e04e-4937-f455-446fe6869f46.png)\n\n\n\n## こんな人におすすめ\n・スプレッドシートに集まるデータを毎回DWHに転送するのは面倒\n・Googleフォームを利用したアンケートの結果などを自動的に分析できるようにしたい\n・スプレッドシート上だけでの分析では不十分なので手軽にDWHへ統合したい\n\n## 1. DWHと同期する手段の選定\n### 1-1. DWHの選定\nまずはデータを集約する場所である、DWH（データウェアハウス）を選定します。\n\n* Amazon Redshift\n* Google BigQuery\n* MySQLやPostgreSQL\nなど\n\n今回はAmazon Redshiftを利用しましょう。\n\n### 1-2. Google SpreadsheetのデータをAmazon Redshiftに転送する方法\nAmazon Redshiftにデータを集約することが決まったので、続いては転送するための手段を検討します。\n\n1. CSV形式でエクスポートしたGoogle Spreadsheetsのデータを直接Amazon Redshiftのクラスターへ転送する\n1. APIを用いた連携を構築する\n1.  [trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)を利用し、画面上の設定のみで転送する。\n\n１は単発の分析でしたら可能ですが、収集したデータをその都度更新し続けることは困難です。２の方法ではAPIプログラミングに関する知識が必要で、非エンジニアには手が出しにくい、あるいは構築までに大きな時間的コストが必要となります。\n今回はデータの自動更新が可能、かつ複雑なプログラミングの知識もそれほど必要としない４の[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)を利用してみたいと思います。\n\n## 2. troccoでGoogle Spreadsheets→Amazon Redshiftの転送自動化\n### 2-0. 事前準備\nデータ転送のためには[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)のアカウント、データ元となるスプレッドシートにアクセスできるGoogleアカウント、Amazon Redshiftを操作するためAWSのアカウントが必要です。\n\n[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)は無料トライアルを実施しています。ぜひ事前に申し込み・登録しておいてください。\n[https://trocco.io/lp/index.html](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)\n（申込の際に、この記事を見た旨を記載して頂ければご案内がスムーズに行えます）\n\n\n\n### 2-1. 転送元・転送先を決定\n[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)にアクセスして、ダッシュボードから「転送設定を作成」のボタンを押します。\n<img width=\"1792\" alt=\"qiita_20200827_2.png\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/697569/098f74e5-a834-6b9f-0ea2-2b9c592a6169.png\">\n\n\n\n転送元に「Google Spreadsheets」を指定し、転送先に「Amazon Redshift」を選択して転送設定作成ボタンを押します。\n![転送先設定.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/f94f2b84-ac04-266e-fb78-ac5c20f0eda3.png)\n\n\n\n設定画面になるので必要な情報を入力していきます。\n### 2-2. Google Spreadsheetsとの連携設定\nまずはこの転送設定に名前をつけ、後で見返したときなんの設定かわかるようなメモを入力しておきます。複数のユーザーで転送設定を共有する機能もあるので、一度作成した設定をチーム内で使い回すことができます。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/4b59a1fc-051f-c02a-4fa1-b320e29ddbc1.png)\n\n\n次に「転送元の設定」内の「接続情報を追加」ボタンを押します。事前に接続情報を設定しておけば「接続情報を読み込み」から呼び出すことが可能です。\n![スプシ接続設定.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/c8f43a84-ffbe-624b-077f-dfd8bfb2c72b.png)\n\n\n別のタブで接続情報の新規作成画面が開きます。Googleアカウントとの連携が可能です。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/97c0a2a8-fdee-d61b-72d2-6001e55d0923.png)\n\n![接続設定.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/fe716bac-3d09-7160-86ee-54c83a0460f3.png)\n\n\n\n\n再度転送設定画面に戻り、接続情報の「再読込」ボタンを押すと、先ほど作成した接続情報が選択できるようになります。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/0efe9d9e-cf60-9d53-b0f3-db67f8afbb6f.png)\n\n### 2-3. Google Spreadsheetsからのデータ抽出設定\n次に、どのようなデータを取得するかを設定していきます。\n今回は[e-Stat](https://www.e-stat.go.jp/)から取得した、日本の各宗教の信者に関する以下のサンプルデータを用いて分析を行ってみます。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/b95874bb-1cf6-986d-eee5-69502f6ead20.png)\n\n\n\n必要なデータを入力していきます。\n![転送元設定.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/2e98bb55-b578-4868-7ca8-5f0aca1f2581.png)\n\n\n\n\n\n\n### 2-4. 転送先Amazon Redshiftの設定\n転送元と同じく、「接続情報を追加」を押すと別のタブが開くので必要な情報を入力します。事前に設定しておくことでこちらもすぐに呼び出すことが可能です。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/18410059-f4a5-c7f8-277b-f809b2b5bf4a.png)\nRedshiftとの接続設定が完了したら転送に必要な情報を記入していきます。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/b9ec9345-15ce-2888-0034-8ff91269a9fe.png)\n\n\nこれで入力は完了です。「保存して自動データ設定・プレビューへ」をクリックし、確認作業に進みましょう。\n\n\n### 2-5. データのプレビュー\n転送元のデータがプレビューされました。先程設定したシートから取り込んだデータが表示されています。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/c8ec0288-ab78-3597-89ed-11248ddab4ff.png)\n\n\nデータが正常に転送されてることが確認できました。\nこの画面ではマスキング設定・文字列の置換・暗号化といった設定も可能なほか、転送元・転送先に応じたオプション設定が可能です。(下の画像はRedshiftを利用した際のオプション設定です)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/0c275815-cb47-c3e3-1af6-34f995461023.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/e4f830b7-f937-9928-e8ab-da446589101d.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/db2aa0c4-501f-8685-25b7-64085c55e655.png)\n\n\n\n\n\n\n\n### 2-6. ジョブの実行\nこれで設定は終わりです。「実行」ボタンを押してAmazon Redshiftにデータを送ります。\n![設定確認.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/4e43fb4c-bfc7-dcea-f351-cbe443be23bd.png)\n\n\nこれで転送は完了です！\n\n## 3. Redshiftでプレビューを確認\n[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)上の設定に従ってデータが転送されているはずです。\nプレビューで確認してみます。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/68e8ce54-d80e-c5d2-a2e3-1fbc25f83c73.png)\n\n\n\n\n\n転送されていることが確認できました！\n## 4. Lookerを用いた可視化\n###4-1.グラフ作成の準備\n転送されたデータをLookerで可視化していきます。  \nまずはAmazon RedshiftとLookerを接続します。\nLookerを開いて、「管理」タブの「Connections」を開きます。「Add connections」からデータベースを追加します。\n![Looker接続先追加.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/026c379d-5c20-c690-980e-2a18b0f615eb.png)\n\n\n接続に必要な情報を入力していきます。\n![Redshift接続設定.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/645dff73-7d10-783a-6cd6-d2d7c5e9be47.png)\n\n下部のテストボタンから接続を確認したら、エディタでモデルとビューの定義を行いましょう。これで可視化の準備が整いました。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/56a60694-20e0-dbfd-2016-68cb0672dd49.png)\nモデルとビューの書き方は[公式ドキュメント](https://docs.looker.com/ja/data-modeling/getting-started/model-development#adding_a_new_view_from_an_existing_database_table)が参考になるかと思います。\n\n###4-2.グラフの作成\nトップページに戻り、新規のダッシュボードを作成します。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/af07477b-211b-5ae4-ed2c-64f5d065a954.png)\n「ダッシュボードの編集」、「タイルの追加」から先ほどモデルとビューを定義したExploreを選択しましょう。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/1b28b016-61e8-d84f-b377-c24def498ddd.png)\nディメンション（縦軸）、メジャー（横軸）として定義されたデータが表示されています。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/7153f653-c2fb-63b0-8569-620b802e28c3.png)\n試しにディメンションとして「Area」と「Year」を、メジャーとして「Buddhism」を使用し、日本における仏教信者数の変動を可視化するとこのようなグラフができました。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/23b61cc9-f336-4b89-ed25-bf5ec3f9e222.png)\nこのままでは少し見づらいので、フィルター機能を用いて地域を「関東」に限定し、折れ線グラフに変更してみましょう。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/83399cfc-ebfc-84b9-2c9d-8411fb42a60e.png)\n日本の仏教信者数は1990年と1997年を境に大きく増加しているようです。\nこちらをタイルとして保存し、このダッシュボードの説明テキストのタイルも追加します。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/84f94962-89c5-4a5e-76cc-c980f858ade4.png)\n\n他の宗教の信者数のグラフも追加するとこのようなタイルができました！\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1071783/537f48bb-e04e-4937-f455-446fe6869f46.png)\n\n## まとめ\nいかがでしたでしょうか。[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)を使用することで、絶えず更新されていくGoogle Spreadsheetsのデータでも自動でAmazon Redshiftにまとめていくことができるほか、100万規模の大きなデータからそうではない小さなデータまで、複雑なコーディングをせず[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)の画面上の設定だけでデータを転送することができます。\n実際に弊社サービスの[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)においても、マーケティングKPI等をこのような流れで収集・分析しています。\nぜひ広告データ分析の際にはご活用いただければと思います。\n[https://trocco.io/lp/index.html](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)\n\n実際に試してみたい場合は、[無料トライアル](https://trocco.io/inquiry_trial/new?utm_medium=social&utm_source=qiita&utm_campaign=spreadsheets_to_redshift)を実施しているため、この機会にぜひ一度お試しください。（申込時にこの記事を見たという旨を記載していただければスムーズにご案内することができます）\n\nその他にも広告やデータベースなど、様々な分析データをETL・転送した事例をまとめました。\n[troccoの使い方まとめ（CRM・広告・データベース他）](https://qiita.com/hiro_koba_jp/items/2b2caa040804e402bda7)\n","user":"hiro_koba_jp","created_at":"2021-03-29T13:37:01+09:00","updated_at":"2021-03-29T13:37:01+09:00"},{"url":"https://qiita.com/dsuzu88/items/5110fb2b4b7234d2d99e","title":"Html.ActionLinkを使うとhrefに「?Length=4」がついてしまう","body":"##起こったこと\nViewで@Html.ActionLinkを使ってaタグを作成すると、hrefに「?Length=4」がついてしまう。\n\n```C#:CSHTML\n@Html.ActionLink(\"About\", \"About\", \"Home\", new { @class = \"btn btn-primary\" })\n```\n\n##原因\nコントローラーを直で書いているのが原因みたい。\n>string routeValuesのオブジェクト「Home」を取得します。MVCはこれをパブリックプロパティを検索してルート値に変換します。stringオブジェクトの場合、唯一のパブリックプロパティはLengthであり、Lengthパラメータでルートが定義されないため、プロパティ名と値がクエリ文字列パラメータとして追加されます。\n\n##対処\nstring controllerNameにべた書きせずにstring routeValuesに設定する。\n\n```C#:CSHTML\n@Html.ActionLink(\"About\", \"About\", new { controller = \"Home\" }, new { @class = \"btn btn-primary\" })\n```\n","user":"dsuzu88","created_at":"2021-03-29T13:35:57+09:00","updated_at":"2021-03-29T13:35:57+09:00"},{"url":"https://qiita.com/shikumiya_hata/items/392281eed7ec3a2cfafc","title":"[JavaScript] いつものタグ入力UIを、少し簡単にするTagify","body":"# Tagify\n\n2021年のトレンドになっているらしいのでやってみた。\n\nhttps://iainfreestone.hashnode.dev/10-trending-projects-on-github-for-web-developers-12th-march-2021\n\n## ドキュメント\n\n### 公式\nhttps://yaireo.github.io/tagify/\n### GitHub\nhttps://github.com/yairEO/tagify\n\n## サンプル\n\n<p class=\"codepen\" data-height=\"500\" data-theme-id=\"light\" data-default-tab=\"css,result\" data-user=\"shikumiya_hata\" data-slug-hash=\"yLgJZze\" style=\"height: 500px; box-sizing: border-box; display: flex; align-items: center; justify-content: center; border: 2px solid; margin: 1em 0; padding: 1em;\" data-pen-title=\"Tagify\">\n  <span>See the Pen <a href=\"https://codepen.io/shikumiya_hata/pen/yLgJZze\">\n  Tagify</a> by ハタユウジ@コーポレートエンジニア (<a href=\"https://codepen.io/shikumiya_hata\">@shikumiya_hata</a>)\n  on <a href=\"https://codepen.io\">CodePen</a>.</span>\n</p>\n<script async src=\"https://production-assets.codepen.io/assets/embed/ei.js\"></script>\n\n```html:html\n<p>\n  <label for='tags'>1. テキストボックス内にタグ</label>\n  <input id=\"tags\" name='tags' value='javascript, ライブラリ' autofocus>\n</p>\n<p>\n  <label for='tagsOutside'>2. テキストボックスの外にタグ</label>\n  <input id='tagsOutside' name='tags-outside' class='tagify--outside' value='javascript, ライブラリ' placeholder='タグを書くのもwhitelistから選択もできる'>\n</p>\n<p>\n  <label for='tagCustom'>3. 見た目カスタマイズ</label>\n  <input id=\"tagCustom\" class='customLook' value='javascript, ライブラリ'><button type=\"button\">+</button>\n</p>\n```\n\n※CSSは長いので省略\n\n```javascript:js\n/* 1. テキストボックス内にタグ */\nvar inputInside = document.querySelector('input[name=tags]');\nvar tagifyInside = new Tagify(inputInside);\n\n/* 2. テキストボックスの外にタグ */\nvar inputOutside = document.querySelector('input[name=tags-outside]');\nvar tagifyOutside = new Tagify(inputOutside, {\n  whitelist: ['javascript', 'js', 'ライブラリ', 'library'], //デフォルトで選択可能なタグ候補\n  dropdown: {\n    position: \"input\",\n    enabled : 0 \n  }\n});\n\n/* 3. 見た目カスタマイズ */\nvar inputCustomLook = document.querySelector('.customLook'),\n    tagify = new Tagify(inputCustomLook, {\n      dropdown : {\n        position: 'text',\n        enabled: 1\n      }\n    }),\n    button = inputCustomLook.nextElementSibling;\n\nbutton.addEventListener(\"click\", onAddButtonClick)\n\n// ＋ボタン押下時\nfunction onAddButtonClick(){\n    tagify.addEmptyTag() // 新しいタグを追加\n}\n\n```\n\nちなみに、valueを取り出すとこんな風になってます。\n\n```javascript:value\n[\n  {\"value\":\"javascript\"},\n  {\"value\":\"ライブラリ\"}\n]\n```\n","user":"shikumiya_hata","created_at":"2021-03-29T13:31:54+09:00","updated_at":"2021-03-29T14:01:24+09:00"},{"url":"https://qiita.com/yuyuyu555/items/760a0cba804e7eb07487","title":"いい感じのランダムの色が欲しいなぁって時にこれ。","body":"例えば10個のいい感じのランダムの色が欲しいって時。\nガチのランダムにすると意味わからない変な色が出来上がったりしてしまうので。\nっていうものをメモ程度に残しておきます。\n意外と使える！\n\nhueの部分の分母を欲しい個数にするだけです。\nsaturationとbrightnessに関しては自分の好みの色味にしてください。\n\n下記コードそのまま使用した際にはこんな感じの色が出力されます。\n~~似てる色があるとか言わないで~~\n`#CC8B29`\n`#ABCC29`\n`#49CC29`\n`#29CC6A`\n`#29CCCC`\n`#296ACC`\n`#4929CC`\n`#AB29CC`\n`#CC298B`\n`#CC2929`\n\n```swift.swift\nlet colorList = \n   [\n    UIColor(hue: 0/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 1/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 2/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 3/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 4/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 5/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 6/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 7/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 8/10, saturation: 0.8, brightness: 0.8, alpha: 1),\n    UIColor(hue: 9/10, saturation: 0.8, brightness: 0.8, alpha: 1)\n   ]\n```\n\n```java.java\n    /*\n    * いい感じの色のリストを指定数分作成する\n    * colorCount: 色の数\n    * brightness: 色味 0.0~1.0\n    * */\n    private int[] createRandomColorList(int colorCount, float brightness) {\n        float [] f = new float[3];\n        f[1] = brightness;\n        f[2] = brightness;\n        int[] cList = new int[colorCount];\n        for (int i = 0; i < colorCount; i++) {\n            f[0] = 360f * (i+1)/colorCount;\n            cList[i] = Color.HSVToColor(f);\n        }\n        return cList;\n    }\n\n```\n","user":"yuyuyu555","created_at":"2021-03-29T13:31:12+09:00","updated_at":"2021-03-29T13:31:12+09:00"},{"url":"https://qiita.com/hiedaeih/items/f3489269362c71230bc1","title":"Matplotlib Tips - よく使うコード集 -","body":"今回は[Matplotlib](https://matplotlib.org/)について、自分が良く使うコードの部品を以下に書いていきます。\n解説については、冒頭に挙げた参考ページを見ていただければと思います。また、各項目にもリンクを貼ってあります。項目ごとのリンク集としても使えるかなと思います。\n\n随時更新していきます。\n\n動作確認：Python 3.7.9､Matplotlib 3.3.1\n\n# よく参考にするページ\n - [グラフの基本構造 -Anatomy of a figure-(本家サイトより)](https://matplotlib.org/gallery/showcase/anatomy.html#sphx-glr-gallery-showcase-anatomy-py)  \n - [Python♪提出資料で使えるmatplotlibグラフ書式例1](https://snowtree-injune.com/2020/02/02/matplotlib-example1-py001/)\n - [Python♪提出資料で使えるmatplotlibグラフ書式例2](https://snowtree-injune.com/2020/05/16/matplotlib-example2-py004/)\n - [Python matplotlib 説明図を書いてみる（改訂版）](https://qiita.com/damyarou/items/eafcf27aa1a7852d32e9) \n\n# 基本設定\n- [matplotlibで日本語](https://qiita.com/yniji/items/3fac25c2ffa316990d0c)\n- [Matplotlib が PC で追加のフォントをインストールしなくても日本語を表示できるようになった] (https://blank-oldstranger.com/2018/11/08/matplotlib-japanese/)\n- [参考：フォントについて](https://tsutawarudesign.com/yomiyasuku3.html)\n\n\n ```python\nimport matplotlib.pyplot as plt\nimport numpy as np\n%matplotlib inline\n\n# 日本語の使用\nfrom matplotlib import rcParams\nrcParams['font.family'] = 'sans-serif'\nrcParams['font.sans-serif'] = ['Meirio', 'Hiragino Maru Gothic Pro', 'Yu Gothic', \n                               'Takao', 'IPAexGothic', 'IPAPGothic', \n                               'VL PGothic', 'Noto Sans CJK JP']\n```\n# 色の設定\n- [List of named colors](https://matplotlib.org/stable/gallery/color/named_colors.html#sphx-glr-gallery-color-named-colors-py)\n- [matplotlib 色一覧の作成](https://qiita.com/damyarou/items/f8af87a62681161afce5)\n- [matplotlib で指定可能な色の名前と一覧](https://pythondatascience.plavox.info/matplotlib/%E8%89%B2%E3%81%AE%E5%90%8D%E5%89%8D)\n\n ```python\n\n\n```\n\n以下、更新中\n\n","user":"hiedaeih","created_at":"2021-03-29T13:21:29+09:00","updated_at":"2021-03-29T13:23:49+09:00"},{"url":"https://qiita.com/kawada2017/items/311281996641d8180cf3","title":"fbprophetをSPSS Modelerで使用する","body":"SPSS Modelerの拡張モデルノードを使って、時系列予測ライブラリのfbprophetを使ってモデリングとスコアリングを行いました。\n\n\n■環境\nModeler 18.2.2\npython 3.7.7(Anaconda)\nfbprophet 0.7.1\nWindows 10\n\n#サンプルストリーム\n\nhttps://github.com/hkwd/210224PythonExtension/raw/master/fbprophet/210324fbprophet.str\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/566e9e4f-ab98-eb89-825d-f7684e5dae9d.png)\n\n#事前作業\nfbprophetのpipでの導入は、前提となるpystanのWindowsへの導入が難しく、またpystan3からWindowsのサポートがなくなりpystanの導入記事へのリンクも切れてしまっています。\n\nhttps://facebook.github.io/prophet/docs/installation.html#installation-in-python\n\nですので、今回は以下の記事を参考にSPSSの拡張ノードでAnacondaのPythonを利用できるようにしておきます。\n\nhttps://qiita.com/kawada2017/items/04f525727725d199723c\n\nAnacondaでconda-foregeからパッケージを導入して、options.cfgの設定まで行っておきます。私の環境ではAnaconda Public Repositoryのパッケージではうまく動きませんでした。\n\n上の手順でつくったバッチファイルなどを使って、conda環境にPATHが入った状態でModelerを起動しておきます。\n\n\n#fbprophetの導入\n以下のコマンドでconda-forgeからfbprophetを導入します。\n\n```console:コマンド\n#conda config --append channels conda-forge\nconda activate modeler\nconda install -c conda-forge fbprophet\nconda list\n```\n```console:結果\n(base) C:\\Users\\dsuser01>conda activate modeler\n\n(modeler) C:\\Users\\dsuser01>conda install -c conda-forge fbprophet\nCollecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: C:\\Users\\dsuser01\\.conda\\envs\\modeler\n\n  added / updated specs:\n    - fbprophet\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    arviz-0.11.2               |     pyhd8ed1ab_0         1.4 MB  conda-forge\n    bzip2-1.0.8                |       h8ffe710_4         149 KB  conda-forge\n    cftime-1.4.1               |   py37hda49f71_0         205 KB  conda-forge\n    convertdate-2.3.2          |     pyhd8ed1ab_0          37 KB  conda-forge\n    curl-7.75.0                |       hf1763fc_0         127 KB  conda-forge\n    cycler-0.10.0              |             py_2           9 KB  conda-forge\n    cython-0.29.22             |   py37hf2a7229_0         1.9 MB  conda-forge\n    ephem-3.7.7.1              |   py37h4ab8f01_1         715 KB  conda-forge\n    fbprophet-0.7.1            |   py37h1834ac0_0         567 KB  conda-forge\n    freetype-2.10.4            |       h546665d_1         489 KB  conda-forge\n    hdf4-4.2.13                |    h0e5069d_1004         1.1 MB  conda-forge\n    hdf5-1.10.6                |nompi_h5268f04_1114        19.6 MB  conda-forge\n    hijri-converter-2.1.1      |     pyhd8ed1ab_0          17 KB  conda-forge\n    holidays-0.10.5.2          |     pyhd8ed1ab_0          65 KB  conda-forge\n    jpeg-9d                    |       h8ffe710_0         366 KB  conda-forge\n    kiwisolver-1.3.1           |   py37h8c56517_1          58 KB  conda-forge\n    korean_lunar_calendar-0.2.1|     pyh9f0ad1d_0          10 KB  conda-forge\n    krb5-1.17.2                |       hbae68bd_0         856 KB  conda-forge\n    lcms2-2.12                 |       h2a16943_0         882 KB  conda-forge\n    libcurl-7.75.0             |       hf1763fc_0         292 KB  conda-forge\n    libnetcdf-4.7.4            |nompi_h3a9aa94_107         602 KB  conda-forge\n    libpng-1.6.37              |       h1d00b33_2         724 KB  conda-forge\n    libpython-2.0              |   py37h03978a9_1          47 KB  conda-forge\n    libssh2-1.9.0              |       h680486a_6         218 KB  conda-forge\n    libtiff-4.2.0              |       hc10be44_0         1.1 MB  conda-forge\n    lunarcalendar-0.0.9        |             py_0          20 KB  conda-forge\n    lz4-c-1.9.3                |       h8ffe710_0         134 KB  conda-forge\n    m2w64-binutils-2.25.1      |                5        44.3 MB  conda-forge\n    m2w64-bzip2-1.0.6          |                6         102 KB  conda-forge\n    m2w64-crt-git-5.0.0.4636.2595836|                2         3.4 MB  conda-forge\n    m2w64-gcc-5.3.0            |                6        40.8 MB  conda-forge\n    m2w64-gcc-ada-5.3.0        |                6        33.3 MB  conda-forge\n    m2w64-gcc-fortran-5.3.0    |                6        10.2 MB  conda-forge\n    m2w64-gcc-libgfortran-5.3.0|                6         342 KB  conda-forge\n    m2w64-gcc-libs-5.3.0       |                7         520 KB  conda-forge\n    m2w64-gcc-libs-core-5.3.0  |                7         214 KB  conda-forge\n    m2w64-gcc-objc-5.3.0       |                6        15.2 MB  conda-forge\n    m2w64-gmp-6.1.0            |                2         726 KB  conda-forge\n    m2w64-headers-git-5.0.0.4636.c0ad18a|                2         5.6 MB  conda-forge\n    m2w64-isl-0.16.1           |                2         655 KB  conda-forge\n    m2w64-libiconv-1.14        |                6         1.5 MB  conda-forge\n    m2w64-libmangle-git-5.0.0.4509.2e5a9a2|                2          23 KB  conda-forge\n    m2w64-libwinpthread-git-5.0.0.4634.697f757|                2          31 KB  conda-forge\n    m2w64-make-4.1.2351.a80a8b8|                2         117 KB  conda-forge\n    m2w64-mpc-1.0.3            |                3          71 KB  conda-forge\n    m2w64-mpfr-3.1.4           |                4         294 KB  conda-forge\n    m2w64-pkg-config-0.29.1    |                2         467 KB  conda-forge\n    m2w64-toolchain-5.3.0      |                7           3 KB  conda-forge\n    m2w64-toolchain_win-64-2.4.0|                0           4 KB  conda-forge\n    m2w64-tools-git-5.0.0.4592.90b8472|                2         320 KB  conda-forge\n    m2w64-windows-default-manifest-6.4|                3           5 KB  conda-forge\n    m2w64-winpthreads-git-5.0.0.4634.697f757|                2          47 KB  conda-forge\n    m2w64-zlib-1.2.8           |               10         199 KB  conda-forge\n    matplotlib-base-3.3.4      |   py37h3379fd5_0         6.7 MB  conda-forge\n    msys2-conda-epoch-20160418 |                1           3 KB  conda-forge\n    netcdf4-1.5.6              |nompi_py37h4965ef1_100         358 KB  conda-forge\n    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n    packaging-20.9             |     pyh44b312d_0          35 KB  conda-forge\n    pandas-1.2.3               |   py37h08fd248_0         9.9 MB  conda-forge\n    pillow-8.1.2               |   py37h96663a1_0         773 KB  conda-forge\n    pymeeus-0.5.10             |     pyhd8ed1ab_0         534 KB  conda-forge\n    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n    pystan-2.19.1.1            |   py37h9758500_2        35.8 MB  conda-forge\n    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n    pytz-2021.1                |     pyhd8ed1ab_0         239 KB  conda-forge\n    scipy-1.6.1                |   py37h6db1a17_0        23.1 MB  conda-forge\n    tk-8.6.10                  |       h8ffe710_1         3.2 MB  conda-forge\n    tornado-6.1                |   py37hcc03f2d_1         648 KB  conda-forge\n    xarray-0.17.0              |     pyhd8ed1ab_0         561 KB  conda-forge\n    xz-5.2.5                   |       h62dcd97_1         211 KB  conda-forge\n    zlib-1.2.11                |    h62dcd97_1010         126 KB  conda-forge\n    zstd-1.4.9                 |       h6255e5f_0         915 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:       273.0 MB\n\nThe following NEW packages will be INSTALLED:\n\n  arviz              conda-forge/noarch::arviz-0.11.2-pyhd8ed1ab_0\n  bzip2              conda-forge/win-64::bzip2-1.0.8-h8ffe710_4\n  cftime             conda-forge/win-64::cftime-1.4.1-py37hda49f71_0\n  convertdate        conda-forge/noarch::convertdate-2.3.2-pyhd8ed1ab_0\n  curl               conda-forge/win-64::curl-7.75.0-hf1763fc_0\n  cycler             conda-forge/noarch::cycler-0.10.0-py_2\n  cython             conda-forge/win-64::cython-0.29.22-py37hf2a7229_0\n  ephem              conda-forge/win-64::ephem-3.7.7.1-py37h4ab8f01_1\n  fbprophet          conda-forge/win-64::fbprophet-0.7.1-py37h1834ac0_0\n  freetype           conda-forge/win-64::freetype-2.10.4-h546665d_1\n  hdf4               conda-forge/win-64::hdf4-4.2.13-h0e5069d_1004\n  hdf5               conda-forge/win-64::hdf5-1.10.6-nompi_h5268f04_1114\n  hijri-converter    conda-forge/noarch::hijri-converter-2.1.1-pyhd8ed1ab_0\n  holidays           conda-forge/noarch::holidays-0.10.5.2-pyhd8ed1ab_0\n  jpeg               conda-forge/win-64::jpeg-9d-h8ffe710_0\n  kiwisolver         conda-forge/win-64::kiwisolver-1.3.1-py37h8c56517_1\n  korean_lunar_cale~ conda-forge/noarch::korean_lunar_calendar-0.2.1-pyh9f0ad1d_0\n  krb5               conda-forge/win-64::krb5-1.17.2-hbae68bd_0\n  lcms2              conda-forge/win-64::lcms2-2.12-h2a16943_0\n  libcurl            conda-forge/win-64::libcurl-7.75.0-hf1763fc_0\n  libnetcdf          conda-forge/win-64::libnetcdf-4.7.4-nompi_h3a9aa94_107\n  libpng             conda-forge/win-64::libpng-1.6.37-h1d00b33_2\n  libpython          conda-forge/win-64::libpython-2.0-py37h03978a9_1\n  libssh2            conda-forge/win-64::libssh2-1.9.0-h680486a_6\n  libtiff            conda-forge/win-64::libtiff-4.2.0-hc10be44_0\n  lunarcalendar      conda-forge/noarch::lunarcalendar-0.0.9-py_0\n  lz4-c              conda-forge/win-64::lz4-c-1.9.3-h8ffe710_0\n  m2w64-binutils     conda-forge/win-64::m2w64-binutils-2.25.1-5\n  m2w64-bzip2        conda-forge/win-64::m2w64-bzip2-1.0.6-6\n  m2w64-crt-git      conda-forge/win-64::m2w64-crt-git-5.0.0.4636.2595836-2\n  m2w64-gcc          conda-forge/win-64::m2w64-gcc-5.3.0-6\n  m2w64-gcc-ada      conda-forge/win-64::m2w64-gcc-ada-5.3.0-6\n  m2w64-gcc-fortran  conda-forge/win-64::m2w64-gcc-fortran-5.3.0-6\n  m2w64-gcc-libgfor~ conda-forge/win-64::m2w64-gcc-libgfortran-5.3.0-6\n  m2w64-gcc-libs     conda-forge/win-64::m2w64-gcc-libs-5.3.0-7\n  m2w64-gcc-libs-co~ conda-forge/win-64::m2w64-gcc-libs-core-5.3.0-7\n  m2w64-gcc-objc     conda-forge/win-64::m2w64-gcc-objc-5.3.0-6\n  m2w64-gmp          conda-forge/win-64::m2w64-gmp-6.1.0-2\n  m2w64-headers-git  conda-forge/win-64::m2w64-headers-git-5.0.0.4636.c0ad18a-2\n  m2w64-isl          conda-forge/win-64::m2w64-isl-0.16.1-2\n  m2w64-libiconv     conda-forge/win-64::m2w64-libiconv-1.14-6\n  m2w64-libmangle-g~ conda-forge/win-64::m2w64-libmangle-git-5.0.0.4509.2e5a9a2-2\n  m2w64-libwinpthre~ conda-forge/win-64::m2w64-libwinpthread-git-5.0.0.4634.697f757-2\n  m2w64-make         conda-forge/win-64::m2w64-make-4.1.2351.a80a8b8-2\n  m2w64-mpc          conda-forge/win-64::m2w64-mpc-1.0.3-3\n  m2w64-mpfr         conda-forge/win-64::m2w64-mpfr-3.1.4-4\n  m2w64-pkg-config   conda-forge/win-64::m2w64-pkg-config-0.29.1-2\n  m2w64-toolchain    conda-forge/win-64::m2w64-toolchain-5.3.0-7\n  m2w64-toolchain_w~ conda-forge/win-64::m2w64-toolchain_win-64-2.4.0-0\n  m2w64-tools-git    conda-forge/win-64::m2w64-tools-git-5.0.0.4592.90b8472-2\n  m2w64-windows-def~ conda-forge/win-64::m2w64-windows-default-manifest-6.4-3\n  m2w64-winpthreads~ conda-forge/win-64::m2w64-winpthreads-git-5.0.0.4634.697f757-2\n  m2w64-zlib         conda-forge/win-64::m2w64-zlib-1.2.8-10\n  matplotlib-base    conda-forge/win-64::matplotlib-base-3.3.4-py37h3379fd5_0\n  msys2-conda-epoch  conda-forge/win-64::msys2-conda-epoch-20160418-1\n  netcdf4            conda-forge/win-64::netcdf4-1.5.6-nompi_py37h4965ef1_100\n  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n  packaging          conda-forge/noarch::packaging-20.9-pyh44b312d_0\n  pandas             conda-forge/win-64::pandas-1.2.3-py37h08fd248_0\n  pillow             conda-forge/win-64::pillow-8.1.2-py37h96663a1_0\n  pymeeus            conda-forge/noarch::pymeeus-0.5.10-pyhd8ed1ab_0\n  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n  pystan             conda-forge/win-64::pystan-2.19.1.1-py37h9758500_2\n  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n  pytz               conda-forge/noarch::pytz-2021.1-pyhd8ed1ab_0\n  scipy              conda-forge/win-64::scipy-1.6.1-py37h6db1a17_0\n  tk                 conda-forge/win-64::tk-8.6.10-h8ffe710_1\n  tornado            conda-forge/win-64::tornado-6.1-py37hcc03f2d_1\n  xarray             conda-forge/noarch::xarray-0.17.0-pyhd8ed1ab_0\n  xz                 conda-forge/win-64::xz-5.2.5-h62dcd97_1\n  zlib               conda-forge/win-64::zlib-1.2.11-h62dcd97_1010\n  zstd               conda-forge/win-64::zstd-1.4.9-h6255e5f_0\n\n\nProceed ([y]/n)? y\nーーーーーーーーーーーーーーー中略ーーーーーーーーーーーーーーーーーーー\ndone\n\n(modeler) C:\\Users\\dsuser01>conda list\n# packages in environment at C:\\Users\\dsuser01\\.conda\\envs\\modeler:\n#\n# Name                    Version                   Build  Channel\narviz                     0.11.2             pyhd8ed1ab_0    conda-forge\nbrotlipy                  0.7.0           py37hcc03f2d_1001    conda-forge\nbzip2                     1.0.8                h8ffe710_4    conda-forge\nca-certificates           2020.12.5            h5b45459_0    conda-forge\ncertifi                   2020.12.5        py37h03978a9_1    conda-forge\ncffi                      1.14.5           py37hd8e9650_0    conda-forge\ncftime                    1.4.1            py37hda49f71_0    conda-forge\nchardet                   4.0.0            py37h03978a9_1    conda-forge\nconda                     4.9.2            py37h03978a9_0    conda-forge\nconda-package-handling    1.7.2            py37h6dbccfb_0    conda-forge\nconvertdate               2.3.2              pyhd8ed1ab_0    conda-forge\ncryptography              3.4.6            py37h20c650d_0    conda-forge\ncurl                      7.75.0               hf1763fc_0    conda-forge\ncycler                    0.10.0                     py_2    conda-forge\ncython                    0.29.22          py37hf2a7229_0    conda-forge\nephem                     3.7.7.1          py37h4ab8f01_1    conda-forge\nfbprophet                 0.7.1            py37h1834ac0_0    conda-forge\nfreetype                  2.10.4               h546665d_1    conda-forge\nhdf4                      4.2.13            h0e5069d_1004    conda-forge\nhdf5                      1.10.6          nompi_h5268f04_1114    conda-forge\nhijri-converter           2.1.1              pyhd8ed1ab_0    conda-forge\nholidays                  0.10.5.2           pyhd8ed1ab_0    conda-forge\nidna                      2.10               pyh9f0ad1d_0    conda-forge\nintel-openmp              2020.3             h57928b3_311    conda-forge\njpeg                      9d                   h8ffe710_0    conda-forge\nkiwisolver                1.3.1            py37h8c56517_1    conda-forge\nkorean_lunar_calendar     0.2.1              pyh9f0ad1d_0    conda-forge\nkrb5                      1.17.2               hbae68bd_0    conda-forge\nlcms2                     2.12                 h2a16943_0    conda-forge\nlibblas                   3.9.0                     8_mkl    conda-forge\nlibcblas                  3.9.0                     8_mkl    conda-forge\nlibcurl                   7.75.0               hf1763fc_0    conda-forge\nliblapack                 3.9.0                     8_mkl    conda-forge\nlibnetcdf                 4.7.4           nompi_h3a9aa94_107    conda-forge\nlibpng                    1.6.37               h1d00b33_2    conda-forge\nlibpython                 2.0              py37h03978a9_1    conda-forge\nlibssh2                   1.9.0                h680486a_6    conda-forge\nlibtiff                   4.2.0                hc10be44_0    conda-forge\nlunarcalendar             0.0.9                      py_0    conda-forge\nlz4-c                     1.9.3                h8ffe710_0    conda-forge\nm2w64-binutils            2.25.1                        5    conda-forge\nm2w64-bzip2               1.0.6                         6    conda-forge\nm2w64-crt-git             5.0.0.4636.2595836               2    conda-forge\nm2w64-gcc                 5.3.0                         6    conda-forge\nm2w64-gcc-ada             5.3.0                         6    conda-forge\nm2w64-gcc-fortran         5.3.0                         6    conda-forge\nm2w64-gcc-libgfortran     5.3.0                         6    conda-forge\nm2w64-gcc-libs            5.3.0                         7    conda-forge\nm2w64-gcc-libs-core       5.3.0                         7    conda-forge\nm2w64-gcc-objc            5.3.0                         6    conda-forge\nm2w64-gmp                 6.1.0                         2    conda-forge\nm2w64-headers-git         5.0.0.4636.c0ad18a               2    conda-forge\nm2w64-isl                 0.16.1                        2    conda-forge\nm2w64-libiconv            1.14                          6    conda-forge\nm2w64-libmangle-git       5.0.0.4509.2e5a9a2               2    conda-forge\nm2w64-libwinpthread-git   5.0.0.4634.697f757               2    conda-forge\nm2w64-make                4.1.2351.a80a8b8               2    conda-forge\nm2w64-mpc                 1.0.3                         3    conda-forge\nm2w64-mpfr                3.1.4                         4    conda-forge\nm2w64-pkg-config          0.29.1                        2    conda-forge\nm2w64-toolchain           5.3.0                         7    conda-forge\nm2w64-toolchain_win-64    2.4.0                         0    conda-forge\nm2w64-tools-git           5.0.0.4592.90b8472               2    conda-forge\nm2w64-windows-default-manifest 6.4                           3    conda-forge\nm2w64-winpthreads-git     5.0.0.4634.697f757               2    conda-forge\nm2w64-zlib                1.2.8                        10    conda-forge\nmatplotlib-base           3.3.4            py37h3379fd5_0    conda-forge\nmenuinst                  1.4.16           py37hc8dfbb8_1    conda-forge\nmkl                       2020.4             hb70f87d_311    conda-forge\nmsys2-conda-epoch         20160418                      1    conda-forge\nnetcdf4                   1.5.6           nompi_py37h4965ef1_100    conda-forge\nnumpy                     1.20.1           py37hd20adf4_0    conda-forge\nolefile                   0.46               pyh9f0ad1d_1    conda-forge\nopenssl                   1.1.1j               h8ffe710_0    conda-forge\npackaging                 20.9               pyh44b312d_0    conda-forge\npandas                    1.2.3            py37h08fd248_0    conda-forge\npillow                    8.1.2            py37h96663a1_0    conda-forge\npip                       21.0.1             pyhd8ed1ab_0    conda-forge\npycosat                   0.6.3           py37hcc03f2d_1006    conda-forge\npycparser                 2.20               pyh9f0ad1d_2    conda-forge\npymeeus                   0.5.10             pyhd8ed1ab_0    conda-forge\npyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge\npyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\npysocks                   1.7.1            py37h03978a9_3    conda-forge\npystan                    2.19.1.1         py37h9758500_2    conda-forge\npython                    3.7.7                h81c818b_4\npython-dateutil           2.8.1                      py_0    conda-forge\npython_abi                3.7                     1_cp37m    conda-forge\npytz                      2021.1             pyhd8ed1ab_0    conda-forge\npywin32                   300              py37hcc03f2d_0    conda-forge\nrequests                  2.25.1             pyhd3deb0d_0    conda-forge\nruamel_yaml               0.15.80         py37hcc03f2d_1004    conda-forge\nscipy                     1.6.1            py37h6db1a17_0    conda-forge\nsetuptools                49.6.0           py37h03978a9_3    conda-forge\nsix                       1.15.0             pyh9f0ad1d_0    conda-forge\nsqlite                    3.35.2               h8ffe710_0    conda-forge\ntk                        8.6.10               h8ffe710_1    conda-forge\ntornado                   6.1              py37hcc03f2d_1    conda-forge\ntqdm                      4.59.0             pyhd8ed1ab_0    conda-forge\nurllib3                   1.26.4             pyhd8ed1ab_0    conda-forge\nvc                        14.2                 hb210afc_4    conda-forge\nvs2015_runtime            14.28.29325          h5e1d092_4    conda-forge\nwheel                     0.36.2             pyhd3deb0d_0    conda-forge\nwin_inet_pton             1.1.0            py37h03978a9_2    conda-forge\nwincertstore              0.2             py37h03978a9_1006    conda-forge\nxarray                    0.17.0             pyhd8ed1ab_0    conda-forge\nxz                        5.2.5                h62dcd97_1    conda-forge\nyaml                      0.2.5                he774522_0    conda-forge\nzlib                      1.2.11            h62dcd97_1010    conda-forge\nzstd                      1.4.9                h6255e5f_0    conda-forge\n\n(modeler) C:\\Users\\dsuser01>\n```\n#モデルを保存するパスを作っておきます。\nモデルを保存するパスを作っておきます。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/114ade4b-3381-4dcc-2b4c-b8176f1ae3db.png)\n\n#ストリームの作成\n公式サイトのQuickStartにあるサンプルデータの[example_wp_log_peyton_manning.csv](https://raw.githubusercontent.com/facebook/prophet/master/examples/example_wp_log_peyton_manning.csv)をダウンロードして読み込みます。\n\nhttps://facebook.github.io/prophet/docs/quick_start.html\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/0aff8da2-2299-edd6-17bd-4f8e0278c38b.png)\n\n以下のようなデータが入っています。日付型のdsという列と実績値のy列があります。fbprophetはモデル作成に使う列名が決められていますので、ほかのデータを使う場合はdsとyの列名でデータを用意する必要があります。\n\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/d2b0836d-915e-980d-481e-9608dad26e2f.png)\n\n拡張モデルノードでPython for Sparkを選びます。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/49e35c42-7250-422c-d811-e2ceb4cc8697.png)\n\n以下のfbprophetのモデリングとスコアリングのスクリプトを入力します。\n\n```python:Pythonモデル作成シンタックス\n#モデルファイルの保存パス\nmodelpath='c:/temp/modelpath/'\nmodelfile='fbprophetModel.pkl'\n\n# Analytics Server 対話用のライブラリのインポート\nimport spss.pyspark.runtime\n# Analytics Serverコンテキストオブジェクト定義\nascontext = spss.pyspark.runtime.getContext()\n\n# データ読込\ndf = ascontext.getSparkInputData()\n#print(df.take(10))\n#print(df.printSchema)\n\n#pandas変換してdsでソート\ndf = df.toPandas().sort_values('ds')\n#print(df.tail(10))\n\n#dsがシリアル値でうけ渡されるのでdatetimeに変換\nimport pandas as pd\ndf['ds'] = pd.to_datetime('1970/1/1') + pd.to_timedelta(df['ds'] , unit='days')\n#print(df.tail(10))\n\n#fbprophetモデル作成\nfrom fbprophet import Prophet \nmodel = Prophet()\nmodel.fit(df)\n\n#モデルをファイルシステムに保存\nimport pickle\npickle.dump(model, open(modelpath+modelfile, 'wb'))\n```\n\n```python:Pythonモデルスコアリングシンタックス\n#モデルファイルの保存パス\nmodelpath='c:/temp/modelpath/'\nmodelfile='fbprophetModel.pkl'\n\n#予測期間の設定\nfutureperiods=365\n\n# Analytics Server 対話用のライブラリのインポート\nimport spss.pyspark.runtime\nfrom pyspark.sql.types import DoubleType, StructField \nfrom pyspark.sql.context import SQLContext\n\n# Analytics Server 対話用のライブラリのインポート\nimport spss.pyspark.runtime\n# Analytics Serverコンテキストオブジェクト定義\nascontext = spss.pyspark.runtime.getContext()\n\n#予測値列と上側予測列、下側予測列を出力スキーマに追加\noutputSchema = ascontext.getSparkInputSchema()\noutputSchema.fields.append(StructField('yhat', DoubleType(), nullable=True))\noutputSchema.fields.append(StructField('yhat_lower', DoubleType(), nullable=True))\noutputSchema.fields.append(StructField('yhat_upper', DoubleType(), nullable=True))\n\nascontext.setSparkOutputSchema(outputSchema)\n\nif not ascontext.isComputeDataModelOnly():\n\n        #ファイルシステム上のモデルを読み込む\n        import pickle\n        model = pickle.load(open(modelpath+modelfile, 'rb'))\n        \n        #スコアリングデータの読み込み\n        indf = ascontext.getSparkInputData()\n        #pandas変換してdsでソート\n        df = indf.toPandas().sort_values('ds')\n        import pandas as pd\n        df['ds'] = pd.to_datetime('1970/1/1') + pd.to_timedelta(df['ds'] , unit='days')\n \n        #スコアリング\n        future = model.make_future_dataframe(periods=futureperiods)\n        forecast = model.predict(future)\n        #インプットDataframeと外部結合をして、必要列に絞る\n        forecast = pd.concat([forecast[['ds','yhat','yhat_lower','yhat_upper']],df[['y']]], axis=1)[['ds','y','yhat','yhat_lower','yhat_upper']]\n \n        #dsをシリアル値でModelerが受け取るので変換\n        import datetime\n        forecast['ds'] = (pd.to_datetime(forecast['ds']) - pd.to_datetime('1970/1/1'))/ datetime.timedelta(days=1)\n        #print(forecast.tail(10))\n\n        #Sparkコンテキストの取得\n        sc = ascontext.getSparkContext()\n        #データの出力\n        sqlCtx = SQLContext(sc)\n        outdf = sqlCtx.createDataFrame(forecast,schema=outputSchema)\n\n        # return the output DataFrame as the result\n        ascontext.setSparkOutputData(outdf)\n```\n\n実行するとモデルナゲットができるので、テーブルノードを繋ぎます。\nテーブルノードを実行するとｙhatに予測値、yhat_lower、yhat_upperに下側予測、上側予測が出力されます。\nこのデータでは2016-01-21以降は将来の予測になっています。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/2a0ed9c4-03d3-4eed-baeb-6080cb64d5d0.png)\n\n\n時系列グラフノードを接続し、以下の設定で実行します。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/28aef3ab-a092-d4d7-4fbc-02cee9982520.png)\n\n以下のように予実の可視化が可能です。\n水色のポイントが実測値でそれ以外が予測値です。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/19150210-7af5-6789-4809-7d5d1b489bfb.png)\n\n#モデリングスクリプトの解説\n最初にモデルの保存パスを定義しています。\n本来はascontext.setModelContentFromStringでモデルナゲット内にモデルが保存できると思うのですが、どうしても失敗するために、ファイルシステム内に保存しています。\nスコアリング時にはこのファイルが必要になります。特にModeler ServerやCADSと組み合わせて実行する場合など、別のマシンでスコアリングを行う場合には、同じ場所にモデルファイルがないと動きませんので注意が必要です。\n\n\n```python:Pythonモデル作成シンタックス-モデルの保存パスを定義\n#モデルファイルの保存パス\nmodelpath='c:/temp/modelpath/'\nmodelfile='fbprophetModel.pkl'\n```\n以下でModelerとのやり取りを行うためのコンテキストオブジェクトを作っています。\n\n\n```python:Pythonモデル作成シンタックス-AnalyticsServerコンテキストオブジェクト定義\n# Analytics Server 対話用のライブラリのインポート\nimport spss.pyspark.runtime\n# Analytics Serverコンテキストオブジェクト定義\nascontext = spss.pyspark.runtime.getContext()\n```\n\n\n以下でデータを読み込んでいます。\nModelerから取得されるデータフレームはSpark DataFrameなので、sdf.toPandas()\nでpandasのDataFrameにして取り扱いやすくしています。\nまた、SparkDataFrameは順序が保証されないようなので、日付を表すds列でソートします。\n\n```python:Pythonモデル作成シンタックス-データ読込\n# データ読込\nsdf = ascontext.getSparkInputData()\n#pandas変換してdsでソート\ndf = sdf.toPandas().sort_values('ds')\n```\n\n日付型のdsがシリアル値で読み込まれるので、datetime型に変換します。\n\n```python:datetime型変換\n#dsがシリアル値でうけ渡されるのでdatetimeに変換\nimport pandas as pd\ndf['ds'] = pd.to_datetime('1970/1/1') + pd.to_timedelta(df['ds'] , unit='days')\n```\n\n以下でfbprophetのモデルを作っています。\nfbprophetには様々なパラメーターがありますが、ここではデフォルトで動かしています。\n\n```python:Pythonモデル作成シンタックス-モデル作成\n#fbprophetモデル作成\nfrom fbprophet import Prophet \nmodel = Prophet()\nmodel.fit(df)\n```\n\n最後に、生成されたモデルをpickleを使ってシリアライズして、スクリプトの先頭で定義したmodelpath+modelfileに保存しています。\n\n```python:Pythonモデル作成シンタックス-モデルをファイルシステムに保存\n#モデルをファイルシステムに保存\nimport pickle\npickle.dump(model, open(modelpath+modelfile, 'wb'))\n```\n#スコアリングスクリプトの解説\n\nモデリングスクリプトで指定したものと同じモデルファイル保存パスを指定します。\n\n```python:Pythonモデルスコアリングシンタックス-モデルファイル保存パス指定\n#モデルファイルの保存パス\nmodelpath='c:/temp/modelpath/'\nmodelfile='fbprophetModel.pkl'\n```\n\n以下ではスコアリング時の将来予測期間を指定しています。ここでは365日を指定しています。\n\n```python:Pythonモデルスコアリングシンタックス-予測期間の設定\n#予測期間の設定\nfutureperiods=365\n```\n\nモデリングスクリプトでも行ったように、Modelerとのやり取りを行うためのコンテキストオブジェクトを作っています。\nモデリングスクリプトに加えて、ここでは新しいSparkDataFrameを作成するためにSQLContextを、また新しい列をつくるためにDoubleType, StructFieldもインポートしています。\n\n```python:Pythonモデルスコアリングシンタックス-AnalyticsServerコンテキストオブジェクト定義\n# Analytics Server 対話用のライブラリのインポート\nimport spss.pyspark.runtime\nfrom pyspark.sql.types import DoubleType, StructField \nfrom pyspark.sql.context import SQLContext\n\n# Analytics Serverコンテキストオブジェクト定義\nascontext = spss.pyspark.runtime.getContext()\n```\n以下で入力データのスキーマに予測値列と上側予測列、下側予測列を追加して、出力スキーマとしています。データ型はDoubleType()を指定しています。\n\n```python:Pythonモデルスコアリングシンタックス-予測値列と上側予測列、下側予測列を出力スキーマに追加\n#予測値列と上側予測列、下側予測列を出力スキーマに追加\noutputSchema = ascontext.getSparkInputSchema()\noutputSchema.fields.append(StructField('yhat', DoubleType(), nullable=True))\noutputSchema.fields.append(StructField('yhat_lower', DoubleType(), nullable=True))\noutputSchema.fields.append(StructField('yhat_upper', DoubleType(), nullable=True))\n\nascontext.setSparkOutputSchema(outputSchema)\n```\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/633e1fed-f281-7210-9d52-c380d467b8b3.png)\n\n以下は実際にスコアリングを行う場合に以降のスクリプトを実行するという条件になります。\nここは少しややこしいところです。\nここまでのスクリプトはsetSparkOutputSchemaで出力スキーマを定義するものでした。モデルナゲットの後ろにノードを追加する場合、DataModelをComputeしてスキーマを定義することは必要ですが、実際にスコアリングしたデータは必要ありません。\nですので無駄なスコアリング処理をしないために、「スコアリングデータがいる場合にのみ」（Not isComputeDataModelOnly）、スコアリングをするスクリプトを実行するという条件を入れています。\nマニュアルに[DataModelOnly モード](https://www.ibm.com/support/knowledgecenter/ja/SS3RA7_18.2.2/modeler_r_nodes_ddita/clementine/r_pyspark_api.html)という解説があります。\n\n```python:Pythonモデルスコアリングシンタックス-スコアリング実行判定\nif not ascontext.isComputeDataModelOnly():\n```\n\n以下で、スクリプトの先頭で定義したmodelpath+modelfileからモデルをファイルシステムから読み込みます。\n\n```python:Pythonモデルスコアリングシンタックス-モデルをファイルシステムから読み込む\n        #ファイルシステム上のモデルを読み込む\n        import pickle\n        model = pickle.load(open(modelpath+modelfile, 'rb'))\n```\n\n以下で入力データを読み込んでPandasのDataFrameに変換しています。モデリングと同様にds列でソートをかけ、dsをシリアル値からdatetime型に変換しています。\n\n```python:Pythonモデルスコアリングシンタックス-スコアリングデータの読み込み\n        #スコアリングデータの読み込み\n        indf = ascontext.getSparkInputData()\n        #pandas変換してdsでソート\n        df = indf.toPandas().sort_values('ds')\n        import pandas as pd\n        df['ds'] = pd.to_datetime('1970/1/1') + pd.to_timedelta(df['ds'] , unit='days')\n```\n\n以下で、スコアリングをしています。yhatは予測値を得ています。yhat_upper、yhat_lowerは上側予測列、下側予測列を得ています。\nスコアリング結果のdataframeであるforecastには実績値yは入らないので、インプットデータと結合を行っています。\nなお、forecastにはtrendなど別のスコアリング値もありますので、必要に応じて取り出してください。\n\n```python:Pythonモデルスコアリングシンタックス-スコアリング\n        #スコアリング\n        future = model.make_future_dataframe(periods=futureperiods)\n        forecast = model.predict(future)\n        #インプットDataframeと外部結合をして、必要列に絞る\n        forecast = pd.concat([forecast[['ds','yhat','yhat_lower','yhat_upper']],df[['y']]], axis=1)[['ds','y','yhat','yhat_lower','yhat_upper']]\n```\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/223763/44b20bb2-876e-329e-b926-bcd0267a6c71.png)\n\n\nModelerに返すために日付型データのdsをシリアル変換しています。\n\n```python:Pythonモデルスコアリングシンタックス-シリアル値変換\n        #dsをシリアル値でModelerが受け取るので変換\n        import datetime\n        forecast['ds'] = (pd.to_datetime(forecast['ds']) - pd.to_datetime('1970/1/1'))/ datetime.timedelta(days=1)\n```\n\n以下で予測値列と予測列、下側予測列を追加したPandas DataFrameであるdfを、sqlCtx.createDataFrame(df,schema=outputSchema)でSparkDataFrameに変換しなおして、setSparkOutputDataでModelerに返しています。\n\n```python:Pythonモデルスコアリングシンタックス-データ出力\n        #Sparkコンテキストの取得\n        sc = ascontext.getSparkContext()\n        #データの出力\n        sqlCtx = SQLContext(sc)\n        outdf = sqlCtx.createDataFrame(forecast,schema=outputSchema)\n\n        # return the output DataFrame as the result\n        ascontext.setSparkOutputData(outdf)\n```\n\n#参考\n\nhttps://qiita.com/kawada2017/items/04f525727725d199723c\n\nhttps://qiita.com/kawada2017/items/b75cd4191ba90b91983b\n\nfbprophet Quick Start\nhttps://facebook.github.io/prophet/docs/quick_start.html\n\nPython for Spark を使用したスクリプト\nhttps://www.ibm.com/support/knowledgecenter/ja/SS3RA7_18.2.2/modeler_r_nodes_ddita/clementine/r_pyspark_api.html\n\n","user":"kawada2017","created_at":"2021-03-29T13:19:34+09:00","updated_at":"2021-03-29T13:22:07+09:00"},{"url":"https://qiita.com/sakyoyuto/items/7b6d428b78eea208cac4","title":"flutter runでError launching application on iPhone.","body":"#エラー\n\n```\n$ flutter run\n```\nすると\n\n```\nError launching application on iPhone.\n```\nと表示されてしまう。\n実機でのビルド自体はでき、インストールされた状態になるが、上記のエラーが表示されてしまうため、Hot reload等ができない。\n\n#解決法\n\nXcodeを開き、メニューからWindow -> Devices and Simuratorsでウィンドウを開き、ビルドしたい端末を右クリック。\n\nUnpair device\n\nもう一度実行で解決。\n\n（デバイスがBusyだよってのが原因ぽい。）\n","user":"sakyoyuto","created_at":"2021-03-29T13:11:27+09:00","updated_at":"2021-03-29T13:11:27+09:00"},{"url":"https://qiita.com/naname_tk/items/b39f4bcf58a928d35d9f","title":"【MySQL】複数のカラムで重複しているデータを見つける方法","body":"データ解析に使ったので、メモ\nサブクエリ内では、countを実行するだけ。\nメインクエリ内では、countが１以上のものは重複していると言えるので、以下のような形でできる。\n\n```sql\nselect * from (\n\tselect concat(column1, '-', column2) as token,\n\t\tCOUNT(*) as cnt\n\t\tFROM table_name GROUP BY (token)\n) as contents WHERE cnt > 1;\n```\n\n解析に使っただけだが、実際のプロダクションコードとしてで扱うには、あまりよくない気がする。\n","user":"naname_tk","created_at":"2021-03-29T13:04:34+09:00","updated_at":"2021-03-29T13:06:53+09:00"},{"url":"https://qiita.com/ming_hentech/private/fdf1ccd720fd1bbcfce2","title":"Qiita トラブルシューティング・失敗集 【(半)自動更新: 2021年03月29日】","body":"## Rails 6にTailwindCSSを導入して失敗【メモ書き】\nURL: https://qiita.com/guy/items/a03151613d1cde6e6591\n[@guy](https://qiita.com/guy)さん(Created at: 2021-03-29T12:34:00+09:00)\n\n## pyenvでインストール時に「BUILD FAILED (OS X 10.15.7 using python-build 20180424)」が発生した場合の対処法\nURL: https://qiita.com/kzrashi/items/80ff82d4330d51a398dc\n[@kzrashi](https://qiita.com/kzrashi)さん(Created at: 2021-03-29T12:09:25+09:00)\n\n## 【エラー】自動デプロイの際のエラー【AWS】\nURL: https://qiita.com/y-ussy/items/b76e1afa5d0a1dc1b6ba\n[@y-ussy](https://qiita.com/y-ussy)さん(Created at: 2021-03-29T11:47:56+09:00)\n\n## Nest.js/TypeORMでエラー ~ Cannot use import statement outside a module\nURL: https://qiita.com/toki_k/items/dbbb77aa0d6ebd96139c\n[@toki_k](https://qiita.com/toki_k)さん(Created at: 2021-03-29T11:35:12+09:00)\n\n## 【docker】docker-compose build  したらERROR: Service 'web' failed to build : The command '/bin/sh -c bundle install' returned a non-zero code: 7\nURL: https://qiita.com/tomo-IR/items/74d1b4762fe62dc82766\n[@tomo-IR](https://qiita.com/tomo-IR)さん(Created at: 2021-03-29T10:24:41+09:00)\n\n## 失敗から学ぶ｜「Appleでサインイン」していたIFTTTの退会\nURL: https://qiita.com/hann-solo/items/67a7abe008c767b522e1\n[@hann-solo](https://qiita.com/hann-solo)さん(Created at: 2021-03-29T09:49:31+09:00)\n\n## Rails (V1::Auth::Customers::ConfirmationsController, but didn't (Zeitwerk::NameError))\nURL: https://qiita.com/gonza_kato_atsushi/items/bd52462e2a54968ba57f\n[@gonza_kato_atsushi](https://qiita.com/gonza_kato_atsushi)さん(Created at: 2021-03-29T09:29:08+09:00)\n\n## Visual Studio 2017 で Assembly が不足しているのを解決する方法\nURL: https://qiita.com/tukiyo3/items/e9889200883ff3a8a596\n[@tukiyo3](https://qiita.com/tukiyo3)さん(Created at: 2021-03-29T08:32:24+09:00)\n\n## 【docker】db:createすると、Plugin caching_sha2_password could not be loaded...のエラーハマった話\nURL: https://qiita.com/tomo-IR/items/224d33f14561e759dd16\n[@tomo-IR](https://qiita.com/tomo-IR)さん(Created at: 2021-03-29T06:14:57+09:00)\n\n## thisなきJS エラーあり\nURL: https://qiita.com/kyokucho1989/items/3001d3bf4c67511be4d8\n[@kyokucho1989](https://qiita.com/kyokucho1989)さん(Created at: 2021-03-29T05:30:32+09:00)\n\n## 【備忘録】【エラー解決】bundle updateをするとコンフリクトエラーが返ってくるためrubyのバージョンを下げて解決\nURL: https://qiita.com/asami___t/items/64572b0384aacb35884f\n[@asami___t](https://qiita.com/asami___t)さん(Created at: 2021-03-29T00:19:25+09:00)\n\n## firebaseでError in snapshot listener: FirebaseError: Missing or insufficient permissions.というエラーが出た際の対処法\nURL: https://qiita.com/takeiin/items/a22de585f1f9f4ed1b12\n[@takeiin](https://qiita.com/takeiin)さん(Created at: 2021-03-28T23:36:09+09:00)\n\n## WiXSharpでサービスを登録する方法と、WiXSharpで日本語を含めたときにランタイムエラーになるのを防ぐ方法\nURL: https://qiita.com/nao-a/items/31fd03fe5f8867420766\n[@nao-a](https://qiita.com/nao-a)さん(Created at: 2021-03-28T22:49:45+09:00)\n\n## defer内でのエラーを考慮する。\nURL: https://qiita.com/english_muffin/items/4674269d06fd7f9d1b02\n[@english_muffin](https://qiita.com/english_muffin)さん(Created at: 2021-03-28T22:38:04+09:00)\n\n","user":"ming_hentech","created_at":"2021-03-29T13:03:26+09:00","updated_at":"2021-03-29T13:03:26+09:00"},{"url":"https://qiita.com/yoshuuua/items/ebeefffc04d966d238e4","title":"TerraformでAWS RDSのDBユーザを管理する","body":"# はじめに\n\nMySQLやPostgreSQLのユーザをTerraformで管理するときの備忘録としてこの記事を残します。\n\n# 前提条件\n\n基盤はAWS、DBはPostgreSQLでDBがいるネットワークは内部ネットワークでインターネットのアクセスがないです。TerraformはローカルPC(Mac)から実行するものとします。\n\n# 実行方法\n\n## Terraform\n\n[こちら](https://registry.terraform.io/providers/cyrilgdn/postgresql/latest/docs)のPostgreSQL用のTerraform providerを使い実行します。\n\n```bash\nprovider \"postgresql\" {\n  scheme   = \"awspostgres\" # AWSを使う場合はこれを指定\n  host     = var.db_host\n  username = \"postgres\"\n  port     = 5432\n  password = var.db_password\n\n  superuser = false\n}\n\n```\n\nバージョンはこのように指定します。\n\n```bash\n  required_providers {\n    postgresql = {\n      source  = \"cyrilgdn/postgresql\"\n      version = \"1.11.2\"\n    }\n  }\n```\n\nPostgreSQLのユーザを追加します。\n\n```bash\nresource \"postgresql_role\" \"my_role\" {\n  name     = \"my_role\"\n  login    = true\n  password = var.my_role_password\n}\n\nresource \"postgresql_grant\" \"readonly_my_role\" {\n  database    = \"test_db\"\n  role        = postgresql_role.my_role.name\n  schema      = \"public\"\n  object_type = \"table\"\n  privileges  = [\"SELECT\"]\n}\n```\n\n## ローカル\n\nローカルから直接PostgreSQLを触ることはできないので、踏み台サーバを経由してSSHトンネリングすることで、アクセスします。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/575547/70da608c-9875-39e6-54c3-140b0ff2fb61.png)\n\nsshトンネリング用のコマンドを実行します。\n\n```bash\n# ssh -N -L [ローカル側で転送に使用するPort（10000〜60000）]:[DBのHostName]:[DBが解放しているPort] -i [IdentityFile（秘密鍵のパス）] -p [踏み台が解放しているPort] [踏み台のUser]@[踏み台のHostName]\n\nssh -N -L 5432:test_db.XXX.ap-northeast-1.rds.amazonaws.com:5432 -i ~/.ssh/bastion.pem -p 22 ec2-user@XXX\n\n```\n\n後述するSSL証明書エラーになるので、ホストを偽装します。\n `/etc/hosts` に `localhost 127.0.0.1 test_db.XXX.ap-northeast-1.rds.amazonaws.com` を追加してください。\n\nこれでTerraformを実行するとPostgreSQLへのユーザ追加ができます。\n\n## Tips\n### SSL証明書エラー\n上記に記載されているsshトンネリングコマンドを実行し、\n\n```bash\nssh -N -L 5432:test_db.XXX.ap-northeast-1.rds.amazonaws.com:5432 -i ~/.ssh/bastion.pem -p 22 ec2-user@XXX\n```\n\nsshトンネリングで `localhost`の `5432`ポートにアクセスするとPostgreSQLにアクセスできるようになったので、Terraformのproviderのhost名を `locahost`に指定して、Terraformを実行させます。\n\n```bash\nprovider \"postgresql\" {\n  scheme   = \"awspostgres\" # AWSを使う場合はこれを指定\n  host     = \"localhost\"\n  username = \"postgres\"\n  port     = 5432\n  password = var.db_password\n\n  superuser = false\n}\n```\n\nそうすると、SSL証明書の確認でホスト名が異なるとエラーが出てしまいます。\n\n```bash\nError: error detecting capabilities: error PostgreSQL version: x509: certificate is valid for stg-knew-rds.coh5dxpjppgc.ap-northeast-1.rds.amazonaws.com, not localhost\n```\n\n### セッションマネージャーを使ったポートフォワード\nセッションマネージャーを使ってポートフォワードができないかと調べたが、\n結局ポートフォワードはできなかった。\n\ncf. https://dev.classmethod.jp/articles/port-forwarding-using-aws-system-manager-sessions-manager/\n","user":"yoshuuua","created_at":"2021-03-29T12:53:11+09:00","updated_at":"2021-03-29T12:54:06+09:00"},{"url":"https://qiita.com/hiro-tech1192/items/6cff6aa94c52770c89f5","title":"ChaliceとCloud9の連携方法について記載してみます（AWS）","body":"# はじめに\nみなさんChaliceはご存知でしょうか？AWSでサーバレスアプリケーションを構築する際に、爆速の開発効率を誇るフレームワークです。\n今回はこのChaliceを使い、AWS謹製のIDEであるCloud9上で開発を行うための手順について記載したい思います。\n\n# Chaliceとは何か？\n上にも記載していますが、ChaliceはAWSが開発したサーバレスアプリケーション向けのフレームワークです。Python向けのライブラリとして提供されており、pipでインストールができます。\nサーバレスフレームワークと言えばSAMやAmplifyなんかもありそれぞれ一長一短ありますが、こと開発効率においてはChaliceの右に出るものはいないと思います。（たぶん。。）\nChaliceはコマンド一発でAPI Gateway + Lambdaの環境を構築できてしまう優れものです。ゴチャゴチャ書く前にまずはサンプルコードを見て頂きましょう。\n\n```python\nfrom chalice import Chalice\napp = Chalice(app_name='example')\n\n@app.route('/')\ndef index():\n    return {'hello': 'world'}\n```\n\nChaliceでプロジェクトを作成した際に自動生成される、HELLO WORLD用のサンプルアプリケーションです。エンドポイント（/）にアクセスすると簡単なJSONを返してくれます。\nこのアプリケーションのデプロイ方法ですが、以下の通りコマンド一発でできてしまいます。（Linuxコンソールでの例です）\n\n```\n$ chalice deploy\n```\n\nこれだけで必要なLambda関数だけでなく、API Gatewayまで勝手に作ってくれます。感激です。\nエンドポイントを複数切りたい場合はこんな感じに書きます。\n\n```python\nfrom chalice import Chalice\napp = Chalice(app_name='example')\n\n@app.route('/')\ndef index():\n    return {'hello': 'world'}\n\n@app.route('/hoge')\ndef hoge():\n    return {'hello': 'hoge'}\n\n@app.route('/fuga')\ndef fuga():\n    return {'hello': 'fuga'}\n```\n\nこれだけで /、 /hoge、 /fuga という３つのエンドポイントが作れてしまいます。最高。。\nというわけで、Chaliceに興味を持たれて詳しく知りたくなった方は以下AWSのBlackBeltをご覧ください。できれば動画で見るのがよいと思います。理解度が全然違いますので。\n\nhttps://d1.awsstatic.com/webinars/jp/pdf/services/20190619_AWS-BlackBeltOnlineSeminar_DiveDeepIntoAWSChalice.pdf\n\nhttps://www.youtube.com/watch?v=u4LKbQZawaQ\n\n\n# Cloud9とは何か？\nAWS謹製の統合開発環境（IDE）です。ブラウザ上で動き、AWSコンソールにログインするだけで使えてしまうので場所を選ばずに開発を行うことができます。ブラウザさえあれば何とかなるので端末も問いません。スタバでコーヒー片手にiPadで優雅にコーディング、なんてこともできてしまいます。\n詳細については言わずもがなのBlackBeltを参照ください。動画も貼っておきます。\n\nhttps://d1.awsstatic.com/webinars/jp/pdf/services/20180613_AWS-BlackBelt-Introducing-AWS-Cloud9.pdf\n\nhttps://www.youtube.com/watch?v=3Sl6Hzcw7Bk\n\n\n# Cloud9上でChaliceを動かしてしまおう\nそんな素敵なChaliceとCloud9ですので、当然連携して使いたくなります。というわけで以下、手順をしたためていきたいと思います。\nちなみにこの手順はChalice + Cloud9でシステム開発案件を行った2020年7月頃の情報に基づいており、さらにPython初心者（Java屋）の私が知識ゼロから手探りで調べて対応したものです。間違ってるよ！ とか もっといいやり方あるよ！ とかあればお気軽にご指摘頂けると助かります。\n\n\n## Cloud9環境の作成\nまずはCloud9環境を作成します。トップメニューからCloud9コンソールに遷移し、画面上の「Create environment」をクリックしてあとはポチポチするだけです。最初に決める名前以外は全てデフォルトでもOKなので、ここで何か迷うことはないと思います。\nCloud9環境を立ち上げると、内部的には専用のEC2インスタンスが割り当てられ、このインスタンス上でCloud9が実行されることになります。\n\n\n## Cloud9用のロール作成と付与\nCloud9にはAMTCという機能が用意されており、デフォルトでONになっています。AMTCにより、AWSコンソールにログインしたユーザと概ね同じ権限がCloud9（のEC2）に与えられるため便利なのですが、全権限が付与されるわけではなく、IAMなどの一部については制限がかかるようです。\nこの状態ではChaliceが使えないため、AMTCをOFFにして専用のIAMロールをEC2へ割り当てていきたいと思います。\n\n### IAMロールの作成\nIAMコンソールから新規ロールを作成します。流れは以下の通りです。\n\n- IAMコンソールにアクセスし、左メニューの「ロール」を選択し、画面内に表示される「ロールの作成」をクリックします。\n- 続いて表示される画面で「信頼されたエンティティの種類」に「AWSサービス」を、「ユースケースの選択」に「EC2」を選択して「次へ」をクリックします。\n- 次の画面でロールを選択します。ここではAdministratorAccessを選択した前提で話を進めますが、必要に応じて権限レベルは見直してください。選択後「次へ」をクリックします。\n- 次の画面でタグを指定します。何も入れなくてOKです。\n- 最後にロール名を指定します。任意の文字列を入力後、「ロールの作成」をクリックすれば終了です。\n\n### ロールのEC2へのアタッチ\n上記で作成したロールをCloud9用のEC2インスタンスへ割り当てます。流れは以下の通りです。\n\n- EC2コンソールにアクセスし、左メニューの「インスタンス」を選択します。\n- インスタンス一覧が表示されるので、Cloud9用のEC2を選択し、「右クリック→セキュリティ→IAMロールを変更」を選択します。なおCloud9で生成したインスタンス名には「aws-cloud9-」の接頭語が割り当たるようです。\n- IAMロールの割り当て画面が表示されますので、先ほど作成したロールを選択し、「保存」ボタンをクリックします。\n\n### Cloud9でのAMTCを無効化\n先程記載した通り、デフォルトONになっているAMTCを無効化します。\nCloud9のコンソールを開き、「アイコン（9の雲マーク）→Preference」を選択します。\n![010.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/90d97241-e2ae-cb75-faf3-26c54d927c8a.png)\n\n\n設定画面が開くので、左メニューの「AWS Settings→AWS Resources」を選択。「AWS managed temporary credentials」をOFFにします。\n![020.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/87abe799-3c49-cfe4-1868-f24f0b2084b7.png)\n\n\n### Cloud9に対し、デフォルトリージョンを設定\nAMTCを無効化すると、リージョンの設定もなくなってしまうようなので、以下の手順に従い設定を入れます。\nまずは左メニューからトップ階層のディレクトリを右クリックし、「Open Terminal Here」を選択します。これによりCloud9コンソールからEC2インスタンスに対してSSHアクセスできます。超便利。\n![030.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/79c14070-b48c-69cc-6739-daa8d6e21c98.png)\n\nコンソールはこんな感じです。\n![040.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/127a39a8-2acd-a65b-f5f6-0282f32ac7f5.png)\n\n\nコンソール上で「aws configure list」を実行します。以下の通り、リージョンの割り当てはありません。\n\n```\n$ aws configure list\n      Name                    Value             Type    Location\n      ----                    -----             ----    --------\n   profile                <not set>             None    None\naccess_key     ****************V6LL         iam-role    \nsecret_key     ****************PW2P         iam-role    \n    region                <not set>             None    None\n```\n\n設定ファイルの有無を確認します。初期状態であればたぶん存在しないはずです。\n\n```\n$ ll -a ~/.aws/\ntotal 4\ndrwxr-xr-x  2 ec2-user ec2-user    6 Mar 29 01:52 .\ndrwx------ 13 ec2-user ec2-user 4096 Mar 29 01:36 ..\n```\n\nというわけで作成します。\n\n```\n$ vi ~/.aws/config\n※以下入力して保存（:wq）\n[default]\nregion = ap-northeast-1\n\n$ ll ~/.aws/\ntotal 4\n-rw-rw-r-- 1 ec2-user ec2-user 36 Mar 29 02:01 config\n\n$ cat ~/.aws/config \n[default]\nregion = ap-northeast-1\n```\n\nリージョン設定が完了しましたので、再確認します。ちゃんと入ってくれたようです。\n\n```\n$ aws configure list\n      Name                    Value             Type    Location\n      ----                    -----             ----    --------\n   profile                <not set>             None    None\naccess_key     ****************V6LL         iam-role    \nsecret_key     ****************PW2P         iam-role    \n    region           ap-northeast-1      config-file    ~/.aws/config\n\n```\n\n\n## Chaliceのインストール\n引き続きCloud9のターミナルで作業していきます。\nカレントディレクトリを確認します。/home/ec2-user/environment にいなければ移動してください。\n\n```\n$ pwd\n/home/ec2-user/environment\n```\n\nChaliceをEC2インスタンスへインストールします。\n\n```\n$ sudo pip install chalice\nWARNING: Running pip install with root privileges is generally not a good idea. Try `pip install --user` instead.\nCollecting chalice\n  Downloading https://files.pythonhosted.org/packages/26/de/79e471e7eb590586880b0e90f29742881eb60dffdc2fcb3e340db5f13367/chalice-1.22.3-py2.py3-none-any.whl (384kB)\n～～～（略）～～～\nInstalling collected packages: wcwidth, blessed, readchar, python-editor, inquirer, attrs, click, wheel, typing, mypy-extensions, chalice\nSuccessfully installed attrs-20.3.0 blessed-1.17.6 chalice-1.22.3 click-7.1.2 inquirer-2.7.0 mypy-extensions-0.4.3 python-editor-1.0.4 readchar-2.0.1 typing-3.6.4 wcwidth-0.2.5 wheel-0.36.2\n```\n\n無事インストールされました。続けてChalice用のプロジェクトを作成します。以下のコマンドをコンソール上で実行するだけでOKです。ここでのプロジェクト名はとりあえず helloworld にしました。\n　chalice new-project [プロジェクト名]\n\n```\n$ chalice new-project helloworld\nYour project has been generated in ./helloworld\n```\n\nプロジェクトができました。フォルダ構成とデフォルトで作成されるサンプルアプリ（app.py）はこんな感じです。\n![050.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1234157/432ba9bd-3687-29c5-aefb-a382eeeb53e8.png)\n\n\nサンプルアプリをデプロイしてみます。以下の通り、コマンド一発でAPI GatewayとLambdaが自動作成されます。ステキ。。なお、デプロイ前にコンソール上でプロジェクトフォルダへ移動する必要があるのでご注意ください。\n\n```\n$ cd helloworld/\n$ chalice deploy\nCreating deployment package.\nReusing existing deployment package.\nCreating IAM role: helloworld-dev\nCreating lambda function: helloworld-dev\nCreating Rest API\nResources deployed:\n  - Lambda ARN: arn:aws:lambda:ap-northeast-1:123456789:function:helloworld-dev\n  - Rest API URL: https://xxxxxx.ap-northeast-1.amazonaws.com/api/\n```\n\n上記結果の最終行にAPIのURLが記載されています。このURLからAPIをキックすることができるので、コンソールからCurlコマンドで試してみます。\n\n```\n$ curl https://xxxxxx.execute-api.ap-northeast-1.amazonaws.com/api/\n{\"hello\":\"world\"}\n```\n\n無事JSONが返却されました。とても楽ちんで素晴らしいですね。\nテストが終わったらAPI GatewayとLambdaは消しておきましょう。これもコマンド一発です。\n\n```\n$ chalice delete\nDeleting Rest API: xxxxxxxxxx\nDeleting function: arn:aws:lambda:ap-northeast-1:123456789:function:helloworld-dev\nDeleting IAM role: helloworld-dev\n```\n\n# 最後に\nCloud9＋Chaliceの連携方法と簡単な使い方だけ記載しました。次回以降はもうちょっと踏み込んだ内容を解説できればと思っています。\n\n今回の記事が誰かのお役に立てると幸いです。\n","user":"hiro-tech1192","created_at":"2021-03-29T12:45:50+09:00","updated_at":"2021-03-29T12:45:50+09:00"},{"url":"https://qiita.com/kazumawada/items/6737e44ee26037bd9cfb","title":"gemの特定のバージョンが配信停止になった時の対処法(the author of mimemagic 0.3.5 has removed it)","body":"## エラー文\n\n```bash\nFetching gem metadata from https://rubygems.org/............\nYour bundle is locked to mimemagic (0.3.5), but that version could not be found\nin any of the sources listed in your Gemfile. If you haven't changed sources,\nthat means the author of mimemagic (0.3.5) has removed it. You'll need to update\nyour bundle to a version other than mimemagic (0.3.5) that hasn't been removed\nin order to install.\n```\n\n大事な部分切り取る\n\n```bash\nthat means the author of mimemagic (0.3.5) has removed it. You'll need to update\n```\n\n## 解決方法\n\n```\nbundle update mimemagic\n```\n","user":"kazumawada","created_at":"2021-03-29T12:38:10+09:00","updated_at":"2021-03-29T12:39:01+09:00"},{"url":"https://qiita.com/guy/items/a03151613d1cde6e6591","title":"Rails 6にTailwindCSSを導入して失敗【メモ書き】","body":"\n#背景\n新しいアプリ(ボートフォリオ用)を作成のためTailwind CSSを導入に挑む\n新たな技術を学んでサクサク作れるようになれればよき\n今回もQiitaさんに投稿されている方々にお世話になりました、ありがとうございます\n\n**参考文献**\n[Tailwind on Rails](https://qiita.com/d0ne1s/items/5a2cf50167afd988e9f7)\n[RailsにTailwindCSSを導入](https://qiita.com/kazuya_minei109/items/e76ff2b0af49e69eb441)\n\n##開発環境\n- Ruby 3.0.0\n- Rails 6.1.3.1\n- tailwindcss 2.0.4\n\n##作業工程\nまずは@d0ne1sさんが投稿してくださった「[Tailwind on Rails](https://qiita.com/d0ne1s/items/5a2cf50167afd988e9f7)」の手順で進める\n\n```\n$ yarn add tailwindcss\n$ yarn tailwindcss init\n$ mkdir app/javascript/css\n$ touch app/javascript/css/tailwind.css\n```\n```app/javascript/css/tailwind.css\n@import \"tailwindcss/base\";\n@import \"tailwindcss/components\";\n@import \"tailwindcss/utilities\";\n```\n```app/javascript/packs/application.js\nimport Rails from \"@rails/ujs\"\nimport Turbolinks from \"turbolinks\"\nimport \"channels\"\n\nimport '../css/tailwind.css'; // 追記\n\nRails.start()\nTurbolinks.start()\n```\n```postcss.config.js\nmodule.exports = {\n  plugins: [\n    require('postcss-import'),\n    require('postcss-flexbugs-fixes'),\n    require(\"tailwindcss\"),  // 追記\n    require(\"autoprefixer\"), // 追記\n    require('postcss-preset-env')({\n      autoprefixer: {\n        flexbox: 'no-2009'\n      },\n      stage: 3\n    })\n  ]\n}\n```\n```app/views/layouts/application.html.erb\n// 削除　<%= stylesheet_link_tag 'application', media: 'all', 'data-turbolinks-track': 'reload' %>\n// 追記　<%= stylesheet_pack_tag 'application', media: 'all', 'data-turbolinks-track': 'reload' %>\n```\nこれで準備は整ったはず!!\nでは動作確認を行うため準備を・・・・\n\n```app/views/tests/index.html.erb\n<div class=\"max-w-sm mx-auto bg-white shadow-lg rounded-lg overflow-hidden\">\n  <div class=\"sm:flex sm:items-center px-6 py-4\">\n    <img class=\"block mx-auto sm:mx-0 sm:flex-shrink-0 h-16 sm:h-24 rounded-full\" src=\"https://randomuser.me/api/portraits/women/17.jpg\" alt=\"Woman's Face\">\n    <div class=\"mt-4 sm:mt-0 sm:ml-4 text-center sm:text-left\">\n      <p class=\"text-xl leading-tight\">Erin Lindford</p>\n      <p class=\"text-sm leading-tight text-gray-600\">Customer Support Specialist</p>\n      <div class=\"mt-4\">\n        <button class=\"text-purple-500 hover:text-white hover:bg-purple-500 border border-purple-500 text-xs font-semibold rounded-full px-4 py-1 leading-normal\">Message</button>\n      </div>\n    </div>\n  </div>\n</div>\n```\n###動作確認\nでは準備が出来たので「rails s」っと\nあ、うまくいってませんでした・・・・\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1215137/a3b9848b-4f96-75ef-cd35-46287c69083e.png)\nうまくいくと下記のサイトに載ってる状態になるみたいです\n[RailsでTailwind CSSを使用する](https://qiita.com/tabakazu/items/4c152de6e9a2c293d1f2)\n\n##作業工程2\n次に@kazuya_minei109さんが投稿してくださった[RailsにTailwindCSSを導入](https://qiita.com/kazuya_minei109/items/e76ff2b0af49e69eb441)の手順も行う\n\nデフォルトで入っているWebpackerを削除して、\n新しいWebpackerを追加を実施\n\n```\n$ yarn remove @rails/webpacker\n$ yarn add rails/webpacker#b6c2180\n```\ngem spring アンインストールを実施\n\n```\n$ bundle exec gem uninstall spring\n```\n\n```\n# gem 'spring'  #念の為にコメントアウト\n```\n```\n$ bundle install\n```\n次に、TailwindsCSS、PostCSS、Autopfrefixer、Tailwindプラグインをインストール\n\n```\nyarn add tailwindcss postcss autoprefixer @tailwindcss/forms @tailwindcss/typography @tailwindcss/aspect-ratio\n```\nこの段階で動作確認を実施\nrails sっと・・・・\n![スクリーンショット 2021-03-29 11.25.20.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1215137/0e17c7b3-3362-c688-f1b1-aef945dd208f.png)\n\n上手くいってるな・・・・\n\n###少し調査\nここから場合分けで色々試してみた結果\n\n- デフォルトで入っているWebpackerを削除\n- 新しいWebpackerを追加を実施\n- PostCSSのインストール\n\n```\n$ yarn remove @rails/webpacker\n$ yarn add rails/webpacker#b6c2180\n$ yarn add postcss\n```\n上記が必要であった\n下記の\n「tailwindcss」は既にインストール済であったこと\n「autoprefixer」は postcss.config.jsに追記してあったこと\n「@tailwindcss/〜」はtailwindsccのプラグイン各種をインストールすること\nそのため、あまり関係ないかと思います\n\n###さいごに\nPostCSSについても少し調べてみた\n[Rails & Webpacker環境でPostCSSを使う](https://qiita.com/yamashun/items/587e487a885a5291e3a2)\nしかし、理解が追いつきませんでした!!\n少しずつ学んでいくしかないかな\n\n\n\n## 参考文献\n[Tailwind on Rails](https://qiita.com/d0ne1s/items/5a2cf50167afd988e9f7)\n[RailsにTailwindCSSを導入](https://qiita.com/kazuya_minei109/items/e76ff2b0af49e69eb441)\n[RailsでTailwind CSSを使用する](https://qiita.com/tabakazu/items/4c152de6e9a2c293d1f2)\n[Rails & Webpacker環境でPostCSSを使う](https://qiita.com/yamashun/items/587e487a885a5291e3a2)\n","user":"guy","created_at":"2021-03-29T12:34:00+09:00","updated_at":"2021-03-29T12:34:00+09:00"},{"url":"https://qiita.com/39_isao/items/10a74dd7e14528de7e53","title":"cssのdisplay:grid;を見るとヤバい！と思う君と僕を救う8分","body":"ある日、僕の元に渡ってきたコードに普通に書いてあった\n### display:grid;\n\nあかん！！   flexじゃねぇ！！！\nヒゲダン鼻歌歌ってる場合じゃねぇ！\nヤバい、、、と思いました。:japanese_goblin:\n\nなんとなく聞いたことはあった、どうにか調べて解決したけど、その場しのぎで全くわかってねぇ！\nこれは次きたらマズイと思い、自戒の念も含めこの記事を書こうと思います。(書くと理解するから)\n\n\n# １、flexboxと何が違うの？使い分けは？\nどうやらGrid Layoutを使うと、\n**HTMLの記述がシンプルで短くなる(flex用のdivがめっちゃ増えるのを防げる)** \n\n**シンプルな横並びとか、タイルのレイアウトならflexbox**でいいけど\n**複雑なtableみたいなレイアウトだと、display:grid;のが向いてるみたい。**\n\n入門\n\n![スクリーンショット 2021-03-29 9.58.26.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/76843/101cc0bf-046c-b3ef-b63e-549499f18c5b.png)\nこれはflexでも簡単そうだけど、、基本として\n\n# 2、display:grid;ってどこに指定するの？\nflexと一緒で親要素に指定するそうです。\nまた、親要素（いつもdisplay:flex;かけてたとこ）を\n**Gridコンテナ**\nそれぞれの子要素を\n**Gridアイテム**\nと呼ぶそうです！\n\n\n![grid2.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/76843/b0ad2887-3947-e48e-78bb-2ac5688b1d2a.png)\n\n# ３、さぁまずはHTMLや！\n\nHTML書きます！簡潔！:relaxed:\n\n```\n    <div id=\"container\"> \n        <div id=\"item_header\">ここヘッダー</div>\n        <div id=\"itemA\">A</div> \n        <div id=\"itemB\">B</div> \n        <div id=\"item_footer\">ここフッター</div>\n    </div>\n```\n\n# ４、そしてCSS \n\nこれで準備完了！！！！\n\n```\n#container {\n   display: grid; \n   width: 500px;\n   height: 300px;\n}\n```\n\n## ５、まずは行の縦幅の調整 grid-template-rows\n\n```\n#container {\n    display: grid;\n    width: 500px;\n    height: 300px;\n    grid-template-rows: 50px auto auto 100px; \n\n    /* それぞれのheight  ピンクが50px、肌色と青可変、グレー100px */\n}\n```\n\nこんな結果になります！\nautoは#containerの高さに応じて、可変します！便利！\n\n\n![スクリーンショット 2021-03-29 11.44.47.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/76843/c8c1b47c-c4e9-0898-3737-f03f1d338d81.png)\n\n\n\n\n# ６、次はgrid-template-columnsで列の横幅調整！\n```\n#container {\n    display: grid;\n    width: 500px;\n    height: 300px;\n    grid-template-rows: 50px auto auto 100px; \n    grid-template-columns:1fr 100px;\n}\n```\n\n![スクリーンショット 2021-03-29 11.48.26.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/76843/8f1175d4-acc1-6ae6-5a64-b57b95ffb478.png)\n\n\nこんな感じになりました！（レイアウトがぶっ壊れましたね。。このあと調整します。）\nここであえて使った **1fr** というのは、**残り全て** という意味です。\n今回だったら、100px意外全てのwidthという意味ですね。\n**肌色の部分はちゃんと100pxになってますね！**\nそしてここで検証ツールで出てきてくれた数字がすっごく役にたちます(神)\n\n\n# ７、バラバラになったアイテムの位置を指定する(grid-row、grid-column)ここが曲者、、\n\nアイテムの配置指定は、\n**grid-row**   **grid-column** を使用します。\nこれは番号で指定するようなのですが、\n例えばheaderの赤い部分\n横（行）の幅が番号でいうと、\n1番 ~ 2番なので、**grid-row:1/2;** という風に指定するそうです。\n縦(列は)全ての列を含んでいて、1番~4番なので\n**grid-column:1/4;**\nと指定するそうです！\n\n↑\n難しいので手を動かさないとわからないと思います\n\nこの部分は、この記事がわかりやすかったです。(全体的にも)\n\nhttps://qiita.com/kura07/items/e633b35e33e43240d363\n\n# 正直慣れるまで難しいと思ったので、これは検証ツール見ながらやった方がいいと思いました！！！！\n\n\n\nこんな感じですね。\n\n![スクリーンショット 2021-03-29 12.05.27.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/76843/ebedc1ea-8ae6-9e4b-739c-956d6713695b.png)\n\n\n\nコード全て載せときます\n\n\n```\n\n<!DOCTYPE html>\n<html lang=\"en\">\n<head>\n    <meta charset=\"UTF-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <title>Document</title>\n    <style>\n    #container {\n        height: 300px;\n        width: 500px;\n        display: grid; /* グリッドレイアウト */\n        grid-template-rows: 50px auto auto 100px; \n        grid-template-columns:1fr 100px;\n    } \n\n    #item_header{\n        background: #E16162;\n        grid-row: 1/2;\n        grid-column: 1/4;\n    }\n    #itemA{\n        background: #FFEED0;\n        grid-row: 2 / 4;\n        grid-column: 1/2;\n    }\n    #itemB{\n        background: #72A6EF;\n        grid-row: 2/ 4;\n        grid-column: 2/4;\n    }\n    #item_footer{\n        background: #B2AFAF;\n        grid-row: 4 / 5;\n        grid-column: 1/5;\n    }\n    </style>\n</head>\n<body>\n    <div id=\"container\"> <!-- コンテナ -->\n        <div id=\"item_header\">ここヘッダー</div> <!-- アイテム -->\n        <div id=\"itemA\">A</div> <!-- アイテム -->\n        <div id=\"itemB\">B</div> <!-- アイテム -->\n        <div id=\"item_footer\">ここフッター</div> <!-- アイテム -->\n    </div>\n</body>\n</html>\n\n```\n\n\n以上！\nあとは先ほどの記事とか見ながら上級版をやってみてください。\nざっくり入門の記事でした！\n\n変なとこあったらコメントいただけると嬉しいです。\n\n","user":"39_isao","created_at":"2021-03-29T12:32:41+09:00","updated_at":"2021-03-29T12:33:51+09:00"},{"url":"https://qiita.com/jackfrost/items/fffc91dbdbf43fa77778","title":"Pythonで月末・月初を取得","body":"メジャーな方法は下記２パターン\n・カレンダーで最終日を取得して組み合わせる\n・翌月の１日前を計算する\n\n翌月の１日前を計算する方が個人的にしっくりくるので書いてみた\n\n```python\nfrom datetime import date,timedelta\n#月末は「翌月初日の1日前」として計算する\nyear = 2021\nfor month in range(1,13):\n  month_first_day = date(year,month,1) #月の初日\n  #date関数は月の引数に13以上が入ると1~12に収めろとエラーするので対応\n  if month == 12: exec_year = year + 1; next_month = 1\n  else: exec_year = year; next_month = month + 1\n  next_month_first_day = date(exec_year,next_month,1) #翌月の初日\n  month_end_day = next_month_first_day - timedelta(days=1) #月の最終日(翌月の初日-１日)\n  print(str(year)+'年'+str(month).zfill(2)+'月の月初＝'+str(month_first_day))\n  print(str(year)+'年'+str(month).zfill(2)+'月の月末＝'+str(month_end_day))\n```\n\n実行結果\n\n```bash\n2021年01月の月初＝2021-01-01\n2021年01月の月末＝2021-01-31\n2021年02月の月初＝2021-02-01\n2021年02月の月末＝2021-02-28\n2021年03月の月初＝2021-03-01\n2021年03月の月末＝2021-03-31\n2021年04月の月初＝2021-04-01\n2021年04月の月末＝2021-04-30\n2021年05月の月初＝2021-05-01\n2021年05月の月末＝2021-05-31\n2021年06月の月初＝2021-06-01\n2021年06月の月末＝2021-06-30\n2021年07月の月初＝2021-07-01\n2021年07月の月末＝2021-07-31\n2021年08月の月初＝2021-08-01\n2021年08月の月末＝2021-08-31\n2021年09月の月初＝2021-09-01\n2021年09月の月末＝2021-09-30\n2021年10月の月初＝2021-10-01\n2021年10月の月末＝2021-10-31\n2021年11月の月初＝2021-11-01\n2021年11月の月末＝2021-11-30\n2021年12月の月初＝2021-12-01\n2021年12月の月末＝2021-12-31\n```\n","user":"jackfrost","created_at":"2021-03-29T12:30:22+09:00","updated_at":"2021-03-29T12:33:38+09:00"},{"url":"https://qiita.com/gyuki/items/8fcdce98af20ceac87cf","title":"buttonタグ忘れそう","body":"buttonタグにはoutline: none;をつけておく\nクリックしたときに緑色の枠が表示されてしまうから気を付ける\n","user":"gyuki","created_at":"2021-03-29T12:29:34+09:00","updated_at":"2021-03-29T12:29:34+09:00"},{"url":"https://qiita.com/Air_Hold/items/de2d0ffda31cd661ae39","title":"JavaのObjectはObjectかとか","body":"# クイズとか\nまたもや突然クイズです。\n**「Javaにおいて、全ての配列およびクラスは暗黙的にObjectクラスを継承している」**\nYESかNOか\n\n# 答えとか\nこれ、自分もよくこういうことを言ってしまっていますし、[日本語のJavaDoc](https://docs.oracle.com/javase/jp/8/docs/api/java/lang/Object.html)読んでみたら\n>Objectクラスは、クラス階層のルートです。すべてのクラスは、スーパー・クラスとしてObjectを持ちます。配列を含むすべてのオブジェクトは、このクラスのメソッドを実装します。\n\nと書いてありますし。\n\nが、**答えはNO**です。\n\nJavaにおいて、全ての配列およびクラスは暗黙的にObjectクラスを継承しているわけではありません。\n**例外がある**んです。\n\n# 例外のクラスとか\n例外となるクラスはObjectクラスです。\n**ObjectクラスはObjectを継承しません**。\nそりゃそーですよね。\nObject extends Objectとかやったら\nObjcet::newを実施→super();→Object::newを実施→super();→以下略\nと、コンストラクタが無限再帰しちゃいます。\n\"GNU's Not Unix!\"みたいになっちゃう！\n\n# 何を継承してるのかとか\nそうすると、気になるのは**Objectクラスが何を継承しているか**ですよね。\n特にObject::new後。\nそういうわけで、コードで確認してみました。\n```java\nSystem.out.println(new Object().getClass().getSuperclass().toString());```\n>Exception in thread \"main\" java.lang.NullPointerException\n\n**ぬるぽ**\n\n# おまけとか\nついでなので[Javaの言語仕様](https://docs.oracle.com/javase/specs/jls/se16/html/jls-4.html#jls-4.3.2)を見てみましょう。\n>The class Object is a superclass (§8.1.4) of all **other** classes. \n「Objectクラスは**\"他の\"**全てのクラスのスーパークラスである」\n\nちゃんと書いてあった！\n","user":"Air_Hold","created_at":"2021-03-29T12:29:26+09:00","updated_at":"2021-03-29T12:29:26+09:00"},{"url":"https://qiita.com/peta_67/items/66dd85de6de8306f0889","title":"Upup.js","body":"自分用メモ\n\nなぜか、初めはうまくいかなかった。\nいろいろといじっているうちにできた。\n\nただ、どうしてできたのかがわからないから、メモ。\n\nできたときにやったことは、Service Workerの登録とかをした。\nまあ、たぶんこれ。\n","user":"peta_67","created_at":"2021-03-29T12:16:58+09:00","updated_at":"2021-03-29T12:16:58+09:00"},{"url":"https://qiita.com/kzrashi/items/80ff82d4330d51a398dc","title":"pyenvでインストール時に「BUILD FAILED (OS X 10.15.7 using python-build 20180424)」が発生した場合の対処法","body":"\n# 概要\nmacのpyenvでpythonをインストールしようとした際に、以下のエラーが発生しました。\n以下の手順で動くようになったので、対処法を記載します\n\n## エラー内容\n```zsh\n$ pyenv install 3.5.6\n　:\n　:\n\npython-build: use openssl@1.1 from homebrew\npython-build: use readline from homebrew\nDownloading Python-3.5.6.tar.xz...\n-> https://www.python.org/ftp/python/3.5.6/Python-3.5.6.tar.xz\nInstalling Python-3.5.6...\npython-build: use readline from homebrew\npython-build: use zlib from xcode sdk\n\nBUILD FAILED (OS X 10.15.7 using python-build 20180424)\n\n```\n\n## 対処法\nエラーメッセージに従い、zlibを追加して環境変数に追加することで解決しました\n\n- brewでzlibをインストールする\n\n```zsh\n$ brew install zlib\n　:\n　:\n######################################################################## 100.0%\n==> Pouring zlib-1.2.11.catalina.bottle.tar.gz\n==> Caveats\nzlib is keg-only, which means it was not symlinked into /usr/local,\nbecause macOS already provides this software and installing another version in\nparallel can cause all kinds of trouble.\n\nFor compilers to find zlib you may need to set:\n  export LDFLAGS=\"-L/usr/local/opt/zlib/lib\"\n  export CPPFLAGS=\"-I/usr/local/opt/zlib/include\"\n\nFor pkg-config to find zlib you may need to set:\n  export PKG_CONFIG_PATH=\"/usr/local/opt/zlib/lib/pkgconfig\"\n\n==> Summary\n🍺  /usr/local/Cellar/zlib/1.2.11: 12 files, 376.4KB\n```\n\n- シェルの設定ファイルに加える  \n※zsh以外のシェルを使用している場合、対応する設定ファイルに追記して下さい\n\n```\n$ echo 'export LDFLAGS=\"-L/usr/local/opt/zlib/lib\"' >> ~/.zshrc\n$ echo 'export CPPFLAGS=\"-I/usr/local/opt/zlib/include\"' >> ~/.zshrc\n$ echo 'export PKG_CONFIG_PATH=\"/usr/local/opt/zlib/lib/pkgconfig\"' >> ~/.zshrc\n```\n\n- ターミナルを再起動する  \n  ※　下記のようにsourceコマンドで設定ファイルを再読み込みしても可能\n\n```\n$ source ~/.zshrc\n```\n\n## 参考サイト\nhttps://github.com/aws/aws-elastic-beanstalk-cli-setup/issues/76\n","user":"kzrashi","created_at":"2021-03-29T12:09:25+09:00","updated_at":"2021-03-29T12:09:25+09:00"},{"url":"https://qiita.com/masudaryo/items/d37cdabfdceb78db082d","title":"当月の祝日を取得","body":"内閣府で公示されている資料をもとに特定の月の祝日の一覧を求めます。内包表記多めです。\n\n資料はWebでCSV形式で公開されているのでPandasを使うと一発です。エンコードがShift_JIS(cp932との厳密な違いはよく知らない)になっているのが注意点です。\n\nJupyterで実行すると下記のような結果が得られます。\n\nIn[1]:\n\n```python\nimport pandas as pd\nh_ = pd.read_csv('https://www8.cao.go.jp/chosei/shukujitsu/syukujitsu.csv',encoding='cp932')\nh_\n```\n\nOut[1]:\n\n&nbsp;|国民の祝日・休日月日|国民の祝日・休日名称\n-|-|-\n0|1955/1/1|元日\n1|1955/1/15|成人の日\n2|1955/3/21|春分の日\n3|1955/4/29|天皇誕生日\n4|1955/5/3|憲法記念日\n...|...|...\n970|2022/9/19|敬老の日\n971|2022/9/23|秋分の日\n972|2022/10/10|スポーツの日\n973|2022/11/3|文化の日\n974|2022/11/23|勤労感謝の日\n975 rows × 2 columns\n\n---\n生まれる前の年代から翌年までの祝日一覧が得られます。今回は日付にしか興味がないのでdatetimeを使ってdate型にします。最後部の40件を表示します。\n\nIn[2]:\n\n```python\nimport datetime\n[datetime.datetime.strptime(h,'%Y/%m/%d').date() for h in h_['国民の祝日・休日月日']][-40:]\n```\n\nOut[2]:\n\n```\n[datetime.date(2020, 7, 23),\n datetime.date(2020, 7, 24),\n datetime.date(2020, 8, 10),\n datetime.date(2020, 9, 21),\n datetime.date(2020, 9, 22),\n datetime.date(2020, 11, 3),\n datetime.date(2020, 11, 23),\n datetime.date(2021, 1, 1),\n datetime.date(2021, 1, 11),\n datetime.date(2021, 2, 11),\n datetime.date(2021, 2, 23),\n datetime.date(2021, 3, 20),\n datetime.date(2021, 4, 29),\n datetime.date(2021, 5, 3),\n datetime.date(2021, 5, 4),\n datetime.date(2021, 5, 5),\n datetime.date(2021, 7, 22),\n datetime.date(2021, 7, 23),\n datetime.date(2021, 8, 8),\n datetime.date(2021, 8, 9),\n datetime.date(2021, 9, 20),\n datetime.date(2021, 9, 23),\n datetime.date(2021, 11, 3),\n datetime.date(2021, 11, 23),\n datetime.date(2022, 1, 1),\n datetime.date(2022, 1, 10),\n datetime.date(2022, 2, 11),\n datetime.date(2022, 2, 23),\n datetime.date(2022, 3, 21),\n datetime.date(2022, 4, 29),\n datetime.date(2022, 5, 3),\n datetime.date(2022, 5, 4),\n datetime.date(2022, 5, 5),\n datetime.date(2022, 7, 18),\n datetime.date(2022, 8, 11),\n datetime.date(2022, 9, 19),\n datetime.date(2022, 9, 23),\n datetime.date(2022, 10, 10),\n datetime.date(2022, 11, 3),\n datetime.date(2022, 11, 23)]\n```\n\n---\nある月の日付の部分のみを抽出する内包表記です。 `(e.year,e.month)==(2021,3)`の部分がそのフィルタです。\n\nIn[3]:\n\n```python\n[e.day for e in [datetime.datetime.strptime(h,'%Y/%m/%d').date() for h in h_['国民の祝日・休日月日']] if (e.year,e.month)==(2021,3)]\n```\n\nOut[3]:\n\n```\n[20]\n```\n---\n\n上記を総合すると、下記の1行で当月の祝日の日付一覧が得られることになります(長いけど一行です)。\n※実行時点で2021年3月末です。\n\nIn[4]:\n\n```python\n[e.day for e in \n [datetime.datetime.strptime(h,'%Y/%m/%d').date() for h in \n  pd.read_csv('https://www8.cao.go.jp/chosei/shukujitsu/syukujitsu.csv',encoding='cp932')['国民の祝日・休日月日']]\n if (e.year,e.month)==(datetime.datetime.today().year,datetime.datetime.today().month)]\n```\n\nOut[4]: \n\n```\n[20]\n```\n","user":"masudaryo","created_at":"2021-03-29T12:09:17+09:00","updated_at":"2021-03-29T12:09:17+09:00"},{"url":"https://qiita.com/meruneru/items/0b7aa23ea505a80d60f5","title":"ゼロからのOS自作入門をMacで勉強する方法 (Docker使用)","body":"# ゼロからのOS自作入門をMacで読み進めたい\n\nhttps://www.amazon.co.jp/%E3%82%BC%E3%83%AD%E3%81%8B%E3%82%89%E3%81%AEOS%E8%87%AA%E4%BD%9C%E5%85%A5%E9%96%80-%E5%86%85%E7%94%B0-%E5%85%AC%E5%A4%AA/dp/4839975868\n\n本書ではLinux(Ubuntu)を開発環境に選んでおり、\nWindowsのWSLを使った方法を紹介しているが、Macでの方法は記載されていなかった。\n\n## 私の環境\n* macOS Big Sur(ver. 11.2.2)\n* Docker Engine v20.10.2\n\n## Docker上で環境を作っていく\n\nDocker上のUbuntuでビルドしたOSをQEMUで起動させることにした。\n\n### 今回作ったDockerfile\n\n```\n$ cat works/os/Dockerfile\n```\n```\nFROM ubuntu:18.04\n\nMAINTAINER meruneru\n\nENV IMAGE_NAME=MikanOS\n\nRUN apt-get update\nRUN apt-get install -y  vim \\\n                        build-essential \\\n                        python3 \\\n                        git \\\n                        okteta \\\n                        tmux \\\n                        dosfstools\n\n# https://github.com/uchan-nos/mikanos-build\nRUN cd $HOME; \\\n    git clone https://github.com/uchan-nos/mikanos-build.git osbook; \\\n    apt install -y ansible; \\\n    cd $HOME/osbook/devenv; \\\n    ansible-playbook -K -i ansible_inventory ansible_provision.yml\n\nCMD [\"/bin/bash\"]\n\n```\n\n### Dockerfileからイメージを作成する\n```\n$ docker build -t os works/os\n```\n\n\n### Docker内のGUIアプリをMacOS側に出力するために・・・\nXQuartz(X11サーバ)を別途インストールし、XQuatzの環境設定のセキュリティタブで、\n\"ネットワーク・クライアントからの接続を許可\"にチェックを入れておく。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/15085/b7bd27ec-f0eb-7ce1-478d-80f42d0dacd0.png)\n\n### Dockerイメージを起動する\n\n以下のコマンドでOSを起動させることができる。\n起動後に書籍に載っているコマンドがインストールされていれば、環境構築完了:sunny:\n\nコマンドが長いので、私は下記ファイルをシェルスクリプトにして起動してる。\n\n\n\n```\ndocker run -it --rm \\\n           --privileged \\\n           -e DISPLAY=$(hostname):0 \\\n           -v ~/.Xauthority:/root/.Xauthority \\\n           -v $HOME/works/os:/root/os/ \\\n           os\n\n```\n","user":"meruneru","created_at":"2021-03-29T12:08:02+09:00","updated_at":"2021-03-29T12:20:22+09:00"},{"url":"https://qiita.com/liu-wei/items/e3f734646952bc01becb","title":"OCI カスタム・イメージの移行","body":"\n__初めに__\n今回は、テナンシーを跨ぎ、OCIカスタマイズ・イメージの移行方法を紹介します。\n例えば、OCIの検証環境から他テナンシーの本番環境に、Computeインスタンスを移行したいなら、この方法は適用します。\n\n* 対応OS<br>\nOracle Linux 6,7,8;\nCentOS 6,7;   Ubuntu 16.04以上;\nWindows 2012, 2016, 2019\n\n__作業の流れ__\n\n* シナリオ 1\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/509caa9d-4851-2d45-c6d1-83f8d564d732.png)\n作業流れ：\n　１．カスタム・イメージを作成。\n　２．<font color=\"blue\">PAR（読み取り専用）</font>を作成し、カスタム・イメージを移行元のオブジェクト・ストレージにエクスポートする。\n　３．カスタム・イメージをインサートする。\n　４．カスタム・イメージより、インスタンスを作成。\n※１と２は、移行元のテナンシーで実施し、３と４は、移行先のテナンシーで実施します。\n以下のシナリオ２と比べて、読み取り専用のPARで済みますので、<font color=\"blue\">ベストプラクティス</font>となります。\n\n\n* シナリオ 2\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/c25a1cae-e748-7644-78ee-b3b084c4ceb6.png)\n作業流れ：\n　１．カスタム・イメージを作成。（移行元のテナンシーで実施）\n　２．<font color=\"blue\">PAR（読み書き）</font>を作成。（移行先のテナンシーで実施）\n　　　カスタム・イメージを移行先のオブジェクト・ストレージにエクスポートする。（移行元のテナンシーで実施）\n　３．カスタム・イメージをインサートする。　（移行先のテナンシーで実施）\n　４．カスタム・イメージより、インスタンスを作成。（移行先のテナンシーで実施）\n\n__作業手順__\nシナリオ１を例として実施します。\n\n* カスタム・イメージの作成\n実行中のインスタンスのイメージを作成すると、インスタンスが停止し、数分間使用できない状態になります。インスタンスは、プロセスが完了したときに再起動します。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/f0ddeffc-4869-72dd-22aa-eed7b15c3f0b.png\" width=\"600\">\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/440d4f36-4fc7-3370-39ad-029988d94cfd.png\" width=\"450\">\n\n* カスタム・イメージのエクスポート\n Compute -> Instance -> Custom Images\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/3d1fdc66-e936-e7cf-5633-278bae90d557.png\" width=\"600\">\nBUCKETを指定します。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/b8c4e506-3460-f0a1-5a36-20dd37169e37.png\" width=\"450\">\nエクスポート実施中　（完了後、状態は\"Available\"に変わります。）\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/b728df10-f355-47b7-dbbf-13fb689d9628.png\" width=\"600\">\n\n* PARの作成　（読み取り専用）\nObject Storage -> Bucket Details (Custom-Image) -> Source-Instance-Image ->Create Pre-Authenticated Request\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/f50eca4f-0534-468c-a4f9-424a3e179748.png\" width=\"450\">\nURLをコピーしておいてください。（二度と表示できませんので、ご注意ください。）\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/dbdb3bbc-e820-5449-499d-524559e3a539.png\" width=\"450\">\n* カスタム・イメージのインポート\nここから、移行先のテナンシーで実施します。\nCompute -> Custom Images -> Import Image\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/60e4f450-8c30-1c06-3529-42713d427cd6.png\" width=\"600\">\nコピーしたURLを入力します。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/39e90a80-36a7-3d92-0edc-e9af80810e06.png\" width=\"500\">\nインポート実施中　（完了後、状態は\"Available\"に変わります。）\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/c3abc88a-6cb7-a3b0-bd82-d4f651c80d3c.png\" width=\"600\">\n\n* インスタンスの作成\nカスタム・イメージより新インスタンスを作成\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/f0d24b8b-e735-a191-8dec-628658c25d9d.png\" width=\"600\">\nイメージを指定\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121622/9b198c03-b45a-7379-d1ae-29488c4f73fe.png\" width=\"600\">\n\n----\n__参考ドキュメント__\nカスタム・イメージの管理\nhttps://docs.oracle.com/ja-jp/iaas/Content/Compute/Tasks/managingcustomimages.htm\nイメージのインポート/エクスポート\nhttps://docs.oracle.com/ja-jp/iaas/Content/Compute/Tasks/imageimportexport.htm\n","user":"liu-wei","created_at":"2021-03-29T12:02:21+09:00","updated_at":"2021-03-29T12:02:21+09:00"},{"url":"https://qiita.com/Kbayatch12345/items/53142bcc40d1dc7596e2","title":"【JDBCドライバ】MySQL Connector/J 8.0ダウンロード手順","body":"##はじめに\n自身がJava学習中にDB接続の環境を整える際に悩んだので、\nJDBCドライバのダウンロードから環境のセットアップまでを記載します。\n\n##使用環境\n開発環境：paizacloud\nJavaバージョン：13.0.1\nApache Tomcatバージョン：9.0.41\nDB：MySQL\nJDBCバージョン：8.0.23\n\n##１．JDBCのインストーラーダウンロード\n\nhttps://dev.mysql.com/downloads/\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/573636/75f58bb3-950c-f08c-b5b5-2f2b70bc9ffa.png)\n------------------------------\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/573636/5d49a746-5048-6b92-f23b-0ee244462728.png)\n------------------------------\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/573636/a8630a36-cf9d-b0c2-15e6-2ea05265b56b.png)\n------------------------------\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/573636/72a2939e-a89d-5eea-18cd-629337e6f372.png)\n------------------------------\n##2.インストーラ起動\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/573636/fa8cdf9b-f829-cfda-0764-23eeb5b10759.png)\n------------------------------\n##3.connect/Jをダウンロード\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/573636/a53b1074-dbe6-0579-5ef9-9edde8edef0f.png)\n＜ファイルダウンロード先（例）＞\n\n```\nC:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.23.jar\n```\n##4.jarファイルを配置\nダウンロードしたドライバ（jarファイル）をWEB-INF\\libに配置する。\n\n\n##5.Javaには下記のように記載する。\nドライバ名がバージョンで異なるそうです。\n\n####ドライバのバージョンが8.0系の場合\n\n```\nClass.forName(\"com.mysql.cj.jdbc.Driver\");\n```\n\n####※ドライバのバージョンが8.0系よりも前の場合\n\n```\nClass.forName(\"com.mysql.jdbc.Driver\");\n```\n\n##参考\n\nhttps://support.asteria.com/hc/ja/articles/360019113133-JDBC%E3%83%89%E3%83%A9%E3%82%A4%E3%83%90%E3%83%BC-MySQL-Connector-J-8-0-%E3%82%92%E4%BD%BF%E3%81%86%E3%81%A8%E3%81%8D%E3%81%AE%E6%B3%A8%E6%84%8F%E7%82%B9%E3%81%AF%E3%81%82%E3%82%8A%E3%81%BE%E3%81%99%E3%81%8B-\n","user":"Kbayatch12345","created_at":"2021-03-29T11:59:27+09:00","updated_at":"2021-03-29T12:07:29+09:00"},{"url":"https://qiita.com/arata0520/items/0c6c5904197ff19980c3","title":"備忘録 - ワークブック・シートの指定・操作【VBA】","body":"##ワークブックの指定方法\n\n```vb\nThisWorkBook 'マクロが書かれているワークブック\nActiveWorkBook　'現在アクティブのワークブック\nWorkbooks(\"ワークブック名.xlsm\")　'パスは含めず、拡張子も記載する。ワークブックを開いていないと指定できない。\n```\n\n##ワークシートの指定\n```vb  \nコードネーム　'コードネームの前でワークブックを指定しない\nWorksheets(\"ワークシート名\") 'タブの名前を用いる（ワークブックを指定可）\nActiveSheet '現在アクティブのワークシート\n```\n##現在アクティブのワークブックの名前・パスを調べる\n \n```vb  \nワークブック.Name　'ファイル名を表示\nワークブック.Path  'ファイルまでのパスを表示\nワークブック.FullName　'パスとファイル名を表示\n```\n\n##ワークブックを開く\n\n```vb \nApplication.Workbooks.Open \"パスとファイル名\"\n```\n\n##ワークブックを閉じる\n```vb \nワークブック.Close\n\n'保存して閉じる\nワークブック.Close SaveChanges:=True\n```\n\n##ワークブックを保存する\n```vb\nワークブック.Save\n```\n\n##ワークブックを新たに追加する\nAddメソッド\n\n```vb\nDim NewBook As Workbook\nSet NewBook = Workbooks.Add\n```\n\n##ワークシートを新たに追加する\nAddメソッド\n\n```vb\nDim NewSheet As Worksheet\nSet NewSheet = NewSheets.Add\n\n'名前を付ける\nNewSheet.Name = \"名前\"\n```\n","user":"arata0520","created_at":"2021-03-29T11:56:21+09:00","updated_at":"2021-03-29T11:56:21+09:00"},{"url":"https://qiita.com/ichi_zamurai/items/b4c7ecc0189ed4379464","title":"【Docker+Nginx+Angular】Dockerfileでイメージ作ってMacでアプリ立ち上げてみた","body":"#はじめに\n\nあるプロジェクトで、フロントでは[Angular](https://angular.jp/)を使用していたけど、\nローカルに直にWebサーバーを立ち上げる感じだったので、\nDockerコンテナ上にAngularを入れて、Webサーバー起動できないかなと思い、\n挑戦してみました！\n\n#TL;DR\n- 構成の説明\n- Angularのローカル上のセットアップ\n- Dockerfile解説\n- docker-compose.yml解説\n- nginx.conf解説\n- 実践とキャプチャ\n\n\n#構成\nとりあえず自分は以下のようなディレクトリ構成で進めました。\n\n```\ndocker-local\n├── .env \n├── docker-compose.yml\n├── docker\n│   └── nginx\n│       ├── Dockerfile\n│       └── nginx.conf\n└── web\n    ├── app ── (Angular一式)\n    └── env\n        └── nginx ── site.conf\n```\n\n#Angularのローカル上のセットアップ\nAngularに関連するファイル等をDockerコンテナ側にマウントするために、\n一旦ローカルで、Angularのセットアップをします。\n\n###1.`Node.js`のインストール\n[nodejs.org](https://nodejs.org/ja/)に行って、\n2021/03時点で、LTS(長期サポート)の推奨版`14.16.0 LTS`をダウンロード。\n\n###2.npmの関連ディレクトリのオーナーを自分のアカウントに権限変更\n```shell\n$ npm config get prefix\n/usr/local\n$ sudo chown -R $(whoami) $(npm config get prefix)/{lib/node_modules,bin,share}\n```\n自分の環境では、アクセス権限エラーが出たので、\n`/usr/local/bin, /usr/local/share, /usr/local/lib/node_modules`\nに対してオーナー権限を自分に与えた。\n\n###3.`angular/cli`のインストール\n```bash\nnpm install -g @angular/cli\n```\n- `-g, --global`：グローバルインストール\n    - npmのインストール場所にパッケージインストール\n    - つけない場合は、カレントディレクトリのnode_modules内にインストール\n\n###4.Angularアプリの作成\n```bash\n$ cd ./web\n$ ng new app\n? Do you want to enforce stricter type checking and stricter bundle budgets in t\nhe workspace?\n  This setting helps improve maintainability and catch bugs ahead of time.\n  For more information, see https://angular.io/strict Yes\n? Would you like to add Angular routing? Yes\n? Which stylesheet format would you like to use? Less   [ http://lesscss.org   \n```\n`web`のディレクトリに移動してから、`angular`アプリを`app`と言う名前で作成。\n3つほど、質問されるので、適宜選択。\n\n- `strict mode`でインストールするか\n- `routing`を追加するか\n- `stylesheet`のフォーマットはどうするか\n\n###5.一応、立ち上げ確認\n`localhost:4200`上に立ち上がりました！ \nこれで、マウント用のフォルダはOK。\n![スクリーンショット 2021-03-29 10.55.06.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1075243/9cca5317-7d81-1ead-e305-26eb4f6204bb.png)\n\n#Dockerfile\n```dockerfile:Dockerfile\nFROM node:14.16.0-alpine3.12 as build-stage\nWORKDIR /app\nCOPY ./web/app/package*.json /app/\nRUN npm install\nCOPY ./web/app/ /app/\nARG configuration=production\nRUN npm run build -- --output-path=./dist/out --configuration $configuration\n\nFROM nginx:1.17.3-alpine\nCOPY --from=build-stage /app/dist/out/ /var/www/html\nCOPY ./docker/nginx/nginx.conf /etc/nginx/\n```\n###解説\nローカル上でやった手順を`Dockerfile`上に書いてあげるイメージです。\n\n`linux`は`docker`コンテナに向いている超軽量の`alpine`を使用。\n\n今回は、[マルチステージビルド](https://docs.docker.jp/develop/develop-images/multistage-build.html)を利用してます。Dockerfileに複数の`FROM`命令を記述し、異なるベースイメージ使って、それぞれで新しいビルドステージを開始する感じです。\n\n- `Angualr`のビルド環境として`node:14.16.0-alpine3.12`をインストール。(`build-stage`と名付け)\n- Angularのビルド生成物を、Nginxのステージでコピーして使ってます。\n- docker側のワーキングディレクトリを`/app`に指定\n- ローカルの`package.json`を`/app/`配下にコピー\n- その`package.json`を使って、`npm install`\n- ローカルのAngularのソースをコピー\n- ビルドを走らせて、生成物は`./dist/out`に出力\n    - `configuration `はオプションだと思う。\n- `nginx`のイメージをインストール\n- 先述の`Angular`のビルド生成物を`Docker`上の`Nginx`のドキュメントとして扱うため、`nginx`のルートディレクトリ`/var/www/html`にコピー\n- Nginx の設定ファイル`nginx.conf`もコピー\n\n###※ビルドのポイント\n`docker-compose up`をする前に、`docker-compose.yml`がある場所を**カレントディレクトリ**として、事前にdockerイメージのビルドをしておきます。\n理由として、\n`./web/app/`のファイル等をコピーしたいが、\n`Dockerfile`は**親のディレクトリを参照することができない**ので、\n今回のフォルダ構成的に、コピーすることができず、こういったやり方にしてます。(他にももっと良いやり方あるかも。)\n\n```shell\n# buildコマンド実行場所を docker build のカレントディレクトリにできる\n$ docker build -f ./docker/nginx/Dockerfile -t image-name:nginx-1.17.3-alpine .\n```\n**※最後のドット . が大事**\n※buildに`cache`使いたくない場合は、`--no-cache`つける。\n※`docker-compose up --build`とかでも良いかもしれないが、自分はまだ試していない、\n\n#docker-compose\n```docker:docker-compose.yml\nversion: \"3.8\"\n\nservices:\n  nginx:\n    image: image-name:nginx-1.17.3-alpine\n    build: \n      context: ./docker/nginx\n      dockerfile: Dockerfile\n    container_name: nginx\n    ports:\n      - 80:80\n    volumes:\n      - ./web/env/nginx:/etc/nginx/conf.d\n    logging:\n      driver: \"none\"\n    restart: always\n```\n※`site.conf`は、docker-compose側でマウントしちゃう感じ。（実際Dockerfile内でもかけるかも）\n**※`image`の設定を、`build`した時のイメージ名にすることが大切**\n\n#nginx.conf\n※nginxについて内容の精査がまだできていないので、一旦自分のローカルで動いたものの貼り付け。\n`nginx.conf`内で`site.conf`をincludeする感じ。\n\n```conf:nginx.conf\nuser nginx;\nworker_processes 1;\nerror_log /var/log/nginx/error.log warn;\npid       /var/run/nginx.pid;\nevents {\n    worker_connections 1024;\n}\nhttp {\n    include      /etc/nginx/mime.types;\n    default_type application/octet-stream;\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n    access_log  /var/log/nginx/access.log main;\n    sendfile        on;\n    keepalive_timeout  65;\n    include /etc/nginx/conf.d/*.conf;\n}\n```\n\n```conf:site.conf\nserver {\n    listen      80;\n    listen      8080;\n    server_name localhost;\n    root        /var/www/html;\n    location / {\n        index  index.html index.htm;\n        root   /var/www/html;\n        try_files $uri $uri/ /index.html =404;\n    }\n    error_page   500 502 503 504  /50x.html;\n    location = /50x.html {\n        root   /var/www/html/error;\n    }\n}\n```\n\n#実際に立ち上がるか確認\n\n###コマンドを打ってコンテナ起動・・・\n```shell\n$ cd docker-local\n$ docker-compose up -d --remove-orphans\nCreating nginx ... done\n```\n\n###作成されたのでアクセス！！！\n![スクリーンショット 2021-03-29 10.55.06 2.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1075243/d8a0b1d5-c683-a8c0-f8eb-1fe5337abd96.png)\n\n###おお、ちゃんと表示された。\n\n`localhost:80`で起動してるので、URLをみると`:80`が省略されて、\nちゃんと`localhost`で立ち上がった。\n\nデフォルトのままなので、これから何かしらのアプリでも作ってみたいと思いまする。\n\n\n#まとめ\n\n今回の学びは、\n**マルチステージビルド**と\n**Dockerfileが参照できる範囲**\n等でした。\n\nやっぱりまだまだ、相対パスだったり、マウントの仕方だったりが、なかなか難しいので、\nその感覚をもっと養っていけたらと思いました。\n\nあとは、`nginx`のconfiguration周りがトーシロ(素人)レベルで全くわかっていないので、\nそこら辺を次は追求していきたいなと思ったりしてます。\n\n\n以上、ありがとうございました。\n","user":"ichi_zamurai","created_at":"2021-03-29T11:55:00+09:00","updated_at":"2021-03-29T13:26:55+09:00"},{"url":"https://qiita.com/y-ussy/items/b76e1afa5d0a1dc1b6ba","title":"【エラー】自動デプロイの際のエラー【AWS】","body":"# Aws::Sigv4::Errors::MissingCredentialsError\n\nアプリを自動デプロイした際、下記のようなエラーが出現。\n※アプリのサーバには、EC2、unicorn、Nginxを利用\n\n```\nAws::Sigv4::Errors::MissingCredentialsError: Cannot load `Rails.config.active_storage.service`:\nmissing credentials, provide credentials with one of the following options:\n  - :access_key_id and :secret_access_key\n  - :credentials\n  - :credentials_provider\n```\n\n※上記のエラー内容は下記の方法にて確認した。\n （ターミナルにて、EC2にログインし下記コマンドを入力。）\n\n```\n[ec2-user@ip-000-00-0-000 アプリ名]$ cd current\n[ec2-user@ip-000-00-0-000 current]$ cd log\n[ec2-user@ip-000-00-0-000 log]$ cat unicorn.stderr.log\n```\n\n# 結論\nEC2の環境変数にAWSのアクセスキーが設定がされておらず、デプロイ時にActive storageが読み込まれなかった事が原因。\n\n【EC2に環境変数の設定を行う方法】\nEC2にログインした状態で下記コマンドを入力。\n\n```\n[ec2-user@ip-000-00-00-000 ~]$ sudo vim /etc/environment\n```\ni を入力し、入力モードに変更。\n\n```\nAWS_ACCESS_KEY_ID='Access key ID'\nAWS_SECRET_ACCESS_KEY='Secret access key'\n```\n\nアクセスキーの入力が完了したら、「esc」キー　→　「:wq」の順に入力。\n設定した環境変数が反映されているかを確認する為、exitコマンドにてログアウト。\n\n```\n[ec2-user@ip-172-31-23-189 ~]$ exit\n```\n","user":"y-ussy","created_at":"2021-03-29T11:47:56+09:00","updated_at":"2021-03-29T11:47:56+09:00"},{"url":"https://qiita.com/yosukei3108/items/eb5815bf90110625ce0a","title":"Kubernetes の環境を作りたい [Raspberry Pi 編 2]","body":"1 回目 \n\nhttps://qiita.com/yosukei3108/items/c6f49d4d3477427124d2\n\n<h1> Raspberry Pi のキッティング </h1>\n前回イメージを書きこんだ microSD カードを使って Raspberry Pi をまずは単体で動作できる状態にしていきます。\n行き当たりばったりなので、状況によってはイメージから選びなおさないといけなくなるかもしれないけどまぁヨシ。\n\nとりあえず、複数台あってネットの情報も豊富そうな 3 B+ から行こうかな。\n\n\n(届いた Raspberry Pi 達の様子。ｵﾎｰｰｰｯ!!!!!!)\n![Pi34_s.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/616231/551a6153-8d2a-fec6-e802-2d8481310c2d.jpeg)\n\nパーティションのリサイズについてはこちらの記事を参考にさせていただきました。\n\nhttps://qiita.com/revsystem/items/9989a18116e554c133b6\n\nまた、各ノード初回ログオン時に root のパスワードは変更するようにしています。\n特に外部向けに運用する予定はないですが、習慣として。\n\n```console\n# passwd\n```\n\nついで、とりあえず更新できるものは更新しておきます。\n\n```console\n# yum update\n```\nちなみにですが、-y はよく知らない状況では使わないようにしています。\n今回で言えば、yum update が初回なので gpg-key のインポートについて確認されたりしますね。じゃあ、fingerprint とか全部つぶさに確認してるかっていうと、してないんですけど。。。\n\n<h1> ノードの設定 </h1>\nやっとこの環境固有の設定に入ります。\n\nPi 3 B+ についてはワーカー ノードとして有線 LAN のみ利用予定のため、Wi-Fi は無効 (既定) のまま利用します。\n\n参考にしている『入門 Kubernetes』ではマスター ノードを DHCP サーバーとしていますが、今後ワーカー ノードの電源オン/オフの順序が一意であるとは限らないので全部 static に以下のようにしてしまいます (全て /24) (何か理解が間違っているような気もする。。)。\n各ノードの hosts ファイルにもこの内容を記述しておきます。\n\n10.0.0.10 kubernetes\n10.0.0.11 node-1\n10.0.0.12 node-2\n10.0.0.13 node-3\n\nネットワーク周りの設定にあたって調べてみると、ifconfig は今触ってるイメージでは使えてるけど、非推奨なんですね。。\n\nhttps://i-think-it.net/centos7-ip-setting/\n\nhttps://server.etutsplus.com/centos-7-network-configuration/\n\n上記のページ等を参考にしつつ、nmcli で設定を行いました。\n\n```console\n# nmcli d\nDEVICE          TYPE       STATE      CONNECTION\neth0            ethernet   connected  Wired connection 1\n(略)\n\n# nmcli c mod \"Wired connection 1\" ipv4.addresses 10.0.0.11/24\n# nmcli c mod \"Wired connection 1\" ipv4.gateway 10.0.0.10\n# nmcli c mod \"Wired connection 1\" ipv4.method manual\n```\n(CONNECTION が普通に空白を含んでいるんですが、そういうものなんでしょうか、、、?)\n\nホスト名については hostnamectl コマンドを使いました。\n\n```console\n# hostnamectl set-hostname node-1\n```\nこのへんで一度再起動しておきます。\n\nで、設定がうまく入っているかの確認ですが、よくわからなかったので結局 /etc/sysconfig/network-scripts/ifcfg-Wired_connection_1 というファイルの中を見て確認しました。。\n\n\nこれを 3 台分繰り返したら、マスター ノードの設定です。\n\nが、ちょっと休憩。\n\nなんかよくわかんなくなってきた。\n一旦マスター ノードの作業に移ろう。\n\nということで続く。\n\n\n","user":"yosukei3108","created_at":"2021-03-29T11:41:53+09:00","updated_at":"2021-03-29T15:18:05+09:00"},{"url":"https://qiita.com/matsunao722/items/fff12e9b9460273adb75","title":"RDSの自動起動と自動停止スクリプト","body":"RDSは起動しっぱなしだとお金がかかる。\n\nしかし、停止しても7日後に再度起動してしまう。\n\n特に検証用とかで使用しない間が多い場合、いちいち起動したら停止するという運用はかなり面倒。\n\nそのため、検証時以外は、起動したらすぐ停止するというスクリプトを作成して、**無駄なコスト**がかからないようにする。\n\nそこで使用するのが、AWSのLambdaを使う。\n\n## Lambdaとは何？\n\nLambdaと聞いてもわからないので調べた。\n\nAWSの「サーバレスコンピューティングとアプリケーション」と言われる。\n\nこれまではPHPやPythonをうごかすためのwebサーバーが必要だったが、Lambdaならサーバーレスのため、サーバーを準備しなくても環境が揃っていると言うことである。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/255267/1235389f-8f51-f11f-ea6b-dc23ef67432e.png)\n\n\n**LambdaはJava、Node.js、C#、Pythonのプログラミング言語に対応しているので、各種「機能」（プログラム）はこの言語で開発すればOK、ということのようです。**\n\n「S3にアップされた画像のサムネイル化」で考えると、S3に画像ファイルがアップされるのを監視するためのサーバを用意して、監視し続けるプログラムを用意して、ファイルがアップされたことを検知したら、リサイズする処理を行う必要があったのが、Lambdaならこの「リサイズする処理」だけを作ればOKということ。\n\n今回はこのLambdaを利用し、指定された時間に関数を実行すると言うことを実装し、RDSの起動停止を自動で実施する。\n\n## 流れ\n\n### IAMによるロール(権限)作成\n\nIAMページでロールの作成を実施。\n\n「信用されたエンティティの種類を選択」については、「AWS サービス」を選択。「このロールを使用するサービスを選択」は「Lambda」を選択します。\n\n![https://www.t3a.jp/wp-content/uploads/2019/09/rds_auto_start_stop_iam3-1024x480.jpg](https://www.t3a.jp/wp-content/uploads/2019/09/rds_auto_start_stop_iam3-1024x480.jpg)\n\nAttach(アタッチ)する権限ポリシーは、\n\n・CloudWatchFullAccess\n\n・AmazonRDSFullAccess\n\n### Lambdaの設定でStartとStopの関数を作成\n\nLambdaで関数を作成する。関数はStartとStopの二つ。\n\nスクリプトは下記を登録する。\n\n```php\nimport boto3\n\nregion = 'ap-northeast-1'\n\ninstance = 'RDSインスタンス名'\ndef lambda_handler(event, context):\n    rds = boto3.client('rds', region_name=region)\n    rds.start_db_instance(DBInstanceIdentifier=instance)\n    print('started instance: ' + instance)\n```\n\n```php\nimport boto3\n\nregion = 'ap-northeast-1'\n\ninstance = 'RDSインスタンス名'\ndef lambda_handler(event, context):\n    rds = boto3.client('rds', region_name=region)\n    rds.stop_db_instance(DBInstanceIdentifier=instance)\n    print('stoped instance: ' + instance)\n```\n\nまた、関数起動を自動でやるため、cronで動かすようにも設定する。\n\ncronによる起動はトリガーの追加で「CloudWatch Events」を選択する。\n\n**〇RDS の起動時間**\n\n```php\ncron(15 23 */6 * ? *)\n```\n\n**〇RDS の停止時間**\n\n```php\ncron(45 23 0/6 * ? *)\n```\n\n### テスト\n\n起動が大丈夫かをテストできる。\n\n失敗したらスクリプトをチェックする。\n\n## RDS 自動停止を実装する際の実行時間の考え方\n\n設定に関して少し蛇足になりますが、RDS インスタンスが7日後に再起動する仕様について。\n\nコストを下げる基本的な考え方として、AWS 側のシステムで再起動を発生させないことが良いと思います。\n\nそのため一定時間ごとに RDS を起動して1時間以内に停止命令を送る実装をすれば良いです。\n\n**※aws は1時間以内の起動時間は1時間の使用としてコストが計上されるため**\n\nそこで今回は6日間隔で1時間以内の起動と停止を繰り返す設定を行っています。\n\nつまり毎月1日、7日、13日、19日、25日、29日にスクリプトを実行します。\n\n## 参考記事\n\nhttps://www.t3a.jp/blog/infrastructure/rds-auto-start-stop/\n","user":"matsunao722","created_at":"2021-03-29T11:40:23+09:00","updated_at":"2021-03-29T11:40:23+09:00"},{"url":"https://qiita.com/MeguruMokke/items/78ff972bbd4efe3e1398","title":"Clojure x ClojureScript で深める Web 開発 (6) クライアントサイドと re-frame","body":"# Git Repo\nソースコードと原文が入ったレポジトリ\nhttps://github.com/MokkeMeguru/clj-web-dev-ja/tree/main/chap6\n\n## シリーズ\n- [Clojure x ClojureScript で深める Web 開発 (0)](https://qiita.com/MeguruMokke/items/c6e059f109122be5f991)\n- [Clojure x ClojureScript で深める Web 開発 (1) Duct x Clean Architecture](https://qiita.com/MeguruMokke/items/af003d5a665095c0f3c8)\n- [Clojure x ClojureScript で深める Web 開発 (2) 環境の構築](https://qiita.com/MeguruMokke/items/9fe8e11a134e4c4dee2b)\n- [Clojure x ClojureScript で深める Web 開発 (3) API 作成入門](https://qiita.com/MeguruMokke/items/0ff941bcad6c86618b3d)\n- [Clojure x ClojureScript で深める Web 開発 (4) Auth](https://qiita.com/MeguruMokke/items/5ccf00bd2831551309d5)\n- [Clojure x ClojureScript で深める Web 開発 (5) API 開発 トランザクション添え](https://qiita.com/MeguruMokke/items/258c04caacdf66f706a2)\n- [Clojure x ClojureScript で深める Web 開発 (6) クライアントサイドと re-frame](https://qiita.com/MeguruMokke/items/78ff972bbd4efe3e1398)\n\n\n\n# 本編\n- [re-frame と DDD、関数型プログラミング](#org01850c2)\n  - [re-frame と DDD](#org8fe3487)\n  - [re-frame と関数型プログラミング](#orgdd56d49)\n- [プロジェクトのセットアップ](#org99c3a10)\n- [ClojureScript ライブラリの追加、npm ライブラリの追加](#orgdc5863e)\n- [index.html の更新](#org176902e)\n- [ルーティングとホームの実装](#orge8e65c8)\n  - [ホーム画面をブラウザに表示する](#orgc3ffb60)\n  - [Clojure Garden で CSS を書いてみる](#org6bbeaf7)\n  - [SPA とルーティング](#org0af39d5)\n- [付録](#org1f7e4f7)\n  - [ルーティングの検証](#org48685be)\n\n長いサーバサイドの実装は一旦終了とし、ここからはクライアントサイドの実装を行います。\n\nクライアントサイドの実装では、re-frame (<https://github.com/day8/re-frame>) という ClojureScript x React x Redux (のようなもの) な SPA 開発を支援するフレームワークを利用します。 サーバサイドと同様に、Clean Architecture で仕上げることもできますが、クライアントサイドに Clean Architecture が必要とされるようなデータ操作を行わせるケースを想定しないために、フレームワークを用いることを選択しました。\n\n<a id=\"org01850c2\"></a>\n\n# re-frame と DDD、関数型プログラミング\n\nre-frame で重要となるアイテムは、 **db** **subs(subscribers)** **events** **views** の 4 つです。\n\n簡単のために図示すると、それぞれのアイテムは下記のような役割を担っています。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap6/img/re-frame-cycle.png)\n\n重要なのは、中央のサイクル部です。 データモデル (DB) と HTML (Views) とのやり取りを、 **events** 、 **subs** のそれぞれが **単方向ずつ** 担っているのが確認できます。 この単方向のベクトルが re-frame 特徴である、データの流れを追いやすく、検証が行いやすい理由の一つになっています。\n\n参考\n\n- <https://qiita.com/lagenorhynque/items/3770e520bee0007e417c>\n\n<a id=\"org8fe3487\"></a>\n\n## re-frame と DDD\n\n上記のサイクルを達成するためには、いくつかあったほうが良い性質があります。\n\n一つは、DB と Views で扱うコンテンツが共通である、という性質です。 言い換えれば、ドメインごとに **db** **events** **subs** **views** が整備されていたほうが良い、ということになります。 実際に、 re-frame のプロジェクトのディレクトリ構造は次のようになることが推奨されています。\n\n    project\n         |- content_A\n         |        |- db.cljs\n         |        |- events.cljs\n         |        |- subs.cljs\n         |        `- views.cljs\n         |- content_B\n         |        |- db.cljs\n         |        |- events.cljs\n         |        |- subs.cljs\n         |        `- views.cljs\n         |- ...\n\nこれはまさに ドメイン駆動のディレクトリ構造に近いものです。 また、HTML を考えれば、1 画面 1 コンテンツを半ば強制的に実現させることになります (勿論組み合わせることもできます)。\n\n<a id=\"orgdd56d49\"></a>\n\n## re-frame と関数型プログラミング\n\n当然のことながら、re-frame は ClojureScript で記述されるフレームワークです。 そして、ClojureScript は、Clojure の JavaScript サポート版のような立ち位置で、関数型言語の一つと言えます。\n\n関数型言語の多くは、副作用という言葉に敏感です。 副作用というのは、例えば db を書き換えたり、HTML にデータを入力したり、API を叩いて出力を受け取ったり、といった、データの入出力やデータを不可逆的に操作することを指します。\n\nre-frame では、 **views** と **db** 、 **subs** では (基本的に) 副作用のある処理を書きません。 この性質のために、 re-frame は他の JavaScript (や TypeScript) のフレームワークに比べてもテストの実装が容易です (副作用がない部分は入力と出力の関係が明らか)。\n\nただし、 re-frame はこの性質のために、ゴリゴリのアニメーション処理が必要がコードなどはあまり得意では (そもそも React 自体が brabra &#x2026;) ないです。\n\n<a id=\"org99c3a10\"></a>\n\n# プロジェクトのセットアップ\n\nre-frame はフレームワークなので、アプリのセットアップにテンプレートを使うことができます。\n\n次のオプションをつけてプロジェクトを初期化します。\n\n```shell\nlein new re-frame pic-gallery-web +garden +10x +cider +test\n```\n\n`+xxx` はオプションを表しています。今回追加したオプションは、次のとおりです。\n\n- garden: clojure で css を書くライブラリの追加\n- 10x: デバッグツールの追加\n- cider: emacs での開発支援ツールの追加\n- test: テストのテンプレートの追加\n\n現在のディレクトリ構造は次の通り\n\n    pic-gallery-web\n    ├── README.md\n    ├── dev\n    │   └── cljs\n    │       └── user.cljs\n    ├── karma.conf.js\n    ├── package.json\n    ├── project.clj\n    ├── resources\n    │   └── public\n    │       └── index.html\n    ├── src\n    │   ├── clj\n    │   │   └── pic_gallery_web\n    │   │       └── css.clj\n    │   └── cljs\n    │       ├── deps.cljs\n    │       └── pic_gallery_web\n    │           ├── config.cljs\n    │           ├── core.cljs\n    │           ├── db.cljs\n    │           ├── events.cljs\n    │           ├── subs.cljs\n    │           └── views.cljs\n    └── test\n        └── cljs\n            └── pic_gallery_web\n                └── core_test.cljs\n\nここで、 React をはじめとする re-frame の依存ライブラリをインポートするために、次のコマンドを実行します。\n\n```shell\nlein deps\n```\n\nさらに、初期化のために一度、 次のコマンドを実行する必要があります。\n\n    $ lein watch\n    OpenJDK 64-Bit Server VM warning: Options -Xverify:none and -noverify were deprecated in JDK 13 and will likely be removed in a future release.\n    lein-shadow - running: npm --version\n    lein-shadow - 'npm' version 7.7.5\n\n    lein-shadow - found existing package.json file at /run/media/meguru/P/Github/clj-web-dev/chap6/pic-gallery-web/package.json\n    lein-shadow - reading node dependencies from /run/media/meguru/P/Github/clj-web-dev/chap6/pic-gallery-web/src/cljs/deps.cljs\n    lein-shadow - running: npm ci\n\n    lein-shadow - node package manager successfully built node_modules directory:\n\n    added 196 packages, and audited 197 packages in 1m\n\n    found 0 vulnerabilities\n\n    lein-shadow -  node package shadow-cljs@2.11.24 does not exist in /run/media/meguru/P/Github/clj-web-dev/chap6/pic-gallery-web/package.json!:devDependencies. Adding.\n    lein-shadow -  node package karma@6.2.0 does not exist in /run/media/meguru/P/Github/clj-web-dev/chap6/pic-gallery-web/package.json!:devDependencies. Adding.\n    lein-shadow -  node package karma-chrome-launcher@3.1.0 does not exist in /run/media/meguru/P/Github/clj-web-dev/chap6/pic-gallery-web/package.json!:devDependencies. Adding.\n    lein-shadow -  node package karma-cljs-test@0.1.0 does not exist in /run/media/meguru/P/Github/clj-web-dev/chap6/pic-gallery-web/package.json!:devDependencies. Adding.\n    lein-shadow -  node package karma-junit-reporter@2.0.1 does not exist in /run/media/meguru/P/Github/clj-web-dev/chap6/pic-gallery-web/package.json!:devDependencies. Adding.\n    lein-shadow - running: npm install --save-dev --save-exact shadow-cljs@2.11.24 karma@6.2.0 karma-chrome-launcher@3.1.0 karma-cljs-test@0.1.0 karma-junit-reporter@2.0.1\n    lein-shadow - node dev packages added successfully:\n\n    added 197 packages, and audited 394 packages in 23s\n\n    9 packages are looking for funding\n      run `npm fund` for details\n\n    found 0 vulnerabilities\n\n    lein-shadow - running shadow-cljs...\n    running: npm install --save --save-exact react@17.0.1 react-dom@17.0.1 highlight.js@10.7.1\n\n    added 6 packages, and audited 400 packages in 4s\n\n    9 packages are looking for funding\n      run `npm fund` for details\n\n    found 0 vulnerabilities\n    shadow-cljs - HTTP server available at http://localhost:8280\n    shadow-cljs - HTTP server available at http://localhost:8290\n    shadow-cljs - server version: 2.11.24 running at http://localhost:9630\n    shadow-cljs - nREPL server started on port 8777\n    shadow-cljs - watching build :app\n    shadow-cljs - watching build :browser-test\n    [:app] Configuring build.\n    shadow-cljs - watching build :karma-test\n    [:browser-test] Configuring build.\n    [:karma-test] Configuring build.\n    [:app] Compiling ...\n    [:karma-test] Compiling ...\n    [:browser-test] Compiling ...\n    ------ WARNING #1 -  -----------------------------------------------------------\n     Resource: node_modules/highlight_DOT_js/lib/core.js:1475:23\n     Missing \"...\" in type annotation for rest parameter.\n    --------------------------------------------------------------------------------\n    [:browser-test] Build completed. (209 files, 208 compiled, 0 warnings, 24.66s)\n    [:karma-test] Build completed. (146 files, 146 compiled, 0 warnings, 15.39s)\n    [:app] Build completed. (533 files, 532 compiled, 0 warnings, 25.15s)\n    C-c C-c\n    $\n\nプロジェクトの REPL 実行方法は、各エディタの利用方法に従って下さい。\n\n例えば、Emacs であれば、 `lein watch` した状態で、 cider-connect-clojurescript (コマンド) -> 8777 (入力) -> shadow (選択) -> app (入力) とすることで REPL に接続することができます。\n\nなお、ClojureScript は Hot Loading が有効なので、コードを保存したものが現在画面に表示されるものになります。\n\n参考:\n\n- <https://github.com/day8/re-frame-template>\n\n<a id=\"orgdc5863e\"></a>\n\n# ClojureScript ライブラリの追加、npm ライブラリの追加\n\nClojureScript も Clojure と同様に元言語のライブラリを利用することができます。 本章では、ClojureScript、npm のライブラリを両方追加します。\n\nまずは ClojureScript のライブラリを project.clj へ追加します。\n\n```clojure\n(defproject pic-gallery-web \"0.1.0-SNAPSHOT\"\n  :dependencies [[org.clojure/clojure \"1.10.3\"]\n                 [org.clojure/clojurescript \"1.10.773\"\n                  :exclusions [com.google.javascript/closure-compiler-unshaded\n                               org.clojure/google-closure-library\n                               org.clojure/google-closure-library-third-party]]\n                 [thheller/shadow-cljs \"2.11.24\"]\n                 [reagent \"1.0.0\"]\n                 [re-frame \"1.2.0\"]\n                 [day8.re-frame/tracing \"0.6.2\"]\n                 [garden \"1.3.10\"]\n                 [ns-tracker \"0.4.0\"]\n\n                 ;; add these libraries\n                 ;; routing\n                 [metosin/reitit \"0.5.10\"]\n                 [metosin/reitit-malli \"0.5.10\"]\n\n                 ;; http request\n                 [day8.re-frame/http-fx \"0.2.1\"]\n\n                 ;; testing\n                 [day8.re-frame/test \"0.1.5\"]]\n\n  :plugins [[cider/cider-nrepl \"0.25.6\"]\n            [lein-shadow \"0.3.1\"]\n            [lein-garden \"0.3.0\"]\n            [lein-shell \"0.5.0\"]\n            [lein-pprint \"1.3.2\"]]\n\n  :min-lein-version \"2.9.0\"\n\n  :jvm-opts [\"-Xmx1G\"]\n\n  :source-paths [\"src/clj\" \"src/cljs\"]\n\n  :test-paths   [\"test/cljs\"]\n  ;; ...\n  :prep-tasks [[\"garden\" \"once\"]])\n```\n\n次に JavaScript ライブラリとして、bulma と node-sass をインストールします。 bulma は CSS フレームワークで、node-sass を経由することで、フレームワーク内の CSS の一部分を変更することができます。\n\nCSS を 1 から手書きするのは大変 + Sass を使うほうが CSS を使うよりもよりも変数管理が楽 + bulma フレームワークを使いたい、という背景から、上述した 2 つのライブラリを追加します。\n\n```shell\nnpm install node-sass --save-dev\nnpm install bulma --save-dev\n```\n\nディレクトリ内の、 `package.json` が次のように更新されます。\n\n```json\n{\n  \"name\": \"pic-gallery-web\",\n  \"devDependencies\": {\n    \"bulma\": \"^0.9.2\",\n    \"node-sass\": \"^5.0.0\"\n  }\n}\n```\n\nさらに、 `package.json` を編集して、 node-sass を使うための npm CLI コマンドを追加します。\n\n```json\n{\n  \"name\": \"pic-gallery-web\",\n  \"devDependencies\": {\n    \"bulma\": \"^0.9.2\",\n    \"node-sass\": \"^5.0.0\"\n  },\n  \"scripts\": {\n    \"css-build\": \"node-sass --omit-source-map-url sass/mystyles.scss resources/public/css/mystyles.css\",\n    \"css-watch\": \"npm run css-build -- --watch\"\n  }\n}\n```\n\n- npm run css-build\n\n  scss -> css へコンパイルするためのコマンド\n\n- npm run css-watch\n\n  scss -> css への変換を Hot Loading するためのコマンド\n\n試しに、 次のような `sass/mystyles.scss` を追加します。\n\n```scss\n@charset \"utf-8\";\n$navbar-breakpoint: 760px;\n@import \"../node_modules/bulma/bulma\";\n```\n\n    $ npm run css-build\n\n    > css-build\n    > node-sass --omit-source-map-url sass/mystyles.scss resources/css/mystyles.css\n\n    Rendering Complete, saving .css file...\n    Wrote CSS to /run/media/meguru/P/Github/clj-web-dev/chap6/pic-gallery-web/resources/css/mystyles.css\n\nこれで、 bulma のカスタムされた css コードが `resources/css/mystyles.css` へ追加されました。\n\n<a id=\"org176902e\"></a>\n\n# index.html の更新\n\n以前、firebase auth を使うために、仮のクライアントサイドコードを実装しましたが、その実装をこちらの re-frame のコードにも移植します。\n\n移植には前回と同様に `index.html` を編集する必要があります。\n\n初期状態は次のとおりです。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\" />\n    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n    <link href=\"css/screen.css\" rel=\"stylesheet\" type=\"text/css\" />\n    <title>pic-gallery-web</title>\n  </head>\n  <body>\n    <noscript>\n      pic-gallery-web is a JavaScript app. Please enable JavaScript to continue.\n    </noscript>\n    <div id=\"app\"></div>\n    <script src=\"js/compiled/app.js\"></script>\n  </body>\n</html>\n```\n\nここに、firebase auth を利用するためのコードの追加、そして、前章で追加した bulma の css コードの追加を行うと、次のようになります。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\" />\n    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n\n    <!-- js libaries -->\n    <script\n      defer\n      src=\"https://use.fontawesome.com/releases/v5.6.0/js/all.js\"\n    ></script>\n    <script\n      src=\"https://code.jquery.com/jquery-3.5.1.slim.js\"\n      integrity=\"sha256-DrT5NfxfbHvMHux31Lkhxg42LY6of8TaYyK50jnxRnM=\"\n      crossorigin=\"anonymous\"\n    ></script>\n    <script src=\"https://www.gstatic.com/firebasejs/ui/4.7.1/firebase-ui-auth__ja.js\"></script>\n\n    <!-- css -->\n    <link\n      type=\"text/css\"\n      rel=\"stylesheet\"\n      href=\"https://www.gstatic.com/firebasejs/ui/4.7.1/firebase-ui-auth.css\"\n    />\n    <link href=\"/css/mystyles.css\" rel=\"stylesheet\" type=\"text/css\" />\n    <link href=\"css/screen.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n    <title>pic-gallery-web</title>\n  </head>\n  <body>\n    <noscript>\n      pic-gallery-web is a JavaScript app. Please enable JavaScript to continue.\n    </noscript>\n    <div id=\"app\"></div>\n\n    <!-- firebase -->\n    <script src=\"https://www.gstatic.com/firebasejs/7.23.0/firebase-app.js\"></script>\n    <script src=\"https://www.gstatic.com/firebasejs/7.23.0/firebase-analytics.js\"></script>\n    <script src=\"https://www.gstatic.com/firebasejs/7.23.0/firebase-auth.js\"></script>\n\n    <script type=\"text/javascript\">\n      // set your values from firebase project\n      // --------------------------------------------\n      var apiKey = \"AIzaSyA-AfxCZtmMBfbA6xJsDqA5wSNmod8VrIk\";\n      var projectId = \"sample-picture-gallery-c12rb\";\n      // --------------------------------------------\n\n      var authDomain = projectId + \".firebaseapp.com\";\n      var firebaseConfig = {\n        apiKey: apiKey,\n        authDomain: authDomain,\n        projectId: projectId,\n      };\n\n      // Initialize Firebase\n      firebase.initializeApp(firebaseConfig);\n    </script>\n\n    <script src=\"js/compiled/app.js\"></script>\n  </body>\n</html>\n```\n\nまた、近年ほぼ必須となっている ServiceWorker の追加は次のようになります。\n\n```html\n<html>\n  <body>\n    <!-- ... -->\n    <script src=\"/js/compiled/app.js\"></script>\n    <script>\n      if (\"serviceWorker\" in navigator) {\n        navigator.serviceWorker.register(\"/sw.js\").then(function () {\n          console.log(\"service worker registered\");\n        });\n      }\n    </script>\n  </body>\n</html>\n```\n\n`sw.js` は次の通り\n\n```javascript\nself.addEventListener(\"install\", function (e) {\n  console.log(\"[ServiceWorker] Install\");\n});\n\nself.addEventListener(\"activate\", function (e) {\n  console.log(\"[ServiceWorker] Activate\");\n});\n```\n\nPWA のための マニュフェストファイルも追加しましょう (ワガママ)。\n\n```html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\" />\n    <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\n\n    <!-- js libaries -->\n    <script\n      defer\n      src=\"https://use.fontawesome.com/releases/v5.6.0/js/all.js\"\n    ></script>\n    <script\n      src=\"https://code.jquery.com/jquery-3.5.1.slim.js\"\n      integrity=\"sha256-DrT5NfxfbHvMHux31Lkhxg42LY6of8TaYyK50jnxRnM=\"\n      crossorigin=\"anonymous\"\n    ></script>\n    <script src=\"https://www.gstatic.com/firebasejs/ui/4.7.1/firebase-ui-auth__ja.js\"></script>\n\n    <!-- css -->\n    <link\n      type=\"text/css\"\n      rel=\"stylesheet\"\n      href=\"https://www.gstatic.com/firebasejs/ui/4.7.1/firebase-ui-auth.css\"\n    />\n    <link href=\"/css/mystyles.css\" rel=\"stylesheet\" type=\"text/css\" />\n    <link href=\"css/screen.css\" rel=\"stylesheet\" type=\"text/css\" />\n\n    <!-- for PWA -->\n    <link\n      rel=\"apple-touch-icon\"\n      sizes=\"180x180\"\n      href=\"/icons/apple-touch-icon.png\"\n    />\n    <link\n      rel=\"icon\"\n      type=\"image/png\"\n      sizes=\"32x32\"\n      href=\"/icons/favicon-32x32.png\"\n    />\n    <link\n      rel=\"icon\"\n      type=\"image/png\"\n      sizes=\"16x16\"\n      href=\"/icons/favicon-16x16.png\"\n    />\n    <link rel=\"manifest\" href=\"pic-gallery.webmanifest\" />\n\n    <title>pic-gallery-web</title>\n  </head>\n  <body>\n    ...\n  </body>\n</html>\n```\n\n`pic-gallery.webmanifest` は次の通り (icon 部は各自用意して下さい)。\n\n```json\n{\n  \"name\": \"Pic Gallery\",\n  \"short_name\": \"PicGallery\",\n  \"description\": \"Pic Gallery: Show your Picture and its Memory as your Gallery\",\n  \"icons\": [\n    {\n      \"src\": \"/icons/android-chrome-192x192.png\",\n      \"sizes\": \"192x192\",\n      \"type\": \"image/png\"\n    },\n    {\n      \"src\": \"/icons/android-chrome-512x512.png\",\n      \"sizes\": \"512x512\",\n      \"type\": \"image/png\"\n    }\n  ],\n  \"display\": \"standalone\"\n}\n```\n\n参考:\n\n- <https://developer.mozilla.org/ja/docs/Web/Progressive_web_apps/Offline_Service_workers>\n- <https://developer.mozilla.org/ja/docs/Web/Progressive_web_apps/Installable_PWAs>\n- <https://realfavicongenerator.net/>\n\n<a id=\"orge8e65c8\"></a>\n\n# ルーティングとホームの実装\n\nre-frame の機構を用いた実装の前に、ルーティングとシンプルな View を用いたホームの実装を行います。\n\nまずは Home 画面を切り出すためにディレクトリ構造を見直します。\n\n    src/cljs/pic_gallery_web\n    ├── config.cljs\n    ├── core.cljs\n    ├── db.cljs\n    ├── events.cljs\n    ├── subs.cljs\n    └── views.cljs\n\n上の形ですと、別のコンテンツを追加したときに困るので、 `services` というディレクトリを作ります。 その中に `home/views.cljs` を作り、ホーム画面の View とします。\n\n```clojure\n(ns pic-gallery-web.services.home.views)\n\n(defn about []\n  [:<>\n   [:p.subtitle \"Pic Gallery とは\"]])\n\n(defn how-to-use []\n  [:div.content\n   [:p.title \"使い方\"]])\n\n(def home-body\n  [:<>\n   [about]\n   [:hr]\n   [how-to-use]])\n\n(def home-content\n  {:title \"Welcome to Pic Gallery\"\n   :body home-body})\n\n(def home-page\n  [:div.container.pt-5 {:style {:max-width \"640px\"}}\n   [:div.titles\n    [:p.title (:title home-content)]\n    (:body home-content)]])\n```\n\nここで、Clojure (の Hiccup という記法) での HTML の書き方を紹介します。\n\nHiccup は Clojure で HTML を表現するためのライブラリです。\n\nClojure のベクトル `[]` の第一引数が html tag を表し、オプショナルな第二引数が html element の属性を表します。そして、第三引数以降が中身のテキスト、子要素表します。\n\n```clojure\n;; [<html tag> {<attribute-key> <attribute-value>} <value or children of html element>]\n;; e.g.\n[:div {:style {:max-width \"640px\"}} [:p \"Hello\"] [:ul [:li \"item_1\"] [:li \"item_2\"]]]\n```\n\nまた、第一引数について、 `.class_name` でクラス名を、 `#id_name` で ID を追加できます。\n\n参考:\n\n- <https://github.com/weavejester/hiccup>\n\n<a id=\"orgc3ffb60\"></a>\n\n## ホーム画面をブラウザに表示する\n\nhome の View は今の所静的なものであるので、 db や subs、events は不要です。 これを実際の画面に反映してみます。\n\nまず、 `src/cljs/pic_gallery_web` 下の、 db, events, subs, views を `services` の中に移動します。\n\n```clojure\n;; services/main/db.cljs\n(ns pic-gallery-web.services.main.db)\n\n(def default-db\n  {:name \"re-frame\"})\n\n;; services/main/events.cljs\n(ns pic-gallery-web.services.main.events\n  (:require\n   [re-frame.core :as re-frame]\n   [pic-gallery-web.services.main.db :as db]\n   [day8.re-frame.tracing :refer-macros [fn-traced]]\n   ))\n\n(re-frame/reg-event-db\n ::initialize-db\n (fn-traced [_ _]\n   db/default-db))\n\n;; services/main/subs.cljs\n(ns pic-gallery-web.services.main.subs\n  (:require\n   [re-frame.core :as re-frame]))\n\n(re-frame/reg-sub\n ::name\n (fn [db]\n   (:name db)))\n\n\n;; services/main/views.cljs\n(ns pic-gallery-web.services.main.views\n  (:require [re-frame.core :as re-frame]\n            [pic-gallery-web.main.subs :as subs]\n            [pic-gallery-web.services.home.views :as home-views]))\n\n(defn main-panel []\n  (let [name (re-frame/subscribe [::subs/name])]\n    [:div\n     [:h1 \"Hello from \" @name]\n     home-views/home-page]))\n```\n\n`pic_gallery_web/core.cljs` を移動した namespace を読みに行くことができるよう編集します。\n\nこれをブラウザで確認すると、次のようになります。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap6/img/init_home.png)\n\nだいぶ質素ですが、CSS を何も適用していないせいです。妖怪のせいではないです。\n\n<a id=\"org6bbeaf7\"></a>\n\n## Clojure Garden で CSS を書いてみる\n\nClojure は Java、 JavaScript、HTML も書けますが、 CSS も書けます。\n\nClojure で CSS を書くためのライブラリとして、 Garden (<https://github.com/noprompt/garden>) があります。\n\n詳細な使い方はドキュメントに委託するとして、簡単な使い方を紹介します。\n\n`src/clj/pic_gallery_web/css.clj` に Garden の初期コードが含まれています。\n\n```clojure\n(ns pic-gallery-web.css\n  (:require [garden.def :refer [defstyles]]))\n\n(defstyles screen\n  [:body {:color \"red\"}]\n)\n```\n\nコンパイルするには次の選択肢が用意されています。\n\n- lein garden once 一度だけコンパイルする\n- lein garden auto Hot loading を有効にする\n\n```text\n    $ lein garden auto\n    OpenJDK 64-Bit Server VM warning: Options -Xverify:none and -noverify were deprecated in JDK 13 and will likely be removed in a future release.\n    Compiling Garden...\n    Compiling \"resources/public/css/screen.css\"...\n    Wrote: resources/public/css/screen.css\n    Successful\n```\n\nコンパイル先の CSS ファイルは `resources/public/css/screen.css` に示されるものになります。\n\n```css\nbody {\n  color: red;\n}\n```\n\nHiccup と同様に、ベクトルとマップを使って表現されていることが観察できると思います。\n\n試しに、 body-color を black にするとブラウザでの表示にある、 **Hello from re-frame** の文字が黒くなっていることを確認することができます。\n\n応用として、複雑な CSS を Garden を用いて書いてみます。\n\nhome.views.cljs を見てみると、 `#how-to-use` 内に `content>title` クラスが確認できます。 今の画面ですと、ちょっと文字が大きいかもしれないので、調節してみます。\n\n```clojure\n(defn how-to-use []\n  [:div.content\n   [:p.title \"使い方\"]])\n```\n\n```clojure\n(defstyles screen\n  [:body {:color \"black\"}]\n  [:.content\n   [:.title {:font-size \"1.5rem\"}]])\n\n;; =>\n;; body {\n;;   color: black;\n;; }\n\n;; .content .title {\n;;   font-size: 1.5rem;\n;; }\n```\n\nブラウザの画面を確認すると、調節されていることが確認できます。 \n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap6/img/cssed_home.png)\n\n<a id=\"org0af39d5\"></a>\n\n## SPA とルーティング\n\nre-frame は SPA の開発フレームワークです。 SPA ということは URL に基づいてクライアント側でルーティングを行う必要があります。\n\n今回はこのルーティングを、サーバサイド開発でも用いた、 reitit (<https://github.com/metosin/reitit>) で実装します。\n\n以前も紹介しましたが、 Clojure と ClojureScript は同一構文を用いた言語であり、低レイヤーの部分を入れ替えれば全く同じコードを用いることができます。 reitit はこの特徴を生かし、サーバサイド、クライアントサイド両方で同様の構文を利用できるライブラリとして成立している非常に有用なライブラリです。(Java と JavaScript が同一言語かどうか、というプログラム初心者を判別する話がありますが、reitit では本当に同一であるかのように扱うことができます)\n\n今回はまず、Home 画面が &ldquo;/&rdquo; で表示されるようにルーティングを行っていきます。\n\nルーティング先を表すキーを domain として記述します。 (この部分は Clean Architecture を意識しています)\n\n```clojure\n(ns pic-gallery-web.domain.routes)\n\n(def ::home :_home)\n```\n\n```clojure\n(ns pic-gallery-web.routers\n  (:require\n   ;; re-frame\n   [re-frame.core :as re-frame]\n\n   ;; reitit\n   [reitit.coercion :as coercion]\n   [reitit.coercion.spec]\n   [reitit.frontend.easy :as rfe]\n   [reitit.frontend :as rf]\n\n   [pic-gallery-web.services.home.views :as home-views]\n   [pic-gallery-web.services.main.events :as main-events]\n   [pic-gallery-web.domain.routes :as routes-domain]))\n\n(def home-controllers\n  [{:start (fn [_]\n             (println \"entering home\"))\n    :stop (fn [_]\n            (println \"exit home\"))}])\n\n(def routes\n  [\"/\"\n   [\"\"\n    {:name ::routes-domain/home\n     :view home-views/home-page\n     :link-text \"app-home\"\n     :controllers home-controllers}]])\n\n(def router (rf/router routes))\n\n(defn on-navigate [new-match]\n  (when new-match\n    (re-frame/dispatch [::main-events/navigated new-match])))\n\n(defn init-routes! []\n  (rfe/start!\n   router\n   on-navigate\n   {:use-fragment false\n    ;; if true, use # routing\n    ;; if false, use http-histroy API\n    }))\n```\n\nre-frame と組み合わせるための **events** を追加します。 (ルーティングは外部から与えられる URL に基づいて起きるので events に書きます)\n\n```clojure\n(ns pic-gallery-web.services.main.events\n  (:require\n   [re-frame.core :as re-frame]\n   [pic-gallery-web.services.main.db :as db]\n   [reitit.frontend.easy :as rfe]\n   [reitit.frontend.controllers :as rfc]\n   [day8.re-frame.tracing :refer-macros [fn-traced]]))\n\n(re-frame/reg-event-db\n ::initialize-db\n (fn-traced [_ _]\n            db/default-db))\n\n;; navigation\n(re-frame/reg-fx\n ::navigate!\n (fn [route]\n   (apply rfe/push-state route)))\n\n(re-frame/reg-event-fx\n ::navigate\n (fn [_cofx [_ & route]]\n   {::navigate! route}))\n\n(re-frame/reg-event-db\n ::navigated\n (fn [db [_ new-match]]\n   (let [old-match (:current-route db)\n         controllers (rfc/apply-controllers (:controllers old-match) new-match)]\n     (when-not (= new-match old-match) (.scrollTo js/window 0 0))\n     (assoc db :current-route (assoc new-match :controllers controllers)))))\n```\n\n最後に、re-frame の起動と同時に reitit のルーティングを有効化する設定をします。\n\n```clojure\n(ns pic-gallery-web.core\n  (:require\n   [reagent.dom :as rdom]\n   [re-frame.core :as re-frame]\n   [pic-gallery-web.services.main.events :as main-events]\n   [pic-gallery-web.services.main.views :as main-views]\n   [pic-gallery-web.config :as config]\n   [pic-gallery-web.routers :as routers]))\n\n(defn dev-setup []\n  (when config/debug?\n    (println \"dev mode\")))\n\n(defn ^:dev/after-load mount-root []\n  (re-frame/clear-subscription-cache!)\n  (routers/init-routes!) ;; add here!\n  (let [root-el (.getElementById js/document \"app\")]\n    (rdom/unmount-component-at-node root-el)\n    (rdom/render [main-views/main-panel] root-el)))\n\n(defn init []\n  (re-frame/dispatch-sync [::main-events/initialize-db])\n  (dev-setup)\n  (mount-root))\n```\n\n`localhost:8280/` へアクセスし、コンソールログを見ると次のようなログが見えます。\n\n    dev mode\n    entering home\n    (index):59 service worker registered\n    browser.cljs:20 shadow-cljs: #52 ready!\n    browser.cljs:20 shadow-cljs: load JS pic_gallery_web/core.cljs\n\n&ldquo;entering home&rdquo; は、pic-gallery-web.routers/home-controller にある、 `:start` に書いた関数の実行結果になります。 controller の `:start` はルーティング先のページに入った際に呼び出される関数で、 `:stop` はルーティング先のページから出た際に呼び出される関数です。\n\n例えば自動ログインなどを実装する際には、この機能を利用することが想定できます。\n\n参考:\n\n- <https://github.com/metosin/reitit/tree/master/examples/frontend-re-frame>\n\n<a id=\"org1f7e4f7\"></a>\n\n# 付録\n\n<a id=\"org48685be\"></a>\n\n## ルーティングの検証\n\nルーティングが正しく行われているかを検証するには、次のような関数をテストに実装することで達成できます。 特に URL の path にユーザ ID などを用いる際には、以下のような方法でテストを書くことが推奨できます。\n\n```clojure\n(= ::routes-domain/home (-> (rf/match-by-path router \"/\") :data :name))\n```\n\n例えばこんな感じに書きます。(test/cljs/pic_gallery_web/routers_test.cljs)\n\n```clojure\n(ns pic-gallery-web.routers-test\n  (:require [pic-gallery-web.routers :as sut]\n            [pic-gallery-web.domain.routes :as routes-domain]\n            [reitit.frontend :as rf]\n            [cljs.test :as t :include-macros true]))\n\n(t/deftest route-match\n  (t/testing \"home\"\n    (t/is ::routes-domain/home (-> (rf/match-by-path sut/router \"/\") :data :name))))\n\n```\n\ncore_test を以下のように修正します。(わざと fail するテストが書かれています。)\n\n```clojure\n(ns pic-gallery-web.core-test\n  (:require [cljs.test :refer-macros [deftest testing is]]\n            [pic-gallery-web.core :as core]))\n\n;; (deftest fake-test\n;;   (testing \"fake description\"\n;;     (is (= 1 2))))\n```\n\n修正できたら、次のコマンドを実行して下さい。\n\n    $ lein ci\n    [:karma-test] Compiling ...\n    [:karma-test] Build completed. (175 files, 2 compiled, 0 warnings, 3.89s)\n    29 03 2021 09:34:40.099:INFO [karma-server]: Karma v6.2.0 server started at http://localhost:9876/\n    29 03 2021 09:34:40.100:INFO [launcher]: Launching browsers ChromeHeadless with concurrency unlimited\n    29 03 2021 09:34:40.103:INFO [launcher]: Starting browser ChromeHeadless\n    29 03 2021 09:34:40.341:INFO [Chrome Headless 88.0.4324.182 (Linux x86_64)]: Connected on socket HccaKZMZQn0nRFsMAAAB with id 51594150\n    LOG: 'Testing pic-gallery-web.routers-test'\n    .\n    Chrome Headless 88.0.4324.182 (Linux x86_64): Executed 1 of 1 SUCCESS (0.005 secs / 0.001 secs)\n\nExecuted 1 of 1 SUCCESS とのことで、テストが pass していることがわかります。\n\nなお、Linux 普段遣い (chrome ではなく chromium がブラウザの場合) のお兄さんは、 `CHROME_BIN=/usr/bin/chromium lein ci` として動かしてください。\n","user":"MeguruMokke","created_at":"2021-03-29T11:36:59+09:00","updated_at":"2021-03-29T11:42:41+09:00"},{"url":"https://qiita.com/toki_k/items/dbbb77aa0d6ebd96139c","title":"Nest.js/TypeORMでエラー ~ Cannot use import statement outside a module","body":"以下を使っています。\nマイグレーションファイル作成時にエラーが出たので、その解決方法をメモ。\n\n* Nest.js\n* Typeorm\n* postgres\n\n#エラーまで\nマイグレーションファイルを作成しようと以下のコマンドを実行したらエラーが出ました。\n\n```\nnpm run build\nnpx typeorm migration:generate -d src/migrations -n create-item\n```\n\n#エラー内容\nエラー内容は以下の通りです。\n\n```\n..........src/entities/item.entity.ts:1\nimport {\n^^^^^^\n\nSyntaxError: Cannot use import statement outside a module\n```\n\n#解決方法\n\nentitiesとmigrationsの探しに行く場所を\nコンパイル後のjsに変更することでエラーが解消されました。\n\n```ormconfig.json\n{\n    \"type\": \"postgres\",\n    \"host\": \"localhost\",\n    \"port\": 5432,\n    \"username\": \"root\",\n    \"password\": \"password\",\n    \"database\": \"test_db\",\n    \"entities\": [\"src/entities/**/*.ts\"], \n    \"migrations\": [\"src/migrations/**/*.ts\"],\n    \"logging\": true,\n    \"synchronize\": false\n}\n```\n以下の様に編集\n\n```ormconfig.json\n{\n    \"type\": \"postgres\",\n    \"host\": \"localhost\",\n    \"port\": 5432,\n    \"username\": \"root\",\n    \"password\": \"password\",\n    \"database\": \"test_db\",\n    \"entities\": [\"dist/entities/**/*.entity.js\"],\n    \"migrations\": [\"dist/migrations/**/*.js\"],\n    \"logging\": true,\n    \"synchronize\": false\n}\n```\n\n無事に実行されました。\n\n###参考資料\n[Githubのnestのissuesを参考](https://github.com/nestjs/nest/issues/4283)\n[NestJSで簡単なtudoリストを実装するチュートリアル](https://taroosg.io/nestjs-tutorial)\n","user":"toki_k","created_at":"2021-03-29T11:35:12+09:00","updated_at":"2021-03-29T11:37:09+09:00"},{"url":"https://qiita.com/hisayan/items/5f1eee40e9d5c115dd5c","title":"PLATEAU について、いろいろ調べてみた","body":"PLATEAU（プラトー）とは国土交通省が主導する日本全国の3D都市モデルの整備・オープンデータ化プロジェクトです。\n\nhttps://www.mlit.go.jp/plateau/\n\nオープンデータ化と、おそらく次いで発表されてくるであろうオープンソース化について、調べてみたことを整理整頓してみました。2021年3月末現在。\n\n# 簡単な経緯\n\n以前より、全国的な3D都市モデルの整備等については、内閣府地方創生推進事務局の「i-都市再生」として進められていたようです。\n\n>i-都市再生とは\n◆まちづくりの計画や効果を３Ｄの地図によって「見える化」\nする情報基盤（骨太方針：経済財政運営と改革の基本方針 2018）\n◆ＶＲ技術や地球地図、ビッグデータ等を活用し、都市再生に\nついての空間的、数値的な理解が直感的に得られる、見える\n化情報基盤（都市再生に取り組む基本的考え方 平成30年4月26日）\n◆まちづくりの課題や効果、将来像を、地理情報やVR技術等を\n用いて住民や投資家等に対して分かりやすく示す都市再生の\n見える化情報基盤（まち・ひと・しごと創生基本方針 2018）\n\nその後スマートシティという言葉もでてきたり、いろいろと発展する中で、3D都市モデル部分は、PLATEAUプロジェクトと切り出され、国土交通省が主管されるようになったのかしら？\n\n# オープンデータ化\n\n2021年3月26日(金)に、東京23区の3D都市モデルが公開されました。\n\nこちらでダウンロードいただけます。\n\nhttps://www.geospatial.jp/ckan/dataset/plateau\n\n\nおおくは LOD1, 大手町や新宿など一部はLOD2のテクスチャつきで発表されているようです。\n\nCityGML でいう LOD とは、Level of Detail の略で、LOD0 から LOD4 まで定義されています。\n\nざっくりと表現すると、\n\nLOD1 は、建物が四角い豆腐のようなモデル。\nLOD2 は、屋根の形状も再現されたモデル。\n\nです。\n\nここで注意しておきたいのは、PLATEAU プロジェクトは、ただポリゴンを準備するだけのプロジェクトではないということです。\n\n東京23区の建物のポリゴン情報がオープンデータ化された！\n3D地図をビジュアルに表現できるようになる。\nリアリティがあるゲームとかつくれそうだ！！\n\nという発想ももちろん楽しいですね。\n\n## 3D都市モデルとはポリゴンのことだけじゃない\n\nただ、それだけじゃない！！ポリゴンだけじゃない！！\nということを強くここに書いておきます。自分自身へも言い聞かせるために。\n\n今回のPLATEAUプロジェクトは、建物のポリゴンひとつひとつに、属性情報が付加されていることに強みがあります。\n\n属性情報とは、建物ひとつひとつが、\n\n+ 木造か鉄筋か\n+ 商業施設か工業施設か、あるいは宗教施設か\n+ 洪水が想定されたとき、浸水しそうかどうか\n\nこのような情報の整備も「見た目の3Dポリゴン」とともにすすめられているのです。\n\nこれらをもちいて、防災予測につなげたり、あらたなスマートシティの基盤としても活用されることを想定されているのです。\n\n\n\n\n\n# オープンソース化\n\nPLATEAU プロジェクト は、GitHub にレポジトリが用意され始めています。\n\nhttps://github.com/Project-PLATEAU\n\n正式なアナウンスはまだですし、ざっと拝見したところ整備が完了しているようにみうけられるレポジトリもあれば、まだ整備中のものもあるようです。\n\nおそらく、数か月以内に、オープンソース化についても発表があるのではないでしょうか。\n\nCityGML の変換機能や、データの整合性をチェックする環境などが用意されていますが、やはり興味をひかれたのが、PLATEAU Viewer です。ここではとくに、PLATEAU View について整理整頓してみます。\n\n## PLATEAU View\n\nまだアナウンスはありませんが、とりあえずのレポジトリはこちらのようです。\n\nhttps://github.com/Project-PLATEAU/PLATEAU-VIEW\n\n基盤として活用されているのは、CesiumJS および TerriaJS です。\n\nhttps://cesium.com/\n\nhttp://terria.io/\n\nCesium という、（超手抜きでわかりやすく表現すると）Google Earth ような３D地球儀上でいろいろプログラミングできるような仕組みがあって、それにさらにデータ属性関連などを表現しやすい仕組みを追加し Wrap したのが、terria(JS) です。\n\nですから、PLATEAU View は、terriaJS を通じて CesiumJS を利用していることになります。\n\nなお、terriaJS も CesiumJS もオープンソース化されています。\n\nterriaJS のレポジトリをみてみると、branch main は、バージョン7 のようです。そして、かなり以前より branch next で バージョン 8 (V8 と表記されていることが多い）の開発がすすんでいます。\n\nPLATEAU View は、どちらをベースにしているかというと、どうやら V8 のようです。\n\nV8 は、この数か月でも頻繁にアップデートされています。まだ beta 版的な状態でしょうか。\n\n国土交通省関連プロジェクトで、オープンソース化することを未来に見据えながら、オープンソース化されている terriaJS にがっつりのっかりすすめている PLATEAU View をいざリリースし始めたら、元となった terriaJS が頻繁にバージョンアップする。\n\nオープンソースあるあるではあるものの、PLATEAU View を開発されている方々の現場には、さまざまなご苦労があるような気がします。がんばってください！ \n\nあるある妄想。\n\n+ beta 版特有のこまかいバグにぶつかって色々調べて対応し、プルリク送ろうかとしたところ、本家でもその修正がはいってて調査時間を返してほしいと遠い目をしたり。\n+ ドキュメントが整備されていないから、ちょっとしたパラメーター設定するのに、ソースコードを深くまで潜って調査する必要があったり\n+ 先月動いていたものが、レポジトリを origin から merge してきたら、今月うごかなくなったり。\n+ オープンソース化をみすえていたら（しかも国のプロジェクトという立場で）、恥ずかしい適当コードですすめてるとあれだから、清書的なリファクタリングが。。。が。。。が。。。\n\nさて、V7 はあるていど枯れているようで、新規バグもなさそうだし、現段階で PLATEAU View としての開発ベースに採用しても十分な気もしているのですが、どうして V8 という beta 状態な、ややもするとイバラな道をすすんだのか。\n\nもちろん新しいバージョン採用もよいことなんですよね。面白い機能も増えていたり、関連ライブラリーとかも新しくなっていたり、あれこれ。製品寿命も新しいのですすめてたら自然と長くなりますし。\n\n100%の私見ですが、V8 は標準で、i18n（国際言語化・日本語化）対応が考慮されていました。V7 はそれがみあたりませんでした。日本で展開するにあたって、やはり日本語表示は必要不可欠か。V7にそれをつっこむよりも、V8 でいくことを選ばれた、、、のかしら？\n\n# toMap というサービスを開始してみた\n\nそんなこんな調べながら、toMap という PLATEAUプロジェクトと可能な限り互換性を担保する3D都市モデルプラットフォームサービス「toMap」を始めてみました。\n\nご興味ある方はぜひお気軽にご相談ください。\n\nhttps://tomap.app\n","user":"hisayan","created_at":"2021-03-29T11:34:42+09:00","updated_at":"2021-03-29T11:34:42+09:00"},{"url":"https://qiita.com/MeguruMokke/items/258c04caacdf66f706a2","title":"Clojure x ClojureScript で深める Web 開発 (5) API 開発 トランザクション添え","body":"# Git Repo\nソースコードと原文が入ったレポジトリ\nhttps://github.com/MokkeMeguru/clj-web-dev-ja/tree/main/chap5\n\n## シリーズ\n- [Clojure x ClojureScript で深める Web 開発 (0)](https://qiita.com/MeguruMokke/items/c6e059f109122be5f991)\n- [Clojure x ClojureScript で深める Web 開発 (1) Duct x Clean Architecture](https://qiita.com/MeguruMokke/items/af003d5a665095c0f3c8)\n- [Clojure x ClojureScript で深める Web 開発 (2) 環境の構築](https://qiita.com/MeguruMokke/items/9fe8e11a134e4c4dee2b)\n- [Clojure x ClojureScript で深める Web 開発 (3) API 作成入門](https://qiita.com/MeguruMokke/items/0ff941bcad6c86618b3d)\n- [Clojure x ClojureScript で深める Web 開発 (4) Auth](https://qiita.com/MeguruMokke/items/5ccf00bd2831551309d5)\n- [Clojure x ClojureScript で深める Web 開発 (5) API 開発 トランザクション添え](https://qiita.com/MeguruMokke/items/258c04caacdf66f706a2)\n- [Clojure x ClojureScript で深める Web 開発 (6) クライアントサイドと re-frame](https://qiita.com/MeguruMokke/items/78ff972bbd4efe3e1398)\n\n\n\n# 本編\n- [画像をローカルに保存する](#org3931e49)\n- [画像の REST のフロー確認](#orgb17ef8b)\n  - [post](#org41e3185)\n  - [get](#orgd11e09f)\n  - [update](#org2a6a62f)\n  - [delete](#org45255b1)\n  - [user&rsquo;s image list](#org044e511)\n    - [get](#org1274ae3)\n- [ドメイン・ハンドラの作成](#orga8ca3a1)\n  - [ドメイン](#org4a7b869)\n  - [ハンドラ](#org762f6b1)\n- [infrastructure の実装](#org5de0570)\n- [interface の実装](#orgc9ddaf2)\n  - [画像を保存するための interface](#orgf7f5174)\n  - [Pic 情報を保存するための SQL interface](#org97ae223)\n- [interface の組み込み](#org483db03)\n- [動作確認](#orgdb40875)\n- [付録](#orgabd7c30)\n  - [Repository 内に Transaction を封じ込める](#orgdc4fcba)\n    - [同一 サービス 内での Transaction](#org9fb6020)\n    - [複数サービスをまたいだ Transaction](#orgcb0627d)\n\n~~安心して下さい。長い戦いは終わったので、後は消化試合です~~\n\n本稿では、画像を投稿し、閲覧することができる簡易サービスを想定し、以前までに作った Auth と組み合わせた API 開発を進めていきます。\n\nまた、本稿では実装に難儀するトランザクションの処理を Repository 内に封じ込める / TCC (try-confirm/catch) を用いる手法で解決し [8.1](#repository-内に-transaction-を封じ込める) 、実例として紹介します。\n\n<a id=\"org3931e49\"></a>\n\n# 画像をローカルに保存する\n\n本ガイドでは、画像をローカルに保存します。 一般には、GCS などの外部ストレージを利用することが多いのですが、連携に関する話をまとめるには紙面と時間が足りないので、 ローカルに保存、というシンプルな方法を利用します。\n\nClojure で画像ファイルを保存する方法は、 `javax.imageio.ImageIO/write` 関数を用いることです。 名前空間からして Java の機能を使っていますが、実際そのとおりです。 このように優秀な Java のドキュメント付きライブラリを使える点が Clojure の強みの一つです。\n\n```clojure\n;; docs https://docs.oracle.com/javase/jp/8/docs/api/javax/imageio/ImageIO.html\n(import javax.imageio.ImageIO)\n\n(def image (ImageIO/read (io/file \"resources/sample.png\")))\n\n(ImageIO/write image \"png\" (io/file \"resources/copy-sample.png\"))\n;; return true (success) / false (failure)\n;; catch IllegalArgumentException ... any parameter is null\n;;       IOException              ... write error\n```\n\n<a id=\"orgb17ef8b\"></a>\n\n# 画像の REST のフロー確認\n\nbase-URL は、 `/api/pics` とします。 なお、post / delete については header に認証情報が付与されているものとします。\n\n<a id=\"org41e3185\"></a>\n\n## post\n\n画像ファイルである images は、json で扱うことが難しいので、FormData を利用する。\n\n- request\n\n  ```json\n  {\n    \"images\": [\"<image-file>\"],\n    \"title\": \"<title>\",\n    \"description(optional)\": \"<description>\"\n  }\n  ```\n\n- response\n\n  ```json\n  {\n    \"id\": \"<id>\"\n  }\n  ```\n\n<a id=\"orgd11e09f\"></a>\n\n## get\n\n- request (query)\n\n  ```json\n  {\n    \"id\": \"<id>\"\n  }\n  ```\n\n- response\n\n  ```json\n  {\n    \"id\": \"<id>\",\n    \"user-id\": \"<user-id>\",\n    \"title\": \"<title>\",\n    \"description(optional)\": \"<description>\",\n    \"created_at\": \"<created_at as long number>\",\n    \"image-urls\": [\"<image-url>\"]\n  }\n  ```\n\n<a id=\"org2a6a62f\"></a>\n\n## update\n\n今回は実装しません。\n\n<a id=\"org45255b1\"></a>\n\n## delete\n\n- request\n\n  ```json\n  {\n    \"id\": \"<id>\"\n  }\n  ```\n\n- response なし、成功であれば `204`\n\n<a id=\"org044e511\"></a>\n\n## user&rsquo;s image list\n\nユーザで絞り込んだ画像のリスト、と解釈し、 base-URL を `/api/users/<user-id>/pics` とします。\n\n<a id=\"org1274ae3\"></a>\n\n### get\n\n簡単のために、pagination を offset 法で実装することを前提に request query を組み立てています。\n\n- request (query)\n\n  ```json\n  {\n    \"page-id\": \"<page-index>\"\n  }\n  ```\n\n- response `description` は長い文字列を想定しており、 list 表示では必要としていないので省略します。 `image-urls` についても、(現状では) 一枚の `image-url` のみを返すようにします。\n\n  ```json\n  [\n    {\n      \"id\": \"<id>\",\n      \"title\": \"<title>\",\n      \"created_at\": \"<created_at as long number>\",\n      \"image-urls\": [\"<image-url>\"]\n    }\n  ]\n  ```\n\n<a id=\"orga8ca3a1\"></a>\n\n# ドメイン・ハンドラの作成\n\n<a id=\"org4a7b869\"></a>\n\n## ドメイン\n\n```clojure\n(ns picture-gallery.domain.pics\n  (:require [clojure.java.io :as io]\n            [clojure.spec.alpha :as s]\n            [clojure.string]\n            [picture-gallery.domain.users :as users-domain]\n            [picture-gallery.domain.base :as base-domain]\n            [picture-gallery.domain.auth :as auth-domain])\n  (:import javax.imageio.ImageIO))\n\n;; 不適切名のはじき出し\n(def invalid-title-substrs\n  [\"fuck\"])\n\n(defn acceptable-title? [title]\n  (apply\n   = false\n   (mapv (partial clojure.string/includes? title)\n         invalid-title-substrs)))\n\n;; 画像ファイルかどうかのチェック\n(defn image-file? [image-file]\n  (and (instance? java.io.File image-file)\n       (some? (ImageIO/read image-file))))\n\n(def min-title-length 0)\n(def max-title-length 128)\n(def min-description-length 0)\n(def max-description-length 1024)\n(def max-images-per-one-pic 3)\n\n(s/def ::pic-id uuid?)\n(s/def ::image-file image-file?)\n(s/def ::title (s/and string?\n                      #(< min-title-length (count %) max-title-length)\n                      acceptable-title?))\n(s/def ::description (s/and string?\n                            #(< min-description-length (count %) max-description-length)))\n\n(s/def ::image-url  string?)\n(s/def ::image-files (s/coll-of ::image-file :min-count 1 :max-count max-images-per-one-pic))\n(s/def ::image-urls (s/coll-of ::image-url :min-count 1 :max-count max-images-per-one-pic))\n\n;; model\n(s/def ::pic-images-create-model ::image-files)\n\n(s/def ::pic-create-model\n  (s/keys :req-un [::users-domain/user-id ::image-urls ::title]\n          :opt-un [::description]))\n\n(s/def ::pic-model\n  (s/keys :req-un [::users-domain/user-id ::pic-id ::image-urls ::title ::base-domain/created-at]\n          :opt-un [::description]))\n\n(s/def ::pics-model\n  (s/coll-of ::pic-model))\n\n;; usecase 内の出入り部分の型\n(s/def ::pic-post-input\n  (s/keys :req-un [::auth-domain/encrypted-id-token ::image-files ::title]\n          :opt-un [::description]))\n\n(s/def ::pic-post-output\n  (s/keys :req-un [::pic-id]))\n\n(s/def ::pic-get-input\n  (s/keys :req-un [::pic-id]))\n\n(s/def ::pic-get-output ::pic-model)\n\n(s/def ::pic-delete-input\n  (s/keys :req-un [::auth-domain/encrypted-id-token ::pic-id]))\n\n(s/def ::pic-delete-output true?)\n\n(s/def ::pic-image-get-input\n  (s/keys :req-un [::image-url]))\n\n(s/def ::pic-image-get-output\n  (s/keys :req-un [::image-file]))\n```\n\n<a id=\"org762f6b1\"></a>\n\n## ハンドラ\n\nベースのハンドラは `/api/pics` 以下に切り出します。\n\n```clojure\n(ns picture-gallery.infrastructure.router.pics\n  (:require [picture-gallery.domain.openapi.pics :as pics-openapi]))\n\n(defn pics-router [db auth image-db]\n  [\"/pics\"\n   {:swagger {:tags [\"pics\"]}}\n   [\"\"\n    {:swagger {:tags [\"pics\"]}\n     :post {:summary \"post pic\"\n            :swagger {:security [{:Bearer []}]}\n            :parameters {:multipart pics-openapi/pics-post-parameters-multipart}\n            :responses {200 {:body ::pics-openapi/pics-post-response}}\n            :handler (fn [input-data]\n                       {:status 200\n                        :body {:id \"1\"}})}}]\n   [\"/:pic-id\"\n    [\"\"\n     {:get {:summary \"get a pic\"\n            :parameters {:path {:pic-id ::pics-openapi/id}}\n            :responses {200 {:body ::pics-openapi/pic-get-response}}\n            :handler (fn [input-data]\n                       {:statsu 200\n                        :body {}})}\n      :delete {:summary \"delete a pic\"\n               :parameters {:path {:pic-id ::pics-openapi/id}}\n               :responses {204 {}}\n               :handler (fn [input-data]\n                          {:status 204\n                           :body {}})}}]]])\n```\n\nユーザの中にある pics という認識に立ち、 `users` namespace へ切り出しました。\n\n```clojure\n(ns picture-gallery.infrastructure.router.users\n  (:require [picture-gallery.domain.openapi.pics :as pics-openapi]\n            [picture-gallery.domain.openapi.users :as users-openapi]))\n\n(defn users-router [db auth]\n  [\"/users\"\n   {:swagger {:tags [\"users\"]}}\n   [\"/:user-id\"\n    [\"/pics\"\n     {:get {:summary \"get pics per user\"\n            :parameters {:query {:page-id pos-int?}\n                         :path {:user-id ::users-openapi/user-id}}\n            :responses {200 {:body ::pics-openapi/user-pics-get-response}}\n            :handler (fn [input-data]\n                       {:status 200\n                        :body {}})}}]]])\n```\n\n画像そのもののへの URL についても別の namespace に切り出しました。\n\n```clojure\n(ns picture-gallery.infrastructure.router.images\n  (:require [picture-gallery.domain.openapi.pics :as pics-openapi]))\n\n(defn images-router [db image-db]\n  [\"/img\"\n   {:swagger {:tags [\"images\"]}}\n   [\"/pics/:image-id\"\n    {:get {:summary \"get a image of pic\"\n           :parameters {:path {:image-id ::pics-openapi/image-id}}\n           :swagger {:produces [\"image/png\"]}\n           :handler (fn [input-data]\n                      {:status 200\n                       :body {}})}}]])\n```\n\nここまでで swagger は次の通りになります。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap5/img/swagger-overview.png)\n\n<a id=\"org5de0570\"></a>\n\n# infrastructure の実装\n\nローカルに画像を保存するために、image-db の infrastructure を作ります。 今回は、保存先の親ディレクトリ (`parent-dir`) を持つだけの infrastructure とします。\n\n```clojure\n(ns picture-gallery.infrastructure.image-db.core\n  (:require [integrant.core :as ig]))\n\n(defrecord LocalImageDBBoundary [image-db])\n\n(defmethod ig/init-key ::image-db\n  [_ {:keys [env]}]\n  (let [parent-dir (:local-image-db-parent-dir env)]\n    (->LocalImageDBBoundary {:parent-dir parent-dir})))\n```\n\ninfrastructure を書いたので、config を編集します。\n\n```clojure\n{:picture-gallery.infrastructure.env/env {}\n :picture-gallery.infrastructure.logger/logger {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.firebase.core/firebase {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.sql.sql/sql {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                              :logger #ig/ref :picture-gallery.infrastructure.logger/logger}\n :picture-gallery.infrastructure.image-db.core/image-db {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.sql.migrate/migration  {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                         :operation :migrate\n                                                         :logger #ig/ref :picture-gallery.infrastructure.logger/logger}\n :picture-gallery.infrastructure.router.core/router {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                     :auth #ig/ref :picture-gallery.infrastructure.firebase.core/firebase\n                                                     :db #ig/ref :picture-gallery.infrastructure.sql.sql/sql}\n :picture-gallery.infrastructure.server/server {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                :router #ig/ref :picture-gallery.infrastructure.router.core/router\n                                                :port 3000}}\n```\n\n`env.clj` `profiles.clj` についても、以前と同様に編集します。\n\n<a id=\"orgc9ddaf2\"></a>\n\n# interface の実装\n\ninterface も前回と同様に、 `defprotcol` を書いて、実装を書くだけです。\n\n<a id=\"orgf7f5174\"></a>\n\n## 画像を保存するための interface\n\nprotocol は次の通り。保存、取得、削除のみの小さい interface です。\n\n```clojure\n(ns picture-gallery.interface.gateway.image-db.pics-service\n  (:import (java.io File))\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.domain.pics :as pics-domain]\n            [integrant.core :as ig]\n            [clojure.java.io :as io]))\n\n(defprotocol Pics\n  (get-pic-image [image-db blob])\n  (save-pic-image [image-db ^File image])\n  (delete-pic-image [image-db blob]))\n\n(defn pics-service? [inst]\n  (satisfies? Pics inst))\n\n(s/def ::pics-service pics-service?)\n\n(s/fdef get-pic-image\n  :args (s/cat :image-db ::pics-service\n               :blob ::pics-domain/image-url)\n  :ret (s/or :exist ::pics-domain/image-file\n             :not-exist empty?))\n\n(s/fdef save-pic-image\n  :args (s/cat :image-db ::pics-service\n               :image ::pics-domain/image-file)\n  :ret ::pics-domain/image-url)\n\n(s/fdef delete-pic-image\n  :args (s/cat :image-db ::pics-service\n               :blob ::pics-domain/image-url)\n  :ret (s/and int? (partial <= 0)))\n```\n\n<details><summary>impl</summary><div>\n\n```clojure\n(ns picture-gallery.interface.gateway.image-db.local.pics-service\n  (:require [picture-gallery.interface.gateway.image-db.pics-service :refer [Pics]]\n            [clojure.java.io :as io]\n            [taoensso.timbre :as timbre])\n  (:import (javax.imageio ImageIO)))\n\n(extend-protocol Pics\n  picture_gallery.infrastructure.image_db.core.LocalImageDBBoundary\n\n  (get-pic-image [{{:keys [parent-dir]} :image-db} blob]\n    (let [file (io/file parent-dir \"pic\" blob)]\n      (if (.isFile file) file nil)))\n\n  (save-pic-image [{{:keys [parent-dir]} :image-db} image]\n    (try\n      ;; check duplicate\n      (loop [blob (java.util.UUID/randomUUID)\n             retry 0]\n        (let [file (io/file parent-dir \"pic\" (.toString blob))]\n          (cond\n            (> retry 10) (throw (ex-info \"save pic's image failed: at apply unique random uuid\"))\n            (and file (.isFile file)) (recur (java.util.UUID/randomUUID) (inc retry))\n            :else (do (ImageIO/write (ImageIO/read image) \"png\" file)\n                      (.toString blob)))))\n      (catch java.io.IOException e\n        (timbre/error \"Pics save image Error: \" (.getMessage e))\n        (throw (ex-info \"failed to save image\" {:parent-dir parent-dir :image image})))))\n\n  (delete-pic-image [{{:keys [parent-dir]} :image-db} blob]\n    (try\n      (io/delete-file (io/file parent-dir \"pic\" blob)) 1\n      (catch Exception e\n        (timbre/warn \"Pics delete image Error: \" (.getMessage e)) 0))))\n```\n\n</div>\n</details>\n\n<a id=\"org97ae223\"></a>\n\n## Pic 情報を保存するための SQL interface\n\n前回ユーザ用に作った interface と同様に作ります。\n\n今回は、1 つの投稿について、複数枚の画像が投稿できることを（長期的に）想定しているので、 テーブルを分離し( one-many )ます。\n\nそして、usecase に transaction を持ち込まないため、この複数テーブルの操作を一つの repository に押し込んでしまいます。\n\n```clojure\n(ns picture-gallery.interface.gateway.database.pics-repository\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.domain.pics :as pics-domain]\n            [picture-gallery.domain.users :as users-domain]\n            [picture-gallery.domain.base :as base-domain]\n            [clojure.java.io :as io]\n            [integrant.core :as ig]\n            [orchestra.spec.test :as st]\n            [next.jdbc :as jdbc]))\n\n(defprotocol Pics\n  (get-pics [db])\n  (get-pics-by-user [db user-id page-id])\n  (get-pic [db pic-id])\n  (create-pic [db pic-create-model state])\n  (update-pic-state [db pic-id state])\n  (delete-pic [db pic-id logical?]))\n\n(defn pics-repository? [inst]\n  (satisfies? Pics inst))\n\n(s/def ::pics-repository pics-repository?)\n\n(s/fdef get-pics\n  :args (s/cat :db ::pics-repository)\n  :ret ::pics-domain/pics-model)\n\n(s/fdef get-pics-by-user\n  :args (s/cat :db ::pics-repository\n               :user-id ::users-domain/user-id\n               :page-id pos-int?)\n  :ret ::pics-domain/pics-model)\n\n(s/fdef get-pic\n  :args (s/cat :db ::pics-repository\n               :pic-id ::pics-domain/pic-id)\n  :ret (s/or :exist ::pics-domain/pic-model\n             :not-exist empty?))\n\n(s/fdef create-pic\n  :args (s/cat :db ::pics-repository\n               :pic-create-model ::pics-domain/pic-create-model\n               :state ::base-domain/tcc-state)\n  :ret (s/tuple ::pics-domain/pic-model ::base-domain/tcc-state))\n\n(s/fdef update-pic-state\n  :args (s/cat :db ::pics-repository\n               :pic-id ::pics-domain/pic-id\n               :state ::base-domain/tcc-state)\n  :ret (s/and int? (partial <= 0)))\n\n(s/fdef delete-pic\n  :args (s/cat :db ::pics-repository\n               :pic-id ::pics-domain/pic-id\n               :logical? boolean?)\n  :ret (s/and int? (partial <= 0)))\n```\n\n<details><summary>impl(複数テーブルの操作のため、かなり長いです)</summary><div>\n\n```clojure\n(ns picture-gallery.interface.gateway.database.sql.pics-repository\n  (:require [picture-gallery.interface.gateway.database.pics-repository :refer [Pics]]\n            [picture-gallery.interface.gateway.database.sql.utils :as sql-utils]\n            [next.jdbc :as jdbc]\n            [clojure.string]\n            [next.jdbc.sql :as njs]\n            [next.jdbc.types :refer [as-other]]\n            [clojure.spec.alpha :as s]))\n\n(defn pic-create-model->sql [{:keys [user-id title description]} state]\n  (cond->\n   {:user_id user-id\n    :title title\n    :tcc_state (as-other (name state))}\n    description (assoc :description description)))\n\n(defn pic-image-urls->sql [image-urls]\n  (vec (map-indexed  (fn [idx image-url]\n                       {:blob image-url\n                        :index idx}) image-urls)))\n\n(defn sql->pic-model [sql-pic sql-pic-image]\n  (let [{:keys [id user_id title description created_at updated_at is_deleted tcc_state]} sql-pic\n        image-urls (mapv #(:blob %) (sort-by :index sql-pic-image))]\n    (if-not id\n      nil\n      (cond->\n       {:pic-id id\n        :user-id user_id\n        :title title\n        :image-urls image-urls\n        :created-at (sql-utils/sql-to-long created_at)\n        :is-deleted is_deleted\n        :tcc-state tcc_state}\n        description (assoc :description description)\n        updated_at (assoc :updated-at (sql-utils/sql-to-long updated_at))))))\n\n(def sql-basic-selection\n  \"SELECT * FROM pics INNER JOIN pic_images ON (pics.id = pic_images.id)\")\n\n(extend-protocol Pics\n  picture_gallery.infrastructure.sql.sql.Boundary\n\n  (get-pics [{:keys [spec]}]\n    (with-open [conn (jdbc/get-connection (:datasource spec))]\n      (let [pics (jdbc/execute! conn [(clojure.string/join \" \" [sql-basic-selection \"limit 100\"])] sql-utils/default-jdbc-option)\n            pics-images (mapv #(jdbc/execute! conn [\"SELECT * FROM pic_images WHERE id = ?\" (:id %)] sql-utils/default-jdbc-option) pics)]\n        (mapv sql->pic-model pics pics-images))))\n\n  (get-pics-by-user [{:keys [spec]} user-id page-id]\n    (with-open [conn (jdbc/get-connection (:datasource spec))]\n      (let [sql-offset (* 20 (dec page-id))\n            pics (jdbc/execute! conn [\"SELECT * FROM pics WHERE user_id = ? AND is_deleted = false AND tcc_state = ? limit 20 offset ?\" user-id (as-other \"confirm\") sql-offset] sql-utils/default-jdbc-option)\n            pics-head-images (mapv #(jdbc/execute! conn [\"SELECT * FROM pic_images WHERE id = ? AND index = 0\" (:id %)] sql-utils/default-jdbc-option) pics)]\n        (mapv sql->pic-model pics pics-head-images))))\n\n  (get-pic [{:keys [spec]} pic-id]\n    (with-open [conn (jdbc/get-connection (:datasource spec))]\n      (sql->pic-model\n       (jdbc/execute-one! conn [\"SELECT * FROM pics WHERE id = ? AND is_deleted = false AND tcc_state = ?\" pic-id (as-other \"confirm\")] sql-utils/default-jdbc-option)\n       (jdbc/execute! conn [\"SELECT * FROM pic_images WHERE id = ?\" pic-id] sql-utils/default-jdbc-option))))\n\n  (create-pic [{:keys [spec]} pic-create-model state]\n    (let [sql-pic-create-model (pic-create-model->sql pic-create-model state)\n          sql-pic-image-urls (pic-image-urls->sql (:image-urls pic-create-model))]\n      (jdbc/with-transaction [tx (:datasource spec)]\n        (let [pic-id (loop [pic-id (java.util.UUID/randomUUID) retry 0]\n                       (cond\n                         (> retry 10) (throw (ex-info \"pic's unique random uuid generation failed\" {:pic-create-model pic-create-model}))\n                         (nil? (jdbc/execute-one! tx [\"SELECT * FROM pics WHERE id = ?\" pic-id])) pic-id\n                         :else (recur (java.util.UUID/randomUUID) (inc retry))))\n              pic-result (njs/insert! tx :pics (assoc sql-pic-create-model :id pic-id) sql-utils/default-jdbc-option)\n              pic-image-result (njs/insert-multi! tx :pic_images [:blob :id :index] (mapv (fn [{:keys [blob index]}] [blob pic-id index]) sql-pic-image-urls) sql-utils/default-jdbc-option)]\n          [(sql->pic-model pic-result pic-image-result) (keyword (:tcc_state pic-result))]))))\n\n  (update-pic-state [{:keys [spec]} pic-id state]\n    (sql-utils/update! spec :pics {:tcc_state (as-other (name state))} {:id pic-id}))\n\n  (delete-pic [{:keys [spec]} pic-id logical?]\n    (if logical?\n      (sql-utils/logical-delete! spec :pics {:id pic-id})\n      (sql-utils/physical-delete! spec :pics {:id pic-id}))))\n```\n\n</div>\n</details>\n\n<a id=\"org483db03\"></a>\n\n# interface の組み込み\n\nusecase 層に interface を組み込んでいきます。 一番問題となるのは、投稿処理の部分で、TCC パターンを組み合わせて実装することになります。\n\nそこで、まずは実装フローを図にしてみます。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap5/img/pic_tcc_flow.png)\n\nClojure において、 (エラー処理を省いて) 処理が一本筋であると、かなり綺麗な (ref: 前回の signin の usecase ) 実装ができます。 しかし、今回は枝分かれのある処理を行った後、集約する必要が見えています。\n\nそのため、本ガイドでは、この TCC 処理の部分を取り出すことで、一本筋に見えるよう関数の実装を工夫しています。\n\n結果として実装がかなり長くなったため、内部関数の TCC 処理部分について、 spec を書いて、仕様を明らかにしています。 このように複雑な関数を実装する必要性に迫られた際には、REPL で動作を確認しながら、 spec を用いて、 **どのような関数を実装するのか削り出せる点** が、Clojure の強みの一つです (と思っています)。\n\n<details><summary> 実装 (300 line +) </summary><div>\n\n```clojure\n(ns picture-gallery.usecase.pic-post\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.domain.pics :as pics-domain]\n            [picture-gallery.utils.error :refer [err->> border-error]]\n            [picture-gallery.interface.gateway.database.pics-repository :as pics-repository]\n            [picture-gallery.interface.gateway.image-db.pics-service :as pics-service]\n            [orchestra.spec.test :as st]\n            [clojure.java.io :as io]\n            [picture-gallery.domain.error :as error-domain]\n            [taoensso.timbre :as timbre]\n            [picture-gallery.interface.gateway.auth.auth-service :as auth-service]\n            [picture-gallery.interface.gateway.database.users-repository :as users-repository]\n            [integrant.core :as ig]\n            [picture-gallery.domain.users :as users-domain]\n            [picture-gallery.domain.base :as base-domain]))\n\n(s/fdef pic-post\n  :args (s/cat :db (s/and ::users-repository/users-repository\n                          ::pics-repository/pics-repository)\n               :auth ::auth-service/auth-service\n               :image-db ::pics-service/pics-service\n               :input-model ::pics-domain/pic-post-input)\n\n  :ret (s/or :success (s/tuple ::pics-domain/pic-post-output nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n;; この部分は signin と同じ関数を使いまわしています。\n;; 小さな機能で分割することでコードを再利用できるようになり、メンテナンスコストの低下が望めるかもしれません。：\n(defn decode-id-token \"\n  decode encrypted id-token\n  \"\n  [{:keys [input-model auth] :as m}]\n  (let [[[status body] err] (border-error {:function #(auth-service/decode-id-token auth (:encrypted-id-token input-model))\n                                           :error-wrapper error-domain/auth-error})]\n    (cond\n      err [nil err]\n      (= :failure status) [nil body]\n      :else [(assoc m :id-token (:id-token body)) nil])))\n\n(defn get-exist-user-has-id-token \"\n  get active (not logical deleted) user\n  which has id-token\"\n  [{:keys [id-token db] :as m}]\n  (let [[active-user err] (border-error {:function #(users-repository/get-exist-user-by-auth-token db id-token)\n                                         :error-wrapper error-domain/database-error})]\n    (cond\n      err [nil err]\n      (empty? active-user) [nil error-domain/signin-failed-by-user-not-found]\n      :else [(assoc m :exist-user active-user) nil])))\n\n\n;; --- tcc-process -------\n;; 以下が spec の定義です。REPL 経由で 実装と往復し、仕様を決めていきます。\n;; 極力関数の概形を揃えることで、可読性を向上させると良いでしょう (そのためにも沢山仮実装してみて下さい)。\n;; spec helper\n(s/def ::input-model ::pics-domain/pic-post-input)\n(s/def ::exist-user ::users-domain/user-model)\n(s/def ::db (s/and ::pics-repository/pics-repository\n                   ::users-repository/users-repository))\n(s/def ::image-db ::pics-service/pics-service)\n\n(s/def ::tcc-image-process (s/or :success ::pics-domain/image-urls :failure nil?))\n(s/def ::tcc-db-process (s/or :success ::pics-domain/pic-model :failure nil?))\n(s/def ::tcc-error (s/or ::no-error nil? ::error ::error-domain/error))\n(s/def ::tcc-result ::base-domain/tcc-state)\n(s/def ::tcc-status (s/keys :req-un [::tcc-image-process ::tcc-db-process ::tcc-result ::tcc-error]))\n\n;; try\n(s/fdef pic-post-try-phase-save-images\n  :args (s/cat :image-files ::pics-domain/image-files\n               :image-db ::image-db)\n  :ret (s/or :success (s/tuple ::pics-domain/image-urls nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n(s/fdef pic-post-try-phase-save-pic\n  :args (s/cat :m (s/keys :req-un [::input-model ::exist-user ::pics-domain/image-urls]) :db ::db)\n  :ret (s/or :success (s/tuple ::pics-domain/pic-model nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n(s/fdef pic-post-try-phase\n  :args (s/cat :m (s/keys :req-un [::input-model ::exist-user ::db ::image-db]))\n  :ret (s/tuple boolean? ::tcc-status))\n\n;; confirm\n(s/fdef pic-post-confirm-phase-save-images\n  :args (s/cat :tcc-image-process ::tcc-image-process :image-db ::image-db)\n  :ret (s/or :success (s/tuple ::tcc-image-process nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n(s/fdef pic-post-confirm-phase-save-pic\n  :args (s/cat :tcc-db-process ::tcc-db-process :db ::db)\n  :ret (s/or :success (s/tuple ::tcc-db-process nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n(s/fdef pic-post-confirm-phase\n  :args (s/cat :m (s/keys :req-un [::tcc-status ::db ::image-db]))\n  :ret (s/or :success (s/tuple ::tcc-status nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n;; cancel\n(s/fdef pic-post-cancel-phase-remove-images\n  :args (s/cat :tcc-image-process ::tcc-image-process :image-db ::image-db)\n  :ret (s/or :success (s/tuple ::tcc-image-process nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n(s/fdef pic-post-cancel-phase-remove-pic-model\n  :args (s/cat :tcc-db-process ::tcc-db-process :db ::db)\n  :ret (s/or :success (s/tuple ::tcc-db-process nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n(s/fdef pic-post-cancel-phase\n  :args (s/cat :m (s/keys :req-un [::tcc-status ::db ::image-db]))\n  :ret (s/tuple nil? ::error-domain/error))\n\n;; root\n(s/fdef pic-post-tcc\n  :args (s/cat :m (s/keys :req-un [::input-model ::exist-user ::db ::image-db]))\n  :ret (s/or :success (s/tuple (s/keys :req-un [::tcc-status]) nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n;; --------------------------\n;; 以下が実装です。\n;; try-phase\n(defn pic-post-try-phase-save-images \"\n tcc's try-process\n  ! 1. save images ^ generate each image's url\n  2. save pic model as tried-model into db\n \"\n  [image-files image-db]\n  (loop [acc-image-files image-files\n         image-urls []]\n    (if (-> acc-image-files count zero?)\n      [image-urls nil]\n      (let [[image-url err]\n            (border-error {:function #(pics-service/save-pic-image image-db (first acc-image-files))\n                           :error-wrapper error-domain/image-db-error})]\n        (cond\n          err [image-urls err]\n          :else (recur (rest acc-image-files) (conj image-urls image-url)))))))\n\n(defn pic-post-try-phase-save-pic \"\n  tcc's try-process\n  1. save images ^ generate each image's url\n  ! 2. save pic model as tried-model into db\n  \"\n  [{:keys [input-model exist-user image-urls]} db]\n  (let [pic-create-model {:user-id (:user-id exist-user)\n                          :image-urls image-urls\n                          :title (:title input-model)\n                          :description (:description input-model)}\n        [[new-pic-tried _] err] (border-error {:function #(pics-repository/create-pic db pic-create-model :try)\n                                               :error-wrapper error-domain/database-error})]\n    (cond\n      err [nil err]\n      :else [new-pic-tried nil])))\n\n(defn pic-post-try-phase \"\n  tcc's try-process\n  1. save images ^ generate each image's url\n  2. save pic model as tried-model into db\n  \"\n  [{:keys [input-model exist-user db image-db]}]\n  (let [[image-urls err] (pic-post-try-phase-save-images (:image-files input-model) image-db)\n        [new-pic err] (if err\n                        [nil err]\n                        (pic-post-try-phase-save-pic {:input-model input-model\n                                                      :exist-user exist-user\n                                                      :image-urls image-urls}\n                                                     db))]\n    (if err\n      [false {:tcc-image-process image-urls\n              :tcc-db-process new-pic\n              :tcc-result :try\n              :tcc-error err}]\n      [true {:tcc-image-process image-urls\n             :tcc-db-process new-pic\n             :tcc-result :try\n             :tcc-error nil}])))\n\n;; confirm-process\n(defn pic-post-confirm-phase-save-images \"\n  tcc's confirm-process\n  ! 1. confirm saved images\n  2. save pic model as confirmed-model into db\n  \"\n  [tcc-image-process image-db]\n  [tcc-image-process nil])\n\n(defn pic-post-confirm-phase-save-pic \"\n  tcc's confirm-process\n  1. confirm saved images\n  ! 2. save pic model as confirmed-model into db\n  \"\n  [tcc-db-process db]\n  (let [[_ err] (border-error {:function #(pics-repository/update-pic-state db (:pic-id tcc-db-process) :confirm)\n                               :error-wrapper error-domain/database-error})]\n    (when err\n      (timbre/error \"pic-post tcc confirm phase failed at save-pic\" tcc-db-process))\n    (cond\n      err [nil err]\n      :else [tcc-db-process nil])))\n\n(defn pic-post-confirm-phase \"\n  tcc's confirm-process\n  1. confirm saved images\n  2. save pic model as confirmed-model into db\n  \"\n  [{:keys [tcc-status db image-db] :as m}]\n  (let [{:keys [tcc-db-process tcc-image-process]} tcc-status\n        [tcc-image-process err] (pic-post-confirm-phase-save-images tcc-image-process image-db)\n        [tcc-db-process err] (if err [nil err] (pic-post-confirm-phase-save-pic tcc-db-process db))]\n    (cond\n      err [nil err]\n      :else [{:tcc-image-process tcc-image-process\n              :tcc-db-process tcc-db-process\n              :tcc-result :confirm\n              :tcc-error nil} nil])))\n\n;; cancel-process\n(defn pic-post-cancel-phase-remove-images \"\n  tcc's cancel-process\n  ! 1. remove images\n  2. set pic model's tcc-state :cancel\n  \"\n  [tcc-image-process image-db]\n  (let [delete-image-results\n        (map (fn [image-url]\n               (try (pics-service/delete-pic-image image-db image-url)\n                    (catch Exception e\n                      (timbre/error \"pic-post tcc cancel phase failed at remove-image\" image-url \"cause: \" (.getMessage e))\n                      -1))) tcc-image-process)]\n    (if (every? (partial <= 0) delete-image-results)\n      [tcc-image-process nil]\n      [nil error-domain/image-delete-failed])))\n\n(defn pic-post-cancel-phase-remove-pic-model \"\n  tcc's cancel-process\n  1. remove images\n  ! 2. set pic model's tcc-state :cancel\n  \"\n  [tcc-db-process db]\n  (let [[_ err]\n        (border-error {:function #(pics-repository/update-pic-state db (:pic-id tcc-db-process) :cancel)\n                       :error-wrapper error-domain/database-error})]\n    (cond\n      err [nil err]\n      :else [tcc-db-process  nil])))\n\n(defn pic-post-cancel-phase \"\n  tcc's cancel-process\n  1. remove images\n  2. set pic model's tcc-state :cancel\n  \"\n  [{:keys [tcc-status db image-db]}]\n  (let [{:keys [db-process image-process]} tcc-status\n        [image-process image-err] (pic-post-cancel-phase-remove-images image-process image-db)\n        [db-process db-err] (pic-post-cancel-phase-remove-pic-model db-process db)]\n    (when image-err\n      (timbre/error \"pic-post tcc cancel phase failed at remove-images\" image-process))\n    (when db-err\n      (timbre/error \"pic-post tcc cancel phase failed at remove-pic-model\" db-process))\n    (cond\n      image-err [nil image-err]\n      db-err [nil db-err]\n      :else [nil (-> tcc-status :tcc-error)])))\n\n(defn pic-post-tcc \"\n  tcc-process\n  1. try-phase\n     returns [try-success? tcc-status]\n  2-a. confirm-phase if try-success?\n  2-b. cancel-phase if-not try-success?\n  \"\n  [{:keys [input-model exist-user db image-db]}]\n  (let [m {:input-model input-model :exist-user exist-user :db db :image-db image-db}\n        [try-success? tcc-status]\n        (pic-post-try-phase m)]\n    (when (:error tcc-status)\n      (timbre/warn \"pic-post tcc process error: \" (:error tcc-status)\n                   \"/db-process: \"  (:tcc-db-process tcc-status)\n                   \"/image-process: \" (:tcc-image-process tcc-status)))\n    (let [[tcc-result err] (if try-success?\n                             (pic-post-confirm-phase (assoc m :tcc-status tcc-status))\n                             (pic-post-cancel-phase (assoc m :tcc-status tcc-status)))]\n      (cond\n        err [nil err]\n        :else [(assoc m :tcc-status tcc-result) nil]))))\n\n;; ----------------\n(defn ->output-model [{:keys [tcc-status]}]\n  [{:pic-id (-> tcc-status :tcc-db-process :pic-id)} nil])\n\n;; 大元の関数は、 sigin / signup と同様に err->> マクロでくくるという規格を設けています。\n(defn pic-post [db auth image-db input-model]\n  (err->>\n   {:input-model input-model\n    :auth auth\n    :db db\n    :image-db image-db}\n   decode-id-token               ;; encrypted-id-token を decode します。\n   get-exist-user-has-id-token   ;; ユーザ情報を獲得します。\n   pic-post-tcc                  ;; tcc パターンでデータを db、image-db へ保存します。\n   ->output-model))              ;; output のモデルにフォーマットします。\n```\n\n</div>\n</details>\n\nその他の実装は、signin / signup と同様に作られるので、省略します。\n\n<a id=\"orgdb40875\"></a>\n\n# 動作確認\n\nSwagger を用いて動作確認をします。\n\n- post\n\n  ![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap5/img/post_pic.png)\n\n- get list\n\n  ![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap5/img/get_list_pics.png)\n\n- get image\n\n  ![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap5/img/get_image.png)\n\n<a id=\"orgabd7c30\"></a>\n\n# 付録\n\n<a id=\"orgdc4fcba\"></a>\n\n## Repository 内に Transaction を封じ込める\n\nTransaction は副作用を伴う関数を ACID に扱いたいときに用います。 ACID の A は原子性 (atomicity) であり、原子をやり取りするのに一つの Repository を使おう、という立場であれば、この主張は正しいと言えます。\n\n<a id=\"org9fb6020\"></a>\n\n### 同一 サービス 内での Transaction\n\n例えば、銀行の預金テーブル Y があったとき、Ron から Potter に 20 ポンド 送金があったとき、 Ron の預金を減らす処理と Potter の預金を増やす処理は ACID でなければなりません。\n\nこのとき、次の 2 つのパターンが考えられます。\n\n1.  usecase 側に transaction を漏らして、SQL を実行\n2.  repository 内で Ron と Potter の預金を操作する\n\n参考: <https://github.com/duct-framework/duct/wiki/Boundaries>\n\nしかし、実際の Transaction の利用場面では、 (**同一 DB 上の**) いくつかの異なるテーブルにまたがって ACID な操作を行いたいケースもあります。 例えばソーシャルゲームのポイントガチャがそれに当たります。 (ポイントテーブル Z のポイント z を減らして、アイテムテーブル I にアイテム i を追加する)\n\nこのときには、次の 2 つのパターンが考えられます (他にもありますが簡単のため 2 つとします)。\n\n1.  usecase 側に 該当 DB の transaction を漏らして、 transaction 内で 複数の repository を操作する。\n2.  複数テーブルで表されるモデルを 1 つのモデルとみなして、 1 つの repository とする。\n\n2 については、モデルをどう効率よく設計できているかに依存した方針です。また、 ORM を意識したモデル設計とは異なります。 しかしモデルを原子とみなす考え方をすると、 2 の実装を考えることもできます。\n\nただし弱点として、新しい機能開発をする際に、モデル (= transaction の単位) を見直す必要があります。 言い換えると、 1 を用いることで、モデルが Atomic でなくとも usecase 内部で Atomic な単位を生成することができるので、お手軽に拡張することができます。\n\n<a id=\"orgcb0627d\"></a>\n\n### 複数サービスをまたいだ Transaction\n\n同一 DB だけで完結する transaction は上記解決策を考えればよいのですが、例えば決済サービスと連動して自社 DB を操作します、となると話が変わります。 2 つのサービスを連携させた transaction は通常生成することが困難です。 そのため、TCC (try-confirm/cancel) というアプローチが用いられるケースが有名所さんとなっています。\n\nTCC とは、try-phase, confirm/cancel-phase の 2 つのフェーズを用いた transaction 方式です。\n\ntry-phase とは、各サービスに対してリソースの仮押さえを行う phase です。ここで、抑えたリソースは **必ず** 確定 (confirm) / 棄却 (cancel) ができることが保証されています。 confirm/cancel-phase とは、 すべてのサービスで try が成功すればリソース消費の確定 (confirm)を、一つでも失敗すれば棄却 (cancel) する phase です。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap5/img/tcc.png)\n\nTCC の場合は、 transaction を DB やサービスの repository から usecase へ持ち込む必要がないため、本手続きは usecase 内に書くことも容易です (実際に本ガイドでは、 **同一サービス内の操作は同一 repository** に、 **複数サービスにまたがる操作は TCC を用いて usecase 内** に落としています)。\n\n勿論 TCC ではなく、ログを吐き出して記録することでサーバ外で容易に error-catch / retry できるようにする手法などもあるので、たくさん実験してみて下さい (少なくとも本ガイドは全くフレームワークやライブラリの制約が削ぎ落とされているので、実装は可能なはずです)。\n\n参考:\n\n- <https://qiita.com/nk2/items/d9e9a220190549107282#tcc%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3>\n- <https://engineering.mercari.com/blog/entry/2019-06-07-155849/>\n","user":"MeguruMokke","created_at":"2021-03-29T11:30:26+09:00","updated_at":"2021-03-29T12:52:58+09:00"},{"url":"https://qiita.com/tk2Aprl/items/f3e339f303797fed49a1","title":"vuexのgettersでstateをフィルタリングする方法","body":"stateにあるJSONデータ、もしくはactionsで持ってきたデータをフィルタリングする方法。\n今回はそもそもバックエンド側でフィルタリングしようねという話になったので、自分の環境では使用しなかった。\nでもせっかく組んだし、もったいないので共有します（あんまり使い道は無いだろうけど・・・）\n\n```\nexport const getters = {\n    getFilteringList: (state) => (query) => {\n      // queryの形式を[{key:'',value:''}...]に変換する\n      let conversion = Object.entries(query).map(([key, value]) => ({'key': key, 'value': value}))\n      // 条件に合致したデータを返す関数を定義（every関数なので、全てに合致する必要がある）\n      function isMatchToAllConditions(data, conditions){\n        return conditions.every(c => data[c.key] == c.value)\n      }\n      // null以外の要素を取り出す\n      const conditions = conversion.filter(q => q.value && q.key)\n      // フィルターをかける\n      const searched = state.data.filter(list => {\n        return isMatchToAllConditions(list, conditions)\n      })\n      // 出力\n      return searched\n    }\n  }\n```\n\ngetFilteringListにはコンポーネント側でqueryを投げてあげる必要がある。\n","user":"tk2Aprl","created_at":"2021-03-29T11:25:09+09:00","updated_at":"2021-03-29T11:25:09+09:00"},{"url":"https://qiita.com/hiro_koba_jp/items/66a4b0643dd759088a30","title":"Google Search ConsoleのデータをBigQueryに自動同期し、Googleデータポータル(旧Data Studio)で可視化する","body":"\n## 概要\nGoogle Search Consoleを使うことでGoogle検索での表示回数・掲載順位を把握したり、SEO上の問題点を修正してWebサイトの注目度を高めることができます。しかし、絶えず集められるデータをその都度分析し、最新の状態に保つのにはコストがかかります。そこで今回は、[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)という分析基盤向けデータ統合サービスを使い、Google Search Consoleデータの抽出自動化＋DWH（データウェアハウス）への統合＋可視化までやってみようと思います。\n\n今回、データの転送手段として採用した[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)は、Google Search Consoleの他にも、様々な広告・CRM・DBなどのデータソースにも対応しています。\n[troccoの使い方まとめ（CRM・広告・データベース他）](https://qiita.com/hiro_koba_jp/items/2b2caa040804e402bda7)\n\n![イメージ.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/8fafde44-d85b-f4fd-d50d-149c23ee9401.png)\n\n\n\n## ゴール\nGoogle Search Consoleのデータを下のようにBigQueryに統合し\n![bigquery転送.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/b75f6073-00bf-d3e1-8175-76878a7ea06c.png)\n\n\nデータポータルで可視化します(作成後は自動で最新値に更新することも可能です）\n![円グラフ完成.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/08e5a8d6-bae7-dd68-408b-49b0f7fab5fb.png)\n\n\n\n\n\n\n\n## こんな人におすすめ\n・Search ConsoleのデータをBigQueryに自動的に蓄積させたい\n・Google検索での表示回数・掲載順位について自動的に分析できるようにしたい\n・Google Search Consoleをデータ元として利用したい\n\n## 1. DWHと同期する手段の選定\n### 1-1. DWHの選定\nまずはデータを集約する場所である、DWH（データウェアハウス）を選定します。\n\n* Amazon Redshift\n* Google BigQuery\n* MySQLやPostgreSQL\n\n今回はGoogle BigQueryを利用することにします。\n\n### 1-2. Google Search ConsoleのデータをGoogle BigQueryに転送する４つの方法\nGoogle BigQueryにデータを集約することが決まったので、続いては転送するための手段を検討します。\n\n1. Google Search ConsoleのデータをGoogle Cloud Storage経由でBigQueryに登録する\n1. BigQuery データコネクタであるコネクテッド シートを使用する（ただしGsuiteのプランがEnterprise以上である必要がある）\n1.  [trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)を利用し、画面上の設定のみで転送する。\n\n１は単発の分析でしたら可能ですが、集めたデータをその都度更新し続けるのは手間がかかります。２の方法ではGoogle BigQueryを操作するGoogleアカウントがデータ元となるGoogle Search Consoleに対して閲覧以上の権限を有する必要があります。\n今回は自動での更新が可能で、一度Googleアカウントとの連携を行えば設定を保存して異なる分析にも使い回せる3の[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)を利用してみたいと思います。\n\n## 2. troccoでGoogle Search Console→Google BigQueryの転送自動化\n### 2-0. 事前準備\nデータの転送のためには[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)のアカウント・Googleアカウントが必要です。\n\n無料トライアルを実施しているので、事前に申し込み・登録しておいてください！\n[https://trocco.io/lp/index.html](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)\n（申込の際に、この記事を見た旨を記載して頂ければご案内がスムーズに行えます）\n\nGoogleアカウントに関しては、Google BigQueryとGoogleデータポータルは同じアカウントで運用したほうが接続が簡単だと思います。\n\n### 2-1. 転送元・転送先を決定\n[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)にアクセスして、ダッシュボードから「転送設定を作成」のボタンを押します。\n![ダッシュボード.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/c3b4d666-63f1-a260-8420-a811367e30cf.png)\n\n\n\n転送元に「Google Search Console」を指定し、転送先に「Google BigQuery」を選択して転送設定作成ボタンを押します。\n![転送設定の新規作成.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/6b2d5e0f-269c-c893-7c3a-71ad98152d1c.png)\n\n\n\nすると、設定画面になるので、必要な情報を入力していきます。\n### 2-2. Google Search Consoleとの連携設定\nあとで見たときに自分で分かるように転送設定の名前とメモを入力します。\n![概要設定.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/edf79123-02bd-6186-b0ef-e767a6b2b308.png)\n\n\n次に「転送元Google Search Consoleの設定」内の「接続情報を追加」ボタンを押します。\n![接続情報追加.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/3db92579-22e9-7c66-8ee0-ce4d08646bdc.png)\n\n\n\n別のタブでGoogle Search Consoleの接続情報の新規作成画面が開きます。\n接続情報を作成するためにJSON Keyが必要になります。\n\n![searchconsole接続情報.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/fa8b6470-ab81-608d-0a26-5cb7915e9e59.png)\n\n\n\n問題がなければ保存します。再度転送設定画面に戻り、接続情報の「接続情報を読み込む」ボタンを押すと、先ほど作成した接続情報が選択できるようになります。\n\n![sample追加.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/8e8e664d-d110-d1ee-e4d0-af9ebbc37d7b.png)\n\n\n\n### 2-3. Google Search Consoleからのデータ抽出設定\n次に、どのようなデータを取得するかを設定していきます。\n今回は分析したいサイトについての日付、検索クエリ、リンクに関する情報を取得していきます。\n\n\n必要なデータを入力していきます。\n\n○サイトURL\n転送したいデータのサイトURLを指定してください。\n\n○サーチタイプ\nweb, image, videoの中から選択します。\n今回はwebページ(https://trocco.io/) の分析を行うので「web」を選びます。\n\n○データ取得期間\nGoogle Search Consoleの仕様上、取得できるデータは3日以上前のデータに限られるので要注意です。\n\n○ディメンション\nデータの取得結果をグループ化するための項目です。\ndate, country, device, page, query, searchAppearanceを指定することができます。\n\n![Google Search Console設定.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/491b01ac-5830-1f62-73c7-f521e2f81df0.png)\n\n\n\n### 2-4. 転送先Google BigQueryの設定\n転送元と同様に設定していきます。Google BigQueryに関してはGoogleアカウントとの連携が必要です。（事前に転送先となるデータセットとテーブルを作成しておいてください。）\n![Googleアカウント連携.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/0bb3d4f1-188c-f9b4-1e2d-023684ce65d3.png)\n![BigQuery接続情報作成.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/683df5ea-e4df-008b-b4c7-6b2d1c6364c1.png)\n\n\n\n\n\n転送先とするデータセット名、テーブルを設定します。\n![bigquery設定.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/bfcca46e-2a4c-2c00-1e72-8cf2abcc437f.png)\n\n\n\nこれで入力は完了です。接続状況を確認し問題がなければ、「次のステップへ」をクリックし確認作業に進みましょう。\n\n### 2-5. データのプレビュー\n少し待つと、転送元のデータがプレビューされます。ここではGoolge Search Consoleから取り込んだデータが表示されています。\n![データプレビュー.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/4cbd3eba-6367-d8ea-1387-d7cab0f8e323.png)\n\n\n\n\n\n転送したいデータが取れているので、設定を完了します。\n転送設定の一覧から作成した設定を選び「スケジュール・通知設定」に進みます。\n\n### 2-6. スケジュール・通知設定\n「スケジュール・トリガー設定」タブを開きます。\n\n![転送完了.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/9ca892a4-9982-c783-23f5-55dd4bb57b43.png)\n\n\n\n「スケジュールを追加」ボタンを押すと、以下のようなモーダルが出てきます。ここで実行スケジュールを設定することで、転送を定期的に実行し自動化することが出来ます。\n![スケジュール.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/44650df3-b700-a3ce-8579-905ab1af712b.png)\n\n\n\n\n### 2-7. データ転送ジョブの実行\n設定は以上です。最後に、手動で転送ジョブを実行し、Google BigQueryにデータを送ります。\n手動で実行する場合はジョブ詳細画面の「実行」ボタンを押します。\n![実行する.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/6fdb0391-b4e5-1631-7e18-2ca884fc8f7f.png)\n\n\n\n\nこれで転送は完了です！\n\n## 3. Google BigQueryの設定\n特に設定することはありません。設定で選択したテーブルにデータが転送されているので、今すぐに分析・可視化を行うことが出来ます。\nデータがきちんと送られているかをプレビューで確認してみます。\n![bigquery転送.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/faf858d7-95d7-6160-674a-0cd1ca2a8c35.png)\n\n\n\n転送されていることが確認できました！\n## 4. Googleデータポータルで可視化\nそれでは、これらのデータをGoogleデータポータルで可視化していきます。  \nまずはGoogle BigQueryとGoogleデータポータルの接続設定を行います。\nGoogleデータポータルを開いて、新規のレポートを作成します。\n![Qiitaテスト.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/d5dcbc10-c011-9904-aeeb-e9a2081beae2.png)\n\n「データを追加」のボタンを押し、データ元の選択肢からGoogle BigQueryを選択します。\n![BigQuery選択.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/854d5b3a-1ff5-a6cb-c9ce-41064f9ee0d8.png)\n\n\n転送に使用したプロジェクト、データセット、表（テーブル）を選択し、追加します。\n![データ追加②.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/dc5a1590-89cc-4ca4-00e9-a9d28b6b2c4b.png)\n\n\n\nデータベースに接続できたら、使用可能な項目を利用し、必要な情報を表示させることができます。\n今回は日別のデータを調べるのではなく、１日における検索クエリ、リンクそれぞれの割合を調べたいので円グラフを用いることにします。\n\n![表作成.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/949b9341-5b69-dd4c-3b87-78919d80bc08.png)\nまず、円グラフの項目となるディメンションに「query」を、円グラフの各項目の値となる指標には「Record Count」を選択します。そして「グラフ＞表」から「グラフ＞円」に変更します。\n![query円グラフ.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/99338cce-cc98-e945-0ccd-b731af4e0e35.png)\n次に、pageに関する円グラフを作ります。\n「グラフを追加」をクリックして先ほど同様、円グラフを選択し、ディメンションを「page」に変更します。\n![page円グラフ追加.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/a019578c-ff00-7532-9d56-5a2203e767ff.png)\n最後に、説明を加えてグラフの大きさを調整します。\n![円グラフ完成.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1121252/c500159b-edda-4f73-ed84-764f2245a397.png)\n\n\n\n\n\n\n\n## まとめ\nいかがでしたでしょうか。[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)を使うと、Google Search Consoleのデータでも自動でGoogle BigQueryにまとめていくことができるほか、100万規模の大きなデータからそうではない小さなデータまで複雑なコーディングをせず[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)の画面上の設定のみでデータの転送が可能になります。\n実際に弊社サービスの[trocco](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)においても、マーケティングKPI等をこのような流れで収集・分析しています。\nぜひ広告データ分析の際にはご活用ください。\n[https://trocco.io/lp/index.html](https://trocco.io/lp/index.html?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)\n\n実際に試してみたい場合は、[無料トライアル](https://trocco.io/inquiry_trial/new?utm_medium=social&utm_source=qiita&utm_campaign=searchconsole_to_bigquery)を実施しているので、この機会にぜひ一度お試しください。（申込時に、この記事を見た旨を記載して頂ければスムーズにご案内することができます）\n\nその他にも広告やデータベースなど、様々な分析データをETL・転送した事例をまとめました。\n[troccoの使い方まとめ（CRM・広告・データベース他）](https://qiita.com/hiro_koba_jp/items/2b2caa040804e402bda7)\n","user":"hiro_koba_jp","created_at":"2021-03-29T11:24:30+09:00","updated_at":"2021-03-29T11:24:30+09:00"},{"url":"https://qiita.com/bonoramo/items/bb88390cbc600b1284d2","title":"ShapeファイルをPostGISに投入して結合する","body":"# 概要\n大量のShapeファイルをPostGISを使って結合する手順です。DockerでPostGIS環境を作成してデータベースにShapeを格納した後、一つのShapeファイルに書き出します。\n\n## DockerによるPostGIS環境の構築\n使用するPostGISコンテナーのdocker-compose.yml\n\n```\nversion: '3'\nservices:\n    db:\n        image: postgis/postgis:9.6-2.5-alpine\n        ports: \n         - '5431:5432'\n        environment:  \n            POSTGRES_USER: postgres\n            POSTGRES_PASSWORD: postgres-password\n        volumes: \n         - pgdata:/var/lib/postgresql/data\n         - ./data:/var/tmp/data\n\nvolumes: \n    pgdata: {}\n```\n\n\n\n## Shapeファイルをデータベースに格納する。\n以下のようなスクリプトを作成し、フォルダ内の.shpファイルをPostgreSQLデータベースに格納しました。引数で結合させるShapeファイルの名称を与えて、findで取得した.shpファイルを処理しています。\n\n最初のファイルの時に、-pオプションで格納するShapeのテーブルを作成しています。\n\n```\nshp2pgsql -p -s 4326 -W UTF-8 ${file} base_${var} > ./sqlbase/base_${var}_create.pgsql\n```\n\n作成したSQLファイル（.pgsql）をpsqlで実行してテーブル作成、その後Shapeファイルをテーブルに格納しています。shp2pgsqlの-DオプションでCOPYコマンドで格納します。INSERTよりも高速とのこと。\n\n```\nshp2pgsql -a -D -s 4326 -W UTF-8 ${file} base_${var} > ./sqlbase/base_${var}_data${count}.pgsql\n```\n\n\n```\nvar=$1\ncount=0\nwhile read -d $'\\0' file; do\n\n    echo $var $count\n\n    if [ $count = 0 ]; then\n        shp2pgsql -p -s 4326 -W UTF-8 ${file} base_${var} > ./sqlbase/base_${var}_create.pgsql\n        psql -U postgres -d shape -f ./sqlbase/base_${var}_create.pgsql\n    fi\n    shp2pgsql -a -D -s 4326 -W UTF-8 ${file} base_${var} > ./sqlbase/base_${var}_data${count}.pgsql\n    psql -U postgres -d shape -f ./sqlbase/base_${var}_data${count}.pgsql\n\n    count=`expr $count + 1`\n\ndone < <(find Basemap -name *$var.shp -mindepth 1 -maxdepth 5 -print0)\n```\n\n\n\n## PostgreSQLからShapeを出力する\n\n\n\n```\nbash-5.0# pgsql2shp -u postgres -f ./basemap_join/base_xda.shp shape base_xda\nInitializing...\nDone (postgis major version: 2).\nOutput shape: PolyLine\nDumping: XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n```\n","user":"bonoramo","created_at":"2021-03-29T11:21:10+09:00","updated_at":"2021-03-29T11:21:10+09:00"},{"url":"https://qiita.com/MeguruMokke/items/5ccf00bd2831551309d5","title":"Clojure x ClojureScript で深める Web 開発 (4) Auth","body":"# Git Repo\nソースコードと原文が入ったレポジトリ\nhttps://github.com/MokkeMeguru/clj-web-dev-ja/tree/main/chap4\n\n## シリーズ\n- [Clojure x ClojureScript で深める Web 開発 (0)](https://qiita.com/MeguruMokke/items/c6e059f109122be5f991)\n- [Clojure x ClojureScript で深める Web 開発 (1) Duct x Clean Architecture](https://qiita.com/MeguruMokke/items/af003d5a665095c0f3c8)\n- [Clojure x ClojureScript で深める Web 開発 (2) 環境の構築](https://qiita.com/MeguruMokke/items/9fe8e11a134e4c4dee2b)\n- [Clojure x ClojureScript で深める Web 開発 (3) API 作成入門](https://qiita.com/MeguruMokke/items/0ff941bcad6c86618b3d)\n- [Clojure x ClojureScript で深める Web 開発 (4) Auth](https://qiita.com/MeguruMokke/items/5ccf00bd2831551309d5)\n- [Clojure x ClojureScript で深める Web 開発 (5) API 開発 トランザクション添え](https://qiita.com/MeguruMokke/items/258c04caacdf66f706a2)\n- [Clojure x ClojureScript で深める Web 開発 (6) クライアントサイドと re-frame](https://qiita.com/MeguruMokke/items/78ff972bbd4efe3e1398)\n\n\n\n# 本編\n- [Firebase Auth の準備](#orgbb76b18)\n- [仮フロントエンドの作成](#org519361d)\n- [サインアップ・サインイン・サインアウトフローの確認](#org756ecf0)\n  - [サインアップ](#org4c43c43)\n  - [サインイン](#org2413150)\n  - [サインアウト](#orgaba2230)\n- [ドメイン・ハンドラの作成](#org8fefff5)\n  - [domain](#org4b24899)\n  - [ルータ & ハンドラ](#org4cb52a8)\n- [infrastructure の実装](#orgf6dd18e)\n  - [Firebase Auth の token 読み込み](#org92d5985)\n  - [DB の接続](#org269efe0)\n  - [マイグレーション](#orgb356f95)\n    - [実装方針](#org31d5429)\n    - [マイグレーションファイルを書く](#orgfea33b0)\n    - [integrant のコードを書く](#org0145f15)\n    - [CLI スクリプトを書く](#org5395caa)\n    - [サーバ用コードに埋め込む](#org1d4f4af)\n- [interface の実装](#org303b33d)\n  - [Firebase Auth の token デコード機構](#org8f4ee89)\n  - [SQL の実行機構](#orge8d49ba)\n- [interface の組み込み](#org845e442)\n  - [サインアップ](#org2fbf295)\n  - [サインイン](#org14eeabf)\n  - [実装](#org7424858)\n    - [サインアップ](#org9699495)\n    - [サインイン](#org983f0d9)\n    - [ハンドラの修正](#orga8c423e)\n- [動作確認](#orgd65b047)\n- [付録・捕捉](#org4849120)\n  - [実装してみます](#org9e09a97)\n  - [ランダムな数列と衝突確率](#org575f115)\n  - [テスト用データベースのセットアップ](#orgc4ba16a)\n\n本稿では、Web API を作っていく上で頻出する認証・認可周りの話を、Firebase Auth を用いて片付けます。 一般的に パスワード認証などが基礎のガイドでは紹介されますが、 refresh token を代表とする罠が多すぎるので、外部サービスを利用します。\n\nただし、この手法は、(同等の機能を自前の認証サーバを用いることで実装できるとはいえ) Firebase への依存度が極めて高いため、 **技術的負債になる** 点に注意して下さい。\n\n<a id=\"orgbb76b18\"></a>\n\n# Firebase Auth の準備\n\n1.  Firebase Project (https://console.firebase.google.com/u/0/?hl=ja) よりプロジェクトを追加します。 アナリティクスの追加の有無を聞かれますが、必要に応じて切り替えて下さい。\n2.  左メニューの構築タブにある、Authentication より、 Auth のための設定を行います。\n\n    1.  `Sign-in method` より、 Google を有効にします。 Twitter や Yahoo など他のプロバイダもありますが、 Google が以降の設定について一番楽だと思われます。\n\n        アプリの公開名は、わかりやすい名前 (e.g. 本ガイドで言えば、picture-gallery)を設定すると良いでしょう。\n\n    2.  承認済みドメインに `localhost` が指定されていることを確認して下さい。\n\n        公開時には、公開するドメイン (github pages ならば、 xxx.github.io など) を設定する必要があります。\n\n    3.  プロジェクトの設定 → 全般より、 `プロジェクト名` と `プロジェクトID` を入手して下さい。\n\n        ![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap4/img/prep-firebase-auth.png)\n\n    4.  プロジェクトの設定 → サービスアカウントより、新しい秘密鍵を生成して下さい。生成した秘密鍵の入った JSON ファイルは、 `resources/secrets` に `firebase_secrets.json` として保存して下さい (後の説明のため必要です)。\n\n    5.  `firebase_secrets.json` を Github ないし **外部へ共有しないように設定して下さい** 。\n\n        ファイルは gpg コマンドを使って暗号化するなどの処理をしましょう。\n\n        ```shell\n        # 共通鍵暗号化方式で暗号化する例\n        gpg -c firebase_secrets.json\n        ```\n\n参考:\n\n- <https://firebase.google.com/docs/auth/web/google-signin?authuser=1#before_you_begin>\n- <https://firebase.google.com/docs/admin/setup?hl=ja#initialize-sdk>\n\n<a id=\"org519361d\"></a>\n\n# 仮フロントエンドの作成\n\nFirebase Auth はフロントエンドと Firebase の認証サーバとの通信を繋げて認証情報を獲得します。 そのため、 **フロントエンドの実装が必須** となります。\n\n今回はまず、認証情報を自前の DB に API サーバを通して持ち込む流れを実装していくので、仮のフロントエンドを作成します。\n\n仮フロントエンドは、http-server (<https://github.com/http-party/http-server>) と １枚の `index.html` を用いて作成します。 まずは仮フロントエンドのプロジェクト作成をします。\n\n```shell\n# npm > 5.2.0\nmkdir fba_front_sample\ncd fba_front_sample\nnpm init -y\nnpm install -D http-server\n```\n\n次に、index.html を作成します。\n\n<details><summary>index.html (`set your values from firebase project` 部を編集して下さい)</summary><div>\n\n```html\n<!doctype html>\n<html>\n    <head>\n        <meta charset=\"utf-8\">\n        <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\">\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n\n        <script src=\"https://www.gstatic.com/firebasejs/ui/4.6.1/firebase-ui-auth.js\"></script>\n        <link type=\"text/css\" rel=\"stylesheet\" href=\"https://www.gstatic.com/firebasejs/ui/4.6.1/firebase-ui-auth.css\" />\n    </head>\n    <body>\n        <!-- The surrounding HTML is left untouched by FirebaseUI.\n             Your app may use that space for branding, controls and other customizations.-->\n        <h1>Sample Firebase Auth Page</h1>\n        <div>see. developer console</div>\n        <div id=\"firebaseui-auth-container\"></div>\n        <div id=\"loader\">Loading...</div>\n        <button id=\"signout\">SignOut</div>\n\n        <script src=\"https://www.gstatic.com/firebasejs/8.2.9/firebase-app.js\"></script>\n        <script src=\"https://www.gstatic.com/firebasejs/8.2.9/firebase-auth.js\"></script>\n        <script type=\"text/javascript\">\n\n         // set your values from firebase project\n         // --------------------------------------------\n         var apiKey = <your apiKey>\n         var projectId = <your project id>\n         // --------------------------------------------\n\n         var authDomain = projectId + \".firebaseapp.com\"\n         var firebaseConfig = {\n             apiKey: apiKey,\n             authDomain:  authDomain,\n             projectId: projectId,\n         }\n         firebase.initializeApp(firebaseConfig);\n\n         // Initialize the FirebaseUI Widget using Firebase.\n         var uiConfig = {\n             callbacks: {\n                 signInSuccessWithAuthResult: function(authResult, redirectUrl){ return true;},\n                 uiShown: function() { document.getElementById(\"loader\").style.display='none'; }\n             },\n             signInFlow: 'redirect',\n             signInSuccessUrl: '/',\n             signInOptions: [\n                 firebase.auth.GoogleAuthProvider.PROVIDER_ID,\n             ]\n         }\n\n         var ui = new firebaseui.auth.AuthUI(firebase.auth());\n         var signOutButton = document.getElementById(\"signout\");\n         // default state\n         ui.start('#firebaseui-auth-container', uiConfig);\n         signOutButton.style.display='none'\n\n         // already signIned\n         firebase.auth().onAuthStateChanged((user) => {\n             if (user) {\n                 firebase.auth().currentUser.getIdToken(true).then(function(idToken) {\n                     console.log(\"id token is below:\")\n                     console.log(idToken);\n                 })\n                 ui.delete()\n                 signOutButton.style.display='block'\n             }\n         })\n\n         // signout\n         signOutButton.addEventListener('click', function() {\n             console.log(\"signout\")\n             firebase.auth().signOut().then(_ => {\n                 location.reload()\n             })\n         })\n\n\n        </script>\n\n    </body>\n</html>\n```\n\n</div>\n</details>\n\nここまでのプロジェクトのディレクトリ構造は次のようになります。\n\n    .\n    ├── index.html\n    ├── node_modules\n    ├── package-lock.json\n    └── package.json\n\n`npx run http-server .` より、http サーバを立ち上げ、 `localhost:8080` より `index.html` へアクセスします。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap4/img/sample_html.png)\n\nログインすると、開発者コンソールに idToken が表示されます。この idToken がサーバへ受け渡したい認証情報となります。\n\nなお、この **認証情報は有効期限がある** ため、 API をテストする際には最新のものを利用する必要があります。\n\n<a id=\"org756ecf0\"></a>\n\n# サインアップ・サインイン・サインアウトフローの確認\n\n実装をする前に、今回作る機能の利用フローを考えます。\n\n<a id=\"org4c43c43\"></a>\n\n## サインアップ\n\n    client                                server\n       |                                    |\n       |     +------------------------+     |\n       | --- | /signup                | --> |\n       |     |  'signup-param         |     |\n       |     +------------------------+     |\n       |                                    |\n       |       +----------<success>-+       |\n       |  <--  |  'signup-success   |  ---  |\n       |       +--------------------+       |\n       ~                                    ~\n       |       +----------<failure>-+       |\n       |  <--  |  'error-message    |  ---  |\n       |       +--------------------+       |\n\n- &rsquo;signup-param\n\n  今後作る機能と一貫性を持たせるために、認証情報 (`idToken`) はクエリやボディではなく、ヘッダに乗せます。\n\n  ```clojure\n    {:header \"<idToken>\"}\n  ```\n\n- &rsquo;signup-success\n\n  user-id はユーザに与えられる一意な数列です (e.g. `019012323149`) 。(今回は 15 桁の数字列としましたがスケールなど考えると uuid などのほうが良いです。)\n\n  ```clojure\n    {:user-id \"<userId>\"}\n  ```\n\n<a id=\"org2413150\"></a>\n\n## サインイン\n\n    client                                server\n       |                                    |\n       |     +------------------------+     |\n       | --- | /signin                | --> |\n       |     |  'signin-param         |     |\n       |     +------------------------+     |\n       |                                    |\n       |       +----------<success>-+       |\n       |  <--  |  'signin-success   |  ---  |\n       |       +--------------------+       |\n       ~                                    ~\n       |       +----------<failure>-+       |\n       |  <--  |  'error-message    |  ---  |\n       |       +--------------------+       |\n\n- &rsquo;signin-param\n\n  signin と同様です。\n\n  ```clojure\n    {:header \"<idToken>\"}\n  ```\n\n- &rsquo;signin-success\n\n  signup と同様です。ただし、 signup の `user-id` は生成されるものですが、こちらは検索して得られるものです。\n\n  ```clojure\n    {:user-id \"<userId>\"}\n  ```\n\n<a id=\"orgaba2230\"></a>\n\n## サインアウト\n\nサインイン状態の管理は Firebase Auth 側が受け持っているので、こちらが行うことはありません。 (他アプリ開発をしている上で必要となるケースもあるかもしれませんが、今回は扱いません。)\n\n<a id=\"org8fefff5\"></a>\n\n# ドメイン・ハンドラの作成\n\n今回も見通しを良くするために usecase の詳細を省いた実装を先に行います。\n\n<a id=\"org4b24899\"></a>\n\n## domain\n\n※ **domain は ORM ではない** ので、SQL のテーブルを意識して domain を作るのはおすすめできません。(ORM を意識すると domain が SQL に依存してしまう。とはいえ普通に設計して ORM っぽくなったりすることもあります。)\n\n今回問題になるのは、 firebase auth の `id-token` です。firebase auth の 仮フロントエンドから渡される id-token (`encrypted-id-token`) は、サーバ内で外部ライブラリによって復号され一意のユーザトークン (`id-token`) になります。\n\nまたユーザ ID は衝突確率などを考慮して [9.2](#ランダムな数列と衝突確率) 、 15 桁の数字列としました。\n\n- user の domain\n\n  ```clojure\n  (ns picture-gallery.domain.users\n    (:require [clojure.spec.alpha :as s]))\n\n  (defn user-id? [num-str]\n    (re-matches #\"^[0-9]{15}\" num-str))\n\n  (defn gen-user-id []\n    (apply str (take 15 (repeatedly #(rand-int 10)))))\n\n  (s/def ::user-id (s/and string? user-id?))\n  (s/def ::id-token string?)\n  (s/def ::created-at pos-int?)\n\n  ;; ユーザのモデル\n  (s/def ::user-create-model\n    (s/keys :req-un [::user-id ::id-token]))\n\n  (s/def ::user-model\n    (s/keys :req-un [::user-id ::id-token ::created-at]))\n\n  (s/def ::users-model\n    (s/coll-of ::user-model))\n  ```\n\n- firebase auth の domain\n\n  ```clojure\n  (ns picture-gallery.domain.auth\n    (:require [clojure.spec.alpha :as s]\n              [picture-gallery.domain.users :as users-domain]\n              [picture-gallery.domain.error :as error-domain]\n              [picture-gallery.domain.base :as base-domain]))\n\n  ;; model\n  (s/def ::encrypted-id-token string?)\n\n  ;; ここは usecase の in-out にまつわるモデルの話\n  (s/def ::signin-input\n    (s/keys :req-un [::encrypted-id-token]))\n\n  (s/def ::signin-output\n    (s/keys :req-un [::users-domain/user-id]))\n\n  (s/def ::signup-input\n    (s/keys :req-un [::encrypted-id-token]))\n\n  (s/def ::signup-output\n    (s/keys :req-un [::users-domain/user-id]))\n\n  ;; ここは interface の encrypyed-id-token デコード周りの話\n  (s/def ::decode-id-token-succeed\n    (s/tuple ::base-domain/success (s/keys :req-un [::users-domain/id-token])))\n\n  (s/def ::decode-id-token-failed\n    (s/tuple ::base-domain/failure ::error-domain/error))\n\n  (s/def ::decode-id-token-result\n    (s/or :success ::decode-id-token-succeed\n          :failure ::decode-id-token-failed))\n  ```\n\n\n\n- swagger での auth (signin/signup) の domain\n\n  ```clojure\n  (ns picture-gallery.domain.openapi.auth\n    (:require [clojure.spec.alpha :as s]))\n\n  (s/def ::user-id string?)\n\n  (s/def ::signin-response (s/keys :req-un [::user-id]))\n  (s/def ::signup-response (s/keys :req-un [::user-id]))\n  ```\n\n<a id=\"org4cb52a8\"></a>\n\n## ルータ & ハンドラ\n\ncontroller、 usecase、 presenter など詳細な実装は、この後実装するので省略します。\n\n```clojure\n(ns picture-gallery.infrastructure.router.auth\n  (:require [picture-gallery.usecase.signin :as signin-usecase]\n            [picture-gallery.domain.openapi.auth :as auth-openapi]\n            [clojure.walk :as w]\n            [picture-gallery.utils.error :refer [err->>]]))\n\n(defn signin-post-handler [input-data]\n  (println (-> input-data :headers w/keywordize-keys :authorization))\n  {:status 201\n   :body {:user-id \"123123123123123\"}})\n\n(defn signup-post-handler [input-data]\n  {:status 201\n   :body {:user-id \"123123123123123\"}})\n\n(defn auth-router []\n  [\"/auth\"\n   [\"/signin\"\n    {:swagger {:tags [\"auth\"]}\n     :post {:summary \"signin with firebase-auth token\"\n            ;; swagger に header が必要であることを伝えるキー\n            :swagger {:security [{:Bearer []}]}\n            :responses {201 {:body ::auth-openapi/signin-response}}\n            :handler signin-post-handler}}]\n   [\"/signup\"\n    {:swagger {:tags [\"auth\"]}\n     :post {:summary \"signup with firebase-auth token\"\n            :swagger {:security [{:Bearer []}]}\n            :responses {201 {:body ::auth-openapi/signup-response}}\n            :handler signup-post-handler}}]])\n```\n\nルータのルートに組み込みましょう。\n\n```clojure\n(ns picture-gallery.infrastructure.router.core\n  (:require\n   ;; ...\n   [picture-gallery.infrastructure.router.sample :as sample-router]\n   [picture-gallery.infrastructure.router.auth :as auth-router]))\n\n(defn app []\n  (ring/ring-handler\n   (ring/router\n    [[\"/swagger.json\"]\n      ;; ...\n     [\"/api\"\n      (sample-router/sample-router)\n      (auth-router/auth-router) ;; add here!\n      ]]\n    ;; ...\n    )))\n```\n\n`(restart)` して、Swagger を確認します。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap4/img/swagger_auth.png)\n\n右上に `Authorize` というボタンがあります。 Swagger では、このボタンより、header の `apiKey` の入力ができるようになっています。 試しに、 &ldquo;sample&rdquo; と入力し、 `/api/auth/signin` を実行すると、REPL のログに次の行が記録されます。\n\n    apiKey: sample\n\n繰り返しますが、今回はこの apiKey に firebase auth の id-token を入力していくことになります。\n\n<a id=\"orgf6dd18e\"></a>\n\n# infrastructure の実装\n\nFirebase や DB とやり取りをするためにそれぞれとの接続を作る必要があります。この部分は Clean Architecture 的には infrastructure にあたります。\n\n<a id=\"org92d5985\"></a>\n\n## Firebase Auth の token 読み込み\n\n[1](#firebase-auth-%E3%81%AE%E6%BA%96%E5%82%99) で用意した、 `resources/secrets/firebase_secrets.json` を読み込んで encrypted-id-token をデコードするための準備を行います。 今回はライブラリのドキュメントを信用して説明を省略していますが、時間があれば **API ドキュメントを読んだほうが良いです** (~~サンプルが古すぎるなど~~) 。\n\n```clojure\n(ns picture-gallery.infrastructure.firebase.core\n  (:import (com.google.firebase FirebaseApp FirebaseOptions))\n  (:require [integrant.core :as ig]\n            [taoensso.timbre :as timbre]))\n\n;; いわゆる型、firebaseApp という値をコンストラクタに取る、と考えると良い\n(defrecord FirebaseBoundary [firebaseApp])\n\n(defmethod ig/init-key ::firebase\n  [_ {:keys [env]}]\n  (let [firebase-credentials (:firebase-credentials env)\n        firebase-options (FirebaseOptions/builder)\n        firebaseApp (-> firebase-options\n                        (.setCredentials firebase-credentials)\n                        .build\n                        FirebaseApp/initializeApp)]\n    (timbre/info \"connectiong to firebase with \" firebase-credentials)\n    (->FirebaseBoundary {:firebase-app firebaseApp\n                         :firebase-auth (FirebaseAuth/getInstance)})))\n\n\n(defmethod ig/halt-key! ::firebase\n  [_ boundary]\n  (->\n   boundary\n   .firebase\n   :firebase-app\n   .delete))\n```\n\n参考: <https://firebase.google.com/docs/admin/setup?hl=ja#initialize-sdk>\n\nconfig を編集します。\n\n```clojure\n{:picture-gallery.infrastructure.env/env {}\n :picture-gallery.infrastructure.logger/logger {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.firebase.core/firebase {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.router.core/router {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                     :firebase #ig/ref :picture-gallery.infrastructure.firebase.core/firebase}\n :picture-gallery.infrastructure.server/server {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                :router #ig/ref :picture-gallery.infrastructure.router.core/router\n                                                :port 3000}}\n```\n\n`firebase_secrets.json` のファイル位置は環境変数から教える必要があるので、簡単のために script ファイルを作ります。\n\n```shell\n# env.sh\necho \"please run as \\\"source env.sh\\\"\"\n\nexport GOOGLE_APPLICATION_CREDENTIALS=\"resources/secrets/firebase_secrets.json\"\n```\n\nREPL を再起動し、 `(start)` してみましょう。ログに `picture-gallery.infrastructure.firebase.core` の INFO が流れていることが確認できます。\n\n    dev=> (start)\n    loading environment via environ\n    running in  dev\n    database-url  jdbc:postgresql://dev_db:5432/picture_gallery_db?user=meguru&password=emacs\n    log-level  :info\n    orchestra instrument is active\n    2021-03-16T15:52:05.347Z f04004b3a5e3 INFO [picture-gallery.infrastructure.firebase.core:16] - connectiong to firebase with  ServiceAccountCredentials{clientId=107926774701607421850, clientEmail=firebase-adminsdk-l42c5@sample-picture-gallery-c12rb.iam.gserviceaccount.com, privateKeyId=80f9a8cceb5036d0a96f73a108fa485aeed314a4, transportFactoryClassName=com.google.auth.oauth2.OAuth2Utils$DefaultHttpTransportFactory, tokenServerUri=https://oauth2.googleapis.com/token, scopes=[], serviceAccountUser=null, quotaProjectId=null}\n    # ...\n\n<a id=\"org269efe0\"></a>\n\n## DB の接続\n\n次に DB の接続を行います。 今回は PostgreSQL を用います。 使うライブラリは hirari-cp (<https://github.com/tomekw/hikari-cp>) です。 hikari-cp は 高速に db のコネクションプールを作ることができるライブラリです。\n\n`docker-compose` より、 `dev_db` の `port=5432` から PostgreSQL がコンニチハしていることがわかるので、環境変数のセットアップから先に行います。\n\n`profiles.clj` を次のように編集します。 `database-<option-name>` がちょうど環境変数のセットアップに必要な設定です。\n\n```clojure\n{:profiles/dev\n {:env\n  {:env \"dev\"\n   :database-adapter \"postgresql\"\n   :database-name \"pic_gallery\"\n   :database-username \"meguru\"\n   :database-password \"emacs\"\n   :database-server-name \"dev_db\"\n   :database-port-number \"5432\"\n   :log-level \"info\"}}}\n```\n\nこれに従って、 `env.clj` も更新します。\n\n```clojure\n(defn get-database-options []\n  {:adapter (env :database-adapter)\n   :database-name \"pic_gallery\"\n   :username (env :database-username)\n   :password (env :database-password)\n   :server-name (env :database-server-name)\n   :port-number (Integer/parseInt (env :database-port-number))})\n\n(defmethod ig/init-key ::env [_ _]\n  (println \"loading environment via environ\")\n  (let [database-options (get-database-options)\n        running (env :env)\n        log-level (decode-log-level (env :log-level))]\n    (println \"running in \" running)\n    (println \"log-level \" log-level)\n    (println \"database options\" database-options)\n    (when (.contains [\"test\" \"dev\"] running)\n      (println \"orchestra instrument is active\")\n      (st/instrument))\n    {:database-options database-options\n     :running running\n     :log-level log-level\n     :firebase-credentials (GoogleCredentials/getApplicationDefault)}))\n```\n\n実行サンプルはこんな感じ。\n\n    loading environment via environ\n    running in  dev\n    log-level  :info\n    database options {:adapter postgresql, :username meguru, :password emacs, :server-name dev_db, :port-number 5432}\n    orchestra instrument is active\n    # ...\n\n次に、infrastructure のコードを書きます。 残念ながら、SQL クエリ周りのログは分離することが困難だったので、本コードの中に含めています。\n\n```clojure\n(ns picture-gallery.infrastructure.sql.sql\n  (:require [integrant.core :as ig]\n            [hikari-cp.core :as hikari-cp]\n            [taoensso.timbre :as timbre])\n  (:import\n   [javax.sql DataSource]\n   [net.ttddyy.dsproxy QueryInfo]\n   [net.ttddyy.dsproxy.support ProxyDataSource]\n   [net.ttddyy.dsproxy.listener QueryExecutionListener]))\n\n(defrecord Boundary [spec])\n\n;; define logging\n(defn- query-parameters [params]\n  (->> params (map (memfn getArgs)) (sort-by #(aget % 0)) (mapv #(aget % 1))))\n\n(defn- query-parameter-lists [^QueryInfo query-info]\n  (mapv query-parameters (.getParametersList query-info)))\n\n(defn- logged-query [^QueryInfo query-info]\n  (let [query  (.getQuery query-info)\n        params (query-parameter-lists query-info)]\n    (into [query] (if (= (count params) 1) (first params) params))))\n\n(defn- logging-listener []\n  (reify QueryExecutionListener\n    (beforeQuery [_ _ _])\n    (afterQuery [_ exec-info query-infos]\n      (let [elapsed (.getElapsedTime exec-info)\n            queries (mapv logged-query query-infos)]\n        (if (= (count queries) 1)\n          (timbre/info \"sql/query\" {:query (first queries) :elapsed elapsed})\n          (timbre/info \"sql/batch-query\" {:queries queries :elapsed elapsed}))))))\n\n(defn wrap-logger [datasource]\n  (doto (ProxyDataSource. datasource)\n    (.addListener (logging-listener))))\n\n(defn unwrap-logger [^DataSource datasource]\n  (.unwrap datasource DataSource))\n\n\n;; integrant keys\n(defmethod ig/init-key ::sql\n  [_ {:keys [env logger]}]\n  (let [datasource\n        (-> (:database-options env)\n          (hikari-cp/make-datasource)\n          wrap-logger)]\n    (timbre/info \"setup connection pool ...\")\n    (->Boundary {:datasource\n                 datasource})))\n\n(defmethod ig/halt-key! ::sql\n  [_ boundary]\n  (timbre/info \"close connection pool ...\")\n  (-> boundary\n      .spec\n      :datasource\n      unwrap-logger\n      hikari-cp/close-datasource))\n```\n\n実行例は次のようになります。\n\n    (dev)> (start)\n    ;; ...\n    2021-03-16T20:59:29.564Z f04004b3a5e3 INFO [com.zaxxer.hikari.HikariDataSource:80] - HikariPool-19 - Starting...\n    2021-03-16T20:59:29.568Z f04004b3a5e3 INFO [com.zaxxer.hikari.HikariDataSource:82] - HikariPool-19 - Start completed.\n    2021-03-16T20:59:29.569Z f04004b3a5e3 INFO [picture-gallery.infrastructure.sql.sql:56] - setup connection pool ...\n    ;; => :resumed\n    dev>\n\n参考:\n\n- <https://github.com/tomekw/hikari-cp/blob/master/src/hikari_cp/core.clj> の `core-options`\n- <https://github.com/brettwooldridge/HikariCP> Java の HikariCP (hikari-cp の参照元)\n- <https://github.com/duct-framework/database.sql.hikaricp> hikari-cp への logging 実装\n\n<a id=\"orgb356f95\"></a>\n\n## マイグレーション\n\n<a id=\"org31d5429\"></a>\n\n### 実装方針\n\nDB との接続ができたところで、次に DB マイグレーションの設定を行います。 これは ragtime (<https://github.com/weavejester/ragtime>) を利用します。\n\nマイグレーションで行いたいことは次の 2 つです。\n\n1.  マイグレート マイグレーションのファイルに基づいて DB を掘ります。\n2.  ロールバック マイグレーションしたものを i (> 1) 個だけ元に戻します。\n\n<a id=\"orgfea33b0\"></a>\n\n### マイグレーションファイルを書く\n\nまずマイグレーションファイルを書きます。ragtime のマイグレーションはマイグレート用の up.sql と、ロールバック用の down.sql を書く必要があります。\n\n- 001_users.up.sql\n\n  ```sql\n  -- 001_users.up.sql\n  CREATE TABLE users (\n         id varchar(15) PRIMARY KEY,\n         auth_token varchar(64) NOT NULL,\n         created_at TIMESTAMP default CURRENT_TIMESTAMP,\n         updated_at TIMESTAMP,\n         is_deleted BOOLEAN NOT NULL default FALSE\n  );\n  ```\n\n- 001_users.down.sql\n\n  ```sql\n  -- 001_users.down.sql\n  DROP TABLE users;\n  ```\n\n<a id=\"org0145f15\"></a>\n\n### integrant のコードを書く\n\nマイグレーションのコードそのものは ragtime のドキュメントを参考にしつつ、integrant のシステムと組み合わせる形でまとめます。\n\nこのコードではマイグレートとロールバックを分岐させるために、 `operation` キーを用いました。\n\n```clojure\n(ns picture-gallery.infrastructure.sql.migrate\n  (:require [ragtime.jdbc :as jdbc]\n            [ragtime.repl :as repl]\n            [integrant.core :as ig]\n            [taoensso.timbre :as timbre]))\n\n(defn build-config [database-options migration-folder]\n  (let [{:keys [adapter database-name username password server-name port-number]} database-options]\n    {:datastore (jdbc/sql-database {:dbtype adapter\n                                    :dbname database-name\n                                    :user username\n                                    :password password\n                                    :port port-number\n                                    :host server-name})\n     :migrations (jdbc/load-resources migration-folder)}))\n\n(defmethod ig/init-key ::migration [_ {:keys [env operation rollback-amount]}]\n  (let [{:keys [database-options migrations-folder]} env\n        migration-config (build-config database-options migrations-folder)]\n    (timbre/info \"run migration with operation\" operation \"(rollback-amount is \" rollback-amount \")\")\n    (condp = operation\n      :migrate  (repl/migrate migration-config)\n      :rollback (repl/rollback migration-config (or rollback-amount 1))\n      (let [message  (str \"invalid migration operation \" operation \" is not in #{:migrate :rollback}\")]\n        (timbre/error message)\n        (throw (ex-info message {}))))\n    {}))\n```\n\n環境変数を渡す必要があるので、 `env.clj` も更新します。\n\n<details><summary>更新したコード</summary><div>\n\n```clojure\n(ns picture-gallery.infrastructure.env\n  (:require [environ.core :refer [env]]\n            [integrant.core :as ig]\n            [orchestra.spec.test :as st]\n            [clojure.spec.alpha :as s])\n  (:import (com.google.auth.oauth2 GoogleCredentials)))\n\n(s/fdef decode-log-level\n  :args (s/cat :str-log-level string?)\n  :ret #{:trace :debug :info :warn :error :fatal :report})\n\n(defn decode-log-level [str-log-level]\n  (condp = str-log-level\n    \"trace\" :trace\n    \"debug\" :debug\n    \"info\" :info\n    \"warn\" :warn\n    \"error\" :error\n    \"fatal\" :fatal\n    \"report\" :report\n    :info))\n\n(defn get-database-options []\n  {:adapter (env :database-adapter)\n   :database-name (env :database-name)\n   :username (env :database-username)\n   :password (env :database-password)\n   :server-name (env :database-server-name)\n   :port-number (Integer/parseInt (env :database-port-number))})\n\n(defmethod ig/init-key ::env [_ _]\n  (println \"loading environment via environ\")\n  (let [database-options (get-database-options)\n        running (env :env)\n        migrations-folder (env :migrations-folder)\n        log-level (decode-log-level (env :log-level))]\n    (println \"running in \" running)\n    (println \"log-level \" log-level)\n    (println \"migrations-folder\" migrations-folder)\n    (println \"database options\" database-options)\n    (when (.contains [\"test\" \"dev\"] running)\n      (println \"orchestra instrument is active\")\n      (st/instrument))\n    {:database-options database-options\n     :running running\n     :migrations-folder migrations-folder\n     :log-level log-level\n     :firebase-credentials (GoogleCredentials/getApplicationDefault)}))\n```\n\n</div>\n</details>\n\n<a id=\"org5395caa\"></a>\n\n### CLI スクリプトを書く\n\n動作確認のため、先に CLI スクリプトから仕上げます。 clojure.tools.cli (<https://github.com/clojure/tools.cli>) を利用して、 CLI のオプション処理を実装します。\n\n```clojure\n(ns picture-gallery.cmd.migration.core\n  (:gen-class)\n  (:require\n   [clojure.string]\n   [picture-gallery.core :as pg-core]\n   [integrant.core :as ig]\n   [clojure.tools.cli :refer [parse-opts]]))\n\n(def cli-options\n  [[\"-o\" \"--operation OPERATION\" \"operation key in #{:migrate :rollback}\"\n    :parse-fn keyword\n    :validate [#{:migrate :rollback} \"Invalid key not be in #{:migrate :rollback}\"]]\n   [\"-d\" \"--rollback-amount N\" \"rollback amount when it uses in :rollback opts\"\n    :parse-fn #(Integer/parseInt %)\n    :default 1\n    :validate [pos-int?]]\n   [\"-h\" \"--help\"]])\n\n(defn error-msg [errors]\n  (str \"The following errors occurred while parsing your command:\\n\"\n       (clojure.string/join \\newline errors)\n       \"\\n\\nPlease refer the docs by running this program with the option -h\"))\n\n(defn usage [options-summary]\n  (->> [\"This is the migration program\"\n        \"\" \"Options:\" \"\"\n        options-summary]\n       (clojure.string/join \\newline)))\n\n(defn migration [config-file operation rollback-amount]\n  (try\n    (-> config-file\n        pg-core/load-config\n        (assoc-in [:picture-gallery.infrastructure.sql.migrate/migration :operation] operation)\n        (assoc-in [:picture-gallery.infrastructure.sql.migrate/migration :rollback-amount] rollback-amount)\n        ig/init)\n    (println \"migration operation is succeed\")\n    (catch clojure.lang.ExceptionInfo e\n      (println \"exception:\" (.getMessage e)))))\n\n(defn -main\n  [& args]\n  (let [config-file \"cmd/migration/config.edn\"\n        {:keys [options _ errors summary]} (parse-opts args cli-options)]\n    (cond\n      errors (println (error-msg errors))\n      (:help options) (println (usage summary))\n      (:operation options) (migration config-file (:operation options) (:rollback-amount options))\n      :else (println (usage summary)))))\n```\n\nconfig を書きます。\n\n```clojure\n;; resources/cmd/migration/config.cfg\n{:picture-gallery.infrastructure.env/env {}\n :picture-gallery.infrastructure.sql.migrate/migration {:env #ig/ref :picture-gallery.infrastructure.env/env}}\n\n```\n\n実行用シェルスクリプトを書きます。\n\n```shell\n#!/usr/bin/env bash\n# scripts/migration.sh\n\n# $* でシェルスクリプトに与えられた引数を受け渡す\nlein run -m picture-gallery.cmd.migration.core $*\n```\n\n実行してみます。 Applying 001_users、Rolling back 001_users と、マイグレートとロールバックが行われていることが確認できます。\n\n    # ./sample.sh -h\n    This is the migration program\n\n    Options:\n\n      -o, --operation OPERATION     operation key in #{:migrate :rollback}\n      -d, --rollback-amount N    1  rollback amount when it uses in :rollback opts\n\n    # ./sample.sh -o migrate\n    loading environment via environ\n    running in  dev\n    log-level  :info\n    migrations-folder migrations\n    database options {:adapter postgresql, :database-name pic_gallery, :username meguru, :password emacs, :server-name dev_db, :port-number 5432}\n    orchestra instrument is active\n    2021-03-18T14:37:38.388Z f04004b3a5e3 INFO [picture-gallery.infrastructure.sql.migrate:20] - run migration with operation :migrate (rollback-amount is  1 )\n    Applying 001_users # <--- !!!\n    migration operation is succeed\n\n    # ./sample.sh -o rollback\n    loading environment via environ\n    running in  dev\n    log-level  :info\n    migrations-folder migrations\n    database options {:adapter postgresql, :database-name pic_gallery, :username meguru, :password emacs, :server-name dev_db, :port-number 5432}\n    orchestra instrument is active\n    2021-03-18T14:38:09.085Z f04004b3a5e3 INFO [picture-gallery.infrastructure.sql.migrate:20] - run migration with operation :rollback (rollback-amount is  1 )\n    Rolling back 001_users # <--- !!!\n    migration operation is succeed\n\n<a id=\"org1d4f4af\"></a>\n\n### サーバ用コードに埋め込む\n\nサーバ用コードに埋め込みます。\n\n本ガイドでは、マイグレーションファイルにしたがってマイグレートされた状態を元にサーバコードが書かれている状態を想定します。\n\n```clojure\n;; resources/config.edn\n{:picture-gallery.infrastructure.env/env {}\n :picture-gallery.infrastructure.logger/logger {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.firebase.core/firebase {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.sql.sql/sql {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                              :logger #ig/ref :picture-gallery.infrastructure.logger/logger}\n :picture-gallery.infrastructure.sql.migrate/migration  {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                         :operation :migrate\n                                                         :logger #ig/ref :picture-gallery.infrastructure.logger/logger}\n :picture-gallery.infrastructure.router.core/router {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                     :firebase #ig/ref :picture-gallery.infrastructure.firebase.core/firebase}\n :picture-gallery.infrastructure.server/server {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                :router #ig/ref :picture-gallery.infrastructure.router.core/router\n                                                :port 3000}}\n```\n\n実行してみます。\n\n<details><summary>実行例</summary><div>\n\n    dev> (restart)\n    2021-03-18T14:44:32.012Z f04004b3a5e3 INFO [picture-gallery.infrastructure.sql.sql:62] - close connection pool ...\n    2021-03-18T14:44:32.015Z f04004b3a5e3 INFO [com.zaxxer.hikari.HikariDataSource:350] - HikariPool-1 - Shutdown initiated...\n    2021-03-18T14:44:32.025Z f04004b3a5e3 INFO [com.zaxxer.hikari.HikariDataSource:352] - HikariPool-1 - Shutdown completed.\n    2021-03-18T14:44:32.026Z f04004b3a5e3 INFO [picture-gallery.infrastructure.server:12] - stop server\n    2021-03-18T14:44:32.034Z f04004b3a5e3 INFO [org.eclipse.jetty.server.AbstractConnector:381] - Stopped ServerConnector@5d49c08a{HTTP/1.1, (http/1.1)}{0.0.0.0:3000}\n    :reloading ()\n    loading environment via environ\n    running in  dev\n    log-level  :info\n    migrations-folder migrations\n    database options {:adapter postgresql, :database-name pic_gallery, :username meguru, :password emacs, :server-name dev_db, :port-number 5432}\n    orchestra instrument is active\n    2021-03-18T14:44:32.056Z f04004b3a5e3 INFO [picture-gallery.infrastructure.firebase.core:18] - connectiong to firebase with  ServiceAccountCredentials{clientId=107926774701607421850, clientEmail=firebase-adminsdk-l42c5@sample-picture-gallery-c12rb.iam.gserviceaccount.com, privateKeyId=80f9a8cceb5036d0a96f73a108fa485aeed314a4, transportFactoryClassName=com.google.auth.oauth2.OAuth2Utils$DefaultHttpTransportFactory, tokenServerUri=https://oauth2.googleapis.com/token, scopes=[], serviceAccountUser=null, quotaProjectId=null}\n    set logger with log-level :info\n    2021-03-18T14:44:32.056Z f04004b3a5e3 INFO [picture-gallery.infrastructure.router.core:77] - router got: env {:database-options {:adapter \"postgresql\", :database-name \"pic_gallery\", :username \"meguru\", :password \"emacs\", :server-name \"dev_db\", :port-number 5432}, :running \"dev\", :migrations-folder \"migrations\", :log-level :info, :firebase-credentials #object[com.google.auth.oauth2.ServiceAccountCredentials 0xb74d590 \"ServiceAccountCredentials{clientId=107926774701607421850, clientEmail=firebase-adminsdk-l42c5@sample-picture-gallery-c12rb.iam.gserviceaccount.com, privateKeyId=80f9a8cceb5036d0a96f73a108fa485aeed314a4, transportFactoryClassName=com.google.auth.oauth2.OAuth2Utils$DefaultHttpTransportFactory, tokenServerUri=https://oauth2.googleapis.com/token, scopes=[], serviceAccountUser=null, quotaProjectId=null}\"]}\n    2021-03-18T14:44:32.060Z f04004b3a5e3 INFO [picture-gallery.infrastructure.server:7] - server is running in port 3000\n    2021-03-18T14:44:32.060Z f04004b3a5e3 INFO [picture-gallery.infrastructure.server:8] - router is  clojure.lang.AFunction$1@a8104b8\n    2021-03-18T14:44:32.061Z f04004b3a5e3 INFO [org.eclipse.jetty.server.Server:375] - jetty-9.4.36.v20210114; built: 2021-01-14T16:44:28.689Z; git: 238ec6997c7806b055319a6d11f8ae7564adc0de; jvm 11.0.9+11\n    2021-03-18T14:44:32.063Z f04004b3a5e3 INFO [org.eclipse.jetty.server.AbstractConnector:331] - Started ServerConnector@337d116a{HTTP/1.1, (http/1.1)}{0.0.0.0:3000}\n    2021-03-18T14:44:32.063Z f04004b3a5e3 INFO [org.eclipse.jetty.server.Server:415] - Started @47795489ms\n    2021-03-18T14:44:32.064Z f04004b3a5e3 INFO [picture-gallery.infrastructure.sql.migrate:20] - run migration with operation :migrate (rollback-amount is  nil )\n    Applying 001_users\n    2021-03-18T14:44:32.148Z f04004b3a5e3 INFO [com.zaxxer.hikari.HikariDataSource:80] - HikariPool-2 - Starting...\n    2021-03-18T14:44:32.152Z f04004b3a5e3 INFO [com.zaxxer.hikari.HikariDataSource:82] - HikariPool-2 - Start completed.\n    2021-03-18T14:44:32.153Z f04004b3a5e3 INFO [picture-gallery.infrastructure.sql.sql:56] - setup connection pool ...\n    ;; => :resumed\n\n</div>\n</details>\n\nホストから PostgreSQL に接続して、中身を見てみます。\n\n    $ psql -h localhost -p 5566 pic_gallery\n    psql (13.2、サーバ 10.5 (Debian 10.5-2.pgdg90+1))\n    \"help\"でヘルプを表示します。\n\n    pic_gallery=# \\d\n                     リレーション一覧\n     スキーマ |        名前        |  タイプ  | 所有者\n    ----------+--------------------+----------+--------\n     public   | ragtime_migrations | テーブル | meguru\n     public   | users              | テーブル | meguru\n    (2 行)\n\n                                     テーブル\"public.users\"\n         列     |           タイプ            | 照合順序 | Null 値を許容 |    デフォルト\n    ------------+-----------------------------+----------+---------------+-------------------\n     id         | character varying(15)       |          | not null      |\n     auth_token | character varying(64)       |          | not null      |\n     created_at | timestamp without time zone |          |               | CURRENT_TIMESTAMP\n     updated_at | timestamp without time zone |          |               |\n     is_deleted | boolean                     |          | not null      | false\n    インデックス:\n        \"users_pkey\" PRIMARY KEY, btree (id)\n\n<a id=\"org303b33d\"></a>\n\n# interface の実装\n\nFirebase Auth の token のデコード、SQL の実行部分は interface にあたるので、当該位置に実装していきます。 この部分は、usecase との依存関係の方向上、インターフェースを介して (名前の通りですね) やり取りをする必要があるので、 Clojure におけるインターフェースの記述方法一つ、 `defprotocol` を利用して実装します。\n\n<a id=\"org8f4ee89\"></a>\n\n## Firebase Auth の token デコード機構\n\n作る前にどんな機能があれば考えます (一つだけですが)。\n\n- firebase auth の id-token をデコードする\n\n  デコードに際して出てくるエラーは次のように分類します。簡単のため、try-catch 文を使って、引っかかった 例外のメッセージからエラーを分類します (エラーコードは全部 INVALID\\_ARGUMENT です)。\n\n  - 不正なトークン (トークンとして成立していない) &ldquo;Failed to parse &#x2026;&rdquo; というエラーが発生したとき\n  - 期限切れのトークン &ldquo;Firebase xxx has expired &#x2026; &rdquo; というエラーが発生したとき\n  - 不明なエラー (それ以外のエラー) それ以外\n\n仕様が見えてきたところで実装してみます ([9.1](#実装してみます))。\n\n```clojure\n;; いわゆるインターフェース\n(ns picture-gallery.interface.gateway.auth.auth-service\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.domain.auth :as auth-domain]\n            [orchestra.spec.test :as st]\n            [integrant.core :as ig]))\n\n(defprotocol Auth\n  (decode-id-token [this encrypted-id-token]))\n\n(defn auth-repository? [inst]\n  (satisfies? Auth inst))\n\n(s/def ::auth-repository auth-repository?)\n\n(s/fdef decode-id-token\n  :args (s/cat :this ::auth-repository\n               :encrypted-id-token ::auth-domain/encrypted-id-token)\n  :ret ::auth-domain/decode-id-token-result)\n```\n\n```clojure\n;; java でいう impl\n(ns picture-gallery.interface.gateway.auth.firebase.auth-service\n  (:require [clojure.string]\n            [picture-gallery.domain.error :as error-domain]\n            [picture-gallery.utils.error :refer [err->>]]\n            [picture-gallery.interface.gateway.auth.auth-service :refer [Auth]]))\n\n(defn decode-token [firebase-auth encrypted-id-token]\n  (-> firebase-auth\n      (.verifyIdToken encrypted-id-token)\n      .getUid))\n\n(defn expired-id-token? [cause]\n  (if (clojure.string/includes? cause \"expired\")\n    [nil error-domain/expired-id-token]\n    [cause nil]))\n\n(defn invalid-id-token? [cause]\n  (if  (clojure.string/includes? cause \"Failed to parse\")\n    [nil error-domain/invalid-id-token]\n    [cause nil]))\n\n(defn unknown-id-token? [_]\n  [nil error-domain/unknown-id-token])\n\n(defn safe-decode-token [firebase-auth encrypted-id-token]\n  (try\n    [:success\n     {:id-token (decode-token firebase-auth encrypted-id-token)}]\n    (catch Exception e\n      [:failure\n       (second\n        (err->>\n         (or (.getMessage e) \"unknown\")\n         expired-id-token?\n         invalid-id-token?\n         unknown-id-token?))])))\n\n(extend-protocol Auth\n  picture_gallery.infrastructure.firebase.core.FirebaseBoundary\n  (decode-id-token [{:keys [firebase]} encrypted-id-token]\n    (safe-decode-token (:firebase-auth firebase) encrypted-id-token)))\n```\n\n試してみます (※実際はこうなるまで **無限回** 試行錯誤してます)。\n\n```clojure\n(def system\n  (ig/init {:picture-gallery.infrastructure.env/env {}\n            :picture-gallery.infrastructure.firebase.core/firebase {:env (ig/ref :picture-gallery.infrastructure.env/env)}}))\n\n(decode-id-token\n (:picture-gallery.infrastructure.firebase.core/firebase system) \"Hello\")\n;; => [:failure {:status 400, :body {:code 1702, :message the firebase token is invalid}}]\n(decode-id-token\n (:picture-gallery.infrastructure.firebase.core/firebase system) \"<expired token>\")\n;; => [:failure {:status 400, :body {:code 1701, :message the firebase token is expired}}]\n (decode-id-token\n  (:picture-gallery.infrastructure.firebase.core/firebase system) \"<valid token>\")\n;; => [:success, :body {:decoded-id-token <decoded-token>}]\n(ig/halt! system)\n```\n\n参考:\n\n- <https://github.com/firebase/firebase-admin-java/blob/d8b1583002d60568106bf4a7ba2d5bcbbb6c0463/src/main/java/com/google/firebase/auth/FirebaseTokenVerifierImpl.java>\n\n<a id=\"orge8d49ba\"></a>\n\n## SQL の実行機構\n\n使うライブラリは、 next.jdbc (<https://github.com/seancorfield/next-jdbc>) です。 next.jdbc は非常に低いレベルから JDBC (Java の DB 操作を行うためのライブラリ) を使うことができるライブラリで、チュートリアルがしっかりしているライブラリです。\n\n本章では先程マイグレートした user テーブルとのやり取りを書いていきます。\n\n```clojure\n(ns picture-gallery.interface.gateway.database.users-repository\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.domain.users :as users-domain]\n            [integrant.core :as ig]\n            [orchestra.spec.test :as st]))\n\n(defprotocol Users\n  (get-users [db])\n  (get-user-by-user-id [db user-id])\n  (get-exist-user-by-auth-token [db auth-token])\n  (create-user [db user-create-model])\n  (delete-user [db user-id logical?]))\n\n(defn users-repository? [inst]\n  (satisfies? Users inst))\n\n(s/def ::users-repository users-repository?)\n\n(s/fdef get-users\n  :args (s/cat :db ::users-repository)\n  :ret ::users-domain/users-model)\n\n(s/fdef get-user-by-user-id\n  :args (s/cat :db ::users-repository :user-id ::users-domain/user-id)\n  :ret (s/or :exist ::users-domain/user-model\n             :not-exist empty?))\n\n(s/fdef get-exist-user-by-auth-token\n  :args (s/cat :db ::users-repository :auth-token ::users-domain/id-token)\n  :ret (s/or :exist ::users-domain/user-model\n             :not-exist empty?))\n\n(s/fdef create-user\n  :args (s/cat :db ::users-repository :user-create-model ::users-domain/user-create-model)\n  :ret ::users-domain/user-model)\n\n(s/fdef delete-user\n  :args (s/cat :db ::users-repository :user-id ::users-domain/user-id :logical? boolean?)\n  :ret (s/and int? (partial <= 0)))\n```\n\n<details><summary>Users impl の実装</summary><div>\n\n```clojure\n;; ここは詳細なので説明を省略します。基本的には next.jdbc のガイドを利用した utils を利用しています。\n(ns picture-gallery.interface.gateway.database.sql.users-repository\n  (:require [picture-gallery.interface.gateway.database.sql.utils :as sql-utils]\n            [picture-gallery.interface.gateway.database.users-repository :refer [Users]]))\n\n;; SQL のモデルと domain のモデルを変換するための機構\n(defn user-create-model->sql [{:keys [user-id id-token]}]\n  {:id user-id\n   :auth_token id-token})\n\n(defn sql->user-model [{:keys [id auth_token created_at updated_at is_deleted]}]\n  {:user-id id\n   :id-token auth_token\n   :created-at (sql-utils/sql-to-long created_at)\n   :updated-at (when updated_at (sql-utils/sql-to-long updated_at))\n   :is-deleted is_deleted})\n\n(extend-protocol Users\n  picture_gallery.infrastructure.sql.sql.Boundary\n\n  (get-users [{:keys [spec]}]\n    (->> (sql-utils/get-all spec :users)\n         (mapv sql->user-model)))\n\n  (get-user-by-user-id [{:keys [spec]} user-id]\n    (let [sql-model (sql-utils/get-by-id spec :users :id user-id)]\n      (if sql-model (sql->user-model sql-model) nil)))\n\n  (get-exist-user-by-auth-token [{:keys [spec]} auth-token]\n    (let [sql-model (first (sql-utils/find-by-m spec :users {:auth_token auth-token :is_deleted false}))]\n      (if sql-model (sql->user-model sql-model) nil)))\n\n  (create-user [{:keys [spec]} user-create-model]\n    (sql->user-model\n     (sql-utils/insert! spec :users\n                        (user-create-model->sql user-create-model))))\n\n  (delete-user [{:keys [spec]} user-id logical?]\n    (if logical?\n      (sql-utils/logical-delete! spec :users {:id user-id})\n      (sql-utils/physical-delete! spec :users {:id user-id}))))\n```\n\n</div>\n</details>\n\n実行例としてはこんな形になります。\n\n```clojure\n(def system (ig/init {:picture-gallery.infrastructure.env/env {}\n                      :picture-gallery.infrastructure.sql.sql/sql {:env (ig/ref :picture-gallery.infrastructure.env/env)}}))\n(def sample-user {:user-id \"000000000000\" :id-token \"sample-token\"})\n\n(create-user (:picture-gallery.infrastructure.sql.sql/sql system) sample-user)\n;; => {:user-id 000000000000, :id-token sample-token, :created-at 1616133702682, :updated-at nil, :is-deleted false}\n\n(get-users (:picture-gallery.infrastructure.sql.sql/sql system))\n;; => [{:user-id 000000000000, :id-token sample-token, :created-at 1616133702682, :updated-at nil, :is-deleted false}]\n(get-user-by-user-id (:picture-gallery.infrastructure.sql.sql/sql system) \"000000000000\")\n;; => [{:user-id 000000000000, :id-token sample-token, :created-at 1616133702682, :updated-at nil, :is-deleted false}]\n(get-exist-user-by-auth-token (:picture-gallery.infrastructure.sql.sql/sql system) \"sample-token\")\n;; => [{:user-id 000000000000, :id-token sample-token, :created-at 1616133702682, :updated-at nil, :is-deleted false}]\n\n(delete-user (:picture-gallery.infrastructure.sql.sql/sql system) \"000000000000\" true)\n;; => 1\n(get-exist-user-by-auth-token (:picture-gallery.infrastructure.sql.sql/sql system) \"sample-token\")\n;; => nil (論理削除したので nil)\n(get-user-by-user-id (:picture-gallery.infrastructure.sql.sql/sql system) \"000000000000\")\n;; => [{:user-id 000000000000, :id-token sample-token, :created-at 1616133702682, :updated-at nil, :is-deleted false}]\n\n(delete-user (:picture-gallery.infrastructure.sql.sql/sql system) \"000000000000\" false)\n;; => 1 (こっちは物理削除)\n(get-user-by-user-id (:picture-gallery.infrastructure.sql.sql/sql system) \"000000000000\")\n;; => nil (物理削除したので nil)\n\n(ig/halt! system) ;; (不要なコネクションプールは閉じて下さい)\n```\n\n<a id=\"org845e442\"></a>\n\n# interface の組み込み\n\n(体感)一万年と二千年かかった下準備がようやくおわったので、残りの八千年かけてハンドラを usecase や interface と組み合わせて組み立てていきます。\n\n<a id=\"org2fbf295\"></a>\n\n## サインアップ\n\nサインアップの流れは次のとおりです。\n\n1.  http からデータを持ってくる (controller)\n2.  ユーザを登録する (usecase)\n    1.  encrypted-id-token を decode する (gateway)\n    2.  id-token から 既存のアカウントがあるか確認する (gateway)\n    3.  新しい (重複のない) ユーザ ID を発行する\n        1.  ランダムなユーザ ID を発行する\n        2.  ユーザ ID が重複しているか調べる (gateway)\n        3.  ¬ 規定回数 ^ ユーザ ID が重複していれば 1. へ戻る\n        4.  規定回数を超えたらエラーハンドリング\n    4.  ユーザをデータベースに登録する (gateway)\n3.  登録したユーザデータを http の response に整形する (presenter)\n\n<a id=\"org14eeabf\"></a>\n\n## サインイン\n\nサインインの流れは次のとおりです。\n\n1.  http からデータを持ってくる (controller)\n2.  ユーザの確認をする\n    1.  encrypted-id-token を decode する (gateway)\n    2.  id-token から、既存のアカウントがあるか確認する (geteway)\n    3.  ユーザ情報を取得する\n3.  ユーザ情報を http の response に整形する (presenter)\n\n<a id=\"org7424858\"></a>\n\n## 実装\n\n<a id=\"org9699495\"></a>\n\n### サインアップ\n\n<details><summary>controller</summary><div>\n\n```clojure\n(ns picture-gallery.interface.controller.api.signup-post\n  (:require [clojure.spec.alpha :as s]\n            [clojure.walk :as w]\n            [picture-gallery.domain.auth :as auth-domain]\n            [picture-gallery.domain.error :as error-domain]))\n\n(defn http-> \"\n  http request -> usecase input model\n  \"\n  [input-data]\n  (let [{:keys [headers]} input-data\n        {:keys [authorization]} (w/keywordize-keys headers)\n        input-model {:encrypted-id-token authorization}\n        conformed-input-model (s/conform\n                               ::auth-domain/signup-input\n                               input-model)]\n    (if (not= ::s/invalid conformed-input-model)\n      [conformed-input-model nil]\n      [nil (error-domain/input-data-is-invalid (s/explain-str ::auth-domain/signup-input input-model))])))\n```\n\n</div>\n</details>\n\n<details><summary>presenter</summary><div>\n\n```clojure\n(ns picture-gallery.interface.presenter.api.signup-post\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.domain.openapi.auth :as auth-openapi]\n            [picture-gallery.domain.openapi.base :as base-openapi]\n            [picture-gallery.domain.auth :as auth-domain]\n            [picture-gallery.domain.error :as error-domain]))\n\n(s/def ::body ::auth-openapi/signup-response)\n(s/def ::http-output-data (s/keys :req-un [::base-openapi/status ::body]))\n(s/fdef ->http\n  :args (s/cat :args\n               (s/or :success (s/tuple ::auth-domain/signup-output nil?)\n                     :failure (s/tuple nil? ::error-domain/error)))\n  :ret (s/or :success ::http-output-date\n             :failure ::error-domain/error))\n\n(defn ->http \"\n  usecase output model -> http response\n  \"\n  [[output-data error]]\n  (if (nil? error)\n    {:status 201\n     :body output-data}\n    error))\n```\n\n</div>\n</details>\n\n<details><summary>usecase</summary><div>\n\n```clojure\n(ns picture-gallery.usecase.signup\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.utils.error :refer [err->> border-error]]\n            [picture-gallery.domain.auth :as auth-domain]\n            [picture-gallery.domain.error :as error-domain]\n            [picture-gallery.interface.gateway.database.users-repository :as users-repository]\n            [picture-gallery.interface.gateway.auth.auth-service :as auth-service]\n            [picture-gallery.domain.users :as users-domain]))\n\n(s/fdef signup\n  :args (s/cat :input-model ::auth-domain/signup-input\n               :db ::users-repository/users-repository\n               :auth ::auth-service/auth-service)\n  :ret (s/or :success (s/tuple ::auth-domain/signin-output nil?)\n             :failure (s/tuple nil? ::error-domain/error)))\n\n(defn decode-id-token \"\n  decode encrypted id-token\n  \"\n  [{:keys [input-model auth] :as m}]\n  (let [[[status body] err] (border-error {:function #(auth-service/decode-id-token auth (:encrypted-id-token input-model))\n                                           :error-wrapper error-domain/auth-error})]\n    (cond\n      err [nil err]\n      (= :failure status) [nil body]\n      :else [(assoc m :id-token (:id-token body)) nil])))\n\n(defn validate-duplicate-account \"\n  validate duplicate account\n  by checking the active (not logical deleted) user which has the id-token\n  \"\n  [{:keys [id-token db] :as m}]\n  (let [[active-user err] (border-error {:function #(users-repository/get-exist-user-by-auth-token db id-token)\n                                         :error-wrapper error-domain/database-error})]\n    (cond\n      err [nil err]\n      active-user [nil error-domain/duplicate-account-exist]\n      :else [m nil])))\n\n(defn give-new-user-id \"\n  generate new unique user-id.\n  if it fails over 10 times, raise error\n  \"\n  [{:keys [db] :as m}]\n  (loop [try-time 1\n         suggested-new-user-id (users-domain/gen-user-id)]\n    (let [[exist-user err] (border-error  {:function #(users-repository/get-user-by-user-id db suggested-new-user-id)\n                                           :error-wrapper error-domain/database-error})]\n      (cond\n        err [nil err]\n        (empty? exist-user) [(assoc m :new-user-id suggested-new-user-id) nil]\n        (> try-time 10) [nil error-domain/user-generation-error-by-user-id-allocation]\n        :else (recur (inc try-time)\n                     (users-domain/gen-user-id))))))\n\n(defn create-new-user \"\n  create new user\n  \"\n  [{:keys [id-token new-user-id db] :as m}]\n  (let [new-user {:user-id new-user-id\n                  :id-token id-token}\n        [saved-new-user err] (border-error {:function #(users-repository/create-user db new-user)\n                                            :error-wrapper error-domain/database-error})]\n    (cond\n      err [nil err]\n      :else [(assoc m :saved-new-user saved-new-user) nil])))\n\n(defn ->output-model \"\n  format as output model\n  \"\n  [{:keys [saved-new-user]}]\n  [{:user-id (:user-id saved-new-user)} nil])\n\n(defn signup [db auth input-model]\n  (err->>\n   {:input-model input-model\n    :db db\n    :auth auth}\n   decode-id-token  ;; id-token をデコードする\n   validate-duplicate-account ;; アカウントの重複がないかチャックする\n   give-new-user-id ;; 新規のユーザID を発行する\n   create-new-user ;; 新しいユーザを作成する\n   ->output-model ;; 出力モデルに整形する\n   ))\n```\n\n</div>\n</details>\n\n<a id=\"org983f0d9\"></a>\n\n### サインイン\n\n<details><summary>controller</summary><div>\n\n```clojure\n(ns picture-gallery.interface.controller.api.signin-post\n  (:require [clojure.spec.alpha :as s]\n            [clojure.walk :as w]\n            [picture-gallery.domain.auth :as auth-domain]\n            [picture-gallery.domain.error :as error-domain]))\n\n(defn http-> \"\n  http request -> usecase input model\n  \"\n  [input-data]\n  (let [{:keys [headers]} input-data\n        {:keys [authorization]} (w/keywordize-keys headers)\n        input-model {:encrypted-id-token authorization}\n        conformed-input-model (s/conform\n                               ::auth-domain/signin-input\n                               input-model)]\n    (if (not= ::s/invalid conformed-input-model)\n      [conformed-input-model nil]\n      [nil (error-domain/input-data-is-invalid (s/explain-str ::auth-domain/signin-input input-model))])))\n```\n\n</div>\n</details>\n\n<details><summary>presenter</summary><div>\n\n```clojure\n(ns picture-gallery.interface.presenter.api.signin-post\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.domain.openapi.auth :as auth-openapi]\n            [picture-gallery.domain.openapi.base :as base-openapi]\n            [picture-gallery.domain.auth :as auth-domain]\n            [picture-gallery.domain.error :as error-domain]))\n\n(s/def ::body ::auth-openapi/signin-response)\n(s/def ::http-output-data (s/keys :req-un [::base-openapi/status ::body]))\n(s/fdef ->http\n  :args (s/cat :args\n               (s/or :success (s/tuple ::auth-domain/signin-output nil?)\n                     :failure (s/tuple nil? ::error-domain/error)))\n  :ret (s/or :success ::http-output-date\n             :failure ::error-domain/error))\n\n(defn ->http \"\n  usecase output model -> http response\n  \"\n  [[output-data error]]\n  (if (nil? error)\n    {:status 201\n     :body output-data}\n    error))\n```\n\n</div>\n</details>\n\n<details><summary>usecase</summary><div>\n\n```clojure\n(ns picture-gallery.usecase.signin\n  (:require [clojure.spec.alpha :as s]\n            [picture-gallery.utils.error :refer [err->> border-error]]\n            [picture-gallery.domain.auth :as auth-domain]\n            [picture-gallery.domain.error :as error-domain]\n            [picture-gallery.interface.gateway.auth.auth-service :as auth-service]\n            [picture-gallery.interface.gateway.database.users-repository :as users-repository]))\n\n(s/fdef signin\n  :args (s/cat :input-model ::auth-domain/signin-input)\n  :ret (s/or :success (s/cat :signin-output ::auth-domain/signin-output :error nil)\n             :failure (s/cat :signin-output nil? :error ::error-domain/error)))\n\n(defn decode-id-token \"\n  decode encrypted id-token\n  \"\n  [{:keys [input-model auth] :as m}]\n  (let [[[status body] err] (border-error {:function #(auth-service/decode-id-token auth (:encrypted-id-token input-model))\n                                           :error-wrapper error-domain/auth-error})]\n    (cond\n      err [nil err]\n      (= :failure status) [nil body]\n      :else [(assoc m :id-token (:id-token body)) nil])))\n\n(defn get-exist-user-has-id-token \"\n  get active (not logical deleted) user\n  which has id-token\"\n  [{:keys [id-token db] :as m}]\n  (let [[active-user err] (border-error {:function #(users-repository/get-exist-user-by-auth-token db id-token)\n                                         :error-wrapper error-domain/database-error})]\n    (cond\n      err [nil err]\n      (empty? active-user) [nil error-domain/signin-failed-by-user-not-found]\n      :else [(assoc m :exist-user active-user) nil])))\n\n(defn ->output-model \"\n  format as output model\n  \"\n  [{:keys [exist-user]}]\n  [{:user-id (:user-id exist-user)} nil])\n\n(defn signin [db auth input-model]\n  (err->>\n   {:input-model input-model\n    :db db\n    :auth auth}\n   decode-id-token\n   get-exist-user-has-id-token\n   ->output-model))\n```\n\n</div>\n</details>\n\n<a id=\"orga8c423e\"></a>\n\n### ハンドラの修正\n\ndb や auth の infrastructure と連携する必要があるため、 config と ハンドラを修正します。\n\n```clojure\n{:picture-gallery.infrastructure.env/env {}\n :picture-gallery.infrastructure.logger/logger {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.firebase.core/firebase {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.sql.sql/sql {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                              :logger #ig/ref :picture-gallery.infrastructure.logger/logger}\n :picture-gallery.infrastructure.sql.migrate/migration  {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                         :operation :migrate\n                                                         :logger #ig/ref :picture-gallery.infrastructure.logger/logger}\n :picture-gallery.infrastructure.router.core/router {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                     :auth #ig/ref :picture-gallery.infrastructure.firebase.core/firebase\n                                                     :db #ig/ref :picture-gallery.infrastructure.sql.sql/sql}\n :picture-gallery.infrastructure.server/server {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                :router #ig/ref :picture-gallery.infrastructure.router.core/router\n                                                :port 3000}}\n```\n\nハンドラ\n\n```clojure\n(ns picture-gallery.infrastructure.router.core)\n\n(defn app [db auth]\n  (ring/ring-handler\n   (ring/router\n    [[\"/swagger.json\"\n      {:get {:no-doc true\n             :swagger {:info {:title \"picture-gallery-api\"}\n                       :securityDefinitions\n                       {:Bearer\n                        {:type \"apiKey\"\n                         :in \"header\"\n                         :name \"Authorization\"}}\n                       :basePath \"/\"}\n\n             :handler (swagger/create-swagger-handler)}}]\n     [\"/api\"\n      (sample-router/sample-router)\n      (auth-router/auth-router db auth)]]\n\n    {:exception pretty/exception\n     :data {:coercion reitit.coercion.spec/coercion\n            :muuntaja m/instance\n            :middleware\n            [;; swagger feature\n             swagger/swagger-feature\n             ;; query-params & form-params\n             parameters/parameters-middleware\n             ;; content-negotiation\n             muuntaja/format-negotiate-middleware\n             ;; encoding response body\n             muuntaja/format-response-middleware\n             ;; exception handling\n             exception/exception-middleware\n             ;; decoding request body\n             muuntaja/format-request-middleware\n             ;; coercing response bodys\n             coercion/coerce-response-middleware\n             ;; coercing request parameters\n             coercion/coerce-request-middleware\n             ;; multipart\n             multipart/multipart-middleware]}})\n\n   (ring/routes\n    (swagger-ui/create-swagger-ui-handler {:path \"/api\"})\n    (ring/create-default-handler))\n   {:middleware [wrap-with-logger]}))\n\n(defmethod ig/init-key ::router [_ {:keys [env db auth]}]\n  (timbre/info \"router got: env\" env)\n  (timbre/info \"router got: db\" db)\n  (timbre/info \"router got: auth\" auth)\n  (app db auth))\n```\n\n```clojure\n(ns picture-gallery.infrastructure.router.auth\n  (:require\n   [picture-gallery.usecase.signin :as signin-usecase]\n   [picture-gallery.usecase.signup :as signup-usecase]\n   [picture-gallery.interface.controller.api.signin-post :as signin-post-controller]\n   [picture-gallery.interface.controller.api.signup-post :as signup-post-controller]\n   [picture-gallery.interface.presenter.api.signin-post :as signin-post-presenter]\n   [picture-gallery.interface.presenter.api.signup-post :as signup-post-presenter]\n   [picture-gallery.domain.openapi.auth :as auth-openapi]\n   [picture-gallery.utils.error :refer [err->>]]))\n\n;; handlers\n(defn signin-post-handler [db auth input-data]\n  (signin-post-presenter/->http\n   (err->> input-data\n           signin-post-controller/http->\n           (partial signin-usecase/signin db auth))))\n\n(defn signup-post-handler [db auth input-data]\n  (signup-post-presenter/->http\n   (err->> input-data\n           signup-post-controller/http->\n           (partial signup-usecase/signup db auth))))\n\n;; router\n(defn auth-router [db auth]\n  [\"/auth\"\n   [\"/signin\"\n    {:swagger {:tags [\"auth\"]}\n     :post {:summary \"signin with firebase-auth token\"\n            :swagger {:security [{:Bearer []}]}\n            :responses {201 {:body ::auth-openapi/signin-response}}\n            :handler (partial signin-post-handler db auth)}}]\n   [\"/signup\"\n    {:swagger {:tags [\"auth\"]}\n     :post {:summary \"signup with firebase-auth token\"\n            :swagger {:security [{:Bearer []}]}\n            :responses {201 {:body ::auth-openapi/signup-response}}\n            :handler (partial signup-post-handler db auth)}}]])\n```\n\n<a id=\"orgd65b047\"></a>\n\n# 動作確認\n\nここまでできたところで、実際に仮フロントエンドと swagger を経由して動作を確かめてみます。\n\nsignin の例): ![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap4/img/auth-sample.png)\n\n<a id=\"org4849120\"></a>\n\n# 付録・捕捉\n\n<a id=\"org9e09a97\"></a>\n\n## 実装してみます\n\n期待する機能が実装可能かどうかを REPL を動かしながら試す。 実装可能であれば仕様を固めてテストを書いたり実装を進めたりして、実装できなそうであれば、仕様を見直す。\n\n特に実装が不透明なライブラリを使うときには、先にきっとこんなはずなテストを書いてから実装するよりも、こちらのほうが失敗が少ないので (n=1 orz)、Clojure や Python など使う際には、ぜひ REPL やインタプリタを活用してみて下さい。\n\n<a id=\"org575f115\"></a>\n\n## ランダムな数列と衝突確率\n\nユーザ n 人を想定し、ランダム(要アルゴリズム)な k 桁の数列を id にしたときに衝突しない確率を考えてみます。\n\n```math\n\\begin{align}\n&1 (1 - \\frac{1}{10^k}) (1 - \\frac{2}{10^k}) \\cdots  (1 - \\frac{n-1}{10^k}) \\\\\n&= \\Pi^{n-1}_{i=1}(1-\\frac{i}{10^k})\n\\end{align}\n```\n\n衝突する確率は次の通り (ただし i / 10<sup>k</sup> << n )\n\n```math\n\\begin{align}\n&1 - \\Pi^{n-1}_{i=1}(1-\\frac{i}{10^k}) \\\\\n&\\approx 1- \\Pi^{n-1}_{i=1}exp(- \\frac{i}{10^k}) &\\because e^x \\approx 1 + x\\ where \\ x << n \\\\\n&= 1 - exp (- \\frac{n(n-1)}{2} \\frac{1}{10^k}) &\\because \\Sigma^{n-1}_{i=1}i=\\frac{n(n-1)}{2} \\\\\n&\\approx 1 - exp (- \\frac{n^2}{2 \\cdot 10^k}) \n\\end{align}\n```\n\n仮に 15 桁でユーザ登録総数 100 万 (= 10^6) 人未満のサービス開発をすると仮定すると、衝突する確率は `1 - exp(- (10^12)/(2 x 10^15)) = 1 - exp (- 1 / 2000) = 0.0005` なので、 1% 未満に落とせます。 \n\nとはいえ猿もキーボードを叩けばハムレットを書くので、最低でもリトライ＋上限試行回数を設ける必要があります。 (たとえ UUID であれ、 **衝突は起こります** )\n\n<a id=\"orgc4ba16a\"></a>\n\n## テスト用データベースのセットアップ\n\nテスト用のデータベースをセットアップします。\n\nまずは `docker-compose.yaml` 。\n\n```yaml\nversion: \"3\"\nservices:\n  dev_db:\n    build: containers/postgres\n    ports:\n      - 5566:5432\n    volumes:\n      - \"dev_db_volume:/var/lib/postgresql/data\"\n    environment:\n      POSTGRES_USER: meguru\n      POSTGERS_PASSWORD: emacs\n      POSTGRES_INITDB_ARGS: \"--encoding=UTF-8\"\n      POSTGRES_DB: pic_gallery\n    restart: always\n  test_db:\n    build: containers/postgres\n    ports:\n      - 5577:5432\n    volumes:\n      - \"test_db_volume:/var/lib/postgresql/data\"\n    environment:\n      POSTGRES_USER: meguru\n      POSTGERS_PASSWORD: emacs\n      POSTGRES_INITDB_ARGS: \"--encoding=UTF-8\"\n      POSTGRES_DB: pic_gallery\n    restart: always\n  repl:\n    build: containers/api-server\n    command: /bin/bash\n    ports:\n      - 3000:3000\n      - 39998:39998\n    volumes:\n      - \".:/app\"\n      - \"lib_data:/root/.m2\"\n    depends_on:\n      - dev_db\n      - test_db\nvolumes:\n  test_db_volume:\n  lib_data:\n```\n\n次に `project.clj`\n\n```clojure\n(defproject picture-gallery \"0.1.0-SNAPSHOT\"\n\n  :description \"FIXME: write description\"\n  :url \"http://example.com/FIXME\"\n  ;; :license {:name \"EPL-2.0 OR GPL-2.0-or-later WITH Classpath-exception-2.0\"\n  ;;           :url \"https://www.eclipse.org/legal/epl-2.0/\"}\n  ;; ...\n  :profiles\n  {:dev [:project/dev :profiles/dev]\n   :project/dev {:source-paths [\"dev/src\"]\n                 :resource-paths [\"dev/resources\"]}\n   :profiles/dev {}\n\n   :test [:project/test :profiles/test]\n   :project/test {:source-paths [\"dev/src\"]\n                  :resource-paths [\"dev/resources\"]}\n   :profiles/test {}\n\n   :repl {:prep-tasks ^:replace [\"javac\" \"compile\"]\n          :repl-options {:init-ns user}}\n   :uberjar {:aot :all\n             :jvm-opts [\"-Dclojure.compiler.direct-linking=true\"]}}\n\n  :repl-options\n  {:host \"0.0.0.0\"\n   :port 39998}\n\n  ;; alias for coverage\n  ;; see. https://qiita.com/lagenorhynque/items/f1e3c75439c1625756f3\n  :aliases\n  {\"coverage\" [\"cloverage\"\n               \"--ns-exclude-regex\" \"^(:?dev|user)$\"\n               \"--ns-exclude-regex\" \"picture-gallery.core$\"\n               \"--codecov\"\n               \"--summary\"]})\n```\n\nそして、 `profiles.clj`\n\n```clojure\n{:profiles/dev\n {:env\n  {:env \"dev\"\n   :database-adapter \"postgresql\"\n   :database-name \"pic_gallery\"\n   :database-username \"meguru\"\n   :database-password \"emacs\"\n   :database-server-name \"dev_db\"\n   :database-port-number \"5432\"\n   :migrations-folder \"migrations\"\n   :log-level \"info\"}}\n :profiles/test\n {:env\n  {:env \"dev\"\n   :database-adapter \"postgresql\"\n   :database-name \"pic_gallery\"\n   :database-username \"meguru\"\n   :database-password \"emacs\"\n   :database-server-name \"test_db\"\n   :database-port-number \"5432\"\n   :migrations-folder \"migrations\"\n   :log-level \"info\"}}}\n```\n","user":"MeguruMokke","created_at":"2021-03-29T11:19:58+09:00","updated_at":"2021-03-29T12:49:27+09:00"},{"url":"https://qiita.com/mine820/items/641f08274fda66efb650","title":"ラズパイのSDカードが壊れた？ときの対処","body":"# 経緯\n24時間/365日で動作させていたラズパイが、気が付いたらデスクトップ背景＋マウスポインタだけになっていた（マウスポインタは動かず）ので、再起動してみました。\n\nしかし以下のメッセージを表示して、起動しない．．．:qiitan-cry:\n\n```test\n[   11.366974] mmc0: timeout waiting for hardware interrupt.\n[   21.606972] mmc0: timeout waiting for hardware interrupt.\n[   31.846972] mmc0: timeout waiting for hardware interrupt.\n[   31.849236] print_req_error: I/O error, dev mmcblk0, sector 64614380\n[   42.086972] mmc0: timeout waiting for hardware interrupt.\n[   42.089241] print_req_error: I/O error, dev mmcblk0, sector 64614381\n（以下省略）\n```\n\n調べたところ、メッセージの通り、SDカードに問題がある模様です。\n\nなお、使用しているSDカードは「SanDisk Ultra microSDXC 128GB UHS-1 CLASS10」、ラズパイは「Raspberry Pi 3 Model B+（放熱フィン追加、ケースあり）」、OSは「Raspbian GNU/Linux 10 (Buster)」です。\n\n# 対応\n## SDカードの抜き挿し\n何はともあれ、SDカードの抜き差しをする。が、起動しない。\n接触部分を拭いてみるが、変化なし。\n\n## OS再インストール\nハード的に壊れてる場合は意味がないけど、とりあえずOS（Rasbian）を再インストールしてみる。\nラズパイ起動時、「Shift」キー押下でBIOSメニューが表示され、そこから再インストールができます。\n（ちなみに、このGUIから、起動時の設定等も変更できますが、今回はそのあたりは変更しませんでした）\n\n当然のことながら、OSはバージョンアップされてしまいました。\n（今回は10.8になりました）\n\n# 結果\nOSを再インストールしたら、なぜか起動できるようになった！\nハードの故障ではなかったのか．．．\n何だったんだ、あのエラーメッセージは？\n\n# その後\n初期化されてしまったので、いろいろ設定を復帰させ、現在は無事に運用中。\n\nでもきっと、また同じことが起きると思うので、この記録を残しておくことにしました。\n","user":"mine820","created_at":"2021-03-29T11:16:09+09:00","updated_at":"2021-03-29T11:16:35+09:00"},{"url":"https://qiita.com/ys-office-me/items/5d09c42124dad8f1ffb4","title":"firebase-admin を用いて最も単純な Firebase Cloud Firestore のデータを取得するコードサンプル","body":"# 動機\n\nFirestore のデータを取得する単純な事例があまり見当たらず、本家の資料を見てもいまいちピンとこなかったので、`firebase-admin` を使った最も単純なコードを書きたくなったため。\n\n# 実行環境と利用ツール\n\n- [Ubuntu 20.04.2.0 LTS (Focal Fossa)](https://releases.ubuntu.com/20.04/)\n- [Node.js](https://nodejs.org/en/)\n    - バージョンは 14.16.0\n- [Firebase Admin SDK](https://firebase.google.com/docs/admin/setup)\n\n# Cloud Firestore 設定\n\nまずはじめに Firebase コンソール（Web）から `books` コレクションと自動 ID を割り振ったドキュメントを作成します。\n\n内容は極めて単純にしたかったので string 型の `title` というフィールドのみ追加します。\n\n最後、値は `javascript` としています。\n\n完成形の画面のスナップショットを貼っておきます。\n\n![Firestore data m.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/191117/ae71cbbb-6754-35e0-2c07-b9cb886034f7.png)\n\n# コレクション内のドキュメントを取得する最も単純なコード\n\n```javascript\n\n// Ref : https://www.freecodecamp.org/news/the-firestore-tutorial-for-2020-learn-by-example/\n\nconst admin = require('firebase-admin');\n\nconst serviceAccount = require('./firestore-data-modeling-96db0-firebase-adminsdk-n3i63-0670471cc1.json');\n\nadmin.initializeApp({\n  credential: admin.credential.cert(serviceAccount)\n});\n\nconst db = admin.firestore();\n\nconst booksRef = db.collection('books');\n\n// console.log(booksRef.get());\n\nbooksRef\n  .get()\n  .then((snapshot) => {\n    const data = snapshot.docs.map((doc) => ({\n      id: doc.id,\n      ...doc.data(),\n    }));\n    console.log(data); \n    // [ { id: 'FY7PJJTw7EsS8x2hYphv', title: 'javascript' } ]\n  });\n\n```\n\n# 実行結果\n\nコード中にも記載がありますが JSON オブジェクトの配列を返します。\n\n```javascript\n$ node books.js\n[\n  { id: 'FY7PJJTw7EsS8x2hYphv', title: 'javascript' }\n]\n```\n\n# 参考資料\n\n[The JavaScript + Firestore Tutorial for 2020: Learn by Example](https://www.freecodecamp.org/news/the-firestore-tutorial-for-2020-learn-by-example/)\n","user":"ys-office-me","created_at":"2021-03-29T11:13:44+09:00","updated_at":"2021-03-29T11:13:44+09:00"},{"url":"https://qiita.com/Hyperbolic_____/items/27b00fc07a546291068e","title":"「;」や「\\n」のあるなしで処理が変わるんだと実感した話","body":"##この記事で解決できるかもしれないエラー\n`SyntaxError: Unexpected identifier`\nJavaScriptだと珍しくないエラーのようです。[Blockly](https://developers.google.com/blockly/)を使っている時にこのエラーが出た際はこの記事が参考になるかもしれません。\n\n## プログラムの流れ\n### ブロックを作成するファイル\nBlocklyを使ってLOGOのようなビジュアル言語を作成しています。\n![スクリーンショット 2021-03-29 10.17.54.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/549093/31872a10-8c93-90c1-6c53-21bb9e4639a4.jpeg)\n\nブロックの定義はこんな感じ\n\n```javascript:turtleBlock.js\nBlockly.Blocks['turtleforward'] = {\n  init: function() {\n    this.appendDummyInput()\n        .appendField(\"前に\")\n        .appendField(new Blockly.FieldNumber(0, -10, 10), \"step\")\n        .appendField(\"進む\");\n    this.setPreviousStatement(true, null);\n    this.setNextStatement(true, null);\n    this.setColour(60);\n this.setTooltip(\"\");\n this.setHelpUrl(\"\");\n  }\n};\n```\n\n実行されたの動きはこんな感じ\n\n```js:turtleBlock.js\nBlockly.JavaScript['turtleforward'] = function(block) {\n    var number_step = block.getFieldValue('step');\n    var fowardCode = `TurtleForward(${number_step})`; \n    return fowardCode;\n};\n```\n\n- 引数の数字を読み取る\n- 別の場所で定義されている`TurtleForward()`を実行するために`forwardCode`を定義\n- `return`で渡す\n\n### 実行するファイル\n`turtleBlock.js`から値を受け取り、実行します。\n\n```js:turtleCommand.js\nTurtleForward = (value) => {\n    console.log('実行された'+value);\n    var code = 'TurtleForward(turtle,'+value+')';\n    ggbApplet.evalCommand(code);\n}\n```\n\n## 実際の挙動\nブロックを並べて実行すると\n\n![スクリーンショット 2021-03-29 10.55.20.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/549093/e45bdd28-4159-d200-7aa8-2fff5e6eacf9.jpeg)\n\n\n画像のような挙動が確認されます。\nしかし、ブロックを繋げて実行すると\n![スクリーンショット 2021-03-29 10.54.32.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/549093/dc1effee-3a64-63e9-33d9-d1e83580520a.jpeg)\n\n上述したエラーが出てしまいます。\n\n##解決方法\nタイトルにもありますが、ブロックの定義の際に**`;`**や**`\\n`**をつけていないことが原因でした。試しにブロックによって作成されるコードを表示させてみると\n\n```\nTurtleForward(1)TurtleForward(1)\n```\n\n定義されている`TurtleForward()`を認識することができず、エラーを起こしてしまうようです。\n\n```js:turtleBlock.js\nBlockly.JavaScript['turtleforward'] = function(block) {\n    var number_step = block.getFieldValue('step');\n    console.log(number_step+'進む');\n    var fowardCode = `TurtleForward(${number_step})\\n`; //変更点\n    return fowardCode;\n  };\n```\nあるいは\n\n```js:turtleBlock.js\nBlockly.JavaScript['turtleforward'] = function(block) {\n    var number_step = block.getFieldValue('step');\n    console.log(number_step+'進む');\n    var fowardCode = `TurtleForward(${number_step});`; //変更点\n    return fowardCode;\n  };\n```\nのように**`\\n`**、**`;`**を定義された関数を文字列として扱ったものを最後に入れることでエラーを解決することができました。\n\n;\n","user":"Hyperbolic_____","created_at":"2021-03-29T11:09:36+09:00","updated_at":"2021-03-29T13:09:50+09:00"},{"url":"https://qiita.com/m-eno/items/c3fa75c7a04fc967342e","title":"NSX-T 3.1 :  ホストとEdge TEPの同一サブネット構成","body":"# NSX-T 3.0 & 3.1 :  ホスト内のTEP間通信の違い\n\nVMware NSX-T 3.1以降、ホスト内で**<font color=\"red\">ホストとEdgeのTEPの同一サブネットの指定が可能</font>**となっています。\nNSX-T 3.0での同構成については、[別記事](https://qiita.com/m-eno/items/d7f703437071449d4161)に記載しましたが、図１の様な運用上の対応が必要でした。(ホストとEdgeは、VDSを分ける必要性)\n　\n　　　　　　　**図１ (NSX-T 3.0まで)**\n![図１.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/251519/d0c07326-8196-cc54-e4b5-66144e4347ba.png)\nNSX-T 3.1では**<font color=\"blue\">同一VDSで、ホストとEdgeのTEPの同一サブネット構成が可能</font>**となっています。（図２）　　\n\n　　　　　　　**図２ (NSX-T 3.1以降)**\n![図２.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/251519/d736dc3c-c8db-ed16-29c3-08b9b73c1d93.png)\n\n# NSX-T 3.1： 同一VDS、同一ホスト/Edge TEPサブネットの実装\n\nNSX-T 3.1で、同一ホスト、同一VDSかつ同一サブネットにてホスト TEPとEdge TEPを実装するには、以下の設定が必要となります。\n\n* **<font color=\"red\">NSX-TでTrunkセグメントを構成し、Edgeのネットワークインターフェイスに接続する</font>**\n※Edgeのネットワークの接続先は、VDS上のTrunkポートグループは指定出来ず、NSX-Tのセグメントを選択する必要がある\n![図３.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/251519/bfbe4be2-9b3b-13d1-feef-7ba24b98617d.png)\n\n\n* 上記の設定で、Edgeが正常に動作する（Edge-ホスト間のトンネルがUpする）\n![図４.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/251519/962f0313-8574-0a5f-d576-8211be9c95e2.png)\n![図５.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/251519/5192082d-9ecf-4771-7bfc-a1c13e24322a.png)\n\n\n* 一方EdgeをVDS上のTrunkポートグループに接続すると、EdgeのトンネルがDownし、オーバーレイの通信が失敗する\n\n![図６.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/251519/bde373b1-b351-f1ae-c025-ee219f1cd585.png)\n\n\n# 参考リンク\nhttps://vmwarehosting.com.au/nsx-t-3-1-enhancement-shared-esxi-and-edge-transport-vlan-with-a-single-uplink/\n","user":"m-eno","created_at":"2021-03-29T11:05:49+09:00","updated_at":"2021-03-29T11:30:41+09:00"},{"url":"https://qiita.com/MeguruMokke/items/0ff941bcad6c86618b3d","title":"Clojure x ClojureScript で深める Web 開発 (3) API 作成入門","body":"# Git Repo\nソースコードと原文が入ったレポジトリ\nhttps://github.com/MokkeMeguru/clj-web-dev-ja/tree/main/chap3\n\n## シリーズ\n- [Clojure x ClojureScript で深める Web 開発 (0)](https://qiita.com/MeguruMokke/items/c6e059f109122be5f991)\n- [Clojure x ClojureScript で深める Web 開発 (1) Duct x Clean Architecture](https://qiita.com/MeguruMokke/items/af003d5a665095c0f3c8)\n- [Clojure x ClojureScript で深める Web 開発 (2) 環境の構築](https://qiita.com/MeguruMokke/items/9fe8e11a134e4c4dee2b)\n- [Clojure x ClojureScript で深める Web 開発 (3) API 作成入門](https://qiita.com/MeguruMokke/items/0ff941bcad6c86618b3d)\n- [Clojure x ClojureScript で深める Web 開発 (4) Auth](https://qiita.com/MeguruMokke/items/5ccf00bd2831551309d5)\n- [Clojure x ClojureScript で深める Web 開発 (5) API 開発 トランザクション添え](https://qiita.com/MeguruMokke/items/258c04caacdf66f706a2)\n- [Clojure x ClojureScript で深める Web 開発 (6) クライアントサイドと re-frame](https://qiita.com/MeguruMokke/items/78ff972bbd4efe3e1398)\n\n\n\n# 本編\n- [開発の流れの確認](#orgc3d22b3)\n- [HTTP サーバを建てる](#org45d0e1d)\n- [Test API の作成](#orgc0f1dd2)\n  - [Swagger のある生活](#org4459f98)\n  - [ping - pong フローの確認](#orgb412673)\n  - [domain の作成](#orge324fb7)\n  - [ルーティングを設定し、 Swagger を生やす](#orgd6c82eb)\n  - [swagger で API を試す](#orga21219d)\n- [付録 & 捕捉](#orgd2f6ccb)\n  - [logging 機能の設定](#org874fc5b)\n  - [コードの全評価](#org0edb2b1)\n\n<a id=\"orgc3d22b3\"></a>\n\n# 開発の流れの確認\n\nここまでで、REPL と integrant 、CLI を組み合わせて開発を行う準備が整いました。 以降からサーバ API 開発を行っていくわけですが、一旦ここで開発の流れ (諸説あり) を確認します。\n\n1.  環境変数を設定する。\n\n    `profiles.clj` を編集するか、 `export` を用いて、環境変数を設定します。特に DB の接続先を変えたり、 GCP のシークレットトークンを用いたりする際には、この工程が必須になります。\n\n2.  REPL を立ち上げる。\n\n    `lein repl` より (dev profile) 環境を立ち上げます。各エディタとこの REPL を連携することで、書いたコードの評価ができるようになります。\n\n3.  機能を書く。\n\n   - integrant の機能を書く。\n\n      [integrant のドキュメント](https://github.com/weavejester/integrant#initializing-and-halting) に従って記述します。\n\n   - integrant 外の機能を書く。\n\n      Clean Architecture の様式に従って、domain、usecase などを記述します。\n\n4.  config を更新する。\n\n    `config.edn` を更新します。更新したら、 `dev.clj` で書いた `(restart)` を評価して反映します。 なお、 `config.edn` を更新する必要がなくとも、何らかの機能を更新した場合には `(restart)` を評価する必要があります。\n\n基本的には 3, 4 を繰り返すことで開発を進めていきます。\n\n<a id=\"org45d0e1d\"></a>\n\n# HTTP サーバを建てる\n\nAPI は HTTP サーバに生えるので、HTTP サーバを建てます。 HTTP サーバの機能は、出力口にあたるので、Clean Architecture 的には `infrastructure` に含まれる部分と考えられます。\n\nまた今回は API サーバなので、ルーティングについても考える必要があります。 HTTP の `port=3000` 番ポートを開けて待ち受けることと、ルーティングすることは別なので、それぞれ別の機能とみなして実装を行っていきます。\n\n依存関係を考えてまずはルーティング部分から記述します。 ルーティングは `reitit` (<https://github.com/metosin/reitit>) というライブラリを利用します。 2021 年のところルーティングにおいて、他ライブラリと比較して速度の面で有利であること、良質なドキュメントがあることのためです。\n\n<details><summary>ルータのコード (picture-gallery.infrastructure.router.core)</summary><div>\n\n```clojure\n(ns picture-gallery.infrastructure.router.core\n  (:require\n   [reitit.ring :as ring]\n   [reitit.core :as reitit]\n   [reitit.coercion.spec]\n\n   [reitit.swagger :as swagger]\n   [reitit.swagger-ui :as swagger-ui]\n   [reitit.ring.coercion :as coercion]\n\n   [reitit.ring.middleware.muuntaja :as muuntaja]\n   [reitit.ring.middleware.exception :as exception]\n   [reitit.ring.middleware.multipart :as multipart]\n   [reitit.ring.middleware.parameters :as parameters]\n   [reitit.ring.middleware.dev :as dev]\n   [reitit.ring.spec :as spec]\n\n   [spec-tools.spell :as spell]\n   [muuntaja.core :as m]\n\n   [clojure.java.io :as io]\n\n   [ring.logger :refer [wrap-with-logger]]\n   [integrant.core :as ig]\n   [taoensso.timbre :as timbre]\n\n   [reitit.dev.pretty :as pretty]))\n\n(defn app [env]\n  (ring/ring-handler\n   (ring/router\n    [;; 後述する swagger のためのエンドポイント\n     [\"/swagger.json\"\n      {:get {:no-doc true\n             :swagger {:info {:title \"picture-gallery-api\"}\n                       :securityDefinitions\n                       {:Bearer\n                        {:type \"apiKey\"\n                         :in \"header\"\n                         :name \"Authorization\"}}\n                       :basePath \"/\"}\n\n             :handler (swagger/create-swagger-handler)}}]\n     ;; \"/api\" 以下に機能を追加していく。\n     [\"/api\"]]\n    ;; 細かい設定\n    {:exception pretty/exception\n     :data {:coercion reitit.coercion.spec/coercion\n            :muuntaja m/instance\n            :middleware\n            [;; swagger feature\n             swagger/swagger-feature\n             ;; query-params & form-params\n             parameters/parameters-middleware\n             ;; content-negotiation\n             muuntaja/format-negotiate-middleware\n             ;; encoding response body\n             muuntaja/format-response-middleware\n             ;; exception handling\n             exception/exception-middleware\n             ;; decoding request body\n             muuntaja/format-request-middleware\n             ;; coercing response bodys\n             coercion/coerce-response-middleware\n             ;; coercing request parameters\n             coercion/coerce-request-middleware\n             ;; multipart\n             multipart/multipart-middleware]}})\n   (ring/routes\n    (swagger-ui/create-swagger-ui-handler {:path \"/api\"})\n    (ring/create-default-handler))\n   {:middleware [wrap-with-logger]}))\n\n(defmethod ig/init-key ::router [_ {:keys [env]}]\n  (timbre/info \"router got: env\" env)\n  (app env))\n\n;; halt-key! は何もしないので 省略できる\n```\n</div>\n</details>\n\n次に HTTP サーバ。同じく `reitit` ライブラリを参考に書きます。 `reitit` は Clojure ライブラリの中でもかなり開発・運用環境が良いので、API 開発時のルーティング (また、後に出てくる SPA クライアント側のルーティングにも) おすすめです。\n\n参考: <https://github.com/metosin/reitit/blob/bdfae526bb7184dcb20d40800c81403d3430641d/examples/http/src/example/server.clj#L63-L65>\n\n```clojure\n(ns picture-gallery.infrastructure.server\n  (:require [taoensso.timbre :as timbre]\n            [ring.adapter.jetty :as jetty]\n            [integrant.core :as ig]))\n\n(defmethod ig/init-key ::server [_ {:keys [env router port]}]\n  (timbre/info \"server is running in port\" port)\n  (timbre/info \"router is \" router)\n  (jetty/run-jetty router {:port port :join? false}))\n\n;; server は 常駐アプリケーションなので、停止を強制させる必要がある。\n;; 引数に与えられている server は init-key にある (jetty/run-jetty ...) で返される server\n(defmethod ig/halt-key! ::server [_ server]\n  (.stop server))\n```\n\nconfig を更新します。\n\n```clojure\n{:picture-gallery.infrastructure.env/env {}\n :picture-gallery.infrastructure.router.core/router {:env #ig/ref :picture-gallery.infrastructure.env/env}\n :picture-gallery.infrastructure.server/server {:env #ig/ref :picture-gallery.infrastructure.env/env\n                                                :router #ig/ref :picture-gallery.infrastructure.router.core/router\n                                                :port 3000}}\n```\n\nREPL で `(restart)` を評価してみます。\n\n    (dev)=> (restart)\n    loading environment via environ\n    running in  dev\n    log-level  :info\n    orchestra instrument is active\n    2021-03-13T14:41:44.588Z b343f5d53e9e INFO [picture-gallery.infrastructure.router.core:72] - router got: env {:running \"dev\", :log-level :info}\n    2021-03-13T14:41:44.592Z b343f5d53e9e INFO [picture-gallery.infrastructure.server:7] - server is running in port 3000\n    2021-03-13T14:41:44.592Z b343f5d53e9e INFO [picture-gallery.infrastructure.server:8] - router is  clojure.lang.AFunction$1@22b20c19\n    ;; => :initiated\n    (dev)=>\n\nサーバが立ち上がったのを確認することができました。\n\n<a id=\"orgc0f1dd2\"></a>\n\n# Test API の作成\n\n今回は Test API として ping - pong API を作ってみることにします。\n\nping - pong API とは /ping へリクエストを投げると &ldquo;pong&rdquo; という文字が返ってくる API です。 DB への接続もないので、非常にシンプルに作ることができます。\n\n更に今後の開発のために、 Swagger と呼ばれる API の仕様記述のためのツールを使ってブラウザ上で ping - pong API をテストできるようにします。\n\n<a id=\"org4459f98\"></a>\n\n## Swagger のある生活\n\nサーバとクライアントの接続部分の情報共有をどのように行うのか。サーバ・クライアントアプリケーション (サービス) を開発する際にこの議題がしばしば挙がります。 (※ Rails / Django のようなサーバとクライアントを一つのプログラムで完結させるものを除く)\n\n一般にサーバとクライアントは JSON を始めとする何らかのフォーマットにエンコードされたデータをやり取りし、それらを仕様として各プログラムは認識 / デコードします。\n\n近年では、Swagger (OpenAPI) というツールがこの仕様共有のために注目されています。 Swagger は API のエンドポイントとそのエンドポイントで通信する際のデータ仕様をブラウザを用いて確認できるツールで、また、Swagger を Web クライアントとしてサーバとデータのやり取りをテストすることができます。\n\n本ガイドでは、Swagger を **サーバ側のコードから自動生成する** ことで、Swagger の利用を行っていきます。\n\n<a id=\"orgb412673\"></a>\n\n## ping - pong フローの確認\n\n今回扱う ping - pong API のフローを確認します。今回は練習のため comment という optional な 値を導入しました。\n\n    client                               server\n      |       +--------------------+       |\n      |  ---  | /ping              |  -->  |\n      |       |  'ping-message     |       |\n      |       +--------------------+       |\n      |                                    |\n      |       +----------<success>-+       |\n      |  <--  |  'pong-message     |  ---  |\n      |       +--------------------+       |\n      ~                                    ~\n      |       +----------<failure>-+       |\n      |  <--  |  'error-message    |  ---  |\n      |       +--------------------+       |\n\n- &rsquo;ping-message (query)\n\n  ```clojure\n    {:ping \"ping\"\n     :comment \"<optional string>\"}\n  ```\n\n- &rsquo;pong-message (response body)\n\n  ```clojure\n  {:pong \"pong\"\n   :comment \"<optional string>\"}\n  ```\n\n<a id=\"orge324fb7\"></a>\n\n## domain の作成\n\ndomain (entities) は取り扱うデータの仕様です。文字長のような制約も含めた仕様を記述していきます。\n(golang や Java の String, Integer の代わりです。)\n\n```clojure\n(ns picture-gallery.domain.sample\n  (:require [clojure.spec.alpha :as s]))\n\n(def max-comment-length 1024)\n\n(s/def ::ping (s/and string? (partial = \"ping\")))\n(s/def ::pong (s/and string? (partial = \"pong\")))\n\n(s/def ::not-exist-comment nil?)\n(s/def ::exist-comment (s/and string? #(< (count %) max-comment-length)))\n(s/def ::comment (s/or :not-exist-comment ::not-exist-comment\n                       :exist-comment ::exist-comment))\n```\n\nREPL で動作確認をしてみましょう。\n\n```clojure\n(s/valid? ::ping \"ping\") ;; => true\n(s/valid? ::ping 0)      ;; => false\n(s/valid? ::ping \"pong\") ;; => false\n```\n\n動作確認を元に、テストを書いておきます。\n\n```clojure\n(ns picture-gallery.domain.sample-test\n  (:require [picture-gallery.domain.sample :as sut]\n            [picture-gallery.utils.string :as pg-string]\n            [clojure.spec.alpha :as s]\n            [clojure.test :as t]))\n\n(t/deftest ping\n  (t/is (not (s/valid? ::sut/ping \"pong\")))\n  (t/is (not (s/valid? ::sut/ping 0)))\n  (t/is (s/valid? ::sut/ping \"ping\")))\n\n(t/deftest pong\n  (t/is (not (s/valid? ::sut/pong \"ping\")))\n  (t/is (not (s/valid? ::sut/pong 0)))\n  (t/is (s/valid? ::sut/pong \"pong\")))\n\n(t/deftest _comment\n  (t/is (s/valid? ::sut/comment nil))\n  (t/is (s/valid? ::sut/comment \"hello\"))\n  (t/is (not (s/valid? ::sut/comment (pg-string/rand-str 2048)))))\n```\n\nなお、動作確認、テストの段階で仕様に漏れがあれば、修正を施しましょう。\n\n<a id=\"orgd6c82eb\"></a>\n\n## ルーティングを設定し、 Swagger を生やす\n\nAPI でどのようなデータをやり取りするのかがわかったところで、早速エンドポイントを作っていきます。\n\nまずは条件を無視して、サンプルのデータをやり取りするだけのエンドポイントを作ります。\n\n1.  ルータ\n\n    ```clojure\n    (ns picture-gallery.infrastructure.router.sample\n      (:require [picture-gallery.domain.openapi.sample :as sample-openapi]\n                [picture-gallery.interface.controller.api.sample.ping-post :as ping-post-controller]\n                [picture-gallery.usecase.sample.ping-pong :as ping-pong-usecase]\n                [picture-gallery.interface.presenter.api.ping-post :as ping-post-presenter]\n                [picture-gallery.utils.error :refer [err->>]]))\n\n    ;; handlers\n    (defn ping-post-handler [input-data]\n      (ping-post-presenter/->http ;; 出力データにフォーマットする\n       (err->> input-data  ;; 入力データを\n               ping-post-controller/http-> ;; フォーマットして\n               ping-pong-usecase/ping-pong ;; 処理する\n               )))\n\n    ;; router\n    (defn sample-router []\n      [\"/samples\"\n       [\"/ping\"\n        {:swagger {:tags [\"sample_API\"]}\n         :post {:summary \"ping - pong\"\n                :parameters {:query ::sample-openapi/post-ping-query-parameters}\n                :responses {200 {:body ::sample-openapi/post-ping-response}}\n                :handler ping-post-handler}}]])\n    ```\n\n2.  ハンドラの内部\n\n    Clean Architecture 的には入力データの処理を controller、ロジックを usecase、出力を presenter で行うので、それに従って書いていきます。(先にルータですべてのコードを書いて、後で分割していく方が楽かもしれません。)\n\n- controller\n\n  <details><summary>controller のコード</summary><div>\n\n  ```clojure\n  (ns picture-gallery.interface.controller.api.sample.ping-post\n    (:require [clojure.spec.alpha :as s]\n              [picture-gallery.domain.sample :as sample-domain]\n              [picture-gallery.domain.error :as error-domain]\n              [picture-gallery.domain.openapi.sample :as sample-openapi]))\n\n  (s/def ::query ::sample-openapi/post-ping-query-parameters)\n  (s/def ::parameters (s/keys :req-un [::query]))\n  (s/def ::http-input-data (s/keys :req-un [::parameters]))\n\n  (s/fdef http->\n    :args (s/cat :input-data ::http-input-data)\n    :ret (s/or :success (s/tuple ::sample-domain/ping-pong-input nil?)\n               :failure (s/tuple nil? ::error-domain/error)))\n\n  (defn http-> \"\n    http request -> usecase input model\n    \"\n    [input-data]\n    (let [{:keys [parameters]} input-data\n          {:keys [query]} parameters\n          {:keys [ping comment]} query\n          input-model   (cond-> {:ping (:ping query)}\n                          comment (assoc :comment comment))\n          conformed-input-model (s/conform\n                                 ::sample-domain/ping-pong-input\n                                 input-model)]\n      (if (not= ::s/invalid conformed-input-model)\n        [conformed-input-model nil]\n        [nil (error-domain/input-data-is-invalid (s/explain-str ::sample-domain/ping-pong-input input-model))])))\n  ```\n\n  </div></details>\n\n- usecase\n\n  ```clojure\n       (ns picture-gallery.usecase.sample.ping-pong\n         (:require [clojure.spec.alpha :as s]\n                   [picture-gallery.domain.sample :as sample-domain]\n                   [picture-gallery.domain.error :as error-domain]\n                   [orchestra.spec.test :as st]))\n\n       (s/fdef ping-pong\n         :args (s/cat :input-model ::sample-domain/ping-pong-input)\n         :ret (s/or :success (s/cat :ping-pong-output ::sample-domain/ping-pong-output :error nil?)\n                    :failure (s/cat :ping-pong-output nil? :error ::error-domain/error)))\n\n       ;; ここを後で編集する (ロジックが空)\n       (defn ping-pong [input-model]\n         (let [{:keys [ping comment]} input-model\n               output-model {:pong \"pong\"}]\n           [output-model nil]))\n  ```\n\n- presenter\n\n  <details></summary>presenter のコード</summary><div>\n\n  ```clojure\n     (ns picture-gallery.interface.presenter.api.ping-post\n       (:require [clojure.spec.alpha :as s]\n                 [picture-gallery.domain.sample :as sample-domain]\n                 [picture-gallery.domain.openapi.sample :as sample-openapi]\n                 [picture-gallery.domain.openapi.base :as base-openapi]\n                 [picture-gallery.domain.error :as error-domain]\n                 [orchestra.spec.test :as st]))\n\n     (s/def ::body ::sample-openapi/post-ping-response)\n     (s/def ::http-output-data (s/keys :req-un [::base-openapi/status ::body]))\n     (s/fdef ->http\n       :args (s/cat :arg\n                    (s/or :success (s/tuple ::sample-domain/ping-pong-output nil?)\n                          :failure (s/tuple nil? ::error-domain/error)))\n       :ret (s/or :success ::http-output-data\n                  :failure ::error-domain/error))\n\n     (defn ->http \"\n       usecase output model -> http response\n       \"\n       [[output-data error]]\n       (if (nil? error)\n         {:status 200\n          :body output-data}\n         error))\n  ```\n\n  </div></details>\n\n最後に、大元のルータに接続します。\n\n```clojure\n(defn app []\n  (ring/ring-handler\n   (ring/router\n    [[\"/swagger.json\"\n      {:get {:no-doc true\n             :swagger {:info {:title \"picture-gallery-api\"}\n                       :securityDefinitions\n                       {:Bearer\n                        {:type \"apiKey\"\n                         :in \"header\"\n                         :name \"Authorization\"}}\n                       :basePath \"/\"}\n\n             :handler (swagger/create-swagger-handler)}}]\n     [\"/api\"\n      (sample-router/sample-router) ;; \"/api\" 以下に生やしていく\n      ]]\n    ;; ...\n    )))\n```\n\nすべて記述するとともに、 **実装した関数を評価したら [4.2](#org0edb2b1)** 、 `(restart)` より環境を更新します。 なお、実装した関数を評価していないと、正しく動作しません。\n\nSwagger にアクセスして確かめてみましょう。ブラウザの `localhost:3000/api` より Swagger の画面にアクセスできます。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap3/img/swagger.png)\n\n<a id=\"orga21219d\"></a>\n\n## swagger で API を試す\n\n試しに ping に &ldquo;ping&rdquo; を入力して 実行すると、\n\n```json\n{ \"pong\": \"pong\" }\n```\n\nと返ってきます。これは期待通りですね。\n\nping に &ldquo;hello&rdquo; を入力すると、以下のようなエラーが返ってきます。これは、controller ([3.4](#orgd6c82eb)) で `s/conform` した際に、 domain の ping の仕様 (`:picture-gallery.domain/sample/ping`) に違反しているためです。\n\n```json\n{\n  \"code\": 1,\n  \"message\": \"input data is invalid: \\\"hello\\\" - failed: (partial = \\\"ping\\\") in: [:ping] at: [:ping] spec: :picture-gallery.domain.sample/ping\\n\"\n}\n```\n\n次に、 ping に &ldquo;ping&rdquo;、 comment に &ldquo;hello world&rdquo; を入力してみましょう。 comment がレスポンスに含まれていません。これは仕様とは違いますね。入力や出力の変換部分ではなく、usecase の未実装が原因です (※本来はテストでカバーできている場面ですが、Swagger に慣れてもらうために、意図的にテストを飛ばしています)。\n\n```json\n{ \"pong\": \"pong\" }\n```\n\nusecase ([3.4](#orgd6c82eb)) を見ると、 comment を output モデルに追加していないことがわかるので、これを追加します。 つまり以下のように修正します。\n\n```clojure\n(defn ping-pong [input-model]\n  (let [{:keys [ping comment]} input-model\n        output-model (cond-> {:pong \"pong\"}\n                       ;; もし comment があれば、 assoc 関数を用いて comment を追加する\n                       comment (assoc :comment comment))]\n    [output-model nil]))\n```\n\n修正を反映して、再度 swagger で試してみましょう。\n\n```json\n{\n  \"pong\": \"pong\",\n  \"comment\": \"hello world\"\n}\n```\n\n期待する結果を得ることができました。\n\n<a id=\"orgd2f6ccb\"></a>\n\n# 付録 & 捕捉\n\n<a id=\"org874fc5b\"></a>\n\n## logging 機能の設定\n\nlog の設定機能を追加します。 **timbre** というライブラリを呼び出すだけなのでほとんどコードはないです。\n\n```clojure\n(ns picture-gallery.infrastructure.logger\n  (:require [taoensso.timbre :as timbre]\n            [integrant.core :as ig]))\n\n(defmethod ig/init-key ::logger [_ {:keys [env]}]\n  (println \"set logger with log-level\" (:log-level env))\n  (timbre/set-level! (:log-level env))\n  {})\n```\n\n環境変数からログの出力レベルを得たいので、config に `:env` の依存関係を追加します。\n\n```clojure\n{:picture-gallery.infrastructure.env/env {}\n :picture-gallery.infrastructure.logger/logger {:env #ig/ref :picture-gallery.infrastructure.env/env}}\n```\n\n<a id=\"org0edb2b1\"></a>\n\n## コードの全評価\n\nEmacs の開発環境である、 Cider では、 `cider-eval-all-files` というコマンドで、指定したディレクトリ以下の今まで記述したコードのすべてを評価することができます。\n\nまた、VSCode の Calva では、コードを保存すると評価するオプション `Eval On Save` が存在します。\n","user":"MeguruMokke","created_at":"2021-03-29T11:03:50+09:00","updated_at":"2021-03-29T11:41:56+09:00"},{"url":"https://qiita.com/Mayumi_Pythonista/items/b14c91b020f5f5eba787","title":"【Pandas】MultiIndexとは？(pivotメソッドを学ぶ前に知っておくべきこと)no.24","body":"![見出しを追加 (52).png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/78ced340-1d03-d079-2b2a-d1f396c4badf.png)\nこんにちは、まゆみです。\n\nPandasの記事をシリーズで書いています。\n\n今回の記事は第24回目になります。\n\n今回の記事では、<font color=\"Red\">『Multiindex』(マルチインデックス)</font>という概念を扱っていこうと思います。\n\nMultiindex とは文字通り、<font color=\"Red\">複数のインデックス</font>という意味です。\n\nこの記事を読めば\n<ul>\n<li>MultiIndexとは？</li>\n<li>コラムからインデックスに変更するには</li>\n<li>MultiIndexを扱う時のレベルとは？</li>\n</ul>\n\nが分かります。\n\n\nまた、Multiindexの概要が十分に理解できたら、次回以降の記事で『pivot』や『pivot_table』についても触れていきます。\n\n今回の記事は、そのウォーミングアップのような位置づけになります。\n\nではさっそく始めていきますね。\n\n#今回使うデータ\n![見出しを追加 (53).png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/ca67d6a3-4abf-45df-b65a-77f07916ba27.png)\n\n今回は、[data.world](https://data.world/)さんのサイトから[ウェラブル端末に関するデータ](https://data.world/crowdflower/wearable-technology-database/workspace/file?filename=Wearables-DFE.csv)を使っていきます。\n\nread_csv()で読み込むと下記のような感じになります。\n\n![スクリーンショット 2021-03-29 073342.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/09efec17-6f1a-39ba-f9db-11f1b3783488.jpeg)\n\n\nBody.Location(体のどの部位につけるか)というコラムと、Company...Country(会社がある国)というコラムがあるので、これら２つをインデックスにしていきます。\n\n#set_index()\n\nコラムをインデックスにするメソッドは、<font color=\"Red\">.set_index()</font>があります。\n\n![スクリーンショット 2021-03-29 090700.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/fcede7eb-ef8a-d64a-0b5d-62a6aaff808c.jpeg)\n引用元：[Pandasドキュメント](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html)\n\nkeys には、インデックスにしたいコラム名を引数として渡します。\n\n今回は2つのコラムをインデックスにしたいので、コラム名をリストに入れて、引数として渡します。\n\n```\ndf.set_index(keys=[ \"コラムA\", \"コラムB\" ])\n```\n\nそしてこの実行結果をオリジナルのDataFrame に上書きしたいので、パラメーターinplace = True　とします。\n\nまた、<font color=\"Red\">新たに作ったインデックスをアルファベット順に並べたい</font>ので、\n\n```\n.sort_index()\n```\n\nでインデックスをアルファベット順(インデックスが数字の場合は小さい順)に並べます\n\n実行結果は下記のようになりました。\n\n![スクリーンショット 2021-03-29 0922411.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/a68ec506-f8db-bb77-13a0-0e3c4e5ef63b.jpeg)\n\nリスト型にして引数として渡したコラム名は<font color=\"Red\">一番最初に書かれたものから順番に一番外側のインデックスから配置</font>されます。\n言葉での説明はややこしいので下のイラストをご覧くださいませ。<(_ _)>\n\n![set_index(keys=[]).png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/cd2a5fc1-1b23-597a-a68e-2b20695b7173.png)\n\nリストの最初のアイテムから順番に、外側からインデックスを埋めていきます。\n\n##新たにインデックスにしたインデックスのデータ型は？\n\n![スクリーンショット 2021-03-29 094459.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/eacbaeb5-a43d-adfc-6866-cc6645d12cc6.jpeg)\n上のスクショから分かるように、新たなインデックスのデータ型はタプルです。\n\nまた、インデックスの名前は、2つのコラム名が一緒になったリスト型になっています\n\n![スクリーンショット 2021-03-29 094934.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/1929b93a-0173-d1be-1ee2-a7284dda7a0d.jpeg)\n\n#インデックスのラベルを変更したい時(レベルとは何か？)\nインデックスのラベル名を変更したい時に使うのが.set_names()になります。\n\n![スクリーンショット 2021-03-29 100602.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/68154028-2a76-c746-7fe2-06b0ead25813.jpeg)\n引用元：[Pandasドキュメント](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Index.set_names.html#pandas-index-set-names)\n\nただ、Multiindex になっている時には、注意が必要です。\n\nどちらのインデックス名を変更するのか指定しないといけないからです。\n\nドキュメントに引数としてレベルを渡すと書いていますが、この『レベル』というものが、Multiindex の、どのインデックスを指定するかに使われるものです。\n\n![2.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/81a4d817-ee1e-67e2-0a8a-bd3e436cde2c.png)\n\nでは、2つのインデックスのうち、『Company...Country』を日本語の『国名』に変えてみます。\n\n```\ndf.index.set_names( names=\"変更後のラベル\", level=multiindexのレベル, inplace=上書きするか？)\n```\n実行結果は下記のようになります。\n\n![スクリーンショット 2021-03-29 102317.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1011305/b0a6ddad-f7e8-5986-7132-b6e3de1edf67.jpeg)\n\nこの『レベル』の定義は、後々、Pandasのドキュメントを読む時にも必要になるので、是非覚えておいてくださいね\n\n#まとめ\n\n今回の記事では、実際にデータを集計する前に必要となる作業について書かせていただきました。\n\nデータを集計する前のデータの処理が終われば、実際にデータを集計する事ができます。(エクセルのピボットテーブルを使った事がある方なら、Pandasでも同じことができるメソッドがあります)\n\n少し退屈な記事が続くと思いますが、どうぞよろしくお願いします！\n","user":"Mayumi_Pythonista","created_at":"2021-03-29T10:59:48+09:00","updated_at":"2021-03-29T10:59:48+09:00"},{"url":"https://qiita.com/ryamamoto0406/items/84ab5278c898e0075cab","title":"R leaflet + shiny でGFS のデータを可視化","body":"# はじめに\n[こちらの記事](https://qiita.com/ryamamoto0406/items/34f69e60ed9e33597f49)でR leaflet を用いて GFS のデータの可視化を行った。今回はこの知見をもとに、それをshiny で実装した。また、3時間ごとに予報値のデータがあるので、それをスライドバーから選べるようにした。\n\n# GFS データの処理\n基本的には[こちらの記事](https://qiita.com/ryamamoto0406/items/34f69e60ed9e33597f49)で実装したまんまである。各時刻ごとのラスターデータを作ってリストに格納していくだけ。\n\n```R:GFS.R\nlibrary(raster)\n\n################################################################################\n\n#読み込むGFSデータの詳細\nmode <- \"3\"\ndate <- \"20210321\"\ntime <- \"0000\"\n\ngrb2_dir <- \"./data/GFS/GRIB2\"\ncsv_dir <- \"./data/GFS/CSV\"\n\nkeywd <- \"'TMP:surface'\"\ncsv_key <- \"tmp_surface\"\n\n#GFSデータを一つずつ処理\ngfs_tmp_rs <- list()\nfor (i in 0:8) {\n  j <- i + 1\n  num <- 3*i\n  \n  filename.grb2 <- sprintf(\"%s/gfs_%s_%s_%s_%03d.grb2\", grb2_dir, mode, date, time, num)\n  filename.csv <- sprintf(\"%s/gfs_%s_%s_%s_%03d_%s.csv\", csv_dir, mode, date, time, num, csv_key)\n  \n  # wgrib2 で変換（詳細は前の記事を参照）\n  # system(paste(\"/usr/local/bin/wgrib2\", filename.grb2, \"-match\", keywd, \"-csv\", filename.csv))\n  \n  gfs_csv <- read.csv(filename.csv, header = FALSE)\n  lon_180 <- gfs_csv[(gfs_csv$V5 == 180),]\n  lon_180$V5 <- lon_180$V5 * -1\n  gfs_csv <- rbind(gfs_csv, lon_180)\n  \n  gfs_coords <- cbind(gfs_csv$V5, gfs_csv$V6)\n  \n  cell_size <- 1.0\n  lon_min <- min(gfs_csv$V5)\n  lon_max <- max(gfs_csv$V5)\n  lat_min <- min(gfs_csv$V6)\n  lat_max <- max(gfs_csv$V6)\n  \n  lon_ncols <- ((lon_max - lon_min)/cell_size)+1\n  lat_nrows <- ((lat_max - lat_min)/cell_size)+1\n  \n  grid_gfs <- raster(nrows=lat_nrows, ncols=lon_ncols, xmn=lon_min, xmx=lon_max, ymn=lat_min, ymx=lat_max, res=cell_size, crs=\"+proj=longlat +datum=WGS84\")\n  \n  gfs_tmp_rs[[j]] <- rasterize(gfs_coords, grid_gfs, gfs_csv$V7, fun=mean)\n}\n\n\n\n################################################################################\n\n#color palette\n\ngfs_tmp_pal <- colorNumeric(\n  palette = c(\n    \"#000180\", \"#0007A7\", \"#0019CA\", \"#0035E6\", \"#0058F8\",\n    \"#017FFF\", \"#07A7F8\", \"#19CAE6\", \"#35E6CA\", \"#58F8A7\",\n    \"#80FF80\", \"#A7F858\", \"#CAE635\", \"#E6CA19\", \"#F8A707\",\n    \"#FF8001\", \"#F85800\", \"#E63500\", \"#CA1900\", \"#A70700\"\n  ),\n  domain = range(210, 360),  # カラーパレットの範囲\n  na.color = \"transparent\" # NAのときの色\n)\n```\n\n# leaflet + shiny で可視化\nスライドバーを作りその入力値でraster データを選ぶように設定した。\n\n```R:app.R\nlibrary(shiny)\nlibrary(leaflet)\nlibrary(dplyr)\n\nsource(\"GFS.R\")\n\nui <- fluidPage(\n  tags$style(type = \"text/css\", \"#map {height: calc(100vh - 80px) !important;}\"),\n  leafletOutput(outputId = \"map\"),\n  absolutePanel(\n    bottom = 100,\n    left = 400,\n    sliderInput(inputId = \"data_num\", label = \"Forecast time (hours later)\", min = 0, max = 24, value = 0, step = 3)\n  )\n)\n\nserver <- function(input, output, session){\n  output$map <- renderLeaflet(expr = {\n    num <- input$data_num/3 + 1\n    leaflet() %>%\n      setView(139, 35, zoom = 2) %>%\n      addProviderTiles(provider = providers$Esri.WorldGrayCanvas, group = \"WorldGrayCanvas\") %>%\n      addProviderTiles(provider = providers$Esri.OceanBasemap, group = \"OceanBaseMap\") %>%\n      addProviderTiles(provider = providers$OpenSeaMap, group = \"OpenSeaMap\") %>%\n      addRasterImage(x = gfs_tmp_rs[[num]], colors = gfs_tmp_pal, opacity = 0.7, group = \"GFS_Temperature\", project = TRUE) %>%\n      addLegend(position = 'topleft', pal = gfs_tmp_pal, values = 210:360, opacity = 0.7, title = \"TMP [K]\", group = \"GFS_Temperature\") %>%\n      addLayersControl(\n        baseGroups = c(\n          \"WorldGrayCanvas\",\n          \"OceanBaseMap\"\n        ),\n        overlayGroups = c(\n          \"OpenSeaMap\",\n          \"GFS_Temperature\"\n        )\n      ) %>%\n      hideGroup(\n        group = c(\n        )\n      ) %>%\n      addScaleBar(position=\"bottomleft\") %>%\n      addMiniMap(position=\"bottomright\") %>%\n      addMeasure(position=\"topright\")\n  })\n}\n\nshinyApp(ui=ui, server=server)\n```\n\nスライドバーを動かすことで予報値を変えられる。\n![GFS_app_1.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1077734/96188fe8-afc3-10d5-19ee-cd71e3744794.gif)\n\n# おわりに\nスライドバーを動かしたときにマップのプロットが一瞬消えて画面がちかちかしてしまう。ので、これは次の記事で改訂していきたい。\nまた、GFS はnetcdf 形式にも変換でき、そこからgeojson などにも変換できるよう。leaflet には addGeoJSON というコマンドがある。そこで、csv → raster データではなく、geojson を直接プロットする方法も検討してみたい。\n","user":"ryamamoto0406","created_at":"2021-03-29T10:58:28+09:00","updated_at":"2021-03-29T16:06:38+09:00"},{"url":"https://qiita.com/kyawphyonaing/items/c658eb27418e6dddafe8","title":"configファイルでSSH接続を管理","body":"\n## はじめに\n\n新しいパソコンの購入やパソコンの切り替え際に、再セットアップを必要あると思います。\nそのとき前のPCで行った初期設定は、なかなか思い出せないです。\n一番困るのはsshキーの管理です。理由は個人と会社のGitHub, Bitbucket, GitLabとサーバー（AWS, Azure, GCP）などのアカウントに繋がるキー複数あるからです。\nsshキー管理について、覚書として纏めます。\n\n\n## ~/.ssh/config を分ける\n\n個人と会社用ssh通信を以下のように分ける。\n\n```\n.ssh\n├── conf.d\n│   ├── personal\n│   │   ├── config\n│   │   ├── id_rsa\n│   │   ├── id_rsa.pub\n│   │   └── keys\n│   │       └── *.pem\n│   └── company\n│       ├── config\n│       ├── id_rsa\n│       ├── id_rsa.pub\n│       └── keys\n│           └── *.pem\n├── config\n└── known_hosts\n```\n\n各ファイルに記述しているものを載せていきます。\n\n```\n# ~/.ssh/config\nInclude ~/.ssh/conf.d/**/config\n\nHost *\n  ServerAliveInterval 300\n  AddKeysToAgent yes\n```\n\n※各フォルダのconfig例は後ほどで設定します。\n\n## SSHの秘密鍵・公開鍵を生成\n### 個人用（Personal）\n\n必要な情報\n\n| - | Default Github | Default Gitlab |\n| -------- | -------- | -------- |\n| SSH Key Name | id_rsa_github     | id_rsa_gitlab     |\n| email | name.github@example.com     | name.gitlab@example.com     |\n\nキーの作成\n\n```\nssh-keygen -f \"~/.ssh/conf.d/personal/id_rsa_github\" -t rsa -b 4096 -C \"name.github@example.com\"\nssh-keygen -f \"~/.ssh/conf.d/personal/id_rsa_gitlab\" -t rsa -b 4096 -C \"name.gitlab@example.com\"\n```\n\n### 会社用（Organization）\n\n必要な情報\n\n| - | Default Github | Default Gitlab |\n| -------- | -------- | -------- |\n| SSH Key Name | id_rsa_github_companyName     | id_rsa_gitlab_companyName     |\n| email | name.github@company.com     | name.gitlab@company.com     |\n\nキーの作成\n\n```\nssh-keygen -f \"~/.ssh/conf.d/company/id_rsa_github_companyName\" -t rsa -b 4096 -C \"name.github@company.com\"\nssh-keygen -f \"~/.ssh/conf.d/company/id_rsa_gitlab_companyName\" -t rsa -b 4096 -C \"name.gitlab@company.com\"\n```\n\n## SSH接続の設定をする\n### 公開鍵を各アカウント（Github, Gitlab）に登録する\n\n1. 各アカウントのブラウザを開き、Settings->SSH and GPG keysに行きます。\n2. SSH keysのNew SSH keyをクリックします。\n3. Titleに適当な名前を付けます。\n4. 下のKeyに公開鍵を貼り付ける。\n\n### SSHキーをSSH-Agentに追加\n\n```\n# Run ssh-agent\nssh-agent bash\n\n# Add the personal keys\nssh-add ~/.ssh/conf.d/personal/id_rsa_github\nssh-add ~/.ssh/conf.d/personal/id_rsa_gitlab\n\n# Add the organisation keys\nssh-add ~/.ssh/conf.d/company/id_rsa_github_companyName\nssh-add ~/.ssh/conf.d/company/id_rsa_gitlab_companyName\n\n# Confirm\nssh-add -l\n\n```\n\n### 各configを作成\n#### 個人用（Personal）のconfig\n\n**`~/.ssh/conf.d/personal/config`**\n\n```\nHost github.com\n    HostName github.com\n    User git\n    IdentityFile ~/.ssh/conf.d/personal/id_rsa_github\n\nHost gitlab.com\n    HostName gitlab.com\n    User git\n    IdentityFile ~/.ssh/conf.d/personal/id_rsa_gitlab\n  \nHost AWS\n    HostName 12.123.1.123\n    User ec2-user  \n    Port 22  \n    IdentityFile ~/.ssh/conf.d/personal/keys/awskey.pem \n    TCPKeepAlive yes\n    Identitiesonly yes\n```\n\n#### 会社用（Organization）のconfig\n\n**`~/.ssh/conf.d/company/config`**\n\n```\nHost companyname.github.com\n    HostName github.com\n    User git\n    IdentityFile ~/.ssh/conf.d/company/id_rsa_github_companyName\n\nHost companyname.gitlab.com\n    HostName gitlab.com\n    User git\n    IdentityFile ~/.ssh/conf.d/company/id_rsa_gitlab_companyName\n  \nHost companynameAWS\n    HostName 12.123.1.123\n    User ec2-user  \n    Port 22  \n    IdentityFile ~/.ssh/conf.d/company/keys/awskey.pem\n    TCPKeepAlive yes\n    Identitiesonly yes\n```\n\n#### 説明\n\n| キーワード | 内容 |\n|:--|:--|\n| Host | ホスト名 |\n| HostName | ホスト名またはIPアドレス |\n| User | ログインユーザ名 |\n| IdentityFile | ログインするための秘密鍵のパス |\n| Port | ポート番号(デフォルトは22) |\n| TCPKeepAlive | 接続状態を継続したい場合：yes　継続しない場合：no |\n| IdentitiesOnly | IdentityFileが必要な場合：yes　必要ない場合：no |\n| ServerAliveInterval | 一定期間サーバからデータが送られてこないときに、タイムアウトする秒数。(例) 120 |\n\n\n#### 接続の確認\n\n```\nssh -T git@github.com\n# 成功結果\n# Hi [Username]! You've successfully authenticated, but GitHub does not provide shell access.\n\nssh -T git@gitlab.com\n\nssh AWS\n\nssh companynameAWS\n```\n","user":"kyawphyonaing","created_at":"2021-03-29T10:56:37+09:00","updated_at":"2021-03-29T11:25:47+09:00"},{"url":"https://qiita.com/kawamurashin/items/cf6e87a520b4ccbba59a","title":"JavaScriptでDropbox APIから画像を読み込む","body":"とりあえず動いた喜びと感動とメモ帳書きとして\n\n\n```html\n<!DOCTYPE html>\n<html lang=\"ja\">\n<head>\n    <meta charset=\"UTF-8\">\n    <title>Dropbox Test</title>\n    <script src=\"https://unpkg.com/dropbox/dist/Dropbox-sdk.min.js\"></script>\n</head>\n<body>\n<h1>Dropbox Test</h1>\n<script>\n\n    let accessToken = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\";\n    let dbx = new Dropbox.Dropbox({accessToken: accessToken});\n    let dir_path = \"/Photos\"\n    dbx.filesListFolder({path: dir_path})\n        .then(function (response) {\n            imageLoad(response);\n        })\n        .catch(function (error) {\n            console.error(\"error \" + error);\n        });\n    function imageLoad(json)\n    {\n        let n = json.result.entries.length;\n        for(let i = 0;i<n;i++)\n        {\n            let fileData = json.result.entries[i];\n\n            dbx.filesGetTemporaryLink({\"path\": fileData.path_lower})\n                .then(function(response) {\n                    let img = document.createElement('img');\n                    img.src = response.result.link;\n                    document.body.appendChild(img);\n                })\n                .catch(function(error) {\n                    console.log(\"got error:\");\n                    console.log(error);\n                });\n        }\n    }\n</script>\n</body>\n</html>\n```\n\nサムネールは画像をBlobで受けとるapiがありますが、\n直接画像を取るには、json内のリンクを取るしかないっぽい。\n\n\n#参考\n知識ゼロだけど、Dropbox APIを使用したい\nhttps://qiita.com/Ella_Engelhardt/items/c33f08b6b427eab8b310\n\ndropbox-sdk-jsを使ってフォルダ内アイテムの共有リンクを取得\nhttps://kittagon.hateblo.jp/entry/2018/08/13/000916\n","user":"kawamurashin","created_at":"2021-03-29T10:55:24+09:00","updated_at":"2021-03-29T12:13:13+09:00"},{"url":"https://qiita.com/MeguruMokke/items/9fe8e11a134e4c4dee2b","title":"Clojure x ClojureScript で深める Web 開発 (2) 環境の構築","body":"# Git Repo\nソースコードと原文が入ったレポジトリ\nhttps://github.com/MokkeMeguru/clj-web-dev-ja/tree/main/chap2\n\n## シリーズ\n- [Clojure x ClojureScript で深める Web 開発 (0)](https://qiita.com/MeguruMokke/items/c6e059f109122be5f991)\n- [Clojure x ClojureScript で深める Web 開発 (1) Duct x Clean Architecture](https://qiita.com/MeguruMokke/items/af003d5a665095c0f3c8)\n- [Clojure x ClojureScript で深める Web 開発 (2) 環境の構築](https://qiita.com/MeguruMokke/items/9fe8e11a134e4c4dee2b)\n- [Clojure x ClojureScript で深める Web 開発 (3) API 作成入門](https://qiita.com/MeguruMokke/items/0ff941bcad6c86618b3d)\n- [Clojure x ClojureScript で深める Web 開発 (4) Auth](https://qiita.com/MeguruMokke/items/5ccf00bd2831551309d5)\n- [Clojure x ClojureScript で深める Web 開発 (5) API 開発 トランザクション添え](https://qiita.com/MeguruMokke/items/258c04caacdf66f706a2)\n- [Clojure x ClojureScript で深める Web 開発 (6) クライアントサイドと re-frame](https://qiita.com/MeguruMokke/items/78ff972bbd4efe3e1398)\n\n\n# 本編\n- [開発環境の Dockerize](#org2317877)\n  - [Port の開放](#org6cb8f73)\n  - [Directory のマウント](#org95ee502)\n  - [動作確認](#orgd1ac994)\n- [ライブラリの追加](#org8682b00)\n- [エディタとの接続](#orgb6ff216)\n- [integrant のセットアップ](#orgf8a114b)\n  - [integrant と REPL](#org7be26ff)\n  - [環境変数を読み込む](#org3b98e3e)\n  - [環境変数を読み込む CLI の作成](#org838c828)\n- [付録](#org4f91800)\n  - [ここまでのディレクトリの確認](#org630f578)\n  - [Docker コンテナ内で tmux を走らせる フロー](#org7e49fac)\n  - [Emacs で Clojure 開発を行う Tips](#orga976470)\n\n本稿では、Web API サーバを書いていくにあたり必要な、1. 開発環境の Dockerize、2. 基礎的なライブラリの列挙、3. integrant のセットアップを行います。\n\n<a id=\"org2317877\"></a>\n\n# 開発環境の Dockerize\n\n開発を進めていく上で、デプロイやスケーリングの観点から、Docker という選択肢はかなり受け入れられたものになっています。\n\n今回は Docker を利用して実行環境を構築し、更に RDB もまとめて管理できるよう、docker-compose の利用を行います。 ディレクトリとファイルを次のように追加します。\n\n    picture_gallery\n    ├── README.md\n    ├── containers           (各 Docker コンテナの設定)\n    │   ├── api-server\n    │   │   └── Dockerfile\n    │   └── postgres\n    │       └── Dockerfile\n    ├── dev\n    ├── doc\n    ├── docker-compose.yml  (docker-compose の設定)\n    ├── project.clj\n    ├── resources\n    ├── src\n    ├── target\n    └── test\n\nClojure の API Server 用の Dockerfile (api-server/Dockerfile) は次の通り\n\n```dockerfile\nFROM clojure:openjdk-11-lein\nMAINTAINER MokkeMeguru <meguru.mokke@gmail.com>\nENV LANG C.UTF-8\nENV APP_HOME /app\nRUN apt-get update\nRUN apt-get -y install tmux\nRUN mkdir $APP_HOME\nWORKDIR $APP_HOME\n```\n\nPostgreSQL の Dockerfile (postgres/Dockerfile) は次の通り\n\n```dockerfile\nFROM postgres:10.5\nMAINTAINER MokkeMeguru <meguru.mokke@gmail.com>\n```\n\ndocker-compose.yml は次の通り\n\n```yaml\nversion: \"3\"\nservices:\n  dev_db:\n    build: containers/postgres\n    ports:\n      - 5566:5432\n    volumes:\n      - \"dev_db_volume:/var/lib/postgresql/data\"\n    environment:\n      POSTGRES_USER: meguru\n      POSTGERS_PASSWORD: emacs\n      POSTGRES_INITDB_ARGS: \"--encoding=UTF-8\"\n      POSTGRES_DB: pic_gallery\n    restart: always\n  repl:\n    build: containers/api-server\n    command: /bin/bash\n    ports:\n      - 3000:3000\n      - 39998:39998\n    volumes:\n      - \".:/app\"\n      - \"lib_data:/root/.m2\"\n    depends_on:\n      - dev_db\nvolumes:\n  dev_db_volume:\n  lib_data:\n```\n\ndev_db_volume、lib_data は docker-compose のデータ永続化の機能 (named volume) を用いるために記述されています。\n\n<a id=\"org6cb8f73\"></a>\n\n## Port の開放\n\ndocker-compose で走る Docker コンテナの内部と交信するために、 port の開放をすることができます。\n\n- `localhost:5566` で内部の DB へ接続するため、dev_db/ports に `5566:5432` を追加しています。\n\n- `localhost:3000` を通して API サーバとやり取りするために、 repl/ports に `3000:3000` を追加しています。\n\n- `localhost:39998` を通して repl コンテナ内の Clojure インタプリタへ接続するために、 repl/ports に `39998:39998` を追加しています。\n\n<a id=\"org95ee502\"></a>\n\n## Directory のマウント\n\n今回作るサーバ picture-gallery のソースコードをそのまま repl コンテナで読み込むために、repl/volumes に `.:/app` としてコンテナ内部の `/app` に picture-gallery フォルダをそのままマウントさせています。\n\n<a id=\"orgd1ac994\"></a>\n\n## 動作確認\n\n試しに動かしてみましょう。\n\n    # ビルド\n    $ docker-compose build\n    # 立ち上げ\n    $ docker-compose run --service-port repl bash\n    # REPL 環境の立ち上げ\n    root:@xxx:/app# lein repl\n    user=> (+ 1 2)\n    3\n    user=> exit\n    Bye for now!\n    # 環境から抜け出す (Ctrl-p Ctrl-q)\n    root:@xxx:/app#\n    $\n\nちなみに、今回は `Ctrl-p Ctrl-q` で Docker コンテナから抜け出しましたが、これに復帰するには、 `docker ps` コマンドで実行していた CONTAINER ID (e.g. `5b6d5b45e8aa`) を確認し、\n\n    $ docker exec -it 5b6d5b45e8aa bash\n\nとします。\n\n管理のために、 Docker コンテナ内で tmux や byobu といったツールを利用すると良いでしょう。 [5.2](#org7e49fac)\n\n<a id=\"org8682b00\"></a>\n\n# ライブラリの追加\n\nいよいよ具体的な API サーバ開発を進めていくわけですが、それに伴っていくつかのライブラリを追加する必要性があります。 Rails や Spring といったより便利なフレームワークを用いたサーバ開発ではこの工程は不要ですが、ライブラリ選定を自分で行うことで、 **よくわからないけど動く** を減らすことができます。 (本ガイドでは以下に紹介するライブラリを用いましたが、勿論別のライブラリで代替することが可能です。)\n\n<details><summary>追加するライブラリ一覧</summary><div> 簡単のため、追加するライブラリの詳細については省き、一覧と捕捉のみ紹介します。 これらのライブラリの追加は、Clojure x ClojureScript で深める Web 開発 (1) で紹介される `project.clj` に追加されています。\n\n```clojure\n;; integrant\n[integrant \"0.8.0\"]\n[integrant/repl \"0.3.2\"]\n\n;; firebase auth のためのライブラリ\n[com.google.firebase/firebase-admin \"7.1.0\"]\n\n;; ルーティング、HTTP ハンドラ のためのライブラリ\n[ring/ring-jetty-adapter \"1.9.1\"]\n[metosin/reitit \"0.5.12\"]\n[metosin/reitit-swagger \"0.5.12\"]\n[metosin/reitit-swagger-ui \"0.5.12\"]\n\n[ring-cors \"0.1.13\"]\n[ring-logger \"1.0.1\"]\n[com.fasterxml.jackson.core/jackson-core \"2.12.2\"]\n\n;; 暗号化通信のためのライブラリ\n[buddy/buddy-hashers \"1.7.0\" ]\n\n;; 環境変数の読み込みのためのライブラリ\n[environ \"1.2.0\"]\n\n;; ロギング処理のためのライブラリ\n[com.taoensso/timbre \"5.1.2\"]\n[com.fzakaria/slf4j-timbre \"0.3.20\"]\n\n;; データベースとの通信を行うためのライブラリ\n[honeysql \"1.0.461\"]\n[seancorfield/next.jdbc \"1.1.643\"]\n[hikari-cp \"2.13.0\"]\n[org.postgresql/postgresql \"42.2.19\"]\n[net.ttddyy/datasource-proxy \"1.7\"]\n\n;; マイグレーションを行うためのライブラリ\n[ragtime \"0.8.1\"]\n\n;; テスト、 Spec のためのライブラリ\n[orchestra \"2021.01.01-1\"]\n[org.clojure/test.check \"1.1.0\"]\n\n;; CLI コマンドの実行のためのライブラリ\n[org.clojure/tools.cli \"1.0.206\"]\n\n;; JSON 処理、時刻処理、文字列処理のためのライブラリ\n[clj-time \"0.15.2\"]\n[cheshire \"5.10.0\"]\n[camel-snake-kebab \"0.4.2\"]\n```\n\n</div></details>\n\nなお、注意する点として、ライブラリを追加したら、 **REPL は再起動が必要です** 。 `exit` から `lein repl` で再接続して下さい。\n\n<a id=\"orgb6ff216\"></a>\n\n# エディタとの接続\n\nここまでで、Docker コンテナ内で REPL が立ち上がりました。\n\nREPL は各エディタと連携することでより開発を快適にすることができます。 具体的には、コードを書いたところから環境に反映して動かすことができるようになります。\n\nClojure の REPL と連携できるエディタは Emacs、Vim、VSCode、InteliJ などありますが、今回は多くの人が使っているという理由で VSCode での使い方を紹介します。\n\nまず `project.clj` に以下の設定を追加します。\n\n```clojure\n:repl-options\n{:host \"0.0.0.0\"\n :port 39998}\n```\n\nこれで REPL が開いているポートが、 39998 に固定されます。 先程 docker-compose で port 39998 を開放しているので、 Docker コンテナの外部から REPL のポートへ接続できるようになります。\n\n1.  `lein repl` を Docker コンテナ内で実行します。\n\n2.  VSCode に拡張機能 Calva をインストールします。\n\n3.  左下のボタン nREPL → connect to a running server in your project → Leiningen → localhost:39998\n\n4.  output.calva-repl という画面が出て来ます。\n\n        clj::user=>\n        (+ 1 1) ;; (ここで ctrl+enter で評価)\n        2\n        clj::user=>\n\n    VSCode 上で、 Docker コンテナ内の REPL へ接続することができました。\n\nなお、Calva そのものの詳細な使い方は、 <https://calva.io/> を参考にして下さい。\n\n<a id=\"orgf8a114b\"></a>\n\n# integrant のセットアップ\n\n> integrant (<https://github.com/weavejester/integrant>) は Data-Driven Architecture で アプリケーションを構築するための Clojure および ClojureScript のマイクロフレームワークです。\n\nintegrant で重要となるファイルに、 システムの内部構成を記述したものである、config があります。\n\n例えば、次のようなサーバの例を考えます。 登場人物は、環境変数、データベースのコネクションプール、そしてサーバです。 それぞれには依存関係があり、例えば、\n\n- データベースのコネクションプールには環境変数から得られるアドレスが必要となり、\n- サーバには環境変数と DB のコネクションプールの両方が必要になります。\n\nこれを、integrant の config 、 `config.edn` を用いて記述すると次のようになります。\n\n```clojure\n;; config.edn\n{:env {}\n :db-connector {:ref-env #ig/ref :env}\n :server {:ref-port 3000\n          :ref-env #ig/ref :env\n          :ref-db-connector #ig/ref :db-connector}}\n```\n\n環境変数 `:env` に対しては、特に必要要素がないので空辞書 `{}` が与えられています。 コネクションプール `:db-connector` に対しては、環境変数が必要となるので `:ref-env` として先に宣言した `:env` を `{:ref-env #ig/ref :env}` として追加します。\n\nこの静的なシステム構成ファイルはプログラムコードとは独立であり、 **設計と実装を分離** することができます。\n\nさらに、例えばサーバの起動が不要な CLI コマンドを書く際に、 `:server` を省いた config を別に作ることで、 `:db-connector` をはじめとする他の実装をそのまま再利用することもできます。 この仕組みは Clean Architecture の他要素を変えずに UI や DB を置き換えられる、という考え方と合致しています。\n\n開発時には、コード編集後に config を再読込みすることで、全体のシステムをアップデートすることができます。\n\n以降では、integrant に慣れる、ということで 環境変数を読み込むというコンポーネントを作っていきます。\n\n<a id=\"org7be26ff\"></a>\n\n## integrant と REPL\n\nintegrant を使うためには、 config を書き、読み込む機構を書く必要があります。 さらに、 REPL 開発と組み合わせるための機構も書いておくと便利です。 幸い、この部分は非常にシンプルに書くことができるので、ここですべて紹介します。\n\n最初に integrant の config を作ります。 まだ何も作っていないので何も要素がありません。\n\n```clojure\n;; resources/config.edn\n{}\n```\n\n次に config を読み込むためのコードを作ります。\n\nまずはコマンドで実行する用。 コマンド `lein run` によって 関数 `-main` が実行され、サーバが立ち上がります。\n\n```clojure\n(ns picture-gallery.core\n  (:gen-class)\n  (:require [environ.core :refer [env]]\n            [taoensso.timbre :as timbre]\n            [clojure.java.io :as io]\n            [integrant.core :as ig]))\n\n(def config-file\n  (if-let [config-file (env :config-file)]\n    config-file\n    \"config.edn\"))\n\n(defn load-config [config]\n  (-> config\n      io/resource\n      slurp\n      ig/read-string\n      (doto\n       ig/load-namespaces)))\n\n(defn -main\n  [& args]\n  (-> config-file\n      load-config\n      ig/init))\n```\n\n次に REPL で実行する用。 REPL を起動して、 `(start)` で実行、 `(restart)` で再読込して実行、 `(stop)` で停止します。\n\n```clojure\n(ns user)\n\n(defn dev\n  \"Load and switch to the 'dev' namespace\"\n  []\n  (require 'dev)\n  (in-ns 'dev)\n  (println \":switch to the develop namespace\")\n  :loaded)\n```\n\n```clojure\n(ns dev\n  (:require\n   [picture-gallery.core :as pg-core]\n   [integrant.repl :as igr]))\n\n(defn start\n  ([]\n   (start pg-core/config-file))\n  ([config-file]\n   (igr/set-prep! (constantly (pg-core/load-config config-file)))\n   (igr/prep)\n   (igr/init)))\n\n(defn stop []\n  (igr/halt))\n\n(defn restart []\n  (igr/reset-all))\n```\n\n試しに REPL で実行してみましょう。\n\n    user> (dev)\n    :switch to the develop namespace\n    ;; => :loaded\n    dev> (start)\n    ;; => :initiated\n    dev> (restart)\n    :reloading ()\n    ;; => :resumed\n    dev> (stop)\n    ;; => :halted\n    dev> (in-ns 'user)\n    ;; => #namespace[user]\n    user>\n\n<a id=\"org3b98e3e\"></a>\n\n## 環境変数を読み込む\n\n環境変数を読み込むための機構を作ります。\n\nまずはコード。 具体的には、環境変数を読み込むライブラリ `environ` を用いて環境変数を読み込み、それを辞書として返す、ということを行っています。\n\nこの部分は入力になるので、 `infrastructure` に含められます。\n\n```clojure\n(ns picture-gallery.infrastructure.env\n  (:require [environ.core :refer [env]]\n            [integrant.core :as ig]\n            [orchestra.spec.test :as st]))\n\n(defn decode-log-level [str-log-level]\n  (condp = str-log-level\n    \"trace\" :trace\n    \"debug\" :debug\n    \"info\" :info\n    \"warn\" :warn\n    \"error\" :error\n    \"fatal\" :fatal\n    \"report\" :report\n    :info))\n\n;; (start) で実行される部分\n(defmethod ig/init-key ::env [_ _]\n  (println \"loading environment via environ\")\n  (let [running (env :env)\n    log-level (decode-log-level (env :log-level))]\n    (println \"running in \" running)\n    (println \"log-level \" log-level)\n    (when (.contains [\"test\" \"dev\"] running)\n      (println \"orchestra instrument is active\")\n      (st/instrument))\n    {:running running\n     :log-level log-level}))\n\n;; (stop) で実行される部分\n(defmethod ig/halt-key! ::env [_ _]\n  nil)\n```\n\n次に config の更新。\n\n```clojure\n;; resources/config.edn\n{:picture-gallery.infrastructure.env/env {}}\n```\n\n実際に動かしてみましょう。\n\n    user> (dev)\n    :switch to the develop namespace\n    ;; => :loaded\n    dev> (start)\n    loading environment via environ\n    running in  nil\n    log-level  :info\n    ;; => :initiated\n    dev>\n\nなんの環境変数も設定していないので、nil ばかり返ってきますね。\n\n環境変数の設定を書いてみましょう。\n\n環境変数は、1. `export` コマンドを使って宣言する 2. `profiles.clj` に記述する の手段を用いることができますが、今回は 2. を用います。\n\nまず、 `project.clj` の profiles を次のように編集し、plugin を追加します。\n\n```clojure\n;; project.clj\n{;;...\n :plugins\n [;; 開発のためのプラグイン\n  [lein-ancient \"0.6.15\"]\n  ;; test coverage\n  [lein-cloverage \"1.2.2\"]\n  ;; environ in leiningen (leiningen と environ を組み合わせるために必要な plugin)\n  [lein-environ \"1.1.0\"]]\n\n :profiles\n  {:dev [:project/dev :profiles/dev]\n   :repl {:prep-tasks ^:replace [\"javac\" \"compile\"]\n          :repl-options {:init-ns user}}\n   :project/dev {:source-paths [\"dev/src\"]\n                 :resource-paths [\"dev/resources\"]}\n   :profiles/dev {}\n   :uberjar {:aot :all\n             :jvm-opts [\"-Dclojure.compiler.direct-linking=true\"]}\n   }\n```\n\n次に、 `profiles.clj` を用いて、 profiles/dev を上書きします。\n\n```clojure\n;; profiles.clj\n{:profiles/dev\n {:env\n  {:env \"dev\"\n   :log-level \"info\"}}}\n```\n\nこれで準備は完了です。 REPL で実行してみましょう。 **環境変数を更新したので、REPL を立ち上げ直して下さい。**\n\n    user=> (dev)\n    :switch to dev\n    :loaded\n    dev=> (start)\n    loading environment via environ\n    running in  dev\n    log-level  :info\n    orchestra instrument is active\n    :initiated\n    dev=> exit\n    Bye for now!\n\n次に、 `lein run` を用いて実行してみましょう。 with-profile で **dev** profile を指定します。\n\n    # せっかくなので、 log-level を変えてみます。\n    $ export LOG_LEVEL=error\n    $ lein with-profile dev run\n    Warning: environ value info for key :log-level has been overwritten with error\n    loading environment via environ\n    running in  dev\n    log-level  :error\n    orchestra instrument is active\n\n<a id=\"org838c828\"></a>\n\n## 環境変数を読み込む CLI の作成\n\n今までは REPL ないしサーバ本体の実行コードで環境変数の読み込みができるようになっていました。 しかし、実用上、サーバ本体の実行コードではなく別の CLI コマンドで機能を実行したいケースが出てくると思います。\n\n別の CLI コマンドで実行できるようにするためのコードを書くには、次の手順が必要です。\n\n1.  該当の config を記述する\n\n    ```clojure\n       ;; resources/cmd/print_env/config.edn\n       {:picture-gallery.infrastructure.env/env {}}\n    ```\n\n    1.  該当の config を読み込んで動かすロジックを書く\n\n        ```clojure\n        ;; src/picture_gallery/cmd/print_env/core.clj\n        (ns picture-gallery.cmd.print-env.core\n          (:gen-class)\n          (:require\n           [picture-gallery.core :as pg-core]\n           [integrant.core :as ig]))\n\n        (defn -main\n          [& args]\n          (let [config-file  \"cmd/print_env/config.edn\"]\n            (println \"print environment variables\")\n            (-> config-file\n                pg-core/load-config\n                ig/init)))\n        (-main)\n        ```\n\n2.  実行スクリプトを書く\n\n    ```sh\n    # scripts/print_env.sh\n    #!/usr/bin/env bash\n\n    lein with-profile dev run -m picture-gallery.cmd.print-env.core/-main\n    ```\n\n以上です。 実際に動かしてみましょう。\n\n    $ chmod +x ./scripts/print_env.sh\n    $ ./scripts/print_env.sh\n    print environment variables\n    loading environment via environ\n    running in  dev\n    log-level  :info\n    orchestra instrument is active\n\n動いていることが確認できますね。\n\n<a id=\"org4f91800\"></a>\n\n# 付録\n\n<a id=\"org630f578\"></a>\n\n## ここまでのディレクトリの確認\n\nここまででできたディレクトリ構造を再確認します。 `src/picture_gallery` 以下が Clean Architecture を踏襲したソースコード部分です。\n\n    .\n    ├── CHANGELOG.md\n    ├── LICENSE\n    ├── README.md\n    ├── containers           (Dockerize に利用しました)\n    │   ├── api-server\n    │   │   └── Dockerfile\n    │   └── postgres\n    │       └── Dockerfile\n    ├── dev\n    │   ├── resources\n    │   └── src              (integrant と REPL を組み合わせるために利用しました)\n    │       ├── dev.clj\n    │       └── user.clj\n    ├── doc\n    ├── docker-compose.yml   (Dockerize に利用しました)\n    ├── profiles.clj         (環境変数の設定に利用しました)\n    ├── project.clj          (ライブラリの追加/環境変数の設定に利用しました)\n    ├── resources\n    │   ├── cmd              (CLIのために利用しました)\n    │   │   └── print_env\n    │   │       └── config.edn\n    │   └── config.edn       (integrant の config に利用しました)\n    ├── scripts              (CLI のために利用しました)\n    │   └── print_env.sh\n    ├── src\n    │   └── picture_gallery\n    │       ├── cmd          (CLI のために利用しました)\n    │       │   └── print_env\n    │       │       └── core.clj\n    │       ├── core.clj     (integrant の実行のために利用しました)\n    │       ├── domain\n    │       ├── infrastructure\n    │       ├── interface\n    │       ├── usecase\n    │       └── utils\n    ├── target\n    └── test\n        └── picture_gallery\n\n<a id=\"org7e49fac\"></a>\n\n## Docker コンテナ内で tmux を走らせる フロー\n\n    $ docker exec -it 5b6d5b45e8aa bash\n    root@5b6d5b45e8aa:/app# apt update\n    root@5b6d5b45e8aa:/app# apt install tmux\n    root@5b6d5b45e8aa:/app# tmux\n    # (以下 tmux コンソール)\n    # (Ctrl-b $ より session 名を repl に変更)\n    # PATH の設定\n    root@5b6d5b45e8aa:/app# export $PATH=/usr/local/openjdk-11/bin:$PATH\n    root@5b6d5b45e8aa:/app# lein repl\n    user=> (dev)\n    dev=> (go)\n    :initialized\n    dev=>\n    # (Ctrl-b Ctrl-d より デタッチ)\n    [detached (from session repl)]\n    # (以降 コンテナ内のシェル)\n    # 環境から抜け出す (Ctrl-p Ctrl-q)\n    root:@xxx:/app#\n    $ docker exec -it 5b6d5b45e8aa bash\n    root:@xxx:/app# tmux a -t repl\n    # (repl session へ復帰)\n\n<a id=\"orga976470\"></a>\n\n## Emacs で Clojure 開発を行う Tips\n\nEmacs で Clojure 開発を行う際には Cider <https://github.com/clojure-emacs/cider> が有名であり、例えば Doom Emacs <https://github.com/hlissner/doom-emacs> と組み合わせて用いることができます。\n\nVim や Emacs を使ったことのある人であれば、 Doom Emacs を利用するほうが良いでしょう。\n\nEmacs で Docker コンテナ内の REPL と接続するには、 `M-x cider-connect` より `localhost:39998` で接続することができます。\n","user":"MeguruMokke","created_at":"2021-03-29T10:53:18+09:00","updated_at":"2021-03-29T11:41:41+09:00"},{"url":"https://qiita.com/shimac/items/557dd5e6b3071ba12f05","title":"FlaskのWSGIサーバーにWaitressを使い、スレッド数を変更する","body":"# 内容\nPythonの代表的なWebアプリケーションフレームワークであるFlaskには、組み込みのサーバーで稼働させることができます。\nただし、このサーバーは拡張性の点で本番用途には向かないため、本番用途に適したWSGI準拠のサーバーが必要になります。（Flaskのドキュメントに下記のように記載があります）\n\n[Flask > Deployment Options](https://flask.palletsprojects.com/en/1.1.x/deploying/)\n>While lightweight and easy to use, Flask’s built-in server is not suitable for production as it doesn’t scale well. Some of the options available for properly running Flask in production are documented here.\n\n上記で記載されているように、本番向けのWSGIサーバーには、GunicornやuWSGIなどがあります。\nこの記事では、Flaskのドキュメントで下記のように例として挙がっているWaitressを使う方法を紹介します。\nまた、Waitressのワーカースレッド数の変更方法も紹介します。\n\n[Flask > Run with a Production Server](https://flask.palletsprojects.com/en/1.1.x/tutorial/deploy/#run-with-a-production-server)\n>Instead, use a production WSGI server. For example, to use Waitress, first install it in the virtual environment:\n\n# Flask組み込みサーバー\n\nこのようにFlaskアプリを起動すると、組み込みサーバーで稼働することになります。\n\n```python:app.py\nfrom flask import Flask\n\napp = Flask(__name__)\n\n@app.route('/', methods=['GET'])\ndef hello_world():\n    return 'Hello, World!'\n\nif __name__ == '__main__':\n    app.run(port=8080)\n```\n\n起動時のログに、本番システムで使わないようにとメッセージが出ています。\n\n```sh:実行結果\n% python app.py\n * Serving Flask app \"app\" (lazy loading)\n * Environment: production\n   WARNING: This is a development server. Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n * Running on http://127.0.0.1:8080/ (Press CTRL+C to quit)\n```\n\n補足ですが、組み込みサーバーはデフォルトではシングルスレッドです。\napp.run()の引数に、threaded=Trueを入れると、複数スレッドで処理できるようです。*1\n\n\n# Waitressで稼働\nWaitressでFlaskアプリを稼働させるには下記のように、app.run()の代わりに、Watiressのserve()を使えばOKです。*2\n\n```python:app.py\nfrom flask import Flask\nfrom waitress import serve  # Waitressをインポート\n\napp = Flask(__name__)\n\n@app.route('/', methods=['GET'])\ndef hello_world():\n    return 'Hello, World!'\n\nif __name__ == '__main__':\n    serve(app, host='0.0.0.0', port=8080)  # FlaskアプリをWaitressで稼働させる\n```\n\nアプリを起動してみると、組み込みサーバーのメッセージが表示されなくなりました。\n\n```sh:実行結果\n% python app.py\nServing on http://0.0.0.0:8080\n```\n\n# Waitressのワーカースレッド数の変更方法\n\nWaitressでは、ワーカースレッドがタスクを処理します。デフォルトは4つです。\n\n[Waitress > Design](https://docs.pylonsproject.org/projects/waitress/en/stable/design.html?highlight=thread#design)\n>When a channel determines the client has sent at least one full valid HTTP request, it schedules a \"task\" with a \"thread dispatcher\". The thread dispatcher maintains a fixed pool of worker threads available to do client work (by default, 4 threads). \n\nVSCodeのデバッグモードでアプリを起動すると、スレッド数を見ることができます。下記のようにワーカースレッド（waitress-n）が4つあることがわかります。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100414/e39af77e-df64-9bc4-1360-f59ff3c37257.png)\n\nこのスレッド数は、serve()の引数に、threads=nを設定することで、変更することができます。\n\n[Waitress > waitress-serve](https://docs.pylonsproject.org/projects/waitress/en/stable/runner.html#runner)\n\n>--threads=INT\n    Number of threads used to process application logic, default is 4.\n\nスレッド数を10に変更してみます。\n\n```python:app.py抜粋\nif __name__ == '__main__':\n    serve(app, host='0.0.0.0', port=8080, threads=10)\n```\n\n下記のようにスレッド数が10になることが確認できました。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/100414/2f8eb90f-0473-dacf-cf3c-7544466fcc1c.png)\n\n\n# 参考文献\n本記事では、下記の文献を参考にいたしました。\n- *1 [Flaskのデフォルトでは同時アクセスを処理できない](https://qiita.com/5zm/items/251be97d2800bf67b1c6)\n- *2 [Waitress > Usage](https://docs.pylonsproject.org/projects/waitress/en/stable/usage.html)\n","user":"shimac","created_at":"2021-03-29T10:53:10+09:00","updated_at":"2021-03-29T10:53:10+09:00"},{"url":"https://qiita.com/MeguruMokke/items/af003d5a665095c0f3c8","title":"Clojure x ClojureScript で深める Web 開発 (1) Duct x Clean Architecture","body":"# Git Repo\nソースコードと原文が入ったレポジトリ\nhttps://github.com/MokkeMeguru/clj-web-dev-ja/tree/main/chap1\n\n## シリーズ\n- [Clojure x ClojureScript で深める Web 開発 (0)](https://qiita.com/MeguruMokke/items/c6e059f109122be5f991)\n- [Clojure x ClojureScript で深める Web 開発 (1) Duct x Clean Architecture](https://qiita.com/MeguruMokke/items/af003d5a665095c0f3c8)\n- [Clojure x ClojureScript で深める Web 開発 (2) 環境の構築](https://qiita.com/MeguruMokke/items/9fe8e11a134e4c4dee2b)\n- [Clojure x ClojureScript で深める Web 開発 (3) API 作成入門](https://qiita.com/MeguruMokke/items/0ff941bcad6c86618b3d)\n- [Clojure x ClojureScript で深める Web 開発 (4) Auth](https://qiita.com/MeguruMokke/items/5ccf00bd2831551309d5)\n- [Clojure x ClojureScript で深める Web 開発 (5) API 開発 トランザクション添え](https://qiita.com/MeguruMokke/items/258c04caacdf66f706a2)\n- [Clojure x ClojureScript で深める Web 開発 (6) クライアントサイドと re-frame](https://qiita.com/MeguruMokke/items/78ff972bbd4efe3e1398)\n\n# 本編\n- [Integrant](#org1029249)\n- [Clean Architecture と Directory Structure](#org110c25e)\n  - [Clean Architecture](#org4a0d91b)\n    - [依存関係を意識したサービス開発の例](#orge9856fe)\n  - [Clean Architecture のために Directory Structure を考える](#orge1b3e1e)\n- [余談: threading Macro と エラーハンドリング](#org80c02cb)\n  - [Threading Macro](#orge18f9af)\n  - [エラーハンドリング](#orgd789f8c)\n\n本稿は、Clojure における アプリ開発フレームワーク integrant をベースとして Clean Architecture を採用した API サーバ開発の基礎を紹介します。\n\n<a id=\"org1029249\"></a>\n\n# Integrant\n\n> integrant (<https://github.com/weavejester/integrant>) は Data-Driven Architecture で アプリケーションを構築するための Clojure および ClojureScript のマイクロフレームワークです。\n\nIntegrant (<https://github.com/weavejester/integrant>) は Clojure (ClojureScript) のアプリ開発のためのフレームワークです。\n\n類似する他言語で有名なフレームワークというと、Rails や Django あたりになるのかな、という気持ちもありますが、 Integrant はそれに比べると \\***\\*非常に薄い\\*\\*** フレームワークです。\n\nIntegrant が提供してくれるのは、REPL 開発の支援のみで、より具体的には、 0. システム構成の読み込み 1. アプリの立ち上げ 2. 動的なアプリの更新 3. アプリの停止 が主になります。 HTTP ハンドラやルーティング、ORM などの親切かつ **魔法のような** 機能は提供していません。\n\nIntegrant はフレームワークといえどもファイル構造に一切口出ししないため、プロジェクトの立ち上げから初期ディレクトリ構造の決定がややコストになります。 (逆に言えば、ディレクトリ構造を純粋な Clean Architecture ないし別のアーキテクチャにすることができます)\n\n```shell\n# picture-gallery は本ガイドで作るアプリ名\nlein new app picture-gallery\ncd picture-gallery\n```\n\n以上の shell コードにより、プロジェクト picture-gallery が生成されます。\n\n余談ですが、Integrant を更に Web サーバ開発向けにしたフレームワーク Duct というものが、 Clojure を書いている人々からは人気があります。 Duct は非常に薄いフレームワークながら、ルーティングや DB とのやり取りまで面倒を見てくれる非常に便利なフレームワークなので、まず何かを作ってみたいという方は Clojure の Duct で Web API 開発してみた (<https://qiita.com/lagenorhynque/items/57d5aa086c4a080a1c54>) を参考にすることをおすすめします。\n\n※今回 Duct を用いていない理由は、Duct の詳細な実装を理解・説明するのが困難であること、 Integrant を活用する場面が多いことを挙げることができます。\n\n<a id=\"org110c25e\"></a>\n\n# Clean Architecture と Directory Structure\n\n先の章で picture-gallery という API サーバの骨子を初期化しました。 現在のディレクトリ構造は次のようになっています。\n\n    picture_gallery\n    ├── CHANGELOG.md\n    ├── LICENSE\n    ├── README.md\n    ├── doc\n    │   └── intro.md\n    ├── project.clj\n    ├── resources\n    ├── src\n    │   └── picture_gallery\n    │       └── core.clj\n    └── test\n        └── picture_gallery\n            └── core_test.clj\n\nここから例えば API のハンドラを生やしたり、 DB への接続コードを書いたり、Swagger との連携を考えたりすると、どうファイルを作っていけばよいのか指針がよくわからないことになります。\n\n今回はここに Clean Architecture という概念を導入して開発を進めていきます。\n\n<a id=\"org4a0d91b\"></a>\n\n## Clean Architecture\n\nClean Architecture とは、アプリケーション内の モデル、ロジック、UI、DB といった要素を切り分け、上下関係を作った上で、依存関係を一方向に矯正するアーキテクチャです。\n\n![img](https://raw.githubusercontent.com/MokkeMeguru/clj-web-dev-ja/main/chap1/CleanArchitecture.jpg)\n\n上図において、中央がコアであり、外側は内側の要素に依存しています。(逆に言えば、内側は外側の実装に左右されません。)\n\n本アーキテクチャの利点はいくつかあり、例えば\n\n- 要素ごとに独立したテストができる\n\n  例えばロジック (Use Cases) 部分はテスト用の DB を用意せずともテストできる\n\n- UI や DB を特定させる必要がない\n\n  例えば API サーバから CLI のアプリに置換する際に、ロジック (Use Cases) や DB 部分のコードをいじる必要がない。同様に、DB の接続先を PostgreSQL から MySQL や MongoDB に変えるとして、ロジック (Use Cases) 部分や UI 部分のコードをいじる必要がない。\n\nといったものを挙げることができます。\n\n参考: Clean Architecture で API Server を構築してみる(<https://qiita.com/hirotakan/items/698c1f5773a3cca6193e>)\n\n<a id=\"orge9856fe\"></a>\n\n### 依存関係を意識したサービス開発の例\n\n前章で、Clean Architecture は要素分割をして依存関係を特定の方向に矯正することが特徴であることを紹介しました。 とはいえ概念のみでは理解しづらいので、画像投稿の簡単な例を紹介します。\n\nまず、登場人物を整理します。\n\n- Entities\n\n  画像投稿を行う際のデータの仕様です。\n\n      ID:           uuid\n      ユーザID:      投稿したユーザの ID\n      Title:        タイトル (1 ~ 255 文字)\n      Description： 詳細情報 (0 ~ 1023 文字)\n      Image:        画像\n      Thumbnail:    サムネイル画像\n\n- Use Cases\n\n     画像投稿をする という機能を実現するためのロジックです。\n\n- Controllers、Gateways、Presenters (Interfaces)\n\n    データ加工、SQL の実行を行います。例えば API でやり取りするための JSON encode / decode は、この部分に入ります。\n\n- Web、 UI、Devices、DB、External Interfaces (Infrastructure)\n\n    ルーティングや、DB への接続を行います。\n\n<a id=\"orge1b3e1e\"></a>\n\n## Clean Architecture のために Directory Structure を考える\n\nClean Architecture は要素ごとに分割、という点が重要なので、ディレクトリ構造から要素分割を行う必要があります。 いくつかパターンはありますが、近年では golang を用いて Clean Architecture をベースにしたサーバ開発が行われている (あるいはそれに関する知見が多く紹介されている) ことから、特に Clean Architecture で API Server を構築してみる (<https://qiita.com/hirotakan/items/698c1f5773a3cca6193e>) を参考に次のようなディレクトリ構造を適用します。\n\nなお、他様々なパターンがあるので、自分の書きやすい形に応用して下さい。\n\n    picture_gallery/dev\n    |-- resources                   (開発用の素材)\n    `-- src                         (開発だけに使うコード)\n        `-- user.clj\n\n\n    picture_gallery/src\n    `-- picture_gallery\n        |-- core.clj                (エントリポイント)\n        |-- cmd                     (パッチなどの CLI コマンド用)\n        |-- domain                  (Entities)\n        |-- infrastructure\n        |   |-- env.clj             (環境変数の読み込み)\n        |   |-- firebase            (firebase との接続)\n        |   |-- image_db            (画像保存 DB との接続)\n        |   |-- router              (API ルーティング)\n        |   |-- server.clj          (サーバの起動 / 終了、ポート設定など)\n        |   `-- sql                 (DB との接続、マイグレーション)\n        |-- interface\n        |   |-- controller\n        |   |   `-- api             (入力 json へのデシリアライズ)\n        |   |-- gateway\n        |   |   |-- database        (DB に対する クエリ実行)\n        |   |   |-- image_db        (画像 に対する クエリ実行)\n        |   |   `-- auth            (認証処理 (firebase を用いる))\n        |   `-- presenter\n        |       `-- api             (出力 json へのシリアライズ)\n        |-- usecase\n        `-- utils\n            `-- error.clj           (後述するエラーハンドリングのためのコード)\n\ndev フォルダを利用するために、 `project.clj` を次のように修正します。\n\n```clojure\n(defproject picture-gallery \"0.1.0-SNAPSHOT\"\n  :description \"FIXME: write description\"\n  :url \"http://example.com/FIXME\"\n  ;; :license {:name \"EPL-2.0 OR GPL-2.0-or-later WITH Classpath-exception-2.0\"\n  ;;           :url \"https://www.eclipse.org/legal/epl-2.0/\"}\n  :dependencies [[org.clojure/clojure \"1.10.1\"]]\n  :resource-paths [\"resources\" \"target/resources\"]\n\n  :main ^:skip-aot picture-gallery.core\n  :target-path \"target/%s\"\n  :profiles\n  {:dev [:project/dev]\n   :repl {:prep-tasks ^:replace [\"javac\" \"compile\"]\n          :repl-options {:init-ns user}}\n   :project/dev {:source-paths [\"dev/src\"]\n                 :resource-paths [\"dev/resources\"]}\n   :uberjar {:aot :all\n             :jvm-opts [\"-Dclojure.compiler.direct-linking=true\"]}})\n```\n\n(このあたりのコードはかなり Duct の構造を意識しています)\n\n<a id=\"org80c02cb\"></a>\n\n# 余談: threading Macro と エラーハンドリング\n\n<a id=\"orge18f9af\"></a>\n\n## Threading Macro\n\nClojure には便利なマクロとして threading macro があります。一般的な Lisp 構文では、データ x に対して関数 A -> 関数 B -> 関数 C と適用する際に `(C (B (A x)))` と記述します。これは処理の流れとして\n\n```clojure\n(C (B (A x)))\n(C (B y)) ;; y = (A x)\n(C z)     ;; z = (B y) = (B (A x))\n```\n\nとなるため、内側の括弧から順番に処理されるという考え方を持てば自然なことと言えます。 しかしながら、 x を A -> B -> C と適用するならば、視認性を高めるためにも A, B, C と書いていきたいものがあります。\n\nClojure では threading macro がこの要望を答えるものとしてあります。先程の例ですと、\n\n```clojure\n(C (B (A x)))\n;; is equivalent with\n(-> x A B C)\n```\n\nと threading macro `->` を用いて書くことができます。\n\nここで画像投稿の API サーバ側の処理を考えてみると、\n\n1.  データを受け取る\n2.  データのデシリアライズ\n3.  ユーザの認証\n4.  画像のチェック\n5.  画像の加工\n6.  画像の保存\n7.  DB へ投稿情報の保存\n8.  レスポンスの生成\n9.  レスポンスのシリアライズ\n10. レスポンスの返却\n\nという処理の流れを想定することができます。これを Clojure の threading macro を使って書くと、\n\n```clojure\n(-> data\n    receive-data\n    json->image-topic\n    check-user\n    check-image\n    process-image\n    insert-image\n    insert-image-topic\n    ->image-topic-response\n    image-topic-response->json\n    reply-data)\n```\n\nという形に書くことができます。\n\n<a id=\"orgd789f8c\"></a>\n\n## エラーハンドリング\n\nthreading macro が可読性を高める手法であることを見ていただけられたところで、一つ、実務上の問題が発生します。 そう、エラーハンドリングです。\n\n各処理工程で何らかのエラーがあった際に、それ以降の処理をするのは非効率だと言えます。なので、例えば golang などでは `return` を用いて処理を打ち切る手法が多く取られます。 ところが Clojure では、 `if-else` はあっても途中で処理を切り上げる `return` を実現するのは難しいです。仮に `if-else` を用いて処理を記述すると、括弧を処理単位とする性質上、ネストが深くなってしまい、可読性を下げてしまいます。\n\nそのため、次のような関数とマクロ `bind-error` 、 `err->>` を用いることで、エラーハンドリングを行います。\n\n```clojure\n(defn bind-error [f [val err]]\n  (if (nil? err)\n    (f val)\n    [nil err]))\n\n(defmacro err->> [val & fns]\n  (let [fns (for [f fns] `(bind-error ~f))]\n    `(->> [~val nil]\n          ~@fns)))\n```\n\nやや複雑な関数のため詳細の説明は省略し、例を用いて使い方を説明すると次のような形になります。\n\n```clojure\n(defn start-with-H? [param]\n  (if (.startsWith (:call param) \"H\")\n    [param nil]\n    [nil \"is not start of H\"]))\n\n(defn end-with-!? [param]\n  (if (.endsWith (:call param) \"!\")\n    [param nil]\n    [nil \"is not end of !\"]))\n\n;; 実行例\n;; success\n(err->>\n  {:call \"Hello!\"}\n  start-with-H?\n  end-with-!?)\n;; -> [{:call \"Hello!\"} nil]\n\n;; failure 1\n(err->>\n  {:call \"hello\"}\n  start-with-H?\n  end-with-!?)\n;; -> [nil \"is not start of H\"]\n\n;;failure 2\n(err->>\n  {:call \"Hello\"}\n  start-with-H?\n  end-with-!?)\n;; -> [nil \"is not end of !\"]\n```\n\n重要なところは返り値が `[success-response failure-error-or-nil]` となっていることです。 2 番目の要素 `failure-error-or-nil` がエラーの判定とエラー内容を表しており、関数 `bind-error` によって、エラーがあれば以降の処理を実行しない機能が実現されています。\n","user":"MeguruMokke","created_at":"2021-03-29T10:48:35+09:00","updated_at":"2021-03-29T12:24:52+09:00"},{"url":"https://qiita.com/shinji0320/items/d753ef25b1908ccd8d2b","title":"mapとeachの違い","body":"#map\n配列の入った変数.map {|変数名| 処理内容 }\n\n\n```ruby\nfood = [\"fish\", \"beef\", \"banana\",\"potato\"]\nfood.map {|a| a.length}\n\n#元の配列の変更していない\n#戻り値は [4, 4, 6, 6]\n```\n\n#map!（破壊的メソッド）\n配列の入った変数.map！ {|変数名| 処理内容 }\n\n\n```ruby\nfood = [\"fish\", \"beef\", \"banana\",\"potato\"]\nfood.map {|a| a.length}\n\n#元の配列の変更している\n#戻り値は [4, 4, 6, 6]\n```\n\n#each(mapとの違い)\n\n```ruby\nfood = [\"fish\", \"beef\", \"banana\",\"potato\"]\nfood.map {|a| a.length}\n\n#戻り値がもとの配列を返す\n#戻り値は [\"fish\", \"beef\", \"banana\",\"potato\"]\n```\n","user":"shinji0320","created_at":"2021-03-29T10:43:37+09:00","updated_at":"2021-03-29T10:43:37+09:00"},{"url":"https://qiita.com/MeguruMokke/items/c6e059f109122be5f991","title":"Clojure x ClojureScript で深める Web 開発 (0)","body":"# Git Repo\nソースコードと原文が入ったレポジトリ\nhttps://github.com/MokkeMeguru/clj-web-dev-ja/tree/main/chap0\n\n## シリーズ\n- [Clojure x ClojureScript で深める Web 開発 (0)](https://qiita.com/MeguruMokke/items/c6e059f109122be5f991)\n- [Clojure x ClojureScript で深める Web 開発 (1) Duct x Clean Architecture](https://qiita.com/MeguruMokke/items/af003d5a665095c0f3c8)\n- [Clojure x ClojureScript で深める Web 開発 (2) 環境の構築](https://qiita.com/MeguruMokke/items/9fe8e11a134e4c4dee2b)\n- [Clojure x ClojureScript で深める Web 開発 (3) API 作成入門](https://qiita.com/MeguruMokke/items/0ff941bcad6c86618b3d)\n- [Clojure x ClojureScript で深める Web 開発 (4) Auth](https://qiita.com/MeguruMokke/items/5ccf00bd2831551309d5)\n- [Clojure x ClojureScript で深める Web 開発 (5) API 開発 トランザクション添え](https://qiita.com/MeguruMokke/items/258c04caacdf66f706a2)\n- [Clojure x ClojureScript で深める Web 開発 (6) クライアントサイドと re-frame](https://qiita.com/MeguruMokke/items/78ff972bbd4efe3e1398)\n\n\n# 本編\n- [Clojure という言語](#org450a730)\n  - [Clojure](#org318aff4)\n  - [ClojureScript](#org4c84515)\n  - [関数型言語と REPL 開発](#orge8ce012)\n- [Clojure Spec ~ データと型の仕様、契約プログラミング ~](#org8f89488)\n- [Clojure と テスト、 あと Mock](#orga87f5e8)\n  - [Mock の話](#org50a1b8c)\n\n本稿は、Clojure x ClojureScript 深める Web 開発 を読むにあたり、なんとなく知っておいてほしい事柄について紹介するものです。\n\n# 想定読者\n想定読者はいくつかのパターンに分かれています。\n\n1. Clojure で Web アプリ開発したい人\n   required: \n　　- Clojure で `lein run` したことがある\n\n\n1. Clean Architecture の <any> 言語での実装例を探したい\n   required:\n　　- Lisp 構文 (S式) への抵抗がないこと\n\n※ ~~いずれのケースでも、レポジトリのコードを読んだほうが早いと思います。~~\n\n<a id=\"org450a730\"></a>\n\n# Clojure という言語\n<a id=\"org318aff4\"></a>\n\n## Clojure\n\nClojure は Lisp と呼ばれるプログラミング言語の影響を強く受けた JVM 言語の一つです。JVM 言語の仲間としては、 Scala や Groovy があります。日本では Scala の方が有名かもしれません。\n\nもっぱら (Web) API 開発に用いられていますが、Java でできることは大体できます (e.g. ゲーム開発、深層学習、スタンドアロンアプリ開発)。\n\n構文の基本は、 `(関数 引数1 引数2 ...)` というもので、例えば 足し算 `1 + 2` であれば、 `(+ 1 2)` となります。 また関数の定義は、\n\n```clojure\n(defn 関数名 [引数1 引数2]\n  ;; 実行する内容\n  )\n```\n\nのようになります。基本的には括弧で括った処理単位の組み合わせ、といった感じになっていますが、詳しい構文は書いたり読んだりしながら慣れる方が早いです。\n\nClojure について、基礎的な部分を調べるに最も便利なサイトとしては、<https://clojuredocs.org/> を挙げることができます。 また不明点などは雑に Twitter で僕あたりに Reply / DM を投げるか、#Clojure で Tweet すると捕捉されます。\n\n<a id=\"org4c84515\"></a>\n\n## ClojureScript\n\nClojureScript は Clojure の構文を用いることのできる JavaScript 方言です。 JavaScript 方言としては、TypeScript の方が有名かもしれません。\n\nClojure / ClojureScript の利点は、サーバ、クライアントで同じ構文を用いて開発ができるという点、また、一部のコードを共通化 (同じコードをサーバ、クライアント両方で使える) という点です。\n\n```clojure\n;; clojure\n(defn add [x y] (+ x y))\n\n;; clojurescript\n(defn add [x y] (+ x y))\n```\n\n<a id=\"orge8ce012\"></a>\n\n## 関数型言語と REPL 開発\n\n関数型言語を簡単に説明すると、データを入れてデータを返す &ldquo;関数&rdquo; を基礎としたプログラミング言語です。 Clojure (Lisp) は関数型言語の中でもオブジェクト指向を組み合わせることのできる非純粋な関数型言語で、オブジェクト指向の利点を組み合わせたプログラムの記述ができます。\n\n例えば、足し算をする関数 Add を Java で書くと、次のようになります。\n\n```java\npublic class AddClass {\n  public static int add(int x, int y) { return x + y; }\n  public static void main(String[] args) {\n    int x = 1;\n    int y = 2;\n\n    int z = add(x, y);\n    System.out.printf(\"result is: %d\\n\", z);\n  }\n}\n```\n\n実行方法は、\n\n1.  javac AddClass.java (compile)\n2.  java AddClass (run) => result is 3\n\nという形になります。add 関数は AddClass クラスのクラスメソッドとして実装されていますね。\n\nClojure で書くとこんな感じ。\n\n```clojure\n(defn add [x y] (+ x y))\n\n(format \"result is: %d\" (add 1 2))\n;; => result is: 3\n```\n\n厳密ではないですが、 Python のように add 関数を記述して、実行する形になります。\n\n比較までに Python で同じことを書くと、\n\n```python\ndef add (x, y):\n    return x + y\n\nprint(\"result is: {}\".format(add(1, 2)))\n# => result is: 3\n```\n\nClojure では、コードを書いて評価しその結果を逐次確認する Read-Eval-Print Loop (REPL) という環境で開発を行うことが一般的であるのと同時に、製品時にはコードをコンパイルして実行できるという利点があります。 また、コードを書きながらデータを入力して期待する動作かどうかをチェックできるため、開発が比較的に容易であると言えます。\n\n対して、昨今の テストコードを先に全部記述して、機能開発を行い、コンパイル/テスト実行をする ~~ウォーターフォールのような~~ 開発手法 とは相性があんまり良くないかもしれないです。\n\n<a id=\"org8f89488\"></a>\n\n# Clojure Spec ~ データと型の仕様、契約プログラミング ~\n\nClojure では、Java のように型 (Class) を宣言するすることができますが、Spec や malli といった、データについての型を定義する仕組みを用いることが好まれています。\n\nSpec は、 **データや関数の仕様書** と言いかえることができます。\n\n簡単のために、車を例に Spec を考えてみます。\n\n車は次のような値を持っているとします。\n\n- クラクションの音 (e.g. &ldquo;Beep&rdquo;)\n- 重さ (e.g. 120)\n- 速さ (e.g. 50)\n\nまた車は次のようなことができるとします。\n\n- クラクションの音を鳴らす\n- n 時間走る\n\nこれらは **仕様** であるといえ、 Clojure ではこれを Spec を用いて次のように記述することができます。\n\n```clojure\n(require '[clojure.spec.alpha :as s])\n\n;; クラクションの音は string\n(s/def ::beep string?)\n\n;; 重さは 正の integer\n(s/def ::weight pos-int?)\n\n;; 速さは 正の integer\n(s/def ::speed pos-int?)\n\n;; 車は、クラクションの音、重さ、速さを値として持つ\n(s/def ::car (s/keys :req-un [::beep ::weight ::speed]))\n\n;; 車の音を鳴らす関数は、\n;; car の spec を満たす値を引数にとって、\n;; string を返す\n(s/fdef car-beep\n  :args (s/cat :car ::car)\n  :ret string?)\n\n;; 車を走らせる関数は、\n;; car の spec を満たす値と, integer 型の n を引数にとって、\n;; 走った距離 (n x speed) を返す\n(s/fdef car-run\n  :args (s/cat :car ::car :n (fn [n] (> n 0)))\n  :ret int?\n  :fn (fn [{:keys [args ret]}]\n        (= ret (* (-> args :n) (-> args :car :speed)))))\n```\n\nClojure ではこのようにデータ型を宣言することによって、値のバリデーションを行ったり、関数の実装の説明を行ったりします。 ここで、実際にこれらの仕様を満たすデータを宣言/関数を実装してみましょう。\n\n```clojure\n(def legal-car-example {:beep \"beep!!!\" :weight 120 :speed 50})\n\n;; これは 仕様を満たしていない\n(def illegal-car-example {:beep 123 :weight 120 :speed 50})\n\n(defn car-beep [car]\n  {:pre [(s/valid? ::car car)]\n   :post [(s/valid? string? %)]}\n  (format \"the car says: %s\" (:beep car)))\n\n(defn car-run [car n]\n  {:pre [(s/valid? ::car car) (> n 0)]\n   :post [(s/valid? int? %)]}\n  (* n (:speed car)))\n\n```\n\nなお、pre / post とかあるのは、契約プログラミングにおける 事前条件 / 事後条件を示しています。これは関数を実行する際に、それぞれの条件を満たしているかを毎回チェックする、というものです。 特に安全にコードを実行したい際に利用することができます。\n\n次に、実際に評価して / データを流して結果を見てみましょう。\n\n```clojure\n;; テスト時に spec を利用する際の設定\n(require '[orchestra.spec.test :as st])\n(st/instrument)\n\n;; OK な例\n(s/valid? ::car legal-car-example)\n(car-beep legal-car-example)\n(car-run legal-car-example 2)\n\n;; ダメ な例\n(s/valid? ::car illegal-car-example)\n(car-beep illegal-car-example)\n(car-run legal-car-example -1)\n\n;; 結果\n\n;; OK な例\n;; => true\n;; => \"the car says: beep!!!\"\n;; => 100\n\n;; ダメな例\n;; => false\n;; => class clojure.lang.ExceptionInfo ...\n;; => class clojure.lang.ExceptionInfo ...\n```\n\nとまあこんな形で仕様を満たすかどうかをチェックすることができます。\n\n具体的に開発する際には、REPL で逐次様々なデータを流しながら仕様を満たすコードを書いたり、playground のコードから仕様の記述/見直しを行ったり、更にはテストコードを書いたり修正したりすることができます。\n\n実際に ~~雑な~~ 開発を行っている際には、仕様の変更や仕様ミスがあることは当然のごとくありますし、手探りに開発をするケースもあると思います。その際には Clojure の REPL , Spec を用いた開発はかなり便利だという印象があります。\n\n参考: <https://clojure.org/guides/spec>\n\n<a id=\"org71c1c68\"></a>\n\n\n<a id=\"orga87f5e8\"></a>\n\n# Clojure と テスト、 あと Mock\n\n先程まで Spec を用いてデータや関数の仕様を書く方法を紹介してきましたが、やはりテストは書いておくに越したことはないです。\n\nClojure を用いてテストを書く最もシンプルな方法は、 `deftest` を利用するものです。\n\n試しに簡単な API ハンドラを書いてみましょう。\n\n```clojure\n(s/def ::first-name string?)\n(s/def ::last-name string?)\n(s/def ::full-name string?)\n\n(s/def ::params (s/keys :req-un [::first-name ::last-name]))\n(s/def ::status #{:success :failure})\n(s/def ::result (s/keys :req-un [::status] :opt-un [::full-name]))\n\n(s/fdef handler\n  :args (s/cat :params ::params)\n  :ret ::result)\n\n(defn handler [params]\n  (let [{:keys [first-name last-name]} params]\n    (if (= last-name \"Meguru\")\n      {:status :success :full-name (format \"%s %s\" first-name last-name)}\n      {:status :failure})))\n\n(handler {:first-name \"Mokke\" :last-name \"Meguru\"})\n;; => {:status :success :full-name \"Mokke Meguru\"}\n(handler {:first-name \"Sample\" :last-name \"User\"})\n;; => {:status :failure}\n```\n\nSpec を参考にテストを書くとすると、こんな感じになります。 (first-name, last-name が string であるのは **仕様として** 明らかです。)\n\n```clojure\n(require '[clojure.test :refer [deftest is testing run-tests]])\n\n(st/instrument)\n\n(deftest handler-test\n  (testing \"last name is Meguru\"\n    (let [params  {:first-name \"Mokke\" :last-name \"Meguru\"}\n          result (handler params)]\n      (is (= :success (:status result))) ;; status は success ?\n      (is (= \"Mokke Meguru\" (:full-name result))))) ;; full-name は Mokke Meguru ?\n  (testing \"last name is not Meguru\"\n    (let [params {:first-name \"Sample\" :last-name \"User\"}\n          result (handler params)]\n      (is (= :failure (:status result)))))) ;; status は failure ?\n\n;; テストの実行\n(run-tests)\n\n;; 実行結果\n;; {:test 1, :pass 3, :fail 0, :error 0, :type :summary}\n```\n\n<a id=\"org50a1b8c\"></a>\n\n## Mock の話\n\n上の handler の例は非常に簡単な単体テストですね。 しかし実際に開発していると DB との連携やら Firebase との通信やらの部分が副作用として関数に含まれてしまうことがあります。 そのようなケースに対応するには、 `with-redefs` を用いると良いでしょう。\n\n```clojure\n;; 仕様定義\n(s/def ::db any?)\n(s/def ::birthday pos-int?)\n(s/def ::raw-user-info (s/keys :req-un [::first-name ::last-name ::birthday]))\n(s/def ::user-info (s/keys :req-un [::full-name ::birthday]))\n(s/def ::result (s/keys :req-un [::status ::user-info]))\n\n(s/fdef get-user-info\n :args (s/cat :db ::db :first-name ::first-name :last-name ::last-name)\n :ret ::raw-user-info)\n\n(s/fdef complex-handler\n :args (s/cat :params ::params)\n :ret ::result)\n\n;; 実装\n;; DB へのコネクタ\n(def db nil)\n(defn get-user-info [db first-name last-name]\n ;; 何らかの SQL 処理\n)\n\n(defn complex-handler [params]\n  (let [{:keys [first-name last-name]} params\n        {:keys [firts-name last-name birthday]} (get-user-info db first-name last-name)\n        full-name (format \"%s %s\" first-name last-name)]\n   {:status :success\n    :user-info {:full-name full-name :birthday birthday}}))\n\n;; テスト\n(st/instrument)\n\n(deftest complex-handler-test\n ;; ここで Mock を定義\n (with-redefs [get-user-info (fn [db first-name last-name]\n                                 {:first-name first-name\n                                  :last-name last-name\n                                  :birthday 20210301})]\n  (testing \"complex-handler test with mock\"\n    (let [params {:first-name \"Mokke\" :last-name \"Meguru\"}\n          result (complex-handler params)]\n      (is (= :success (-> result :status)))\n      (is (= \"Mokke Meguru\" (-> result :user-info :full-name)))\n      (is (= 20210301 (-> result :user-info :birthday)))))))\n\n(run-tests)\n;; 結果\n;; {:test 2, :pass 6, :fail 0, :error 0, :type :summary}\n```\n\n参考: <https://clojuredocs.org/clojure.core/with-redefs>\n","user":"MeguruMokke","created_at":"2021-03-29T10:42:22+09:00","updated_at":"2021-03-29T12:04:52+09:00"},{"url":"https://qiita.com/rimorimo/items/8052bcfb32ac640a8796","title":"PythonでWebスクレイピングによりグローバルIPアドレスを調べる方法","body":"# 概要\n\n本記事ではPythonスクリプトを用いて，スクレイピングによりグローバルIPアドレスを調べる方法について記述する．プライベートIPアドレスの調べ方は下記の記事を参照されたし．\n\n[Macのターミナル上でプライベートIPアドレスを調べる方法](https://qiita.com/rimorimo/items/9ee259ffb492a073884a)\n\n# 簡単にプライベートIPアドレスを調べる方法 1\n\n下記のサイトにアクセスするだけで簡単に調べる事ができる．\n\n[あなたの情報（安全な確認くん）](https://kakunin.net/kun/)\n\n# 簡単にプライベートIPアドレスを調べる方法 2\n\n**curlコマンドでWebサイトから取得する**\n\n* inet-ip.info\n\n```bash\n$ curl inet-ip.info\nXXX.XXX.XXX.XXX\n```\n\n* ifconfig.me\n\n```bash\n$ curl -s ifconfig.me; echo;\nXXX.XXX.XXX.XXX\n```\n\n# WebスクレイピングによりグローバルIPアドレスを調べる調べる方法\n\n**システム環境**\nmacOS 10.11.6以降（他のOSでも可）\nPython 3.6.5以降\n\n**本記事ではディレクトリ操作をmacOSに合せて記述しているため，他のOS（Linux, Windows等）の使用時は必要に応じてディレクトリ構造を置き換えて考えるものとする．**\n\n**Pythonライブラリのインストール**\n\n```bash\n$ pip install requests\n$ pip install bs4\n$ pip install html5lib\n```\n\n**Pythonスクリプトとパッケージの作成**\n\n```bash\n$ mkdir ~/GlobalIPAddress\n$ touch ~/GlobalIPAddress/global_ip_addr.py\n$ mkdir ~/GlobalIPAddress/common\n$ touch ~/GlobalIPAddress/common/__init__.py #Python 3.3以降から不要\n$ touch ~/GlobalIPAddress/common/modules.py\n```\n\n**実行ファイル`global_ip_addr.py`のソースコード**\n\n```python:global_ip_addr.py\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nfrom common.modules import getHtml, getText\n\n\"\"\"\n安全な確認くんのURL\n取得した情報は検索エンジンに一切キャッシュさずSSLにより通信も暗号化される\n\"\"\"\nurl = 'https://kakunin.net/kun/'\n\n# getHtmlモジュールにより返されたURLのソースコード\nhtml = getHtml(url)\n\n# CSSセレクタの要素\nelement = 'p'\n\n# CSSセレクタの要素番号\nchild = 3\n\n# getTextモジュールに上記引数を渡しグローバルIPアドレスの文字列を取得\nip = getText(html, element, child)\n\n# 上記により得られた文字列を表示\nprint(ip)\n```\n\n**`__init__.py`はPython 3.3以降から不要**\n\n```python:__init__.py\n# ファイルの中身は何も記述しない\n```\n\n**モジュール`modules.py`のソースコード**\n\n```python:modules.py\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\nfrom requests import get\nfrom bs4 import BeautifulSoup\n\n# URLのソースコードを返すモジュール\ndef getHtml(url):\n\n    # URLのレスポンスコードを取得\n    res = get(url, timeout=3)\n\n    \"\"\"\n    URLのソースコードを取得\n    textの代わりにcontentでも可\n    \"\"\"\n    html = res.text\n\n    return html\n\nif __name__ == '__main__':\n    getHtml(url)\n\n# 文字列の改行コードを削除するモジュール\ndef remNline(arg):\n\n    \"\"\"\n    余分な改行コードを削除\n    replace('\\n', '')の代わりにstrip()でも可\n    \"\"\"\n    arg = arg.replace('\\n', '')\n    #arg = arg.strip()\n\n    return arg\n\nif __name__ == '__main__':\n    remNline(arg)\n\n\"\"\"\n取得したURLのソースコードをパースしCSSセレクタを用いて文字列を取得する関数\n引数html: URLのソースコード\n引数element: CSSセレクタの要素\n引数child: CSSセレクタの要素番号\n\"\"\"\ndef getText(html, element, child):\n\n    # パーサはhtml5libとする\n    soup = BeautifulSoup(html, 'html5lib')\n\n    # 要素と番号を指定し文字列（タグ込み）を取得\n    str = soup.select(element)[child]\n\n    # 文字列（タグ込み）からタグを除去\n    str = str.text\n\n    # 上記remNlineモジュールを用いて余分な改行コードを削除\n    str = remNline(str)\n\n    return str\n\nif __name__ == '__main__':\n    getText(html, element, child)\n```\n\n**`global_ip_addr.py `を実行**\n\n```bash\n$ python ~/GlobalIPAddress/global_ip_addr.py\nXXX.XXX.XXX.XXX\n```\n\n**無事にグローバルIPアドレスの取得に成功！**\n\n今回のような単純なシステムの場合，単一ファイルに全て記述しても差し支えないコード量だが重要な概念なのでしっかりモジュールやパッケージ化を意識して記述した．\n","user":"rimorimo","created_at":"2021-03-29T10:41:40+09:00","updated_at":"2021-03-29T12:39:38+09:00"},{"url":"https://qiita.com/zhikuanchuanshang725/items/9866d144d312db1c0df2","title":"CSSとは、記述の仕方など","body":"# CSSとは\nHTMLに装飾を加えるための言語です。\n\n# 例\n\n##### indexファイル\n\n<!DOCTYPE HTML>\n< html>\n  < head>\n    < meta charset=\"UTF-8\">\n    < title>HTML学習用ウェブサイト< /title>\n    < link rel=\"stylesheet\" href=\"style3-3.css\">\n  < /head>\n  < body>\n    < h1>\n      これは見出しです\n    < /h1>\n    < p>\n      １つ目の段落です\n    < /p>\n    < p class=\"second-message\">\n      2つ目の段落です\n    < /p>\n    < p>\n      3つ目の段落です。< b>この部分は太字になります。< /b>\n    < /p>\n     < a href=\"https://www.google.com/\">クリックすると、Googleへ移動します。</a>\n  < /body>\n< /html>\n\n##### cssファイル\n\np {\n  font-size: 24px;\n  color: red;\n}\n.second-message {\n  color: orange;\n  font-size: 12px;\n}\n\n- p{}は< p>〜< /p>の部分をp{}のようにすること\n- .second-messageはclass = \"second-message\"となっているところを.second-message{}のようにすること\n","user":"zhikuanchuanshang725","created_at":"2021-03-29T10:34:00+09:00","updated_at":"2021-03-29T11:49:36+09:00"},{"url":"https://qiita.com/nakanowatari-taiki/items/f59541ff19d32bb90407","title":"特定条件のみに呼応するプログラムの作成","body":"## 初めに\nrubyの練習問題を私なりの解説で解いてこうと思います。\n\n### 練習問題\n今日の曜日を表示するコードをDateクラスを使用して記述してください。\n\nただし、金曜日だった場合だけ以下のように表示の内容を変えてください。\n\n（出力内容）\n「今日は月曜日」\n「今日は金曜日だ ！！！」\n\nまずはDateクラスについてまとめてきます。\n### Dateクラス\nDateクラスとはrubyの標準ライブラリの1つです。標準ライブラリとはruby本体をインストールした時に自動でインストールされるクラスやモジュールのことです。\n### Dateクラスの読み込み\nDateクラスは日付や曜日を取得することができます。初めにDateクラスを使うにはためにはDateクラスを使用しますと宣言する必要があります。よって以下の文をコードの初めに書きDateクラスを使用することを宣言します。\n\n```\nrequire \"date\"\n```\n上記の記述によりDateクラスをライブラリから読み込みました。\n次に今日の曜日を取得します。\n曜日の取得は以下のような記述になります。\n\n```\nDate.today.wday\n```\nちなみにwdayは曜日を取得することができるDateクラスに用意されているメソッドです。曜日を整数の0（日曜日）から6(土曜日)まで取得します。\nしかしこのままでは使えないので上記の記述を変数dayに代入します。\n\n```\nday = Date.today.wday\n```\n上記の記述で曜日に合わせて整数を取得することができるようになりました。しかし整数だけで文字列がありません。よって配列daysを定義します。そしてその中に整数に合わせて曜日を格納します。\n\n```\ndays = [\"日曜日\", \"月曜日\", \"火曜日\", \"水曜日\", \"木曜日\", \"金曜日\", \"土曜日\"]\n```\nさて、ここまでで準備は完了です。\nあとはif文を使用して問題文のような出力内容になるように記述するだけです。\n\n###問題の解答\n今回は金曜日の場合のみ『今日は金曜日だ！！！』と出力します。まずはif文を使い金曜日の時に上記の内容が出力されるように記述します。\n\n```\nif day == 5\n  puts \"今日は#{days[day]}だ！！！\"\n```\nポイントとしては曜日は日曜日から順番で０から数えることです。私は１から数えてよく間違えました。\nあとは金曜日以外の記述をelseを使い記述します。\n\n```\nelse\n  puts \"今日は#{days[day]}\"\nend\n```\n### 解答全体のコード\n\n```\nrequire \"date\"\n\nday = Date.today.wday\ndays = [\"日曜日\", \"月曜日\", \"火曜日\", \"水曜日\", \"木曜日\", \"金曜日\", \"土曜日\"]\n\nif day == 5\n  puts \"今日は#{days[day]}だ！！！\"\nelse\n  puts \"今日は#{days[day]}\"\nend\n```\n以上です。\n初学者なのでもし間違いなどありましたご指摘お願いします。\n\n\n\n\n\n\n\n","user":"nakanowatari-taiki","created_at":"2021-03-29T10:29:02+09:00","updated_at":"2021-03-29T10:29:02+09:00"},{"url":"https://qiita.com/tomo-IR/items/74d1b4762fe62dc82766","title":"【docker】docker-compose build  したらERROR: Service 'web' failed to build : The command '/bin/sh -c bundle install' returned a non-zero code: 7","body":"railsアプリにローカル環境にdockerを導入していました。buildしようと、```docker-compose build```を実行したら、このようなエラーがでました。\n\n```terminal\nYour bundle is locked to mimemagic (0.3.5), but that version could not be found\nin any of the sources listed in your Gemfile. If you haven't changed sources,\nthat means the author of mimemagic (0.3.5) has removed it. You'll need to update\nyour bundle to a version other than mimemagic (0.3.5) that hasn't been removed\nin order to install.\nERROR: Service 'web' failed to build : The command '/bin/sh -c bundle install' returned a non-zero code: 7\n```\n\nどうも、mimemagicというgemが悪さしてそうで、調べてみると0.3.5はyanked（公開停止）されているようでした。\n\n# 対策\ngem mimemagicをアップデートする。\n\n```terminal\n$ bundle update mimemagic\n```\n\n\nちなみにDOCKERFILEはこのように書いていました。\n\n```dockerfile\nFROM ruby:2.6.6\n\nRUN apt-get update -qq && \\\n  apt-get install -y build-essential \\ \n  libpq-dev \\        \n  nodejs      \n\nRUN mkdir /app_name \n\nENV APP_ROOT /app_name \nWORKDIR $APP_ROOT\n\nADD ./Gemfile $APP_ROOT/Gemfile\nADD ./Gemfile.lock $APP_ROOT/Gemfile.lock\n\nRUN gem install bundler \nRUN bundle install\nADD . $APP_ROOT\n\n```\n\n\n# 参考\nhttps://masahiro.me/2021/03/your-bundle-is-locked-to-mimemagic-0-3-5-but-that-version-could-not-be-found/\n\nhttps://qiita.com/Wacci6/items/dc6ffec9b50578d44d6c\n","user":"tomo-IR","created_at":"2021-03-29T10:24:41+09:00","updated_at":"2021-03-29T10:24:41+09:00"},{"url":"https://qiita.com/yoshiyuki-iwata/items/fd8759c11dccfdf07a64","title":"【OpenRPA】初心者向け操作説明書～その３．変数～","body":"レコーディングの続きを書くつもりでしたが、変数の話をしていなかったのでそっちを先に。\n\n# はじめに\n\nプログラムでは常識のように「変数」という言葉が登場しますが、RPAでも使います。\n\n[出典: フリー百科事典『ウィキペディア（Wikipedia）』](https://ja.wikipedia.org/wiki/%E5%A4%89%E6%95%B0_(%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0))\n> プログラミングにおける変数（へんすう、英: variable）とは、高水準言語のプログラムのソースコードにおいて、扱うデータを読み書きする記憶域 (storage) のことであり、固有の名前（識別子）によって識別される[1]。変数を用いることで、データを一定期間記憶し必要なときに利用することができる。\n\n要は値の入る箱、のようなものです。\nRPAでも、計算結果を一時的に保存したり、文章を編集したりするのに使ったりします。\n\n# 変数の作り方\n\n変数を作るには、シーケンスを選択したあとに「変数」タブから作ります。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/dd8fdca9-18c5-d876-ac5a-d1a3d82dee19.png)\n\n変数タブの中の「変数を作成」をクリックします。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/7c0ed7ba-5622-2bff-77f7-ac62856b056a.png)\n\n「名前」「変数の型」「スコープ」「既定値」を指定します。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/69bc588d-2ce8-6ae7-0690-5c2c1392a365.png)\n\n## 型ってなに？\n\n型とは、変数という箱の形のようなイメージです。\n\n三角形の箱に、四角は入れられないですよね？\nプログラムの世界では、例えば「int（数値）」という型の変数には、文字列を入れることはできません。\n\nよく使うと思われる型は、以下の通りです。\n\n| 型 | 意味 |\n|:-:|:--|\n| Boolean | True(真) または False(偽) のどちらかしか入らない変数。  |\n| Int32 | 整数の数値しか入らない変数 |\n| String | 文字列しか入らない変数 |\n\nほんとはもっとたくさんあるのですが、キリがないのでこれくらいにしておきます。\n\n## スコープってなに？\n\nスコープとは、その変数が使える範囲を示します。\n言葉で説明するより、図で説明するほうがわかりやすいので、こんなかんじ。\n\n例えば、以下のようなシーケンスと変数があったとします。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/b558dcce-0ac8-c822-98e2-4d7b60bd53ab.png)\n\n| 変数 | スコープ |\n|:-:|:--|\n| parent | シーケンス（親） |\n| child1 | シーケンス（子１） |\n| child2 | シーケンス（子２） |\n\nこのとき、それぞれの変数が使える（箱に値を入れることができる or 箱から値を取り出すことができる）のは、以下の範囲になります。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/00fea4ad-503c-53e3-2cc8-4bf32ea308c6.png)\n\n`child1`は、「シーケンス（子１）」の中でしか使うことはできません。\n`child2`も同様に、「シーケンス（子２）」の中でしか使うことはできません。\n\nさて、`parent`が使える範囲はどこでしょう？\n\n`parent`のスコープは「シーケンス（親）」なので、「シーケンス（親）」の中でしか使うことができない、というルールは同じです。\nですが、「シーケンス（親）」の中に「シーケンス（子１）」「シーケンス（子２）」がいますね？\nなので、「シーケンス（親）」の中、つまり「シーケンス（子１）」「シーケンス（子２）」の中からも使うことができます。\n\nこれがスコープです。\n\n## 既定値ってなに？\n\n既定値とは、デフォルト値のことです。\nつまり、最初から変数に設定されている値を指定します。\nここは、状況に応じて設定するものなので、指定しなくても良いです。\n\n# 変数を使ってみよう！\n\nワークフローの中で変数に値を設定するときは、「Assign」というアクティビティを使います。\nやってみましょう。\n\n変数を作って、ワークフローに「Assing」アクティビティを追加します。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/fdeb81c4-7317-9fd2-f27c-853ce9b09cd4.png)\n\n`parent`という変数に、「こんにちは！」という文字列を設定してみます。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/ad98b73b-73d6-54e4-adfb-79742180423b.png)\n\nこれだけだと本当に設定されたかがわからないので、「WriteLine」というアクティビティを使って、出力ウィンドウに変数の値を表示するようにしてみます。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/e3036c97-c50e-fc83-9021-027802c47cdb.png)\n\nワークフローを保存して、動かしてみましょう。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/517338/a8dd63da-110e-37a2-b0d1-fb075899cfbc.png)\n\n変数の内容が表示されました！\n\n# おわりに\n\nRPAって「プログラミングの経験が無くても使える」と言われたりしますが、経験は必要なくても「多少の知識」は必要になると思うんですよね。\n今回の記事はかなり初心者向けの記事になってしまいましたが、「多少の知識」もないのに業務上RPAをやらざるを得なくなった人、そんな方の役に立てば幸いです。\n\n\n","user":"yoshiyuki-iwata","created_at":"2021-03-29T10:18:33+09:00","updated_at":"2021-03-29T10:37:24+09:00"},{"url":"https://qiita.com/REON/items/07118b9be11781f22918","title":"【Swift】大文字のSelfまとめ","body":"#はじめに\n小文字のselfはよく使いますが、大文字のSelfというのもあります。\n大文字のSelfについてまとめてみました。\n\n#型の内部で型自身へのアクセス\n以下のように、`Self.value`で構造体`A`に紐付いたvalueにアクセスすることができます。\n\n```swift\nstruct A {\n    static let value = 10\n    func printValue() {\n        print(Self.value)\n    }\n}\n```\nちなみに、Selfを書かずに直接スタティックプロパティ(value)にアクセスしようとすると\n`Static member 'value' cannot be used on instance of type 'A'`\nこのようなエラーが出てきてしまいます。\n\nスタティックメソッドでも同様です。\n\n```swift \nstruct B {\n    var name: String\n    var age: Int\n    static func isOld(_ x: Int) -> Bool {\n        return x > 60\n    }\n    func ageFunc() {\n        print(Self.isOld(age))\n    }\n}\n```\nちなみに、`Self`を構造体名の`B`と書き換えても同じことです。ここでは`Self == B`ですね。\n\n#プロトコルの定義での利用\nプロトコルはそれに準拠させた型の振る舞いを事前に宣言しておくことができますが、プロトコル自身はどの型で準拠されるのかは知りません。例えるなら、車の大きさ、色、ハンドルの位置などは製造の段階で決める事ができますが、製造の段階では一体この車はどんな人が乗るのかは知りません。利用者（型）が購入（準拠）して初めてどんな人が乗るのか（プロトコル自身がどの型で準拠されるのか）を知る事ができます。\nしかし、その型と同じ型のデータを返すメソッドや、同じ型同士を比較したい時もあります。その時にSelfキーワードを使います。\n\n注意点として、前項ではその定義を含む型自身をSelfと置いていましたが、本項では少し扱い方が異なります。つまり、プロトコル定義内でSelfを用いてもプロトコルがSelfというわけではありません。ここでのSelfとは、`プロトコルを採用した具体的な型 == Self`です。\n\n```swift\nprotocol C {\n    associatedtype Element\n    var x: Element { get }\n    var y: Element { get }\n    func replace() -> Self\n    static func +(lhs: Self, rhs: Self) -> Self\n}\n```\nこのように、xとyを入れ替えるreplaceメソッド、左辺の右辺を加算するスタティックメソッドをprotocol Cで宣言しています。replaceメソッドの戻り値にSelfを指定しています。この時点ではどのような型に準拠するのかわからないためです。スタティックメソッド+も同様です。\n構造体Dに準拠させてみましょう。\n\n```swift\nstruct D: C {\n    typealias Element = Int\n    var x: Int\n    var y: Int\n    func replace() -> D {\n        return D(x: y, y: x)\n    }\n    static func +(lhs: D, rhs: D) -> D {\n        return D(x: lhs.x + rhs.x, y: lhs.y + rhs.y)\n    }\n}\n```\nこのように、Selfのところが具体的なかたDに変わったのがわかります。このプロトコルCは他の型にも紐付く事ができるようにするため、できるだけ具体的な型はプロトコル宣言時に書きたくないためです。(associatedtypeもそのため)\n\n#クラス内での利用\nプロトコルとは違い、メソッドの返り値の型としてのみ扱う事ができます。\n\n```swift \nclass E {\n    func someFunc() -> Self {\n        return self\n    }\n}\n```\n\n#エクステンションでの利用\n前述の通り、プロトコルを準拠する型をSelfで参照できますが、一定の条件を満たす型のみプロトコルエクステンションを有効にしたいこともあります。\nそのような条件を記述するときにSelfでその型を表す事ができます。\n\n```swift\nprotocol SomeProtocol { }\n\nclass SomeClass { }\n\nextension SomeProtocol where Self: SomeClass {\n    func someFunc() {\n        print(type(of: self))\n    }\n}\n\nclass SomeSubClass: SomeClass, SomeProtocol { }\n\nlet someSubClass = SomeSubClass()\nsomeSubClass.someFunc()\n```\nこの例では、`SomeProtocol`を準拠する型が条件`Self: SomeClass`つまり、SomeClassを継承している場合のみ`someFunc()`を利用する事ができます。\n以下のように、`SomeProtocol`に準拠していても`SomeSubClass2`は`SomeClass`を継承していない（条件を満たしていない）ため、`someFunc()`にアクセスしようとするとエラーが出てきてしまいます。\n\n```swift \nclass SomeSubClass2: SomeProtocol { }\n\nlet someSubClass2 = SomeSubClass2()\nsomeSubClass2.someFunc()\n``` \nエラー\n`Referencing instance method 'someFunc()' on 'SomeProtocol' requires that 'SomeSubClass2' inherit from 'SomeClass'`\n\n\n#おわりに\nselfと違ってSelfはややこしいですね。\n\n\n\n\n\n\n\n","user":"REON","created_at":"2021-03-29T10:13:12+09:00","updated_at":"2021-03-29T11:09:14+09:00"},{"url":"https://qiita.com/gnix/items/2eb9ef2130853f68c475","title":"WSL2とDockerを導入してみる","body":"WSL2 と Docker 導入手順の覚書き。\nWSL1 から WSL2 に切り替えて、WSL2 上で動作する Docker を導入します。\n\n\n導入手順は Microsoft の下記ドキュメントを参考にしました。\n\n* [Windows 10 用 Windows Subsystem for Linux のインストール ガイド](https://docs.microsoft.com/ja-jp/windows/wsl/install-win10)\n\n## 導入環境\nBoot Camp ( intel CPU ) 上の Windows 10 Pro 20H2 (10.0.19042) で、既に WSL1 がインストールされている環境です。\n\n```powershell:Windows&#x20;Version\nPS C:\\> Get-CimInstance -Class Win32_OperatingSystem | Format-List Version\nVersion : 10.0.19042\n```\n```powershell:WSL&#x20;Version\nPS C:\\> wsl -l -v\n  NAME            STATE           VERSION\n* Ubuntu-20.04    Stopped         1\n```\n\nまた、 Hyper-V は無効化されている状態です。\n（ WSL2 上で Docker を動作させるため無効状態でOK）\nHyper-V の状態は、「 コントロール パネル\\すべてのコントロール パネル項目\\プログラムと機能 」の「Windowsの機能の有効化または無効化」から確認するか、PowerShellを管理者権限で実行して「Get-WindowsOptionalFeature」コマンドで確認。\n\n```powershell:Run&#x20;the&#x20;PowerShell&#x20;7&#x20;as&#x20;Administrator\nStart-Process pwsh.exe -Verb runas\n```\n```powershell:Hyper-V&#x20;Status\nPS C:\\> Get-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V\nFeatureName      : Microsoft-Hyper-V\nDisplayName      : Hyper-V プラットフォーム\nDescription      : 仮想マシンとそのリソースの作成および管理に使用できるサービスを提供します。\nRestartRequired  : Possible\nState            : Disabled\nCustomProperties :\n```\n\n## BIOS 内部の仮想化を有効にする\nBoot Camp で起動していると、BIOS 内部の仮想化が有効になっていない場合があります。\nこの設定は「タスクマネージャー」の「パフォーマンス」タブにある「仮想化」欄で確認できます。\n最初、この設定が無効になっていたため、下記のエラーメッセージが表示され WSL2 が有効化できませんでした。\n\n>Error: 0x80370102 ??????????????????????????????????????\n\n>コンピューターの BIOS 内部で仮想化が有効になっていることを確認してください\n\nBIOS 内部の仮想化を有効化するには macOS で再起動後、「システム環境設定」から「起動ディスク」 を選択し、ディスクを「BOOTCAMP Windows」に設定してから Windows を起動します。\n\n\n## WSL2 へ切り替える\n\nWSL1 から WSL2 に切り替えます。\nWSL1 がインストール済みのため「Linux用Windowsサブシステム」機能は有効になっており、「仮想マシンプラットフォーム」機能は無効化されている状態です。\n仮想マシンの機能を有効化するため、 PowerShell を管理者権限で起動し、以下のコマンドを実行します。\n有効化したら PC を再起動します。\n\n```powershell:Enable&#x20;Feature&#x20;VirtualMachinePlatform\ndism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart\n```\n \n再起動後、上記の参考ドキュメントに記載されている「[Linux カーネル更新プログラムパッケージ](https://docs.microsoft.com/ja-jp/windows/wsl/install-win10#step-4---download-the-linux-kernel-update-package)」をダウンロードしてインストールします。\nインストールが完了したら、 WSL2 を既定に設定します。\n\n```powershell:Set&#x20;WSL2&#x20;as&#x20;default\nwsl --set-version Ubuntu-20.04 2\n```\n設定完了後、WSL2 に切り替わっているか確認します。\n\n```powershell:WSL&#x20;Version\nPS C:\\> wsl -l -v\n  NAME            STATE           VERSION\n* Ubuntu-20.04    Running         2\n```\n\n## Docker を導入する\nDocker の公式サイトから Docker Desktop for Windows のインストーラをダウンロードします。\nインストーラを実行し、「Install required Windows components for WSL 2」欄にチェックが付いていることを確認して OK ボタンを押します。\nOK ボタンを押すとインストールが始まります。\nインストール完了後、「Close and Log out」ボタンが表示され、押すとログアウトします。\nログインすると、自動的に WSL2 をバックエンドに Docker が起動します。\n\n起動後に表示されているチュートリアルを実行したところ問題なく表示されました。\n\n```shell\ndocker run -d -p 80:80 docker/getting-started\n```\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1172866/caa5a7f7-c55f-8861-4acd-513f80425eaa.png)\n以上で WSL2 上で動作する Docker の導入は完了です。\n","user":"gnix","created_at":"2021-03-29T10:07:56+09:00","updated_at":"2021-03-29T10:07:56+09:00"},{"url":"https://qiita.com/cloghjordan/items/ae5e93739da57f6d9b87","title":"DjangoのQuerySetをJSON形式に変換してVue.jsで受け取る","body":"## はじめに##\nVue.jsが気に入ってしまったので、DjangoのQuerySetをJSON形式に変換してVue.js内で扱える様にしました。忘れっぽい自分のために、備忘録的に残します。\n\n\n###前提条件###\nDjango: version 3.1.7\nVue.js: version 2.6.12(CDN)\naxios等は使用しません\n\n###コード###\n Djangoにアプリ追加したところで各モジュールを書きかえます。\n\n``` urls.py\nfrom django.urls import path\nfrom . import views\n\napp_name= 'app'\n\nurlpatterns = [\n    path('list/', views.ListData, name= 'list'),\n]\n```\n\n``` models.py\nimport uuid\n\nfrom django.db import models\n\nclass Book(models.Model):\n\n    id= models.UUIDField(primary_key=True, default= uuid.uuid4, editable= False)\n    title= models.CharField(verbose_name= 'タイトル', max_length=40)\n```\nここでは、JSONが知らない特別なタイプの型をとるために、idをUUIDにしておきます。\n\n``` views.py\nimport json, uuid\n\nclass ListDataView(ListView):\n    template_name= \"app/listdata.html\"\n    model= Book\n\n    def get_context_data(self, **kwargs):\n        def cnvDataToJson(object):\n            if(isinstance(object, uuid.UUID)):\n                return str(object)\n\n        context= super().get_context_data(**kwargs)\n        books= self.object_list.values('id', 'title')\n        bookList= json.dumps(list(books), ensure_ascii=False, default=cnvDataToJson)\n        context[\"bookList\"]= bookList\n\n        return context\n    \nListData= ListDataView.as_view()\n```\nBookモデルからデータを得る時に、**values()**クエリを使って**「辞書のリスト」**に変換しておきます。\nその後、この辞書リストを**json.dumps()**でJSON形式の配列に変換しますが、***default=cnvDataToJson***のところで、jsonが知らない型を文字列に変換してあげるためのコールバックを設定します。\nなお、***ensure_ascii=False***は文字バケ対策です。\n\n\n``` listdata.html\n <div id=\"v-app\">\n        <button @click=\"get_books()\">GetBooks</button>\n        <div>\n            <table>\n                <tr>\n                    <th>No.</th>\n                    <th>タイトル</th>\n                </tr>\n                <tr v-for=\"(book, index) in books\">\n                    <td>[[index]]</td>\n                    <td>[[book.id]]</td>\n                    <td>[[book.title]]</td>\n                </tr>\n            </table>\n        </div>\n    </div>\n\n    <script src=\"https://unpkg.com/vue@2.6.12/dist/vue.min.js\"></script>\n    <script>\n\n        Vue.options.delimiters = ['[[',']]']\n\n        const vm = new Vue({\n            el: \"#v-app\",\n            data: function(){\n                return{\n                    books:[],\n                }\n            },\n            methods:{\n                get_books: function(){\n                    this.books.splice(0);\n                    this.books= {{bookList|safe}};  //Djangoから受け取るデータを配列にセットする。\n                },\n            },\n        })\n    </script>\n```\n***Vue.options.delimiters = ['[[',']]']***\nDjangoとVue.jsはデフォルトではテンプレート内で使用する{{ }}が衝突してしまうため、Vue.js側でデリミタを再定義してあげます。\n\n***this.books= {{bookList|safe}}***\nJSON配列となったデータをVue.js(javaScript)側の配列に移します。このとき***safe***でフィルタすることで、エクケープ処理をします。（細かいことは解りませんが、これがないとダメでした。）\n\n###あとがき###\njavaScriptからDjangoの{{ }}を扱う時にずっと\"　\"で囲うことをしていたために欲しい結果が得られずにいました。\nDjangoのテンプレートなので\" \"は要らないことが判りました。\nあと、Htmlタグに仕掛けをすることが出きるVue.jsって素晴らしく便利だと思った。(CLIの方は敬遠します)\n\n\n\n","user":"cloghjordan","created_at":"2021-03-29T10:00:55+09:00","updated_at":"2021-03-29T10:32:35+09:00"},{"url":"https://qiita.com/the_haigo/items/593926922a1d72591c3d","title":"Nxで始めるゼロから作るディープラーニング  Nx.Defn.Kernel.gradを読む","body":"# はじめに\n本記事はElixirで機械学習/ディープラーニングができるようになるnumpy likeなライブラリ [Nx](https://github.com/elixir-nx/nx/tree/main/nx)を使って\n「[ゼロから作るDeep Learning ―Pythonで学ぶディープラーニングの理論と実装](https://www.oreilly.co.jp/books/9784873117584/)」\nをElixirで書いていこうという記事になります。\n\n今回は4,5章で使用した Nxのgrad関数が何を行っているのかを読んでみた時のメモ書き的なものになります\n\n[準備編](https://qiita.com/the_haigo/items/1a2f0b371a3644960251)\n1章 pythonの基本 -> とばします\n2章 パーセプトロン -> とばします\n3章 [ニューラルネットワーク](https://qiita.com/the_haigo/items/bedd466142aaaf01641c)\n[with exla](https://qiita.com/the_haigo/items/4ec791c878fd48b9dec1)\n４章 [ニューラルネットワークの学習](https://qiita.com/the_haigo/items/2b7535bcff8b4df50d9d)\n５章 [誤差逆伝播法](https://qiita.com/the_haigo/items/f273a9c687302507d79d)\n[Nx.Defn.Kernel.grad](https://qiita.com/thehaigo/items/593926922a1d72591c3d)\n\n# わかったこと\n\n読んでみたところ、\nforwardを実行\nforwardの結果を保持(cache)\ngrad関数で実行されるdefn内の処理を解析しbackward部分を自動生成（予想）\nbackwrad部分は各関数ごとにgrad.exやexpr.ex内に記載されている\nということがわかりました\ngrad関数というかnxやばいです\n\n\n# Nx.Defn.Karnel.grad \nhttps://github.com/elixir-nx/nx/blob/main/nx/lib/nx/defn/kernel.ex\nhttps://github.com/elixir-nx/nx/blob/a9f7ea8fc09483e5b65783281dd2b459bcda11ae/nx/lib/nx/defn/kernel.ex#L231-L234\n第２引数が関数かチェックしてtransformを呼んでいます\n\n```elixir\ndef grad(var_or_vars, fun) when is_function(fun, 1) do\n    {_value, grad} = Nx.Defn.Grad.transform(var_or_vars, fun)\n    grad\nend\n```\n\nNx.Defn.Grad.transform\nhttps://github.com/elixir-nx/nx/blob/main/nx/lib/nx/defn/grad.ex\n\n```elixir\n  def transform(to_grad, fun) do\n    # 1\n    {to_grad, ids} =\n      Tree.composite(to_grad, %{}, fn to_grad, ids ->\n        validate_grad!(to_grad)\n        to_grad = Expr.metadata(to_grad, %{__MODULE__ => :to_grad})\n        {to_grad, Map.put(ids, to_grad.data.id, :to_grad)}\n      end)\n\n    # 2\n    expr = to_grad |> fun.() |> validate_expr!()\n\n    # Collect all IDs in the function environment and mark\n    # them as stop grads. This is an optimization to avoid\n    # traversing trees when not necessary.\n    # 3\n    {:env, env} = Function.info(fun, :env)\n    ids = stop_grads(env, ids)\n\n    # 4\n    # Grad all the parameters at the same time to share subtrees.\n    {graded, _} = to_grad(expr, Expr.tensor(1.0), {ids, %{}})\n\n    # 5\n    # Now traverse the expression again zerofying\n    # the parts that comes from other variables.\n    # We do so by encoding special nodes in the Expr\n    # AST and unpack them as we verify.\n    graded =\n      Tree.composite(to_grad, fn to_grad ->\n        id = to_grad.data.id\n        {graded, _, _} = zerofy_ids(graded, %{}, Map.delete(ids, id))\n\n        if graded.shape == to_grad.shape do\n          graded\n        else\n          Nx.broadcast(graded, to_grad)\n        end\n      end)\n\n    {expr, graded}\n  end\n\n```\n\n# 1 to_gradの中のTensorにユニークなIDを付けて、Tensor自体とidのリストを返す\nhttps://github.com/elixir-nx/nx/blob/a9f7ea8fc09483e5b65783281dd2b459bcda11ae/nx/lib/nx/defn/tree.ex#L85-L88\n引数がTensorかを確認して第３引数の関数を実行\n\n```elixir\n  def composite(tuple, acc, fun) when is_tuple(tuple) and is_function(fun, 2) do\n    {list, acc} = Enum.map_reduce(Tuple.to_list(tuple), acc, &composite(&1, &2, fun))\n    {List.to_tuple(list), acc}\n  end\n\n  def composite(%T{} = expr, acc, fun) when is_function(fun, 2) do\n    fun.(expr, acc)\n  end\n```\n\nhttps://github.com/elixir-nx/nx/blob/a9f7ea8fc09483e5b65783281dd2b459bcda11ae/nx/lib/nx/defn/expr.ex#L83-L86\nhttps://github.com/elixir-nx/nx/blob/a9f7ea8fc09483e5b65783281dd2b459bcda11ae/nx/lib/nx/defn/expr.ex#L701-L706\nhttps://github.com/elixir-nx/nx/blob/a9f7ea8fc09483e5b65783281dd2b459bcda11ae/nx/lib/nx/defn/expr.ex#L190\nhttps://hexdocs.pm/elixir/Kernel.html#make_ref/0\nメタデータを作成\n\n```elixir\n  #L83-L86\n  def metadata(expr, metadata) when is_map(metadata) do\n    expr = to_expr(expr)\n    expr(expr, expr.data.context, :metadata, [expr, metadata])\n  end\n  #L701-L706\n  defp expr(tensor, context, op, args) do\n    %{tensor | data: %Expr{id: id(), op: op, args: args, context: context}}\n  end\n\n  defp to_expr(%T{data: %Expr{}} = t),\n    do: t\n  # l190\n  def id(), do: make_ref()\n\n```\n\n# 2 functionの実行結果をメタデータ付きtensorかをチェックする\nhttps://github.com/elixir-nx/nx/blob/a9f7ea8fc09483e5b65783281dd2b459bcda11ae/nx/lib/nx/defn/grad.ex#L53-L55\nfunctionの実行結果をメタデータ付きtensorかをチェックする\n\n```elixir\n  expr = to_grad |> fun.() |> validate_expr!()\n\n  defp validate_expr!(%T{data: %Expr{}, shape: {}} = expr) do\n    expr\n  end\n```\n\n# 3 imageとlabelを更新されないように固定する\nhttps://hexdocs.pm/elixir/Function.html#info/2\nhttps://github.com/elixir-nx/nx/blob/a9f7ea8fc09483e5b65783281dd2b459bcda11ae/nx/lib/nx/defn/grad.ex#L67-L83\nFunction.info(func,:env)を実行すると以下のようなデータが出力される\nx_test => mnist test data 10000x784\nt_test => mnist test label 10000x10\n\n```elixir\niex(17)> Function.info(&Ch5.TwoLayerNet.loss_g(&1,x_test,t_test,100),:env)    \n{:env,\n [\n   {[_@4: #Nx.Tensor<\n        s64[10000][10]\n        [\n          [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n          [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n          [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n          [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n          [0, 0, 0, 0, 1, ...],\n          ...\n        ]\n>, _@5: #Nx.Tensor<\n        f32[10000][784]\n        [\n          [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...],\n          ...\n        ]\n>], :none, :none,\n    [\n      {:clause, 17, [{:var, 0, :_@7}], [],\n       [\n         {:call, 17,\n          {:remote, 17, {:atom, 0, Ch5.TwoLayerNet}, {:atom, 17, :loss_g}},\n          [\n            {:var, 0, :_@7},\n            {:var, 17, :_@5},\n            {:var, 17, :_@4},\n            {:integer, 0, 100}\n          ]}\n       ]}\n    ]}\n ]}\n\n```\n\nこれに対してstop_gradsを行うと最終的に(Tensor,ids)か(_,ids) になるので\nTensorのメタデータにあるidをキーにidsにstopフラグを立てる\n\n```elixir\n  {:env, env} = Function.info(fun, :env)\n  ids = stop_grads(env, ids)\n\n  # L67-L83\n  defp stop_grads(list, ids) when is_list(list),\n    do: Enum.reduce(list, ids, &stop_grads/2)\n\n  defp stop_grads(tuple, ids) when is_tuple(tuple),\n    do: tuple |> Tuple.to_list() |> Enum.reduce(ids, &stop_grads/2)\n\n  defp stop_grads(%T{data: %Expr{id: id}}, ids),\n    do: Map.put(ids, id, :stop)\n\n  defp stop_grads(%_{}, ids),\n    do: ids\n\n  defp stop_grads(map, ids) when is_map(map),\n    do: map |> Map.values() |> Enum.reduce(ids, &stop_grads/2)\n\n  defp stop_grads(_, ids),\n    do: ids\n\n```\n\n# 4 再帰的なGrad\nhttps://github.com/elixir-nx/nx/blob/a9f7ea8fc09483e5b65783281dd2b459bcda11ae/nx/lib/nx/defn/grad.ex#L160\n Expr.tensor(1.0) はbackwardのdout = 1 ?\nexpr = {w1,b1,w2,b2}のidはMapのkeyにないので、最後のgrad(op, args, ans, res cache)を実行\n\n```elixir\n  {graded, _} = to_grad(expr, Expr.tensor(1.0), {ids, %{}})\n  ## Recursion\n\n  # The gradient recursion.\n  #\n  # We keep two caches. One is the result cache, which is used for\n  # when visiting the same nodes in the AST.\n  #\n  # The other cache is the JVP cache, that shares parts of the JVP\n  # computation. Both are important to reduce the amount of nodes\n  # in the AST.\n  defp to_grad(expr, res, cache) do\n    Tree.composite(expr, cache, fn\n      %T{data: %Expr{id: id, op: op, args: args}} = ans, {result_cache, jvp_cache} = cache ->\n        key = [id | res.data.id]\n\n        case result_cache do\n          %{^id => :stop} ->\n            {Expr.tensor(0.0), cache}\n\n          %{^id => :to_grad} ->\n            {Expr.metadata(res, %{__MODULE__ => {:tainted, id}}), cache}\n\n          %{^key => res} ->\n            {res, cache}\n\n          %{} ->\n            case grad(op, args, ans, res, cache) do\n              {res, {result_cache, jvp_cache}} ->\n                {res, {Map.put(result_cache, key, res), jvp_cache}}\n\n              :none ->\n                jvps =\n                  case jvp_cache do\n                    %{^id => jvps} -> jvps\n                    %{} -> jvp(op, args, ans)\n                  end\n\n                {res, {result_cache, jvp_cache}} = grad_jvps(jvps, ans, res, cache)\n                {res, {Map.put(result_cache, key, res), Map.put(jvp_cache, id, jvps)}}\n            end\n        end\n    end)\n  end\n```\n\n```elixir\niex(40)> %T{data: %Expr{id: id, op: op, args: args}} = Expr.tensor(w1)\n#Nx.Tensor<\n  f64[784][100]\n  \n  Nx.Defn.Expr\n  tensor a  f64[784][100]\n>\niex(41)> id\n#Reference<0.3878774584.611057665.71016>\niex(42)> op\n:tensor\niex(43)> args\n[#Nx.Tensor<\n    f64[784][100]\n    [\n      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...],\n      ...\n    ]\n>]\n\n```\nhttps://github.com/elixir-nx/nx/blob/85a3d3a4d3eab44c588d05a8f32c25c952ba4787/nx/lib/nx/defn/grad.ex#L479-L481\nop は:tensorなので、:noneを返す\n\n```elixir\n  defp grad(_op, _args, _ans, _g, _cache) do\n    :none\n  end\n```\nhttps://github.com/elixir-nx/nx/blob/85a3d3a4d3eab44c588d05a8f32c25c952ba4787/nx/lib/nx/defn/grad.ex#L748\n:tensorなので []を返す\n\n```elixir\n  defp jvp(op, _, _) when op in @constants do\n    []\n  end\n```\n[] なので {tensor(0.0),cache} を返す\n\n```elixir\ndefp grad_jvps([], _ans, _g, cache), do: {Expr.tensor(0.0), cache}\n```\n\nこれだと何も実行されていないので\n多分opが実行した関数がスタックされて\nNx.{ add, subtract, multiply, divide} なら jvps\nそれ以外なら gradで再帰的に微分を行っていると思われる\n\n以下を見ると [{in,out},{in,out}]として見ると前の記事の乗算レイヤのbackwardと同じ形を取っているのがわかる\nhttps://github.com/elixir-nx/nx/blob/85a3d3a4d3eab44c588d05a8f32c25c952ba4787/nx/lib/nx/defn/grad.ex#L493-L496\n\n```elixir\n  defp jvp(:multiply, [x, y], _ans) do\n    [{x, y}, {y, x}]\n  end\n```\n\nこれらを鑑みると、grad関数は実行されたdefn内のコードを解析してbackward部分を自動的に生成している、誤差逆伝播法ではないかと思われる。\n\n# 5 初期化\n最後は次の学習に影響しないようにidsリストを初期化してると思われるので、割愛\n\n本記事は以上になりますありがとうございました\n","user":"the_haigo","created_at":"2021-03-29T10:00:38+09:00","updated_at":"2021-03-29T10:00:38+09:00"},{"url":"https://qiita.com/kai_kou/items/cf9a58c4d4e12f487b9a","title":"LaravelをAWS Lambdaで動作させてデータベースにはAurora Serverlessを使ってみた","body":"LaravelをAWS Lambdaで動作させることができる素敵な時代になっていたので、Laravel SailとLaravel Breezeでログイン機能を実装したプロジェクトをServerless Frameworkを利用してデプロイしてみました。\n\n## 前提\n[こちらのGitHubリポジトリ](https://github.com/kai-kou/laravel-sail-sample-projects/tree/main)を利用してデプロイ環境を構築する手順です。\n環境構築後の内容は[こちらのブランチ](https://github.com/kai-kou/laravel-sail-sample-projects/tree/feature/deploy-aws-lambda)においています。\n\n## 手順\n### Serverless Frameworkのインストール\nセットアップスクリプトが提供されているのでそれを利用します。\n\n```console\n> curl -o- -L https://slss.io/install | bash\n> serverless -v\nFramework Core: 2.30.3 (standalone)\nPlugin: 4.5.1\nSDK: 4.2.0\nComponents: 3.7.4\n```\nServerless Getting Started Guide\nhttps://www.serverless.com/framework/docs/getting-started/\n### Brefを利用してAWS Lambda用にLaravelを構成する\nBrefというパッケージを利用するとAWS LambdaでLaravelを動作させる環境構築がとても簡単にできます。\nBref - Serverless PHP made simple\nhttps://bref.sh/\nbrefphp/laravel-bridge: Package to use Laravel on AWS Lambda with Bref\nhttps://github.com/brefphp/laravel-bridge\nLaravelをコンテナにしてLambdaでデプロイするのが超簡単になった2021年 - Qiita\nhttps://qiita.com/umihico/items/514cf792d30bf3706ef5\nパッケージをインストールしてServerless Framework用の設定ファイルを生成します。\n\n```console\n> ./vendor/bin/sail composer require bref/bref bref/laravel-bridge\n> ./vendor/bin/sail artisan vendor:publish --tag=serverless-config\n```\n### `serverless.yml`の編集\n生成された`serverless.yml`ファイルにAurora Serverlessに必要となるリソースを追加します。下記の記事を参考にさせてもらいました。(感謝\n\nServerless FrameworkでAurora Postgres + VPC Lambda + RDS Proxyをデプロイする | DevelopersIO\nhttps://dev.classmethod.jp/articles/rds-proxy-deploy-with-serverless-framework/\nAurora Serverless をCloudFormationを利用して設置してみた | DevelopersIO\nhttps://dev.classmethod.jp/articles/aurora-serverless-by-cfn/\nBrefを使って完全サーバレスな、Symfony + Vue.js + Aurora Serverless製TODOリストを作る - Qiita\nhttps://qiita.com/ippey_s/items/bbb4e329c0a919d1a8b5\n\n`serverless.yml`と設定ファイルは下記のようになりました。\n\n```yaml:serverless.yml\nservice: laravel\n\nprovider:\n  name: aws\n  # The AWS region in which to deploy (us-east-1 is the default)\n  region: ap-northeast-1\n  # The stage of the application, e.g. dev, production, staging… ('dev' is the default)\n  stage: dev\n  runtime: provided.al2\n\ncustom:\n  defaultStage: dev\n  profiles:\n    dev: sls-itg\n    stg: sls-stg\n    prd: sls-prd\n  environments: ${file(./config/config.${opt:stage, self:custom.defaultStage}.yml)}\n  secret: ${file(./config/secret/.secret.${opt:stage, self:custom.defaultStage}.yml)}\n\npackage:\n  # Directories to exclude from deployment\n  exclude:\n    - node_modules/**\n    - public/storage\n    - resources/assets/**\n    - storage/**\n    - tests/**\n\nfunctions:\n  # This function runs the Laravel website/API\n  web:\n    handler: public/index.php\n    timeout: 28 # in seconds (API Gateway has a timeout of 29 seconds)\n    layers:\n      - ${bref:layer.php-74-fpm}\n    events:\n      - httpApi: \"*\"\n      # This function lets us run artisan commands in Lambda\n    vpc:\n      securityGroupIds:\n        - !Ref LambdaSecurityGroup\n      subnetIds:\n        - !Ref PrivateSubnetA\n        - !Ref PrivateSubnetC\n    environment:\n      DB_PORT: ${self:custom.environments.DB_PORT}\n      DB_HOST: !GetAtt DBCluster.Endpoint.Address\n      DB_PASSWORD: ${self:custom.secret.PASSWORD}\n\n  artisan:\n    handler: artisan\n    timeout: 120 # in seconds\n    layers:\n      - ${bref:layer.php-74} # PHP\n      - ${bref:layer.console} # The \"console\" layer\n    vpc:\n      securityGroupIds:\n        - !Ref LambdaSecurityGroup\n      subnetIds:\n        - !Ref PrivateSubnetA\n        - !Ref PrivateSubnetC\n    environment:\n      DB_PORT: ${self:custom.environments.DB_PORT}\n      DB_HOST: !GetAtt DBCluster.Endpoint.Address\n      DB_PASSWORD: ${self:custom.secret.PASSWORD}\n\nplugins:\n  # We need to include the Bref plugin\n  - ./vendor/bref/bref\n\nresources:\n  Resources:\n    # The S3 bucket that stores the assets\n    Assets:\n      Type: AWS::S3::Bucket\n      Properties:\n        BucketName: ${self:custom.environments.AWS_BUCKET}\n    # The policy that makes the bucket publicly readable\n    AssetsBucketPolicy:\n      Type: AWS::S3::BucketPolicy\n      Properties:\n        Bucket: !Ref Assets # References the bucket we defined above\n        PolicyDocument:\n          Statement:\n            - Effect: Allow\n              Principal: \"*\" # everyone\n              Action: \"s3:GetObject\" # to read\n              Resource: !Join [\"/\", [!GetAtt Assets.Arn, \"*\"]] # things in the bucket\n              # alternatively you can write out Resource: 'arn:aws:s3:::<bucket-name>/*'\n    ## VPC Resource\n    VPC:\n      Type: AWS::EC2::VPC\n      Properties:\n        CidrBlock: 10.0.0.0/24\n        Tags:\n          - { Key: Name, Value: Sample VPC }\n    PrivateSubnetA:\n      Type: AWS::EC2::Subnet\n      Properties:\n        VpcId: !Ref VPC\n        CidrBlock: 10.0.0.0/25\n        AvailabilityZone: ap-northeast-1a\n        Tags:\n          - { Key: Name, Value: Sample Private A }\n    PrivateSubnetC:\n      Type: AWS::EC2::Subnet\n      Properties:\n        VpcId: !Ref VPC\n        CidrBlock: 10.0.0.128/25\n        AvailabilityZone: ap-northeast-1c\n        Tags:\n          - { Key: Name, Value: Sample Private C }\n    LambdaSecurityGroup:\n      Type: AWS::EC2::SecurityGroup\n      Properties:\n        GroupDescription: SecurityGroup for Lambda Functions\n        VpcId: !Ref VPC\n        Tags:\n          - Key: \"Name\"\n            Value: \"LambdaSecurityGroup\"\n    AuroraSecurityGroup:\n      Type: AWS::EC2::SecurityGroup\n      Properties:\n        GroupDescription: SecurityGroup for Aurora\n        VpcId: !Ref VPC\n        SecurityGroupIngress:\n          - IpProtocol: tcp\n            FromPort: ${self:custom.environments.DB_PORT}\n            ToPort: ${self:custom.environments.DB_PORT}\n            CidrIp: 10.0.0.0/24\n        Tags:\n          - Key: \"Name\"\n            Value: \"AuroraSecurityGroup\"\n      DependsOn: VPC\n    ## RDS Resource\n    DBSubnetGroup:\n      Type: AWS::RDS::DBSubnetGroup\n      Properties:\n        DBSubnetGroupDescription: \"SampleDB subnet group\"\n        DBSubnetGroupName: sampledb-subnet-group\n        SubnetIds:\n          - !Ref PrivateSubnetA\n          - !Ref PrivateSubnetC\n    DBCluster:\n      Type: AWS::RDS::DBCluster\n      Properties:\n        DatabaseName: ${self:custom.environments.DB_DATABASE}\n        Engine: aurora-mysql\n        EngineMode: serverless\n        MasterUsername: ${self:custom.secret.USER_NAME}\n        MasterUserPassword: ${self:custom.secret.PASSWORD}\n        DBClusterParameterGroupName: !Ref DBClusterParameterGroup\n        DBSubnetGroupName: !Ref DBSubnetGroup\n        VpcSecurityGroupIds:\n          - !Ref AuroraSecurityGroup\n      DependsOn: DBSubnetGroup\n    DBClusterParameterGroup:\n      Type: AWS::RDS::DBClusterParameterGroup\n      Properties:\n        Description: A parameter group for aurora\n        Family: aurora-mysql5.7\n        Parameters:\n          time_zone: \"Asia/Tokyo\"\n          character_set_client: \"utf8\"\n          character_set_connection: \"utf8\"\n          character_set_database: \"utf8\"\n          character_set_results: \"utf8\"\n          character_set_server: \"utf8\"\n    AuroraSecret:\n      Type: AWS::SecretsManager::Secret\n      Properties:\n        Name: Sample/aurora\n        SecretString: '{\"username\":\"${self:custom.secret.USER_NAME}\", \"password\":\"${self:custom.secret.PASSWORD}\"}'\n    SecretTargetAttachment:\n      Type: AWS::SecretsManager::SecretTargetAttachment\n      Properties:\n        SecretId: !Ref AuroraSecret\n        TargetId: !Ref DBCluster\n        TargetType: \"AWS::RDS::DBCluster\"\n      DependsOn: DBCluster\n```\n\n```yaml:config/secret/.secret.dev.yml\nUSER_NAME: root\nPASSWORD: password\n```\n\nデータベース名、バケット名は任意で指定します。\n\n```yaml:config/config.dev.yml\nDB_PORT: 3306\nDB_DATABASE: hoge_app\nAWS_BUCKET: kai-laravel-test\n```\n\n#### Lambda関数に環境変数を追加する\nBrefが自動生成してくれるLambda関数のリソースにAurora Serverlessへアクセスするための環境変数を設定します。Aurora Serverlessの場合、インスタンスは自動で生成されるので、`DBCluster.Endpoint.Address`でエンドポイントを取得します。\n\n```yaml\nfunctions:\n  # This function runs the Laravel website/API\n  web:\n    handler: public/index.php\n    timeout: 28 # in seconds (API Gateway has a timeout of 29 seconds)\n    layers:\n      - ${bref:layer.php-74-fpm}\n    events:\n      - httpApi: \"*\"\n      # This function lets us run artisan commands in Lambda\n    vpc:\n      securityGroupIds:\n        - !Ref LambdaSecurityGroup\n      subnetIds:\n        - !Ref PrivateSubnetA\n        - !Ref PrivateSubnetC\n    environment:\n      DB_PORT: ${self:custom.environments.DB_PORT}\n      DB_HOST: !GetAtt DBCluster.Endpoint.Address\n      DB_PASSWORD: ${self:custom.secret.PASSWORD}\n\n  artisan:\n    handler: artisan\n    timeout: 120 # in seconds\n    layers:\n      - ${bref:layer.php-74} # PHP\n      - ${bref:layer.console} # The \"console\" layer\n    vpc:\n      securityGroupIds:\n        - !Ref LambdaSecurityGroup\n      subnetIds:\n        - !Ref PrivateSubnetA\n        - !Ref PrivateSubnetC\n    environment:\n      DB_PORT: ${self:custom.environments.DB_PORT}\n      DB_HOST: !GetAtt DBCluster.Endpoint.Address\n      DB_PASSWORD: ${self:custom.secret.PASSWORD}\n```\n\n#### クラスターの設定\n\n`EngineMode: serverless`と設定するとAurora Serverlessとしてクラスター作成できます。\n\nAWS::RDS::DBCluster - AWS CloudFormation\nhttps://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbcluster.html#cfn-rds-dbcluster-enginemode\n\n```yaml\n    DBCluster:\n      Type: AWS::RDS::DBCluster\n      Properties:\n        DatabaseName: ${self:custom.environments.DB_DATABASE}\n        Engine: aurora-mysql\n        EngineMode: serverless\n        MasterUsername: ${self:custom.secret.USER_NAME}\n        MasterUserPassword: ${self:custom.secret.PASSWORD}\n        DBClusterParameterGroupName: !Ref DBClusterParameterGroup\n        DBSubnetGroupName: !Ref DBSubnetGroup\n        VpcSecurityGroupIds:\n          - !Ref AuroraSecurityGroup\n      DependsOn: DBSubnetGroup\n```\n\nDBClusterParameterGroupで`character_set`を指定していますが、これはMySQL5.7.7未満だと標準のcharasetが`utf8mb4`となり、unique制約をつけたカラムで文字数オーバーになるのを回避するためです。\n詳細は下記が詳しいです。\n\nLaravel5.4以上、MySQL5.7.7未満 でusersテーブルのマイグレーションを実行すると Syntax error が発生する - Qiita\nhttps://qiita.com/beer_geek/items/6e4264db142745ea666f\n\n```yaml\n    DBClusterParameterGroup:\n      Type: AWS::RDS::DBClusterParameterGroup\n      Properties:\n        Description: A parameter group for aurora\n        Family: aurora-mysql5.7\n        Parameters:\n          time_zone: \"Asia/Tokyo\"\n          character_set_client: \"utf8\"\n          character_set_connection: \"utf8\"\n          character_set_database: \"utf8\"\n          character_set_results: \"utf8\"\n          character_set_server: \"utf8\"\n```\n\n### デプロイ\n`serverless deploy`コマンドでデプロイします。時間がかかるのでデプロイ中はお茶でものんでまったりと待ちます。\n\n```console\n> ./vendor/bin/sail npm run prod\n> serverless deploy\n```\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/def4dceb-63b1-d717-524d-2105558781d4.png)\nデプロイ後、エンドポイントにアクセスして以下のように表示されたらOKです。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/7fb6dcc0-b87a-a4ba-3779-f556ff52e444.png)\n\n### 静的ファイルの配置\n\nS3バケットにプロジェクトのpublicディレクトリをコピーします。これはAWS Lambda関数へのアクセスだけだと、`public/css/app.css`などへアクセスできないので、デプロイで作成した、アセット用のS3バケットへファイルを配置するためです。\nファイルがないとブラウザでアクセスした場合、ログイン画面へアクセスすると以下のようになります。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/85a836fd-c583-d387-3f53-e73718ac3fc1.png)\n\n```console\n> aws s3 sync public s3://kai-laravel-test/public --delete\n```\n\nファイルコピー後、下記のようになっていたらOKです。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/1141e8d3-be06-df92-7458-8699b10478b1.png)\n\n#### マイグレーション\n\nBrefには`cli`コマンドが提供されているので、それを利用してAWS Lambdaの`laravel-dev-artisan`関数を利用してマイグレーションします。\n`cli`コマンドはAWSのクレデンシャルファイルを参照するので、`sail`コマンドを挟まないほうが手っ取り早いです。\n\n```console\n> ./vendor/bin/bref cli --region=ap-northeast-1 laravel-dev-artisan -- migrate\n```\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/81664d0d-7422-bf0f-27d1-6fa50671e408.png)\n\n### 動作確認\n\n実際にデプロイした環境にアクセスしています。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/ab81e15e-fc29-ae28-4a2c-2e734397d451.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/ba244bdc-34d4-95e7-b553-5b657c139dcc.png)\n今回はメール送信については対応していないので、パスワード変更のためのメール送信はエラーとなります。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/33415064-5732-773b-69b1-83c962e59ebc.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/48549/29b869b5-af41-84ee-ae0f-9b8b2571c677.png)\n\n### リソースの削除\n\n動作確認ができてリソースが不要であれば削除します。S3バケットにファイルがあるまま削除処理を実行するとエラーになるので、ファイルを削除しておきます。\n\n```console\n> aws s3 rm --recursive s3://kai-laravel-test/\n> serverless remove\n```\n\n## まとめ\n\n実用するにはまだまだ対応するべきことがありますが、ひとまずはやりたいことが実現できました。\nやったぜ\n\n## 参考\n\nServerless Getting Started Guide\nhttps://www.serverless.com/framework/docs/getting-started/\nBref - Serverless PHP made simple\nhttps://bref.sh/\nbrefphp/laravel-bridge: Package to use Laravel on AWS Lambda with Bref\nhttps://github.com/brefphp/laravel-bridge\nLaravelをコンテナにしてLambdaでデプロイするのが超簡単になった2021年 - Qiita\nhttps://qiita.com/umihico/items/514cf792d30bf3706ef5\nServerless FrameworkでAurora Postgres + VPC Lambda + RDS Proxyをデプロイする | DevelopersIO\nhttps://dev.classmethod.jp/articles/rds-proxy-deploy-with-serverless-framework/\nAurora Serverless をCloudFormationを利用して設置してみた | DevelopersIO\nhttps://dev.classmethod.jp/articles/aurora-serverless-by-cfn/\nBrefを使って完全サーバレスな、Symfony + Vue.js + Aurora Serverless製TODOリストを作る - Qiita\nhttps://qiita.com/ippey_s/items/bbb4e329c0a919d1a8b5\nAWS::RDS::DBCluster - AWS CloudFormation\nhttps://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-resource-rds-dbcluster.html#cfn-rds-dbcluster-enginemode\nLaravel5.4以上、MySQL5.7.7未満 でusersテーブルのマイグレーションを実行すると Syntax error が発生する - Qiita\nhttps://qiita.com/beer_geek/items/6e4264db142745ea666f\nCreateDBClusterParameterGroup-Amazon Relational Database Service\nhttps://docs.aws.amazon.com/AmazonRDS/latest/APIReference/API_CreateDBClusterParameterGroup.html\nAWS::RDS::DBInstance - AWS CloudFormation\nhttps://docs.aws.amazon.com/ja_jp/AWSCloudFormation/latest/UserGuide/aws-properties-rds-database-instance.html#cfn-rds-dbinstance-masterusername\nエラー: The policy failed legacy parsing - Qiita\nhttps://qiita.com/sot528/items/f248db0b69c7e1d34220\nCloudformationでエラー: Has prohibited field Resource - Qiita\nhttps://qiita.com/sot528/items/2263fab0dbb55d6ce032\nAurora Serverlessの導入時に気をつけるべきこと | DevelopersIO\nhttps://dev.classmethod.jp/articles/lessons-learned-from-up-and-running-aurora-serverless/\nConsole commands - Bref\nhttps://bref.sh/docs/runtimes/console.html\nServerless Frameworkで環境変数を外部ファイルから読み込み、環境毎に自動で切り替えてみる | DevelopersIO\nhttps://dev.classmethod.jp/articles/serverless-framework-conf-change/\nデータベースの使用-Bref\nhttps://bref.sh/docs/environment/database.html\nBrefが進化してたのでサーバーレスLaravel環境作ってみた - Qiita\nhttps://qiita.com/ippey_s/items/25129dde8c7fe85479e4\nCreating serverless PHP websites - Bref\nhttps://bref.sh/docs/websites.html#architectures\n","user":"kai_kou","created_at":"2021-03-29T10:00:16+09:00","updated_at":"2021-03-29T10:00:16+09:00"},{"url":"https://qiita.com/zhikuanchuanshang725/items/b06623561378693a12b9","title":"HTMLとは、コードの記述","body":"# そもそもHTMLとは\nウェブサイトに表示される情報を記載する言語\n\n# 構成\n<!DOCTYPE HTML>\n< html>\n  < head>\n　　　(head要素)\n  < /head>\n  < body>\n　　　(body要素)\n  < /body>\n< /html>\n","user":"zhikuanchuanshang725","created_at":"2021-03-29T10:00:07+09:00","updated_at":"2021-03-29T11:49:05+09:00"},{"url":"https://qiita.com/keketon/items/97a1a37917057dd7138c","title":"[読書メモ] エリック・エヴァンスのドメイン駆動設計","body":"## 全体\n\n## 第1部 ドメインモデルを機能させる\n\n### 第1章 知識をかみ砕く\n\nドメイン＝解決しようとしている領域\nモデル＝現実世界の物事を抽象化したもの\n\nドメインモデル＝解決しようとしている領域の物事を抽象化したもの\n≠ドメイン層のアクターをコードに落とし込んだ成果物\n\nプログラマとしてはどうしてもプログラムに目がいってしまうが、あくまで「モデル」は抽象的な概念である\n\n善いモデルは表層には現れない。継続的なリファクタリングで常に「深い」洞察をする\n\n\n### 第2章\n\nユビキタス言語\n\n**ドメインモデル図は実装と一致しない、むしろ常に違いが生じる物である**\nドメインモデル図は実装を可視化した物ではない（リバースエンジニアリング不可能？）\n\n\n## 第2章　\n","user":"keketon","created_at":"2021-03-29T09:57:55+09:00","updated_at":"2021-03-29T09:57:55+09:00"},{"url":"https://qiita.com/hann-solo/items/67a7abe008c767b522e1","title":"失敗から学ぶ｜「Appleでサインイン」していたIFTTTの退会","body":"## はじめに\n\nIFTTTに、「Appleでサインイン」を利用してアカウント作成した。退会しようとおもってハマったが、なんとかなった。\n\n## （たぶん）正しいプロセス\n\n1. 「Appleでサインイン」で生成されたパスワードを、なにか任意のものに変える\n1. アカウント削除する\n\n![IMG_4433 (1).jpeg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/184128/414e20a0-ff23-e053-3460-d13d8013de83.jpeg)\n\n\n## ハマったこと\n\n### `pw:abcdef123456`を変更せずに退会しようとした\n\n理由がよくわかっていないが、下記のようなメッセージがあって、パスワードを変えないといけないようだ\n\n![SS 2021-03-29 9.09.09.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/184128/020f1809-8781-bd78-6a3b-97ec7b116e0c.png)\n\n### キーチェーン.appに、「有効ではない方のパスワード」が登録されてしまった。\n\nこれは自分のミス……\n\n1. 古いパスワード入力（間違い）\n1. 新しいパスワード入力\n1. キーチェーンには新しいパスワードが登録される\n1. パスワード変更が失敗して、IFTTTは古いパスワードを認識している\n\nとなり、キーチェーン以外にパスワードを保管していなかったので、IFTTTの「有効なパスワード」がわからない状態におちいった。\n\n`Alfred`でクリップボード履歴を取っているんだけど、デフォルトでパスワード管理ソフトは「対象外」に設定されていて、クリップボード履歴からも拾えない。\n\n自分のミスと言えばミスなんだけど、キーチェーン.appを利用するときの「よくあるハマりどころ」だよなあ。\n\n### パスワードリセットを、Apple IDのメールアドレスでやろうとした\n\n「Appleでサインイン」で生成される`xyz789@priveterelay.appleid.com`を使わなければならない。\n\n\n## けっきょくやったこと\n\n1. `ID:xyz789@priveterelay.appleid.com`を用いて、パスワードリセット\n1. パスワードを変更\n1. アカウント削除\n\nパスワード変更は不要だったのかもしれない。\nあるいは、パスワードリセットが必要で、このやりかたが正しかったのかもしれない。\nいまとなっては謎である（再度会員登録して確かめるほどでもない……）\n\n\n## 補足\n\nIFTTTは、Gmailに届いたメールをLINEに転送しようとおもってはじめた。Gmailの仕様変更で、IFTTTに対応しなくなっていた。IFTTTをつかう理由がなくなったので退会。\n\nIFTTTはいいサービスだとおもったし、また使いたいと思うけれど、毎日のようにメールが届くのに閉口した。未使用アカウントを残すのも良くないのでサクサクと削除。\n\n\n## 環境\n\nここで書いていることは、下記のバージョンで実施しました。\n\n- Safari バージョン14.0.2 (16610.3.7.1.9)\n- macOS BigSur 11.1\n\n","user":"hann-solo","created_at":"2021-03-29T09:49:31+09:00","updated_at":"2021-03-29T09:52:52+09:00"},{"url":"https://qiita.com/mf2t/items/5a5d973b84774c07015a","title":"warning: CRLF will be replaced by LF in hoge.png.","body":"git で某リポジトリを clone してきたところ、\n\n\n    warning: CRLF will be replaced by LF in hoge.png\n    The file will have its original line endings in your working directory\n\n\nといった警告が `git status` でたくさん出てきた。改行コードの設定ということで検索すると、`git config autocrlf false` で直る、と出てくるのだがやってみても一向に改善しない。\n落ち着いてよくメッセージを眺めると、警告の出ているファイルは画像(といくつかのオフィス文書)だ。つまり、テキストじゃないから無視して、と git に伝えられればいいはずだ。\n\nということで正解は attributes。\nhttps://git-scm.com/book/en/v2/Customizing-Git-Git-Attributes\n\n`.gitattributes`に設定されていた内容がこちら。\n\n    * text eol=lf\n\nそのままここに必要な設定を加えてもいいのだが、主に pull しかしないリポジトリでコミットすると管理が面倒なので、`.git/info/attributes` の方に書くことにする。\n\n    *.png binary\n    *.pptx binary\n","user":"mf2t","created_at":"2021-03-29T09:49:27+09:00","updated_at":"2021-03-29T09:49:27+09:00"},{"url":"https://qiita.com/akky-tys/items/b0465a0a7154716f10ab","title":"SwiftUIチュートリアル3を丁寧に説明しながらやってみるよ。","body":"おはよう。:relaxed:だよ。\nさてさて引き続き、SwiftUIチュートリアル３を勉強していくよ。\n20分でできるって書いてあるけれど、調べならやっていると一日余裕で超えるね。能力差？:relaxed:\n以前も書きましたが、チュートリアルに沿って構文とか意味とか覚えていこう！という趣旨なので、間違っているところとかあれば教えていただけると幸いです。\n\n## 教材\n[Introducing SwiftUI]\n(https://developer.apple.com/tutorials/swiftui)\n\n\n##チュートリアル3：ユーザーからの入力を操ろう！\n[Handling User Input](https://developer.apple.com/tutorials/swiftui/handling-user-input)\n\n\n###Section1: ユーザーのお気に入り登録をしちゃおう\n「Landmark.swift」で作業をするよ。\n項目にisFavoriteというお気に入りかどうかを判断する変数を定義するよ。\n\n![スクリーンショット 2021-03-28 21.53.15.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/482103/8a5c0e30-02d5-d2a4-ee2e-2c7935c2f93d.png)\n\n**point1-1**\n画像のように読み込んでいるlandmarkData.jsonにも同名の項目をつけることで、この項目名でjsonの項目とモデルのキーを結びつけているよ。\n\n続いて、「LandmarkRow.swift」で作業をするよ。\n\n```swift:LandmarkRow.swift\nif landmark.isFavorite {\n // point1-2\n  Image(systemName: \"star.fill\")\n    .foregroundColor(.yellow)\n}\n///以下略\n```\n**point1-2:systemName**\n「SF Symbols」というSwiftUIの中で使用できるアイコンのセットがあり、それを使用するときにsystemName:XX--アイコン名--XXという指定の仕方をする。\nちなみに「〜.fill」が塗りつぶしアイコンになるよ。\n\n[参考：SF Symbols](https://developer.apple.com/design/human-interface-guidelines/sf-symbols/overview/)\n\n\n###Section2: リストにフィルターかけちゃおう\n\n「LandmarkList.swift」で作業をするよ。\n\n```swift:LandmarkList.swift\nimport SwiftUI\n\nstruct LandmarkList: View {\n    //point2-1\n    @State private var showFavoritesOnly = true\n\n    //point2-2\n    var filteredLandmarks: [Landmark] {\n        landmarks.filter { landmark in\n            (!showFavoritesOnly || landmark.isFavorite)\n        }\n    }\n\n    var body: some View {\n        NavigationView {\n\n            List(filteredLandmarks) { landmark in\n                NavigationLink(destination: LandmarkDetail(landmark: landmark)) {\n                    LandmarkRow(landmark: landmark)\n                }\n            }\n            .navigationTitle(\"Landmarks\")\n        }\n    }\n}\n\n```\n**point2-1:@State**\n読み書き可能な値として管理される場合に使うプロパティだよ、\nユーザーからの入力によってリストの見え方を変えたい場合、\n@Stateをつけることで、変更を監視して、変更されるとその内容によってViewを再描画してくれるよ。\nまたこれはPrivateにして、呼び出しているViewそのものと、その子View内に限定して使用する必要があるよ。\n[参考:state](https://developer.apple.com/documentation/swiftui/state)\n\n\n**point2-2:filter**\n\n```\n配列.filter {要素　in \n  条件\n} \n```\n\nのような形で処理が書かれていて、\n配列の１行１行が、条件に一致している場合はそれを返すようになっているよ。\n\n24行目のListに渡す値によって、見え方がこんな感じで変わります。\n\n変更前：リストに対してlandmarksのデータ自体を渡しているため、全件表示されている。\n![スクリーンショット 2021-03-27 10.09.16.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/482103/9f6a8fa3-b9e4-cca1-5e6e-e630ea74667b.png)\n\n\n変更後：リストに対して、filterをかけた結果を渡している。今回はshoFavoirteOnly = trueなので、絞り込まれた状態になる！\n![スクリーンショット 2021-03-27 10.10.03.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/482103/752b91f2-6f7e-1a31-3167-cc8e804a091a.png)\n\n\n\n絞り込まれたね:relaxed:\n\n\n###Section3:Toggleボタンで表示を画面から操作してみよう！\n\n次は、showFavoriteOnlyのtrue/falseの切り替えを画面から実施できるようにするよ。\nlandmarkList.swiftで作業をするよ。\n\n```swift:landmarkList.swift\n    var body: some View {\n        NavigationView {\n\n            List {  // point3-1\n                Toggle (isOn:$showFavoritesOnly) { //point3-2\n                    Text(\"Favorites Only\")\n                }\n                ForEach(filteredLandmarks) { landmark in //point3-3\n                  NavigationLink( destination: LandmarkDetail(landmark: landmark)){\n                      LandmarkRow(landmark: landmark)\n                  }\n                }\n            \n            }\n            .navigationTitle(\"Landmarks\")\n        }\n    }\n}\n\n```\n\n**point3-1:List**\n動的な要素と静的な要素を組み合わせるために、Listに直接landmarksを渡す形から、Listの中でネストする形に変更する。\n\n**point3-2:Toggle**\n\n```\nToggle(isOn : バインドする変数) {\n　Toggleのラベル\n}\n```\nのような形で使用します。\n今回は$showFavoritesOnlyにバインドされている。\nこれでToggleがOn,OFFによってshowFavoritesOnlyのTrue,Falseが切り替わるようになったよ。\n\n[参考：Toggle](https://developer.apple.com/documentation/swiftui/toggle)\n\n**point3-3:ForEach**\nshowFavoritesOnlyが切り替わったら、リストもきりかえる必要があるため、ForEachを使う・・？のかな・・？　\nいまいちわからなかったので、もう少し調べます。\n\n\n\n###Section4:ストレージを監視可能なオブジェクトにしよう。\nSection４〜６ではユーザーがお気に入りをチェックしたり、外したりできるようにしていきます。\nSection4ではまず、データモデルの整備をおこないます。\n「ModelData.swift」で作業をするよ。\n\n```swift:ModelData.swift\n\n//point4-1\nfinal class ModelData : ObservableObject {\n\n   //point 4-2\n    @Published var landmarks: [Landmark] = load(\"landmarkData.json\")\n\n}\n\n///以下略\n\n```\n\n\n**point4-1 ObservableObject**\n値の変更などのイベントの発行と監視ができるのがCombineフレームワーク。\nこれを使用することで、イベント処理を組み合わせて、非同期処理を楽に処理できるんだなーと理解しました。\nObservableObjectはそのフレームワークに準拠したかたちのクラスであることを定義していると思われます。@Statusでも同じように値の変更をViewに知らせる役割があったけれど、それをオブジェクト単位で付与できるのがObservableObjectかな。\n[参考：Combine]https://developer.apple.com/documentation/combine\n[参考：ObservableObject](https://developer.apple.com/documentation/combine/observableobject)\n\n**point4-2 Published**\nCombineフレームワークの中で、ポイントとなってくるのが、「Publisher」と「Subscriber」の二つです。\nPublisher  = イベント、データを発行する側\nSubscriber =　イベント、データを受け取る側\n\n今回は、landmarkData.jsonの値の変更を監視して、何か変更された時Subscriberに知らせる必要があります。\nなので、landmarksに＠Publisherをつけて、Publisherとして定義してあげます。\n[参考:publisher](https://developer.apple.com/documentation/combine/publisher)\n\n\n###Section5:ビューにモデルを使おう。\n続いてはView側の修正をしていくよ。\nチュートリアルとは順序が反対になるのですが、個人的にデータの流れを知りたいタイプなので、\nStep6から実施します。\n「LandmarksApp.swift」で作業します。\n\n```swift:LandmarksApp.swift\nimport SwiftUI\n\n@main\nstruct LandmarksApp: App {\n    //  point 5-1\n    @StateObject private var modelData = ModelData()\n    \n    var body: some Scene {\n        WindowGroup {\n            ContentView()\n                .environmentObject(modelData)\n        }\n    }\n}\n\n```\n**point5-1:@StateObject**\nStateObjectは監視対象のオブジェクトをインスタント化する時に使用するよ。これを宣言することで、初期値の設定も行なっています。\nそして作業しているLandmarksApp.swiftはアプリの数あるViewの中で最上位のViewだよね。\nここで、ModelData.swiftのModelDataクラスから「modelData」という新しいインスタンスを作成して、\nContentViewの環境オブジェクトとして渡しているよ。\n\n\n\n\n\n```swift:ContentView.swift\n\nimport SwiftUI\n\nstruct ContentView: View {\n    var body: some View {\n        LandmarkList()\n    }\n}\n\nstruct ContentView_Previews: PreviewProvider {\n    static var previews: some View {\n        ContentView() // point5-2\n            .environmentObject(ModelData())\n    }\n}\n\n\n```\n\n**point5-2:プレビュー用にenvironmentObject**\n次のContentViewでは実際のViewは特に変更はしなけれど、Previewに対しては同じように、\n環境オブジェクトとして、ModelDateクラスを渡しているよ。\n本来のアプリを起動した際に使用するルートでは、上位ViewですでにModelDataが渡されているね。\nでも、開発中はView単体でプレビューすることもあり、そんな時だと「ModelDataがない！　プレビューできない！」って失敗しちゃうので、\nViewごとに値を渡しているイメージかな。\n同じように、LandmarkList.swift、LandmarkRow.swiftでも、プレビュー用に個々で値を設定しているよ。\n\n\n最後に、「LandmarkList.swift」での処理をみてみるよ。\n\n```Swift:LandmarkList.swift\n struct LandmarkList: View {\n    // point 5-3\n    @EnvironmentObject var modelData : ModelData\n    @State private var showFavoritesOnly = true\n    \n    var filteredLandmarks :[Landmark]{\n        // point5-4\n        modelData.landmarks.filter { landmark in\n            (!showFavoritesOnly || landmark.isFavorite)\n            \n        }\n        \n    }\n```\n\n変更を加えたのは、pointをつけた２箇所です。\n\n**point5-3:@EnvironmentObject**\nObservableObjectに準拠したModelとViewをつなぐ役割で、監視対象のModelが変更されると、現在のViewを作成しなおす。\n@ObservableObjectというものもあり、同じくObservableObjectプロトコルで作られたClassをView側で使う時につけるものです。\n違いとしては、@EnvironmentObjectだと、View同士の階層を気にせずそのアプリ全体で使用することができることがあげられます。\nなので、今回みたいにViewAがViewBを読み出して・・のように親子、祖父親子と階層が出来上がっていて、\nかつ、データ自体は１箇所という場合には、EnvironmentObjectとして、設定した方が良いよね..ってことかな？\n\n[参考：environmentobject](\nhttps://developer.apple.com/documentation/swiftui/environmentobject\n)\n\n**point5-4**\nModel側でもModelDataクラスの中で、landmarkを定義したので、View側でも同じように読み出します。\n\n\n\n\n###Section6:お気に入りボタンをつけよう！\nさてさてここまでModelからViewにお気に入りのOn,OFFを知らせるための準備をしてきたので、\n最後に実際にお気に入り処理を追加してみるよ。\n\n\n新しくSwiftUIファイル「FavoriteButton.swift」を作成するよ。\n\n```swift:FavoriteButton.swift\nimport SwiftUI\n\nstruct FavoriteButton: View {\n    // point6-1\n    @Binding var isSet : Bool\n    var body: some View {\n        // point6-2\n        Button(action: {\n            isSet.toggle()       \n        }){\n             \n            Image(systemName: isSet ? \"star.fill\":\"star\")\n                .foregroundColor(isSet ? Color.yellow : Color.gray)\n        }\n    }\n}\n\nstruct FavoriteButton_Previews: PreviewProvider {\n    static var previews: some View {\n        FavoriteButton(isSet: .constant(true))\n    }\n}\n```\n\nこれを「LandmarkDetail.swift」から呼び出すよ。\n\n\n```swift:LandmarkDetail.swift\n\nimport SwiftUI\n\nstruct LandmarkDetail: View {\n    @EnvironmentObject var modelData :ModelData\n    var landmark: Landmark\n    \n    var landmarkIndex: Int {\n        // point 6-3\n        modelData.landmarks.firstIndex(where: { $0.id == landmark.id })!\n        \n    }\n    \n    \n    var body: some View {\n        ScrollView {\n            MapView(coordinate:  landmark.locationCoordinate)\n                .ignoresSafeArea(edges: .top)\n                .frame(height: 300)\n            \n            CircleImage(image : landmark.image)\n                .offset(y: -130)\n                .padding(.bottom, -130)\n\n            VStack(alignment: .leading) {\n                HStack {\n                  Text(landmark.name)\n                    .font(.title)\n                    .foregroundColor(.primary)\n                  //Point 6-1\n                  FavoriteButton(isSet:$modelData.landmarks[landmarkIndex].isFavorite)\n                }\n                HStack {\n                    Text(landmark.park)\n                    Spacer()\n                    Text(landmark.state)\n                }\n                .font(.subheadline)\n                .foregroundColor(.secondary)\n\n                Divider()\n\n                Text(\"About ¥(landmark.name)\")\n                    .font(.title2)\n                Text(landmark.description)\n            }\n            .padding()\n            \n        }\n        .navigationTitle(landmark.name)\n        .navigationBarTitleDisplayMode(.inline)\n    }\n}\n\nstruct LandmarkDetail_Previews: PreviewProvider {\n    static let modelData = ModelData()\n    \n    static var previews: some View {\n        LandmarkDetail(landmark : modelData.landmarks[0]).environmentObject(modelData)\n        \n    }\n}\n```\n\n\n**point6-1:Binding**\nバインディングを使用することで表示側のViewとデータを格納しているプロパティ、双方からの読み書きができるようになるよ。\nまずは、FavoriteButtonの方で、スターのOn,Offによって、True,Falseを変更できるような処理を書いているよね。\nそのボタンを、呼び出しているLandmarkDetail.swift側のPoint６-1がついている部分で\nisSetとlandmark.isFavoriteを結びつけているため、\nisFavoriteが初期値としてisSetに渡され、isSetが変わる=>isFavoriteが変わるようになるよ。\n[参考:Binding](https://developer.apple.com/documentation/swiftui/binding)\n\n**point6-2:Button**\n\n```swift\nButtion(action : トリガーとなる処理){\n ラベル\n}\n```\nのように使用するよ。ラベル部分はText（XXX）ではなく、アイコンでisSetのTrue,Falseによってスターの塗りつぶしと色を変えているよ。\n[参考：Button]https://developer.apple.com/documentation/swiftui/button\n\n**point6-3:firstIndex(where:)**\nwhereに条件を書いて、配列の中で一番最初に条件に一致するIndexを返すよ。\n今回は配列のidと現在のLandmarkListから渡ってきたlandmark.idを比較して、一致しているIndexを返しています。\nhttps://developer.apple.com/documentation/swift/array/2994722-firstindex\n\n\n\n以上で、チュートリアル３が終了です。\n\n###まとめ\nStateやEnvironmentObjectなど、双方向のデータやり取りに必要なプロパティについて学んだよ。\nなんとなーくのイメージしか掴めていないので、もっと調べて、使い分けとか自信持ってできるようになりたい・・・:relaxed:\nまた、今回はJSONから呼び出したけれど、APIなど外部から取得した値を使ってリストを表示する場合はどうやって書くのかな、とか\n色々試してみたい箇所が出てきたよ。\n\n間違っている箇所や、こう理解すると良いよ、といったアドバイスがあれば教えていただけると幸いです。\n\nでは:relaxed:\n\n","user":"akky-tys","created_at":"2021-03-29T09:47:16+09:00","updated_at":"2021-03-29T09:47:16+09:00"},{"url":"https://qiita.com/tomoki0sanaki/items/63e4a1c36293a37ca9c7","title":"grep/sed コマンドの代替としての StreamRelay.NET.exe","body":"---\n### はじめに\n\nじつはgrepもsedも使いこなしていないので、代替になるかどうかは分からないけど、正規表現での検索と置換を実装してみた。\n\n---\n### grep/sed コマンドの代替としての StreamRelay.NET.exe\n\nver3.8.0.0 より、.NET Framework標準の正規表現機能([System.Text.RegularExpressions](https://docs.microsoft.com/ja-jp/dotnet/api/system.text.regularexpressions.regex?view=netframework-4.0)クラス)をスクリプト実装のプラグインの一つとして実装した。\n\nオプションとしては「-RegularExpressionMatch」と「-RegularExpressionReplace」がそれである。\n\n---\n### 使用上の注意(入出力ストリームの文字列化(Byte配列からChar配列へ))\n\n正規表現なので、ストリームからの入力データを文字列として扱う「-LocalCharset」などのオプションがないと面白い結果は出ないと思う。\n\n---\n### 「-RegularExpressionMatch」オプション\n\n`-RegularExpressionMatch 正規表現`\n\nというような正規表現のオプションを一つ受けて、それにヒットした行だけを通過させる。\n\n例えば、\n\n```shell-session:\nC:\\>type abc.txt\nabc\n123\naabc\nC:\\>StreamRelay.NET.exe -LocalPort 0 -RemotePort 0 -LocalCharset SHIFT_JIS -LocalInputFile abc.txt -RegularExpressionMatch aa+\naabc\n```\n\n---\n### 「-RegularExpressionReplace」オプション\n\n`-RegularExpressionReplace 正規表現 置換文字列`\n\nというような正規表現と置換文字列のオプションを2つ受けて、それにヒットした部分を置換して通過させる。\n\n例えば、\n\n```shell-session:\nC:\\>type abc.txt\nabc\n123\naabc\nC:\\>StreamRelay.NET.exe -LocalPort 0 -RemotePort 0 -LocalCharset SHIFT_JIS -LocalInputFile abc.txt -RegularExpressionReplace \"(a+)\" \"zz**$1**zz\"\nzz**a**zzbc\n123\nzz**aa**zzbc\n```\n\n---\n### 正規表現のリファレンス\n\n.NET Framework標準のリファレンスは「[正規表現言語 - クイック リファレンス](https://docs.microsoft.com/ja-jp/dotnet/standard/base-types/regular-expression-language-quick-reference)」\n\n---\n### 目次へ戻る\n\n[目次というか最初の一歩](http://qiita.com/tomoki0sanaki/items/85f20cbe18378e33cd6f)\n\n","user":"tomoki0sanaki","created_at":"2021-03-29T09:46:53+09:00","updated_at":"2021-03-29T09:50:40+09:00"},{"url":"https://qiita.com/nozomi_nozomi/items/d94f9b345d5810c88a4c","title":"【laravel】vue.jsを導入したら、bootstrap動かなくなったよ","body":"# はじめに\n\nlaravelにvue.jsを導入が完了し、喜んでいた最中に発生した、boostrapのモーダルが動いていない問題。\n\n\nこれを解決するのに詰まったので、解決策を記録致します！\n\n#前提\n## 環境\nPHP 7.4.16 \nLaravel  6.20.17\nmysql   8.0.23\nnginx 1.18.0\n\n##コード\n\n```app.blade.php\n\n<!DOCTYPE html>\n<html lang=\"ja\">\n<head>\n  <meta charset=\"utf-8\">\n  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\">\n  <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\">\n  <title>\n    @yield('title')\n  </title>\n  <!-- Font Awesome -->\n  <link rel=\"stylesheet\" href=\"https://use.fontawesome.com/releases/v5.8.2/css/all.css\">\n  <!-- Bootstrap core CSS -->\n  <link href=\"https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/css/bootstrap.min.css\" rel=\"stylesheet\">\n  <!-- Material Design Bootstrap -->\n  <link href=\"https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.11/css/mdb.min.css\" rel=\"stylesheet\">\n  <script src=\"https://ajaxzip3.github.io/ajaxzip3.js\" charset=\"UTF-8\"></script>\n</head>\n\n<body>\n  @include('nav')\n  <div id=\"app\">\n    @yield('content')\n  </div>\n  <script src=\"{{ mix('js/app.js') }}\"></script>  \n  <!-- JQuery -->\n<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js\"></script>\n  <!-- Bootstrap tooltips -->\n  <script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.4/umd/popper.min.js\"></script>\n  <!-- Bootstrap core JavaScript -->\n  <script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.3.1/js/bootstrap.min.js\"></script>\n  <!-- MDB core JavaScript -->\n  <script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.8.11/js/mdb.min.js\"></script>\n</body>\n\n</html>\n```\n\n```webpack.mix.js\nconst mix = require('laravel-mix');\n\n/*\n |--------------------------------------------------------------------------\n | Mix Asset Management\n |--------------------------------------------------------------------------\n |\n | Mix provides a clean, fluent API for defining some Webpack build steps\n | for your Laravel application. By default, we are compiling the Sass\n | file for the application as well as bundling up all the JS files.\n |\n */\n\nmix.js('resources/js/app.js', 'public/js').version();\n\n```\n\n```app.js\n\nimport './bootstrap'\nimport Vue from 'vue'\nimport LocationTagsInput from './components/LocationTagsInput'\n\nconst app = new Vue({\n  el: '#app',\n  components: {\n    LocationTagsInput,\n  }\n})\n```\n\n\n#解決法\n`app.blade.php`から下記をコメントアウトする\n\n```\n  <!-- JQuery -->\n<script type=\"text/javascript\" src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js\"></script>\n```\n\n\n\n## 原因\n```bootstrap.js\ntry {\n    window.Popper = require('popper.js').default;\n    window.$ = window.jQuery = require('jquery');\n\n    require('bootstrap');\n} catch (e) {}\n\n以降省略\n```\n\n上記箇所でも、jQueryを呼んでいたので、`app.blade.php`とダブルで呼び出していたことが原因でした！\n\n","user":"nozomi_nozomi","created_at":"2021-03-29T09:44:03+09:00","updated_at":"2021-03-29T09:53:07+09:00"},{"url":"https://qiita.com/Kubosuke_21/items/4b5f1d8b185086ed49ce","title":"SNS認証を導入する Rails6","body":"## rails6にSNS認証を導入する\nまずomniauthをgemに書き込む。\n\n```Gemfile\ngem 'omniauth-facebook'\ngem 'omniauth-google-oauth2'\ngem \"omniauth-rails_csrf_protection\"\ngem 'omniauth', '~>1.9.1'\n```\n上記を記述してbundle installを行います\n今回はfacebookとgoogleのomniauthを導入するので、その２つとomniauth-rails_csrf_protectionというGemをインストールして脆弱性の対策を行います。\n\n\n```terminal\n% vim ~/.zshrc\n\n# インサートモードに移行し、下記を追記\nexport FACEBOOK_CLIENT_ID='メモしたアプリID'\nexport FACEBOOK_CLIENT_SECRET='メモしたapp secret'\nexport GOOGLE_CLIENT_ID='メモしたクライアントID'\nexport GOOGLE_CLIENT_SECRET='メモしたクライアントシークレット'\n\n# esc,:wqと入力して保存して終了\n\n% source ~/.zshrc\n# 環境変数の読み込み\n```\n\n```config/initializers/devise.rb\nDevise.setup do |config|\n  # 省略\n  config.omniauth :facebook,ENV['FACEBOOK_CLIENT_ID'],ENV['FACEBOOK_CLIENT_SECRET']\n  config.omniauth :google_oauth2,ENV['GOOGLE_CLIENT_ID'],ENV['GOOGLE_CLIENT_SECRET']\nend\n```\nアプリ側で環境変数を読み込む記述をする\n\n## SNS認証のレスポンスを保存する\n\n```terminal\n% rails g model sns_credential \n```\n\n```db/migrate/XXXXXXXXXXXXXXXX_create_sns_credentials.rb\ncreate_table :sns_credentials do |t|\n     t.string :provider\n     t.string :uid\n     t.references :user,  foreign_key: true\n\n     t.timestamps\n```\n\nuidやproviderを保存。Userモデルとのアソシエーションのために、外部キーとしてuser_idを持たせておく。db:migrateを実行する。\n\n### deviseでOumniAuthを使用する\n\n```models/user.rb\nclass User < ApplicationRecord\n  devise :database_authenticatable, :registerable,\n         :recoverable, :rememberable, :validatable, :omniauthable, omniauth_providers: [:facebook, :google_oauth2]\n\n  has_many :sns_credentials\n```\nomniauth_providers: [:facebook, :google_oauth2]と記述することで、FacebookとGoogleのOumniAuthを使用する。SnsCredentialモデルのアソシエーションも設定する。\n\n```models/sns_credential.rb\nclass SnsCredential < ApplicationRecord\n belongs_to :user, , optional: true\nend\n```\noptional: true とは、レコードを保存する際に、外部キーの値がない場合でも保存ができるオプション。\n\n\n### deviseを再設定\n\nターミナルで、rails g devise:controllers usersを実行した後以下のように編集する。生成したコントローラーを使用させるためにdeviseのルーティングを変更。\n\n```config/routes.rb\n#　上略\ndevise_for :users, controllers: {\n   omniauth_callbacks: 'users/omniauth_callbacks',\n   registrations: 'users/registrations'\n }\n```\n\n### アクションの定義\n\n```controllers/users/omniauth_callbacks_controller.rb\ndef facebook\n  authorization\n end\n\n def google_oauth2\n  authorization\n end\n\n private\n\n def authorization\n   sns_info = User.from_omniauth(request.env[\"omniauth.auth\"])\n   @user = sns_info[:user]\n   if @user.persisted? #ユーザー情報が登録済みなので、新規登録ではなくログイン処理\n      sign_in_and_redirect @user, event: :authentication\n    else #ユーザー情報が未登録なので、新規登録画面へ遷移する\n      @sns_id = sns_info[:sns].id\n      render template: 'devise/registrations/new'\n    end\n end\n```\nUserモデルから返ってきた値を＠userに代入。(モデルの処理は後述)\nif @user.persisted?でユーザー情報が登録されているか否かで条件分岐。\n@Userには「nickname」と「email」の情報をもたせて、SNS認証の判断はsns_idで行う為、idだけビューで扱えるようにする。\n\n```views/users/new.html.erb\n<%= link_to \"Facebookで登録\", user_facebook_omniauth_authorize_path, method: :post%>\n<%= link_to \"Googleで登録\", user_google_oauth2_omniauth_authorize_path, method: :post%>\n\n<%= link_to 'Facebookでログイン', user_facebook_omniauth_authorize_path, method: :post%>\n<%= link_to 'Googleでログイン', user_google_oauth2_omniauth_authorize_path, method: :post%>\n```\n記述したアクションが呼び出されるように、ビューを編集する。\n\n### モデル内にメソッドを定義する\n\n```models/user.rb\ndef self.from_omniauth(auth)\n  sns = SnsCredential.where(provider: auth.provider, uid: auth.uid).first_or_create\n  # SNS認証を行ったことがあるかを判断して、データベースに保存\n  user = User.where(email: auth.info.email).first_or_initialize(\n     nickname: auth.info.name,\n       email: auth.info.email\n   )\n  # SNS認証を行っていなかった場合、メールアドレスで検索\n\n  # userが登録済みであるか判断\n   if user.persisted?\n     sns.user = user\n     sns.save\n   end\n   { user: user, sns: sns }\nend\n```\nsns = の中でsns認証したことがあればアソシエーションで取得しています。\nuser = の中でemailでデータベースに保存するかbuildするか判断する。first_or_initializeはwhereメソッドとともに使うことで、whereで検索した条件のレコードがあればそのレコードのインスタンスを返し、なければ新しくインスタンスを作る。\npersisted?で登録済みのユーザーと判断を行い処理を実行する。新規登録時は、SnsCredentialモデルに保存されるタイミングで、user_idが確定していなかったので、SnsCredentialモデルとUserモデルは紐付いていません。ログインの際に、sns.userを更新して紐付けを行います。\n最終行の記述で、SNS認証を行ったかの判断をするためにsnsに入っているsns_idをビューで扱えるようにするため、コントローラーに渡します。\n\n```devise/registrations/new.html.erb\n  <%if @sns_id.present? %>\n   <%= hidden_field_tag :sns_auth, true %>\n  <% else %>\n   <div class=\"field\">\n     <%= f.label :password %>\n     <% @minimum_password_length %>\n     <em>(<%= @minimum_password_length %> characters minimum)</em>\n     <br />\n     <%= f.password_field :password, autocomplete: \"new-password\" %>\n   </div>\n\n   <div class=\"field\">\n     <%= f.label :password_confirmation %><br />\n     <%= f.password_field :password_confirmation, autocomplete: \"new-password\" %>\n   </div>\n  <% end %>\n```\nSNS認証を行っているか、行っていないかの条件分岐を記述する。\n\n```controllers/users/registrations_controller.rb\n# POST /resource\n def create\n   if params[:sns_auth] == 'true'\n     pass = Devise.friendly_token\n     params[:user][:password] = pass\n     params[:user][:password_confirmation] = pass\n   end\n   super\n end\n#省略\n```\nparams[:sns_auth]を取得した時だけDevise.friendly_tokenを使ってパスワードを自動生成し、あとの処理はsuperメソッドでdeviseのregistrations#createを実行する。\nsuperでdeviseのメソッドを継承する。\n\nSNS認証は記述が複雑な部分も多く僕自身理解しきれていない箇所もあるので、今後見返したりして理解を深めていこうと思います。。\nありがとうございました。\n\n\n\n\n\n\n\n\n\n","user":"Kubosuke_21","created_at":"2021-03-29T09:42:48+09:00","updated_at":"2021-03-29T09:42:48+09:00"},{"url":"https://qiita.com/ryamamoto0406/items/b71200830f250f85aa3f","title":"SQLite 事始め","body":"# はじめに\nWSL2 の Ubuntu 20.04 LTS で SQLite を使ってみた備忘録を残しておく。目的としては[こちらの記事](https://qiita.com/ryamamoto0406/items/489e00fe693b688a4a5e)でデータ生成して、[こちらの記事](https://qiita.com/ryamamoto0406/items/ece1a064f85e7c0466aa)でcsvを作成したファイルをDBに登録し、データをいろいろと操作してみた。\n\nDBに触るのは初めてなので、何か間違いやコメントありましたらどしどしお願いします！\n\n# インストール\nSQLite3 をインストールして、そのバージョンを確認した。\n\n```bash\nsudo apt update\nsudo apt install sqlite3\nsqlite3 --version\n```\n\n最後のコマンド実行時にバージョンが表示される。\n\n```:出力\n3.31.1 2020-01-27 19:55:54 3bfa9cc97da10598521b342961df8f5f68c7388fa117345eeb516eaa837balt1\n```\n\n問題なくインストールできているよう。\n\n# DB の作成\nまず、DBファイルを作成する。\n\n```bash\nsqlite3 sample.db\n```\n\nSQLite のコンソールが立ち上がるので以下のコマンドを入力。\n\n```sql\nSQLite version 3.31.1 2020-01-27 19:55:54\nEnter \".help\" for usage hints.\nsqlite> .open sample.db\n```\n\nこれでsample.dbが作られる。\n\n# DB へ csv のインポート\nカレントディレクトリにある data.csv をDBにインポートする。\n\n```sql\nsqlite> .mode csv\nsqlite> .import data.csv data\n```\n\nこれで DB 内に data というテーブルができた。\n\n# データの確認\n格納されてるデータを確認する。\n\n```sql\nsqlite> .table\ndata\nsqlite> select * from data;\n1,female,154.208284956131,47.9648481600305,O\n2,male,177.885610334895,70.8362056783686,A\n3,male,163.380282640745,48.2489691006596,A\n--中略--\n998,male,169.940812644638,75.6647407081827,O\n999,female,148.482217278304,39.0562603398636,O\n1000,male,176.658033371611,86.1710695602122,B\n```\nデータが格納されてることは確認できた。テーブルの要素一覧を取得してみると、\n\n```sql\nsqlite> .schema\nCREATE TABLE data(\n  \"\" TEXT,\n  \"SEX\" TEXT,\n  \"HEIGHT\" TEXT,\n  \"WEIGHT\" TEXT,\n  \"BLOOD\" TEXT\n);\n```\n\nとなり全部のデータ型がTEXTになってしまっていた。これを変更したい。\n\n#データ型の変更\nいろいろ調べてみた結果、SQLite でデータ型を直接変更する方法は無い。なので、[SQliteでカラム定義変更（カラム名変更、属性変更など）を行う最短ルート暫定版](http://distorted-unchi.hatenablog.com/entry/2017/11/30/002139)を参考に、新しいテーブルを作り、そこにデータを移すという方法で実行する。新しいテーブルを作るには、\n\n```sql\nsqlite> create table tmp(\n   ...> id integer,\n   ...> SEX text,\n   ...> HEIGHT real,\n   ...> WEIGHT real,\n   ...> BLOOD text);\n```\n\nと項目名とデータ型を指定する。次にテーブルをコピーする。\n\n```sql\nsqlite> insert into tmp select * from data;\n```\n\nこれでコピーできたので、元データを消す。\n\n```sql\nsqlite> drop table data;\n```\n\nテーブル名を変更してテーブルの中身を確認する。\n\n```sql\nsqlite> alter table tmp rename to data;\nsqlite> .schema\nCREATE TABLE IF NOT EXISTS \"data\"(\nid integer,\nSEX text,\nHEIGHT real,\nWEIGHT real,\nBLOOD text);\nsqlite> select * from data;\n1|female|154.208284956131|47.9648481600305|O\n2|male|177.885610334895|70.8362056783686|A\n3|male|163.380282640745|48.2489691006596|A\n--中略--\n998|male|169.940812644638|75.6647407081827|O\n999|female|148.482217278304|39.0562603398636|O\n1000|male|176.658033371611|86.1710695602122|B\n```\n\n変更ができている。\n\n# おわりに\n次はテーブル内の項目を条件を付けて取り出す、などの細かい操作方法も学んでいきたい。\n","user":"ryamamoto0406","created_at":"2021-03-29T09:42:24+09:00","updated_at":"2021-03-29T09:42:24+09:00"},{"url":"https://qiita.com/gonza_kato_atsushi/items/bd52462e2a54968ba57f","title":"Rails (V1::Auth::Customers::ConfirmationsController, but didn't (Zeitwerk::NameError))","body":"## railsのプロジェクトをEc2にデプロイしたのち、`rails console -e production`を行うと次にようなエラーが\n\n```console\n[ec2-user@ip-10-0-0-93 room_backend]$ /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader/callbacks.rb:18:in `on_file_autoloaded': expected file /var/www/room_backend/app/controllers/v1/auth/customers/confirmations_controller.rb to define constant V1::Auth::Customers::ConfirmationsController, but didn't (Zeitwerk::NameError)\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/kernel.rb:27:in `block in require'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/kernel.rb:26:in `tap'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/kernel.rb:26:in `require'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader.rb:409:in `const_get'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader.rb:409:in `block (2 levels) in eager_load'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader.rb:733:in `block in ls'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader.rb:725:in `foreach'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader.rb:725:in `ls'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader.rb:404:in `block in eager_load'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader.rb:393:in `synchronize'\n\tfrom /home/ec2-user/.rbenv/versions/2.6.1/lib/ruby/gems/2.6.0/gems/zeitwerk-2.4.2/lib/zeitwerk/loader.rb:393:in `eager_load'\n以下略\n\n```\n\nエラー名は Zeitwerk::NameError とのこと\nググってみるとスタックオーバーフローにおんなじような記事があったので処置したら治りました\n\nhttps://stackoverflow.com/questions/57277351/rails-6-zeitwerknameerror-doesnt-load-class-from-module\n\n\n## 解決法\n\n```ruby:config/application.rb\nclass Application < Rails::Application\n   config.load_defaults 6.0\n   #下の一行を追加する\n   config.autoloader = :classic\nend\n```\n","user":"gonza_kato_atsushi","created_at":"2021-03-29T09:29:08+09:00","updated_at":"2021-03-29T09:29:08+09:00"},{"url":"https://qiita.com/yosukei3108/items/c6f49d4d3477427124d2","title":"Kubernetes の環境を作りたい [Raspberry Pi 編 1]","body":"<h1> これは何? </h1>\nタイトルの通り、Raspberry Pi を使った Kubernetes の環境構築の作業記録です。\n解説と言えるほどのものにはならないと思うのでご注意ください。\n\nhttps://www.oreilly.co.jp/books/9784873118406/\n\n基本的には ↑ の本の Appendix にならいつつ、Raspberry Pi 4 model B/4 GB + 3 model B+ * 3 台の計 4 台で環境を構築していきたいと思います。\n\n\n<h1> 調達 </h1>\nRaspberry Pi 本体の調達ですが、Amazon の Raspberry Pi 販売ページを色々みてもどの商品がどのような商流で手元に届くのかいまいちよくわからなかったので、KSY 社の HP から購入しました。\n\nhttps://raspberry-pi.ksyic.com/\n\nPi 3 model B が在庫切れだったことと、せっかくなので Pi 4 model B も触ってみたかったことから上記の構成としました。\n\nPi 4 model B はまずマスター ノードとして構築します。\n将来的にはワーカー ノードにして、ワーカー ノードのスペックが一様でない環境のお勉強にも使えたらな、という感じです。\n\n他に、以下を購入しました。\n\n・Cat 6 UTP (1 m) * 4 -- 100 均で購入\n・USB (type-A) to USB (micro-B/Type-C 兼用) 充電・転送ケーブル (1 m) * 4 -- 100 均で購入\n・16 GB microSD * 4 -- 電気屋さんで購入 (各 870 円)\n・100 BASE-TX/8 ポート スイッチング ハブ -- 電気屋さんで購入 (1600 円)\n\nRaspberry Pi の電源供給は手持ちのケーブルやアダプタを組み合わせました。すっきりさせたい場合は USB ポート付きの電源タップなどを買うといいのかも。\n\n<h1> ホスト OS の準備 </h1>\nホスト OS と言う呼び方が正しいのかまずわかってないんですが、Raspberry Pi を走らせる OS のことを指しています。\n前述の『入門 Kubernetes』では HypriotOS (https://blog.hypriot.com/) が紹介されていますが、私は AWS のお勉強も兼ねたいという考えから CentOS7 を導入したいと思います (Amazon Linux 2 が CentOS 7 に似てると聞いて)。\n\nググってみると色々とうまくいったりいかなかったりするようですが、とりあえずこちらの \"CentOS-Userland-7-armv7hl-RaspberryPI-Minimal-4-2009-sda.raw.xz\" から試してみようと思います。\n\nhttp://ftp.yz.yamagata-u.ac.jp/pub/linux/centos-altarch/7/isos/armhfp/\n\nmicroSD カードへの書き込みには Sillicon Linux 様の DD for Windows (Ver.0.9.9.8) を利用させていただきます。\n\nhttps://www.si-linux.co.jp/techinfo/index.php?DD%20for%20Windows#s74c46f6\n\nうまくいくでしょうか。\n\n結果として、4 枚の SD カードへのイメージ書き込みすべてにおいて 1 回以上の BSoD が発生しました。\nエラーもまちまちで、私の環境では以下が観測されました。\n\nIRQL_NOT_LESS_OR_EQUAL\nPAGE_FAULT_IN_NONPAGED_AREA (失敗した内容: fvevol.sys)\nPFN_LIST_CORRUPT\n\nどうやら書き込み自体はできているらしく、気にしていたら Windows は使っていられないので、この事象の調査はいつか (いつ?) やることにして次に行きたいと思います。\n\n\nメモ:\nSurface の microSD カード スロットを使って書き込みを行いました。\n1 枚目の書き込みで BSoD が起きた後、OS (Windows) を 19042.867 から 19042.870 (※) にアップデートしましたが、そのことによる挙動の変化は確認できませんでした。\n\n(※) 噂の「印刷時に BSoD が発生することがある」という事象の修正が取り込まれた以降のバージョン。ただし、同事象発生時のエラーは APC_INDEX_MISMATCH とのこと。\n\nhttps://support.microsoft.com/en-us/topic/march-18-2021-kb5001649-os-builds-19041-870-and-19042-870-out-of-band-ebbe0617-3a63-467a-aaaa-2a4c68a6de33\n\n\nhttps://qiita.com/yosukei3108/items/eb5815bf90110625ce0a\n\nに続く。\n","user":"yosukei3108","created_at":"2021-03-29T09:20:58+09:00","updated_at":"2021-03-29T13:28:10+09:00"},{"url":"https://qiita.com/gdtypk/items/3df7bf2f25fd8104f049","title":"AWS認定セキュリティ(SCS)を取得しました","body":"AWS認定セキュリティ(SCS)を受験し無事合格しました。\n資格取得までに参考にしたものを投稿します。\n\n![ 2021-03-29 8.42.40.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/290588/ea6cc9ee-a8c7-6bf2-0853-649c42b441ad.jpeg)\n\n\n## 私のAWSの知識\n以下の4資格を取得しています。\n- [クラウドプラクティショナー](https://qiita.com/gdtypk/items/fa87750ec9278eb0db9a)\n- [ソリューションアーキテクト](https://qiita.com/gdtypk/items/52d96a5af0a05f06ebc4)\n- [デベロッパーアソシエイト](https://qiita.com/gdtypk/items/4cfcf3c74b9faf3893aa)\n- [SysOpsアドミニストレータ](https://qiita.com/gdtypk/items/9d8512f0901749f630d7)\n\n業務では、EC2,RDS,Lambda,S3を軽く触っている程度になります。\nAWSサービスをガッツリ使うことは基本ありません。\n\n## 勉強時間\n30時間程度だと思います。(1日1時間を1ヶ月)\n\n### 試験範囲の確認\nhttps://aws.amazon.com/jp/certification/certified-security-specialty/\n\n### 要点整理から攻略する『AWS認定 セキュリティ-専門知識』を読む\nhttps://www.amazon.co.jp/%E8%A6%81%E7%82%B9%E6%95%B4%E7%90%86%E3%81%8B%E3%82%89%E6%94%BB%E7%95%A5%E3%81%99%E3%82%8B%E3%80%8EAWS%E8%AA%8D%E5%AE%9A-%E3%82%BB%E3%82%AD%E3%83%A5%E3%83%AA%E3%83%86%E3%82%A3-%E5%B0%82%E9%96%80%E7%9F%A5%E8%AD%98%E3%80%8F-NRI%E3%83%8D%E3%83%83%E3%83%88%E3%82%B3%E3%83%A0%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BE/dp/4839970947\n\nめちゃくちゃ良かったです。\n試験で出るサービスがほぼ網羅されていると思います。\n\nサービスに対しての説明は少し不足していると思うので、BlackBeltや公式サイトで補完した方がよいと思います。\n\nチュートリアルのリンクとかもあるので、\n実際手を動かして試すことも良いと思います。\n\n### 公式の模擬試験を受ける\n他の試験を合格していたので、無料で受けることができました。\n自分の苦手分野や出題傾向の雰囲気を掴むことができると思います。\n\n### AWS公式のトレーニング(無料)を受ける\n模擬試験や章末問題は必ず理解した方が良いです。\nhttps://www.aws.training/Details/eLearning?id=45684\n\n### Black Beltを見る\n[AWS Black Beltリンク](https://aws.amazon.com/jp/aws-jp-introduction/aws-jp-webinar-service-cut/)\n\n以下のサービスのは見といたほうがよいと思います。(重要そうな順に並べました)\n\n- IAM\n- KMS\n- S3\n- CloudWatch\n- AWS Config\n- SystemsManager\n- Cognito\n- CloudFront\n- AWS WAF\n- Trusted Advisor\n- Athena\n- Shiled\n- Detective\n- Lambda\n- GuradDuty\n- Macie\n- CloudTrail\n- Active Directory\n- AD Connector\n\n## 試験を受けての感想\nAWSの裏側の暗号化の扱い方や、セキュアなインフラ構成など、\n広く知ることができたので、とても良い試験だと思います。\n\n試験中はそんなに迷う問題も無く、高得点で終えられたの良かったです。\n\n## その他、勉強中に重要そうと思ったまとめ\n\n- KMSのキーポリシー\n- KMSのCMK自動ローテーション\n- KMSのEncryption Context\n- KMSのインポートキー\n- S3のぼーるとロック\n- CloudFrontのルール\n- ALBにアクセスする古いOS(Windows XPとか)の挙動\n- CloudFrontとALBの証明書の設置\n- VPCフローログの見方\n- CloudTrailのデフォルトで保持してくれる期間と、その期間過ぎた後のログの扱い\n","user":"gdtypk","created_at":"2021-03-29T09:12:36+09:00","updated_at":"2021-03-29T09:12:36+09:00"},{"url":"https://qiita.com/YOCKOW/items/78e38d423bb4c8f044ca","title":"10年前の世界からやってきたオッサンがCGIをSwiftで書いてみる","body":"# タイトルの意味(≒この記事の概要)\n\n* およそ10年ぶりに[個人サイト](https://YOCKOW.jp/-)[^personal-site]を更新してみた。\n* 全てのページを[Perl](https://www.perl.org)によるCGIで生成していたが、[Swift](https://swift.org)で一から書き直した。\n* しかし、サーバやCSS, HTMLに関する知識は10年前から変わっていない[^knowledge]。\n* 即ち**10年前からタイムスリップしてきたことと同じ**だった(誇張)。\n\n[^personal-site]: ここでいう「個人サイト」とは、「自分の自分による自分のためのサイト」のこと。\n\n[^knowledge]: 実際には2003年ぐらいの知識で止まっているような感覚。そして、もともと知識は乏しい。\n\nそれを踏まえてSwiftでCGIプログラムを書いた経緯をインタビュー形式で記事にします。なぜインタビュー形式なのか、それは永遠の謎です。\n\n一応、CGIプログラムについて基礎的なことから書いてあります。Swiftに限らずいろんな言語でCGIを書くきっかけになれば…。\n\n\n# SwiftでCGI\n\n## そもそもCGIって…\n\n**通りすがりの知ったかぶりインタビュアー(以下I)**: [CGI](https://ja.wikipedia.org/wiki/Common_Gateway_Interface)という言葉自体が死語になりつつあるようですが？\n\n**10年前の世界からやってきたオッサンこと[YOCKOW](https://qiita.com/YOCKOW)(以下Y)**: そうなんですか？昔は自分のサイトに*掲示板(死語)*や*チャット(死語)*を設置するために**フリーのCGIプログラム**をもらってくることが流行った気がします。でも、自分が借りてる*レンタルサーバー*の環境に合わなくてプログラムを修正しなきゃいけなかったり、細かい仕様が気に入らなかったり…。それなら自分で最初から作っちゃえば良いじゃん、ってなってCGIのプログラムを書き書きし始める…というのが一般的な流れでした(N=1)。そういう意味でCGIという言葉はサイト運営をする上で切っても切り離せないものでした。\n\nI: もちろん今もCGIという仕組みが無くなった訳ではないですが、動的なページを作るのにCGIの仕様を意識しなければいけない環境は減っていると言えます。Webアプリケーションのバックエンドを作るにしても便利なフレームワークがありますし、クラウド・アプリケーション・プラットフォームなどというものまでありますからね。\n\nY: ただ、個人サイトを作るだけなら、そんな大層なソフトウェアを使わなくても…という気はします(10年前の感覚)。だって、CGIは標準出力に文字列(データ)を書き出すことができればそれで良い訳ですから。もちろん`POST`を処理するなら標準入力も扱えないといけないですけど。**なんなら[bash](https://www.gnu.org/software/bash/)でだってCGIは書けます**[^cgi-with-command-tools]。\n\n[^cgi-with-command-tools]: 他の例→[Perlから始めないCGI入門](https://qiita.com/amanoese/items/c86eab16f08456b0fbae)\n\nI: ところで、10年前にはSwiftは存在していませんでした[^swift-birth]。当時は何の言語でCGIを？\n\n[^swift-birth]: Swiftは2014年6月登場。\n\nY: **当然**Perlですね。CGIといえばPerl、PerlといえばCGIという時代でした。次点でPHPでしょうか。Yahoo!知恵袋に**「CGIとPerlって何が違うんですか？」**みたいな質問がいくつもありました[^q-cgi-perl]。\n\n[^q-cgi-perl]: 実例→ https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q147029824\n\nI: 「法律と警察って何が違うんですか？」みたいな質問ですね。\n\nY: 確かに質問として本来成り立たないはずのものですが、それだけ**CGIといえばPerlという“常識”**があったのでしょう。\n\n\n## CGIプログラムの実際\n\nI: “CGIは標準出力に文字列を書き出すことができれば良い”という話がありましたが、具体的にはどうすればいいのでしょうか？\n\nY: 厳密な話は[RFC3875](https://tools.ietf.org/html/rfc3875)を読んでいただくとして、最低限`Content-Type`ヘッダ行と0バイト以上のボディーさえあればOKです。Perlで書くと\n\n```Perl:simple.cgi\n#!/usr/bin/perl\n\nprint \"Content-Type: text/plain; charset=utf-8\\n\";\nprint \"\\n\";\nprint \"Hello, CGI.\";\n```\n\nY: これだけで\"Hello, CGI.\"という文字を表示するCGIの完成です。ちなみに、HTTPヘッダの改行は必ず`CR+LF`でなくてはなりませんが、CGIプログラムの段階での改行コードは`LF`で問題ありません。なぜなら、Webサーバが**必ず改行文字を`CR+LF`に変換してくれる**からです[^rfc3875-section-6.3.4]。\n\n[^rfc3875-section-6.3.4]: https://tools.ietf.org/html/rfc3875#section-6.3.4\n\nI: ところで、上記のコードではHTTPレスポンスコードが指定されていませんが、どうなっているのでしょうか？\n\nY: 基本的に、CGIが正常終了すれば`200`、異常終了すれば`500`ですね。\n\nI: え？それだけですか？\n\nY: まぁ、もちろん、それだけではないです。CGIでは`Status`という特別なフィールドが規定されています[^rfc3875-section-6.3.3]。他のHTTPヘッダと同じように`Status: 200 OK`などと出力すれば、Webサーバが**良きに計らってくれて**適切なHTTPレスポンスに変換されます。もちろん404なら`Status: 404 Not Found`とします。Reason Phraseを自分で決めることもできます。`Status: 500 I have given up`とかでも問題ありません[^reason-phrase]。\n\n[^rfc3875-section-6.3.3]: https://tools.ietf.org/html/rfc3875#section-6.3.3\n\n[^reason-phrase]: HTTP/2だとreason phraseが空文字列に…🥺\n\nI: 文字列を出力するだけでいいなら、確かにどんな言語でも良さそうですね。\n\nY: そうですね。もちろんSwiftでもCGIプログラムを書くことが可能です。\n\n```Swift:cgi.swift\n#!/usr/bin/swift\n\nprint(\"\"\"\n  Status: 200 Swift is also OK\n  Content-Type: text/plain; charset=utf-8\n  \n  Hello, Swift CGI.\n  \"\"\")\n```\n\nI: **Swiftでも[shebang](https://ja.wikipedia.org/wiki/%E3%82%B7%E3%83%90%E3%83%B3_%28Unix%29)が使える**んですね。\n\nY: そうなんです[^swift-shebang]。ただ、shebangを使うと単一ファイルのコードしか実行できないですし、<small>Swiftはお世辞にもコンパイルが早いとは言えないので(小声)</small>、予めコンパイルした実行ファイルをCGIプログラムとして起動することをお勧めします。\n\n[^swift-shebang]: https://takuya-1st.hatenablog.jp/entry/2017/03/03/164033\n\n\n## CGIに使える言語\n\nI: 今回CGIを一から作り直すにあたって、最初から言語をSwiftにすると決めていたのでしょうか？\n\nY: それを話すと少し長くなりますが良いですか？\n\nI: (え、めんどくさい…)\n\nY: 私が個人サイト[^personal-site]を立ち上げたのは1999年の春でした。確か「フリーティケットシアター」(freett.com)[^freett]を利用していましたね。\n\n[^freett]: 2016年3月末でサービス終了\n\nI: (話し始めちゃった…)\n\nY: そして、CGIが使えるレンタルサーバに移ったのが2002年頃です。その頃から一部のページをCGIで表示するようになり、遅くとも2003年にはほぼ全てのページをCGIで出力するようにしました。たぶん。\n\nI: 先の話にあったように、その時使っていた言語はPerlだった訳ですね。\n\nY: そうです。最初の頃は[とほほのWWW入門](http://www.tohoho-web.com/)にお世話になりました。\n\nI: 今や老舗のサイトですね。\n\nY: 当時、Mac OS X(macOSの当時の名前)用のソフトウェアを公開することも自分のサイトの目的の一つでした。そして、[Objective-C](https://ja.wikipedia.org/wiki/Objective-C)を触っているうちに気づいてしまったのです。\n\nI: と言いますと？\n\nY: **オブジェクト指向は素晴らしい！**\n\nI: あぁー…。\n\nY: ただ、今思い返すと、オブジェクト指向そのものが素晴らしいというよりは、[Cocoa](https://ja.wikipedia.org/wiki/Cocoa) (= Foundation + AppKit)が素晴らしいということだったとは思いますけどね。ちなみに、木下誠氏[^makoto-kinoshita]の書籍やWeb連載が好きでした。\n\n[^makoto-kinoshita]: 現[エイチエムディティ株式会社](http://hmdt.jp/)社長。\n\nI: なるほど。\n\nY: 本当にFoundationが好きすぎて、PerlでFoundationを再実装するような行為に勤しんでいました。もちろん、完コピではなく自分が必要とする部分だけの実装でしたが。たとえば、`NSString`に倣って書いた`HTB::String`(HTBは当時のサイト名にちなんだprefix)では、\n\n```Perl:String.pm\nsub stringByReplacingOccurrencesOfString_withString_options_range {\n  my $self = shift;\n  my $target = shift;\n  my $replacement = shift;\n  my $options = shift;\n  my $searchRange = shift;\n\n  # 以下実際のコード\n  # :\n}\n```\n\nY: というようにメソッド(Perl用語ではサブルーチン)の名前を付けていました。\n\nI: Foundationにおけるネーミング[そのまま](https://developer.apple.com/documentation/foundation/nsstring/1416484-stringbyreplacingoccurrencesofst?language=objc)ですね。\n\nY: ただ、Perl(Perl 5)は「オブジェクト指向*のような*書き方ができる」程度で、言語レベルでクラス定義などをサポートしていませんでした。…ですよね？当時、\"Perl 6\"が出る出ると言われて全然出なかったこともあり[^perl6]、Perl以外の言語も考えていました。しかし、2008年ごろから<ruby>現実世界<rt>アクチュアル・ワールド</rt></ruby>が忙しくなってプログラミングに時間を割けなくなりました。さらに、2010年頃は[ゆるキャラ](https://ja.wikipedia.org/wiki/%E3%82%86%E3%82%8B%E3%82%AD%E3%83%A3%E3%83%A9)や[某音ゲー](https://ja.wikipedia.org/wiki/REFLEC_BEAT)のことしか考えていませんでした。こうしてプログラミングのブランクが始まったのです。2012年に一念発起してCGIを一からPerlで書き直したのですが8割方完成したところで諸事情により再び中断することになりました。\n\n[^perl6]: 2000年に設計が始まったPerl 6の正式リリースは2015年12月25日のこと。結局Perl 5との互換性はなく、のちに言語名がRakuに変わった。\n\nI: (途中のよくわからない話は無視して)次にプログラミングを始めるのは？\n\nY: まずは**2016年**にVPS(Virtual Private Server)を借りることにしました。多少(時間や金銭に)余裕ができたので。レンタルサーバが公園の砂場なら、VPSは無人島[^desert-island]というところでしょうか。[『何もないから、なんでもできる』](https://www.google.com/search?q=%22%E4%BD%95%E3%82%82%E3%81%AA%E3%81%84%E3%81%8B%E3%82%89%E3%80%81%E3%81%AA%E3%82%93%E3%81%A7%E3%82%82%E3%81%A7%E3%81%8D%E3%82%8B%22)みたいな。でも、すぐに何かをしたいというよりは、いつか何かできたらいいなという感じでした。最初、CGIに使う言語としては[Ruby](https://www.ruby-lang.org/)を考えていました[^without-rails]。日本発の言語で日本語の資料も豊富にあったというのも理由です。Rubyでのプログラミングは実際楽しかったです。Perlの`AUTOLOAD`[^perl-autoload]をRubyでも実現させてみたり。でも、『Rubyは遅い』みたいな話もあったりして。ここらへんは結局宗教論争のようなところはあるので、どうでもいいと言えばどうでもよかったのですが…。そもそも速さを求めるようなサイトではないですし。それでもなんとなく速さのことが気になって…。そこで、速さのことを考えるならそもそもインタプリタ方式ではなくて**コンパイラ方式にすればええやん**と思ったのです。VPSなら色んなコンパイラを導入できますしね。\n\n[^desert-island]: 専サバに比べれば狭い無人島なのでしょうが…。\n\n[^without-rails]: もちろんRailsは使わない\n\n[^perl-autoload]: 参考記事[『AUTOLOADについて』](https://qiita.com/mp0liiu/items/c1205cba9ea22cbdbbf8)\n\nI: なるほど、それでSwiftに？\n\nY: いいえ、**[C言語](https://ja.wikipedia.org/wiki/C%E8%A8%80%E8%AA%9E)** です。\n\nI: まさかのC。…なぜSwiftではなかったのでしょう？Swiftは2015年末にはオープンソース化もされ、名目上Linux対応も謳っていましたが。\n\nY: ただ単に**Swiftを知らなかった**のです。Mac OS X用のソフトウェアを作ったのは2005年が最後でした[^last-mac-software]。そこからはMacソフト開発からは遠ざかっていたので、Swiftなどというものの存在に触れる機会がなかった訳です。結果的に、まずはC言語を試すことになりました。\n\n[^last-mac-software]: 最後に作ったソフトは\"DKT\"という[ディベート甲子園](https://nade.jp/koshien/)専用のタイマー。2005年に[愛・地球博](http://www.expo2005.or.jp/)で開催された第10回大会で実際に使用した。\n\nI: そういえば、かの「2ちゃんねる」(現・5ちゃんねる)も軽量化のためにかつてPerlからC言語に移行したなんていうこともありました<sup>*\\[要出典\\]*</sup>。\n\nY: C言語でまずやり始めたのは…また**Foundationの猿真似**でした。2005年頃にPerlでやっていたことを再度始めたのでした。これも今思い返してみれば、[Core Foundation](https://developer.apple.com/documentation/corefoundation)を使えばそれで良かったんですよね。Objective-CのFoundationはプロプライエタリですが、C言語で書かれた**Core Foundationはオープンソースかつクロスプラットフォーム**ですからね。どうしても**車輪の再発明が大好きな<ruby>質<rt>たち</rt></ruby>なので**、一から作ることを先に考えちゃうんですよね。まぁ、それはそれで楽しかったです。メモリ管理とか、ディクショナリのためのハッシュ関数を自作したりとか。楽しかったけど、もちろん、面倒でした。なので、C言語から別の言語を使うことを考え始めて…。\n\nI: そこでSwift？\n\nY: いいえ、**Objective-C**です。\n\nI: おっと。もしかしてサーバをMacに…？\n\nY: Linuxです。Objective-Cは決してMac専用の言語ではありません。その誕生は1983年(または1984年？)と古く、[GCC](https://gcc.gnu.org/)も標準でObjective-Cをサポートしています。もちろんFoundationは前出の通りプロプライエタリなのでLinuxでは使えませんが、[GNUstep](http://gnustep.org/)があります。GNUstepはNeXTのOPENSTEPと互換性を持たせたフリーソフトウェアです[^gnustep]。ご存知の通り、NeXTはのちにAppleに買収され、OPENSTEPのObjective-CライブラリはCocoaと名前を変え開発が進められることになります。GNUstepはAppleのCocoaに追随しており、Mac, Linux両方で開発を進められると思っていたのです…。\n\n[^gnustep]: Unix系OSだけでなくWindowsでも動作する。\n\nI: 思って*「いた」*？\n\nY: はい。実際初期のコードはMacでもLinuxでも動作したのですが、FoundationのAPIをいろいろ調べているうちに違和感を覚えるようになったのです。…違和感の正体は[Objective-C 2.0](https://ja.wikipedia.org/wiki/Objective-C#Objective-C_2.0)でした。Objective-C 2.0はMac OS X v10.5 Leopardとともに登場したものです。つまり2007年登場です。当時(2016年頃)で既に登場から10年ほど経っているので、Objective-C 2.0は当たり前のように使われていました。しかし、前述の通り私が最後にMac OS X用のソフトウェアを作ったのは**2005年**のことです。Objective-C 2.0などというものを知る由もありませんでした。調べていくと、Linuxでも[libobjc2](https://github.com/gnustep/libobjc2)を使えばObjective-C 2.0が利用できると分かったのですが、自分の中でObjective-C 2.0は新しい言語を覚えるような気分でした。一方で、FoundationのAPIをApple Developerのサイトで調べているときに気づいたことがありました。\n\nI: それは…？\n\nY: ページの右上に\"Language\"を選択するメニューがあったのです。Languageといっても日本語や英語という意味ではなく、プログラミングの言語を選択するメニューです。…Objective-CとSwiftが並んでいました。そこから「Swiftって何だろう？」と調べるようになりました。その時、Swiftのバージョンは2.2で、もうすぐ3が登場するだろうというタイミングでした。最初に見た時は、一見してスクリプト言語のような印象だったので、**AppleScriptの進化版か何か**かと思っていました。でも、Qiitaで[@koherさん](https://qiita.com/koher)や[@omochimetaruさん](https://qiita.com/omochimetaru)の記事を読んだりして、思ったのです。**「SwiftはObjective-Cを置き換えようとしている」**と。実際にAppleがどういう意図をもってSwiftを開発しているのかはわかりませんでしたが、そう思った瞬間、自分のCGIプログラムの言語はSwiftにすることに決まりました。Linuxでも使えるということはもちろん、今後、[Darwin](https://ja.wikipedia.org/wiki/Darwin_%28%E3%82%AA%E3%83%9A%E3%83%AC%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0%29)プラットフォーム(macOSやiOS)のソフトウェアを開発するときにも必ず役に立つと考えたからです[^darwin-software]。\n\n[^darwin-software]: 結局開発してませんが。\n\nI: やっとSwiftに辿り着きましたね(長かった…)。\n\n\n## CGIとSwift\n\nY: まずはLinuxでSwiftコンパイラを動かすところから始めました。当時はCentOSを使っていたのですが、CentOS用のバイナリが配布されておらず、Swiftを2時間ぐらいかけてビルドした記憶があります。しかもFoundation(Swiftで書かれたFoundation)のビルドに失敗してやり直しになるという…。のちにUbuntuに乗り換えたのですが、今はCentOS以外にもAmazon Linux 2用のバイナリまで配布されるなど、便利になりました。\n\nI: 今はLinuxどころかWindows用までありますからね[^swift-for-windows]。\n\n[^swift-for-windows]: https://swift.org/download/#releases\n\nY: 当時既にSwiftはオープンソースになっていたのですが、Swiftで検索してもDarwin以外のプラットフォームで動かす情報が少なかったように思います。そこで、少しずつ自分が得た知見を共有しようと、Qiitaの記事もたまに書くようになりました。初めて書いた記事は、[『C言語とSwiftを一つのプロジェクトで混在させてみる(OS X, Linux)』](https://qiita.com/YOCKOW/items/3b56f546f2bf9bbce5f6)(2016年5月)です。[Swift Package Manager](https://swift.org/package-manager/)がまだ無かった時代の記事ですね。ちなみに、これまでに投稿したSwiftに関する記事は**全てDarwinでもLinuxでも動作するコード**を前提に記載しています。\n\nI: CGIだけであればSwiftUIとかは関係ないですからね。\n\nY: そしてSwiftに多少慣れたタイミングでCGIプログラムを作るためのライブラリを作り始めました。その名も[SwiftCGIResponder](https://github.com/YOCKOW/SwiftCGIResponder)。`CGIResponder`という[単純なstruct](https://github.com/YOCKOW/SwiftCGIResponder/blob/d0f488199b24eb95e682bba96835509533f3d9db/Sources/CGIResponder/CGIResponder.swift#L14)を用意して、CGIとしての出力を任せるというものです。\n\nI: 一応、その頃には[Kitura](https://www.kitura.dev/)も[Vapor](https://vapor.codes/)も登場済みだとは思いますが…。\n\nY: そうだったんですね。全然気にしてませんでした。Perlの時代と同じように、一からCGIプログラムを書くことしか考えていませんでした。ただ、Perlの時代とは大きく違うことがありました。それは、**Foundationが最初から存在する**ということです。PerlのときもRubyのときもCのときも、まず自分で*Foundationっぽい何か*を作るところから始めていました。Foundation大好きっ子ですからね。それがSwiftではLinuxでもFoundationが使えるのです。\n\nI: Foundationがあれば充分だった、と。\n\nY: その通りです。ですが、それはそれで単純ではありませんでした。Darwinでは、Swiftで使うFoundationはObjective-CのFoundationをインポートする形です。即ちCocoaを(原則)そのままSwiftでも使えます。しかし、Darwin以外のプラットフォームでは、Swiftで書かれたFoundation[^swift-foundation]を使うことになります。そのSwiftFoundationが、**バグと未実装の嵐**だったのです。\n\n[^swift-foundation]: 多くはCore FoundationをSwiftでラップしたもの。\n\nI: となると、Swift以外の言語へ移ることも検討を？\n\nY: そんなことはしません。Foundation大好きっ子なので(2回目)。**バグがあるなら直せば良いじゃないですか**。幸いにもSwiftはオープンソースです。GitHubでPRを送ることもできます。というわけで、あると困るバグは[自分で直しました](https://github.com/apple/swift-corelibs-foundation/pulls?q=author%3AYOCKOW)。こうしてFoundationを使ってCGIプログラムを作るという、**夢のような世界**に到達できたのです。今のところ、SwiftCGIResponderを使うと、\n\n```Swift:CGIResponserSample.cgi\nimport CGIResponder\n\nvar responder = CGIResponder()\nresponder.status = .ok\nresponder.contentType = ContentType(pathExtension: .txt, parameters: [\"charset\": \"UTF-8\"])!\nresponder.content = .string(\"Hello, World!\\n\", encoding: .utf8)\ntry! responder.respond()\n\n// -- Output --\n// Status: 200 OK\n// Content-Type: text/plain; charset=UTF-8\n//\n// Hello, World!\n//\n```\n\nY: のように書くことができます。基本的に`CGIResponder`は単純で、上のコードを見るだけだと「直接文字列を出力すればいいのでは？」となりそうですが、その裏では、HTTP Headerを適切に扱うような仕組み・国際化ドメイン名を含めたドメインの処理・HTTP Cookieと[Public Suffix](https://publicsuffix.org/)の処理・XHTMLパーサ/ジェネレータなどを実装してあります。ただ、コードサイズが大きくなってしまったので、結果として、少しずつ機能を切り離して独立したパッケージにしました。見かけ上、依存するパッケージが多くなりましたが、全部自分で作ったものという…。\n\n> https://github.com/YOCKOW/SwiftCGIResponder#dependencies\n> \n> ![SwiftCGIResponder's Dependencies](https://raw.githubusercontent.com/YOCKOW/SwiftCGIResponder/master/dependencies.svg)\n\nI: 車輪の再発明も含まれていそうですね…。\n\nY: そうですね。でも、車輪の再発明も大好きなので。こうして、2008年ごろから更新が滞り始め2012年には完全に止まってしまったサイトの更新を2021年に再開することができました[^restart]。サイトの更新が目的となってしまっているので中身はないですし、CSSやHTMLの知識は昔のままですが。気付いたら、HTMLはフロントエンドで生成することが主流になっているようで(？)、完全に時代に取り残されていますね[^frontend-html-generation]。本当は[Markdown](https://daringfireball.net/projects/markdown/)のパーサもSwiftで書きたかったのですが、一旦はフロントエンド側で処理することにしました。ただ、その時には**「JavaScript怖い」**という思いは強かったです。\n\n[^restart]: いつまた止まるか分かりませんが。\n\n[^frontend-html-generation]: 実は2012年に作り直した(作り直そうとした)サイトはJavaScriptでページを生成する仕組みでした。しかし、当時のGoogleクローラは動的ページに対応しておらず(たぶん)、JavaScript非対応のクライアントにはPerlでページを生成して返していました。つまり、PerlとJavaScriptで同じ結果を生み出すための同じコードを書かなくてはならず、2倍の作業量になっていたのです。時代を先取りしすぎたのかもしれません…。\n\nI: 何が怖かったのでしょう？\n\nY: 動的型付けだからです。Swiftを長く触ったあとに久しぶりにJavaScriptを触ったので、コード上に型表記できないことやnull safetyがないことに強烈な恐怖心を覚えました。そこからTypeScriptを導入するまではすぐでした。Swiftの素晴らしさの再発見でもありますね。\n\n\n# おわりに: SwiftはCGIに相応しい言語か\n\nI: Swift(というかFoundation)への想いは強いようですが、SwiftはCGIプログラムに相応しい言語と言えるでしょうか？\n\nY: 現在のところ最も相応しいですね、**私にとっては**。当たり前ですが、言語の選択は「誰が何のためにどのような環境で動かすプログラムなのか」によって変わってくるものですから。CGIプログラムに限らない話ですね。最初のほうの話にもあったように、CGIプログラムは標準出力と標準入力を扱うことができればそれで良いのです。bashが一番自分にとって書きやすいのであればbashで書けば良いと思いますし、Cが良ければCで書けば良いという話です。少なくともフレームワークがないと何もできないということはあり得ません。まずは`print`文から始めれば良いと思います。Swiftなら[SwiftCGIResponder](https://github.com/YOCKOW/SwiftCGIResponder)を使っても良いですよ(宣伝)。まぁ、あくまで個人サイト[^personal-site]の開発に限った話ですが。\n","user":"YOCKOW","created_at":"2021-03-29T09:11:39+09:00","updated_at":"2021-03-29T09:11:39+09:00"},{"url":"https://qiita.com/PND/items/dd9ffdc45953cb1b8c13","title":"ディスクを食い潰す Docker volume の落とし穴","body":"# 概要\n- `Dockerfile` の `VOLUME` は予期せずディスクを食い潰す原因になる\n- MySQL など多数の公式 Docker イメージで `VOLUME` が使われているため要注意\n\n# 遭遇した問題\nある時、CI サーバーのディスクが圧迫されており、その大部分を Docker volume が占めていることがわかりました。\n\n```bash\n$ docker system df\nTYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE\nImages              14                  5                   6.787GB             3.283GB (48%)\nContainers          8                   4                   137.5MB             131.4MB (95%)\nLocal Volumes       1281                7                   224.8GB             224.3GB (99%)\nBuild Cache         0                   0                   0B                  0B\n```\n\n更に詳しく調べてみると、ランダムな名前でほぼ同じ中身の volume が大量に残っていて、無駄にディスク容量を食っているようでした。\n\n```bash\n$ docker system df -v\n...\nLocal Volumes space usage:\n\nVOLUME NAME                                                        LINKS               SIZE\n68d96aaf9e8a9098c4ab38c26315f4d25b02b96a51eaf70a7037f655e0dccba4   0                   226.6MB\ncdfb0a70f73d997bf5f7abee7d37adea98891d938da17bda8ae6d25ca5decc71   0                   228.6MB\nf043ee71a3a318ae6479bf0205d3192666ca58b43582572b41046421f502cdef   0                   226.6MB\n8d15e829f575564683006cb65340687423749fc6b1e52a5fe0e62c81ed40f2e4   0                   228.6MB\n...\n```\n\n# 問題の原因\nランダムな名前の volume は **anonymous volume** と呼ばれるもので、以下のような場合に作成されます。\n\n- `Dockerfile` に `VOLUME` 指示を書いた場合\n- `docker-compose.yml` や `docker run` のオプションで ` -v /path/in/container` のように指定した場合\n\n前述のケースでは CI のテストに Docker を使用し、終了後にコンテナを削除して後始末していたため、\n起動時に毎回 anonymous volume が新しく作成され、削除されることも再利用されることもなくゴミとして溜まっていたわけです。\n\n一度コンテナから切り離された anonymous volume の出所を特定するのは厄介ですが、\n適当なコンテナに volume をアタッチするなどして中身を調べれば手がかりが得られます。\n\n```sh\n$ docker run -it --rm -v <volume の名前>:/volume busybox sh\n$ ls /volume\nauto.cnf\t client-key.pem  ibdata1\t     private_key.pem  sys\nca-key.pem\t ib_buffer_pool  ibtmp1\t\t     public_key.pem\nca.pem\t\t ib_logfile0\t mysql\t\t     server-cert.pem\nclient-cert.pem  ib_logfile1\t performance_schema  server-key.pem\n``` \n\n今回 anonymous volume を作り出していた大元の原因箇所は、ベースとして使用する [MySQL 公式の Docker イメージ](https://github.com/docker-library/mysql/blob/d72fdef749b3b6c140e4b0d6a87f12737ed3554a/8.0/Dockerfile.debian#L87)の中にありました。\n\n```dockerfile:Dockerfile\nVOLUME /var/lib/mysql\n```\n\n`Dockerfile` で一度指定された `VOLUME` は、派生イメージやコマンドラインオプションなどで解除できないため、\nベースイメージを使用する全てのユーザーが同様の問題に当たる可能性があります。\nこれは MySQL 以外にも多くのメジャーな公式イメージで issue として挙がっており、現在でも解決されていません。\n\n- [Why is there volume for data in the first place? · Issue #255 · docker-library/mysql](https://github.com/docker-library/mysql/issues/255)\n- [Volumes should not be defined in base images · Issue #404 · docker-library/postgres](https://github.com/docker-library/postgres/issues/404)\n- [Volumes should not be defined in base images · Issue #140 · docker-library/redis](https://github.com/docker-library/redis/issues/140)\n- [Should not declare VOLUME for /data/db · Issue #306 · docker-library/mongo](https://github.com/docker-library/mongo/issues/306)\n- [VOLUME declaration can result in difficult to diagnose misbehavior · Issue #410 · docker-library/rabbitmq](https://github.com/docker-library/rabbitmq/issues/410)\n\n\n# 対処法\n## Dockerfile から VOLUME を削除\n根本的に volume を作成させないための方法です。\n\n既に述べた通り `Dockerfile` の `VOLUME` は解除できないので、イメージの使用方法の選択肢を狭めてしまいます。\nvolume の設定は `Dockerfile` の中ではなく、実行時に docker コマンドや `docker-compose.yml` で指定する方が良いでしょう。\n\n問題は、 MySQL 公式のイメージなど、管理外の `Dockerfile` で `VOLUME` が指定されている場合です。\nこの場合は自身でレポジトリをフォークして `Dockerfile` を書き換える以外に解決策がありません。\nしかしこの方法だと、管理すべきコードが増え、フォーク元の変更に追随する手間が発生するためお勧めできません。\n\n\n## 定期的に volume を掃除\n上記の方法が使えない場合、対症療法として volume を定期的に削除する手があります。\n\n```bash\ndocker volume ls -f dangling=true --format \"{{ .Name }}\" | grep -E '^[a-z0-9]{64}$' | xargs --no-run-if-empty docker volume rm\n```\n\n例えばこのコマンドを実行すると、以下の流れで anonymous volume をまとめて削除してくれます。\n\n1. 使用されていない volume のリストを取得\n1. 名前が英数字 64 文字の anonymous volume だけをフィルタ\n1. 該当する volume を削除\n\nただし、**本当に必要な volume まで削除してしまわないか事前によく確認しておきましょう**。\n","user":"PND","created_at":"2021-03-29T08:57:35+09:00","updated_at":"2021-03-29T08:57:35+09:00"},{"url":"https://qiita.com/antk/items/c5fa1a252ef581d3e45e","title":"【Swift】遷移先のTabBarControllerを非表示にする","body":"# どういうことか\n\n遷移先ページの下のタブバーを非表示にしたい。\n\n```swift:NextViewController.swift\nself.tabBarController?.tabBar.isHidden = true\n```\n\n遷移先の `viewDidLoad()` にこれを書いても非表示にはなるが、なんらかの処理で遷移元に戻っても消えたままになってしまう。\n\n## 遷移する処理に追加する\n\n```swift:ViewController.swift\nlet storyboard = UIStoryboard(name: \"NextViewController\", bundle: nil)\nlet vc = storyboard.instantiateViewController(identifier: \"NextViewController\")\n\n// コレ\nvc.hidesBottomBarWhenPushed = true\n\nself.navigationController?.pushViewController(vc, animated: true)\n```\n\nおわり(´・ω・｀)\n","user":"antk","created_at":"2021-03-29T08:43:11+09:00","updated_at":"2021-03-29T08:43:11+09:00"},{"url":"https://qiita.com/NA_simple/items/cccdab7f4370b0f5dcb2","title":"【環境構築】electron-vue と node_addon_api を連携し、C++とVue.jsを使ってelectronアプリを開発する","body":"## この記事の用途\n- electron + vue.jsでモダンなデスクトップアプリ開発を行う\n- C++プログラムと連携する（活用例: 機械学習アプリなど、高速な計算が必要となる場面）\n    - この記事では、環境構築に重点を置いて説明しています。\n\n## 登場人物\n- electron: Webブラウザベースで動くデスクトップアプリ開発フレームワーク\n- Vue.js: フロントエンド開発フレームワーク\n- node_addon_api: javaScriptからC++資産を利用するためのフレームワーク\n    - node_addon_apiを使ったことがない方は、[こちらの記事](https://qiita.com/NA_simple/items/dc31f9ae9519602f9f50) もご覧ください！\n\n## バニラelectron と electron-vue の違い\n- はじめに、バニラelectronとの違いを列挙する\n    - ※ バニラelectronとは、特に拡張機能をインストールしておらず、画面を html, css, js で作成したものを指す\n    - [バニラってどういう意味？](https://ja.wikipedia.org/wiki/バニラ_(ソフトウェア))\n\n| | バニラelectron | electron-vue |\n|--|--|--|\n| メインプロセスファイル | main.js | src/background.js |\n| レンダラープロセスファイル | renderer.js | src/main.js |\n| electronBuilderの設定| package.jsonに記述 | vue.config.jsに記述|\n| 出力先フォルダ | dist | dist_electron |\n| .nodeファイルの読み込み | [bindings](https://www.npmjs.com/package/bindings) | [node-loader](https://www.npmjs.com/package/node-loader) |\n\n## 使用するテンプレート\n- [GitHub: electron-vue](https://github.com/SimulatedGREG/electron-vue)\n\n### electron-vueのインストール\n- こちらの記事を参考にインストールする\n    - [vue + electron で windowsデスクトップアプリを作成する](https://qiita.com/quzq/items/608fa811f7ff2c1ae7f3)\n\n## electron-vueで C++ライブラリを使用するための準備\n### node-addon-apiをインストールする\n- C++ソースのビルド環境として、`node_addon_api`を利用する。\n    - node_addon_apiの使用方法は [こちらの記事](https://qiita.com/NA_simple/items/dc31f9ae9519602f9f50) で紹介しています。\n\n- node_addon_apiを使って、C++ファイルをコンパイルする\n    - コンパイルに成功すると、プロジェクトのルートディレクトリ内に `build/Release`フォルダが生成され、そこに.nodeファイルが生成される\n    - ※ もし、コンパイルしたC++ファイルがOpenCVなどのDLLに依存している場合、`build/Release`内に .dllファイルを設置しないといけません。\n\n- 以降、node-addon-apiでビルドしたC++ライブラリを `.nodeモジュール`と呼ぶことにします。\n    - 以下に .nodeモジュールを使用するための手順を示します。\n\n### vue.config.jsの作成\n- はじめに、ルートディレクトリ(package.jsonと同階層)に `vue.config.js` を手動で作成する\n    - [なぜ vue.config.jsが必要？](https://stackoverflow.com/questions/62777834/how-fix-dirname-not-defined-when-using-electron-events-with-vue)\n\n#### nodeIntegrationの有効化\n- vue.config.js内の `pluginOptinons`セクション内に下記の記述を追加する\n\n    ```js:vue.config.js\n\n    module.exports = {\n        pluginOptions: {\n            electronBuilder: {\n                pluginOptions: {\n                    nodeIntegration: true\n                }\n            }\n        }\n    }\n    ```\n    - 注) nodeIntegration: true はブラウザ側でのネイティブアプリの実行が可能となるが、セキュリティリスクが高まる \n        - https://nklayman.github.io/vue-cli-plugin-electron-builder/guide/security.html#node-integration\n\n#### builderOptionsセクションの作成\n- 作成したvue.config.js内に__\"builderOptions\"__セクションを追加し、package.json内の __\"build\"__ セクション内の項目を移動する\n    - ※ package.json 内に \"build\" セクションがあると、下記のようなエラーとなるため\n\n        ``` bash:error\n        InvalidConfigurationError: 'build' in the application package.json (\\package.json) is not supported since 3.0 anymore. Please move 'build' into the development package.json\n        ```\n\n-  \"builderOptions\"内に、\"extraResources\"セクションを設けて、node_addon_apiでビルドした.dllと.node拡張子を登録する\n    - これにより、`dist-electron/win-unpacked/resources` フォルダ内(※ windowsの場合)にビルドしたファイルが転送され、electron側で読み込めるようになる\n\n        ```js:vue.config.js\n        \"extraResources\": [\n            \"./build/Release/*.node\",\n            \"./build/Release/*.dll\"\n        ],\n        ```\n\n#### builderOptionsセクションの設定項目一覧\n- vue.config.js内の __builderOptions__ 内で設定できるセクション名は下記を参照のこと\n    - [electron-builder: Common-configuration](https://www.electron.build/configuration/configuration)\n\n### node-loaderをインストールする\n- node-addon-apiでビルドした.nodeファイルを読み込むために使用する[（node-loader）](https://www.npmjs.com/package/node-loader)\n    - 初めに npm installを行う\n        - `npm install node-loader`\n\n- vue.config.js内の `pluginOptinons`セクション内に下記の記述を追加する\n\n    ```js:vue.config.js\n        pluginOptions: {\n            // ---- ここから↓ ---- //\n            target: 'node',\n            node: {\n                __dirname: false,\n            },\n            module: {\n                rules: [\n                    {\n                        test: /\\.node$/,\n                        loader: 'node-loader',\n                    },\n                ],\n            },\n            // ---- ↑ここまで ---- //\n            electronBuilder: {\n                ...中略\n            }\n        }\n    ```\n\n- ここまでの準備で、electron側から.nodeアプリを呼び出す準備ができた。\n\n## メインプロセスで .nodeモジュールを使用する\n- src/background.jsで以下のように読み込む。\n    - `__non_webpack_require__` 関数を使用し、.nodeファイルのパスを直接指定する\n    - ※ バニラelectron で使用していた `require(\"bindings\")(\"addon\")`コマンドは使用できない\n\n        ```js:background.js\n            const path = require('path'); // pathモジュールインポート\n            console.log(\"__dirname\",__dirname); // Debug: ルートパスの表示\n            // .nodeファイルのパスを直接指定\n            var nodePath = path.dirname(__dirname) + '/build/Release/○○○.node';\n            var addon = __non_webpack_require__(nodePath);\n            var obj = new addon.○○○(); // nodeモジュールのインスタンス化\n        ```\n\n    - ※ ここでモジュールを読み込むことができるのは、vue.config.js内の __\"extraResourcesFiles\"__ セクションで .nodeファイルと、.dllファイルを登録しているから。\n\n## レンダラープロセスで .nodeモジュールを使用する\n- `preload.js`を経由して .nodeファイルを読み込む必要がある\n\n### preload.jsの作成\n- src/preload.jsを手動で作成する\n- vue.config.jsに以下の項目を追加する\n\n```js:vue.config.js\n    pluginOptions: {\n        nodeIntegration: true,\n        preload: 'src/preload.js' // 追加\n    }\n```\n\n- background.jsのcreateWindow()関数内で下記を追加する\n\n```js:src/background.js\nfunction createWindow() {\n  // Create the browser window.\n  const win = new BrowserWindow({\n      webPreferences: {\n          nodeIntegration: process.env.ELECTRON_NODE_INTEGRATION,\n          preload: path.join(__dirname, 'preload.js'),　// 追加\n      }\n  })\n```\n\n\n### preload.js内で .nodeモジュールを呼び出す\n- 呼び出し方は、 background.jsとほぼ同じ\n    - 相違点は最後の1行。`window.変数名` として登録することで、レンダラープロセスから利用できる\n\n    ```js:preload.js\n        const path = require('path'); // pathモジュールインポート\n        console.log(\"__dirname\", __dirname); // Debug: ルートパス\n        var nodePath = path.dirname(__dirname) + '/build/Release/○○○.node';\n        var addon = __non_webpack_require__(nodePath);\n        var obj = new addon.○○○();\n        window.obj = obj; // !重要: windowオブジェクトに紐付けることで、app.Vueから呼び出せる\n    ```\n\n- App.vueから、preload.jsで呼び出したモジュールを利用する\n    - windowオブジェクトから変数を参照する\n\n    ```js:App.Vue\n      var obj = window.obj; // windowオブジェクトから参照する \n      obj.funcA(); \n    ```\n\n- [参考にしたStackOverflow](https://stackoverflow.com/questions/57807459/how-to-use-preload-js-properly-in-electron)\n   - ※ ゆくゆくは[context-bridge](https://www.electronjs.org/docs/api/context-bridge)を使った方がセキュアだと思います。\n\n## その他Tips\n#### よくあるミス\n- <u>関連するDLLを build/Releaseフォルダに置いていない\n  - \" __build/Release/○○.node__ が見つからない\" とのエラーが出たときは、DLLも確認すること</u>\n\n#### electron + vue で複数ページのアプリを作る方法\n- https://github.com/nklayman/electron-multipage-example\n  \n#### 静的ファイル(assets, images)をコピーする方法\n- vue.config.js の builderOptions内に、`extraFiles`セクションを追加する\n\n    ```js:vue.config.js\n        \"extraFiles\": [\n                    \"images/*.png\",\n                    \"config/**/.txt\"\n        ]\n    ```\n\n#### electron-vueで sass, scss を使う方法\n- `npm install --save-dev sass-loader node-sass`\n    - https://github.com/SimulatedGREG/electron-vue/blob/master/docs/en/using_pre-processors.md\n- npm install 時にエラーが出たら... 古いバージョンを指定して再度インストールする\n    - 例:  `npm install --save-dev sass-loader@10.1.1`\n    - こちらが参考になる -> [StackOverflow](https://stackoverflow.com/questions/66082397/typeerror-this-getoptions-is-not-a-function)\n\n#### レンダラープロセスから、dialogを利用する方法\n- background.js で画面を生成する際に、`enableRemoteModule: true`オプションを追加する\n\n    ```js:background.js\n    new BrowserWindow({\n        webPreferences: {\n            enableRemoteModule: true, // 追加\n         }\n     });\n    ```\n\n## リンク集\n- [__ElectronでcontextBridgeによる安全なIPC通信__](https://qiita.com/pochman/items/64b34e9827866664d436)\n- [__ non_webpack_require__ は、レンダラプロセスで使用できない](https://stackoverflow.com/questions/46185302/non-webpack-require-is-not-defined)\n- electron + Reactでの開発も可能なようだ\n    - [GitHub: secure-electron-template](https://github.com/reZach/secure-electron-template)\n\n\n","user":"NA_simple","created_at":"2021-03-29T08:40:51+09:00","updated_at":"2021-03-29T11:30:02+09:00"},{"url":"https://qiita.com/kang_ping/items/267396abe0e4a08353c1","title":"ピックアップ","body":"library(readr)\n\nsignal_list<-read_csv(\"./signal_list.csv\")\nsignal_master<-read_csv(\"./signal_master.csv\")\n\n#対象がall\n#\n\nmaster<-signal_master$signal\n\nfor (list in 1:3) {\n  tar<-signal_list[list,\"signal\"]\n  tar_val<-as.character(tar)\n  pick<-signal_master[signal_master$signal==tar_val,]\n  \n  pick_dem<-pick[,\"dem\"]\n  pick_dem_val<-as.character(pick_dem)\n  \n  #条件にあった場合優先度を下げる\n  pick_dem_val\n  pri_val<-signal_list[list,\"pri\"]-1\n  signal_list[list,\"pri\"]<-pri_val\n  \n}\n","user":"kang_ping","created_at":"2021-03-29T08:34:01+09:00","updated_at":"2021-03-29T08:34:01+09:00"},{"url":"https://qiita.com/tukiyo3/items/e9889200883ff3a8a596","title":"Visual Studio 2017 で Assembly が不足しているのを解決する方法","body":"## 現象\n\nvs2015 Express や vs2019 Community ではビルドできるプロジェクトを\nvs2017 WDExpress で開くと、以下参照が見つからない。\nSSDT や NuGetしてみたがイマイチ解決しなかった。\n\n```go\nMicrosoft.Data.Tools.Components\nMicrosfot.Data.Tools.Schema.Sql.UnitTesting\n```\n\n![ng.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/25728/6173fee5-ef05-a339-d397-8a647aa26969.png)\n\n\n## 解決方法 (`.csproj`から削除)\n\nプロジェクトの`.csproj`ファイルを直接編集し、以下2行を削除し解決した。\n\n```diff:プロジェクトの.csproj\n- <Import Project=\"$(SQLDBExtensionsRefPath)\\Microsoft.Data.Tools.Schema.Sql.UnitTesting.targets\" Condition=\"'$(SQLDBExtensionsRefPath)' != ''\" />\n- <Import Project=\"$(MSBuildExtensionsPath32)\\Microsoft\\VisualStudio\\v$(VisualStudioVersion)\\SSDT\\Microsoft.Data.Tools.Schema.Sql.UnitTesting.targets\" Condition=\"'$(SQLDBExtensionsRefPath)' == ''\" />\n```\n\n## 解決方法2 (NuGet)\n\n```go\n// Microsoft.Data.Tools.Components\nInstall-Package Microsoft.Data.Tools.Msbuild -Version 10.0.61707.210\n\n// Microsfot.Data.Tools.Schema.Sql.UnitTesting\nInstall-Package Microsoft.Data.Tools.UnitTest -Version 10.0.60809\n```\n\nとしたが、`Microsfot.Data.Tools.Schema.Sql.UnitTesting`のほうがバージョン不一致になったため、\n`プロジェクトの.csproj`から手で削除した。\n\n* [NuGet Gallery | Microsoft.Data.Tools.Msbuild](https://www.nuget.org/packages/Microsoft.Data.Tools.Msbuild/)\n* [NuGet Gallery | Microsoft.Data.Tools.UnitTest](https://www.nuget.org/packages/Microsoft.Data.Tools.UnitTest/)\n\n\n## 参考\n\n* [データベース単体テストプロジェクトはVisualStudio2017でビルドされません-VisualStudioフィードバック](https://developercommunity.visualstudio.com/t/database-unit-test-project-does-not-build-in-visua/29842)\n","user":"tukiyo3","created_at":"2021-03-29T08:32:24+09:00","updated_at":"2021-03-29T11:05:35+09:00"},{"url":"https://qiita.com/hanohrs/items/a54487dcfc29bda1e55d","title":"Java 16 から利用可能な Unix ドメイン ソケット","body":"Java 16 で [JEP 380: Unix-Domain Socket Channels](https://openjdk.java.net/jeps/380) が取り入れられました。今回はこれをご紹介します。\n\n名前の通り、Unix で使われてきたものですが、Windows 10 April 2018 Update 以降は Windows でもサポートされています。Windows Subsystem for Linux (WSL) や Docker コンテナのように、ホスト OS 上の Unix と通信したい場面が増えたためだと思われます。\n\n私なりにわかりやすくご紹介しようと思いますが、にわかユーザーに過ぎませんので、正確な情報や参考になる実装コードがほしい方は、ぜひ JEP 380 のオーナーさんによる [Inside Java - JEP-380: Unix domain socket channels\n](https://inside.java/2021/02/03/jep380-unix-domain-sockets-channels/) ([Logico Inside の和訳](https://logico-jp.io/2021/02/05/jep-380-unix-domain-socket-channels/)) もご覧ください。\n\n\n# Unix ドメイン ソケットとは\n\n> Unix domain sockets are addressed by filesystem pathnames that look much the same as other filenames: eg. /foo/bar or C:\\foo\\bar.\n\n冒頭でご紹介した [Inside Java の記事](https://inside.java/2021/02/03/jep380-unix-domain-sockets-channels/)では、上記のように説明されています。\n\nつまり、Unix ドメイン ソケットでは、アドレスに /foo/bar や C:\\foo\\bar などのファイル名のようなパス名を使います。ポート番号は使いません。\n\n\n## パイプと比べて\n\nWindows では Unix ドメイン ソケットの役割を、名前付きパイプが果たしてきました。\n\n`echo WebSocket | cat` のようにコマンドをつなぐときに使うパイプ `|` とちょっと似ています。\n\n大きな違いは双方向で通信できることです。この例で cat から echo にデータを送り返すことはできませんが、Unix ドメイン ソケットなら双方向でやり取りできます。\n\n\n## ふつうのソケットと比べて\n\n再び [Inside Java の記事](https://inside.java/2021/02/03/jep380-unix-domain-sockets-channels/)を参考に、ローカルのプロセス間通信に Unix ドメイン ソケットを使う利点をご紹介します。\n\n### 性能\n\n![Comparing TCP/IP and Unix domain for local IPC between two sockets](https://inside.java/images/blog/jep380.jpg)\n\n画像は前述の [Inside Java の記事](https://inside.java/2021/02/03/jep380-unix-domain-sockets-channels/)からの引用です。\n\n127.0.0.1 や ::1 のようなループバックと比べ、TCP/IP の処理が不要なため、レイテンシや CPU 使用率を削減できます。\n\n『詳解UNIXプログラミング 第3版』[^u] には具体的に、以下のように書かれていました。\n\n> インターネットドメインソケットも同じ目的に使えますが、UNIX ドメインソケットはより効率的です。UNIX ドメインソケットはデータをコピーするだけです。処理すべきプロトコルはありませんし、付加したり削除したりするネットワークヘッダもなく、チェックサム計算も必要なく、連番を振る必要もなく、肯定応答を送る必要もありません。\n\n言われてみれば TCP って色々と面倒なことを肩代わりしてくれているのでしたね。アプリの担当範囲ではないので関係ない感じもしますが、高速化は嬉しいです。\n\n#### Windows 10 上の PostgreSQL 13 での実測値は TCP と同等\n\n「[Windows 10 の PostgreSQL 13 で Unix ドメイン ソケット【TCP? なにそれおいしいの？】](https://qiita.com/hanohrs/items/0cd93915fcdd5f8f5057)」で検証した際には、性能は TCP と同じでした。通信がボトルネックになりがちな処理を選んで検証したつもりでしたが、差が出ませんでした。性能への過剰な期待は禁物です。\n\n\n### 安全性\n\nパス名をアドレスにしていれば、うっかり外部に公開してもアクセスされる恐れがありません。「おかしいなー。TCP のポートにつながらないなー。ファイアーウォールを切ってアクセスしてみよう」のように思うことは、Unix ドメイン ソケットを使っていればありません。\n\n2点目は少し意外でした。\n\n> Second, because Unix domain sockets are addressed by filesystem objects, this means standard Unix (and Windows) filesystem access controls can be applied to limit access to a service by specific users or groups, as required.\n\nファイルシステム オブジェクトとしてアクセスされるので、アクセス制御リストにより特定のユーザーやグループにのみアクセスさせることができるそうです。まるでユーザーやグループで制御できるファイアーウォールですね。\n\n### 利便性\n\nDocker などで TCP/IP で通信しようとしてハマらなくて済むそうです。私はめったに Docker を使わないので、よくわかりません。\n\n### 互換性\n\nアドレス形式は全く異なりますが、基本的には TCP/IP のソケットのように扱えるので、両方をサポートしてもあまり負担になりません。\n\n\n\n# Java 16 で何ができるようになったの？\n\nUNIX ドメイン ソケット自体の利点は掴んだところで、今度は解説ブログではなく [JEP 380: Unix-Domain Socket Channels](https://openjdk.java.net/jeps/380) 本体から、概要と目標をご紹介します。\n\n\n## 概要\n\n> Add Unix-domain (AF_UNIX) socket support to the [socket channel](https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/nio/channels/SocketChannel.html) and [server-socket channel](https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/nio/channels/ServerSocketChannel.html) APIs in the java.nio.channels package. Extend the [inherited channel mechanism](https://docs.oracle.com/en/java/javase/15/docs/api/java.base/java/nio/channels/spi/SelectorProvider.html#inheritedChannel()) to support Unix-domain socket channels and server socket channels.\n\njava.nio.channels パッケージの [SocketChannel](https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/nio/channels/SocketChannel.html) に Unix ドメイン (AF_UNIX) のソケットが追加され、[ServerSocketChannel](https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/nio/channels/ServerSocketChannel.html) のAPI が変更されています。`open` メソッドの呼び出し時に [StandardProtocolFamily.UNIX](https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/net/StandardProtocolFamily.html#UNIX) を与えると、[SelectorProvider](https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/nio/channels/spi/SelectorProvider.html) が適切な実装を返してくれます。\n\n\n## 目標\n\n> The goal of this JEP is to support all of the features of Unix-domain sockets that are common across the major Unix platforms and Windows.\n\nWindows でサポートされるようになったし、Unix と共通して使える部分は Java で実装してあげようよ、ということです。まさに、みんなが Java に期待していることをしてくれるわけですね。\n\n\n\n# 使ってみた\n\n動くサンプルを書いてみました。\n\n\n## サーバー側\n\n```UnixDomainServer.java\nimport java.io.IOException;\nimport java.net.StandardProtocolFamily;\nimport java.net.UnixDomainSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\n\npublic class UnixDomainServer {\n    public static final Path PATH = Path.of(System.getProperty(\"java.io.tmpdir\"), \".yubaba\");\n    public static final UnixDomainSocketAddress ADDRESS = UnixDomainSocketAddress.of(PATH);\n\n    public static void main(String[] args) throws IOException {\n        try (ServerSocketChannel ssc = ServerSocketChannel.open(StandardProtocolFamily.UNIX)) {\n            Files.deleteIfExists(PATH);\n            ssc.bind(ADDRESS);\n            try (SocketChannel socketChannel = ssc.accept()) {\n                ByteBuffer buf = ByteBuffer.allocate(1024);\n                socketChannel.read(buf);\n                buf.flip();\n                String introString = new String(buf.array(), StandardCharsets.UTF_8);\n                System.out.println(\"She said, \\\"\" + introString + \"\\\"\");\n                String[] words = introString.split(\"\\\\s\");\n                String lastWord = words[words.length - 1];\n                String name = lastWord.substring(0, lastWord.length() - 1);\n                String declaration = \"From now on, your name is %s!\".formatted(yubaba(name));\n                System.out.println(declaration);\n                socketChannel.write(ByteBuffer.wrap(declaration.getBytes(StandardCharsets.UTF_8)));\n            }\n        }\n    }\n\n    private static String yubaba(String origName) {\n        String[] graphemeClusters = origName.split(\"\\\\b{g}\");\n        return graphemeClusters[0];\n    }\n}\n\n```\n\nパスには一時ディレクトリを使っています。サーバーが湯婆婆なので、一時ディレクトリ内の `.yubaba` をアドレスとして使っています。PostgreSQL で設定ファイルに指定したディレクトリ内の `.s.PGSQL.5432` (5432 は TCP 用ポート番号) をアドレスとしていたので、真似ました。\n\nUnix ドメイン ソケットは使い終わった後も 0 バイトのファイルのようなものが残ります。今回は終了時には削除せず、起動時に残っていたら削除するようにしています。\n\n上記コードで、`buf.flip()` を忘れると、一見正しく動くのですが、実際にはたっぷりヌル文字が入ってしまいますのでご注意ください。私はやりました。\n\nUnix ドメイン ソケットとは無関係ですが、今どきの湯婆婆は extended grapheme cluster を意識すると良いと思います。でも細かいことは考えていないので、表示できない文字とか `\"` で始まる名前とかは名乗らないであげてください。\n\n\n## クライアント側\n\n```UnixDomainClient.java\npublic class UnixDomainClient {\n    public static void main(String[] args) throws IOException {\n        try (SocketChannel socketChannel = SocketChannel.open(StandardProtocolFamily.UNIX)) {\n            socketChannel.connect(UnixDomainServer.ADDRESS);\n            String introString = \"My name is \\uD83D\\uDC69\\u200D\\uD83D\\uDC69\\u200D\\uD83D\\uDC66\\u200D\\uD83D\\uDC66\\uD83D\\uDC7B.\";\n            System.out.println(introString);\n            socketChannel.write(ByteBuffer.wrap(introString.getBytes(StandardCharsets.UTF_8)));\n            ByteBuffer buf = ByteBuffer.allocate(1024);\n            socketChannel.read(buf);\n            buf.flip();\n            System.out.println(\"She said, \\\"\" + new String(buf.array(), StandardCharsets.UTF_8) + \"\\\"\");\n        }\n    }\n}\n```\n\n今どきの子は emoji modifier を使った絵文字を名前に含めることにしました。宮崎アニメにこんな奇天烈な名前のキャラクターは出てこないと思いますが...。\n\n\n## 動作確認\n\n1. UnixDomainServer\n2. UnixDomainClient\n\nの順で実行します。\n\n```plaintext:サーバー側\nShe said, \"My name is 👩‍👩‍👦‍👦👻.\"\nFrom now on, your name is 👩‍👩‍👦‍👦!\n```\n\n```plaintext:クライアント側\nMy name is 👩‍👩‍👦‍👦👻.\nShe said, \"From now on, your name is 👩‍👩‍👦‍👦!\"\n\n```\n\nこのサンプルは1回メッセージをやりとりしたらそれで終わりです。\n\n業務で使うなど、より本格的に利用する場合は [Inside Java の記事](https://inside.java/2021/02/03/jep380-unix-domain-sockets-channels/)に掲載のコードを参考にしてください。冒頭でご紹介したとおり、和訳もあります。\n\n\n## 触れられなかったこと\n\n[Inside Java の記事](https://inside.java/2021/02/03/jep380-unix-domain-sockets-channels/)では、Unix で [SO_PEERCRED](https://docs.oracle.com/en/java/javase/16/docs/api/jdk.net/jdk/net/ExtendedSocketOptions.html#SO_PEERCRED) により [UnixDomainPrincipal](https://docs.oracle.com/en/java/javase/16/docs/api/jdk.net/jdk/net/UnixDomainPrincipal.html) を得ることや、Docker での利用例、`inetd` や `launchd` で起動された時の [inherited channels](https://docs.oracle.com/en/java/javase/16/docs/api/java.base/java/nio/channels/spi/SelectorProvider.html#inheritedChannel()) の仕組みへの言及もあります。興味のある方は、ぜひそちらもご覧ください。\n\n\n# まとめ\n\nJava の標準ライブラリを使って同じマシン内で通信する手段が一つ増えました。コンテナとの通信などのプロセス間通信で活用される技術で、セキュリティ上の利点もあります。TCP ソケットのついでに Unix ドメイン ソケットも使えるようにしておくと喜ばれるかもしれません。\n\n\n[^u]: W. Richard Stevens ほか (2014).『詳解UNIXプログラミング 第3版』. 翔泳社.\n","user":"hanohrs","created_at":"2021-03-29T08:26:44+09:00","updated_at":"2021-03-29T08:26:44+09:00"},{"url":"https://qiita.com/kazuki_k/items/3a6b8ac3d47385963adc","title":"【Rails】Rubocopによるコード解析と修正の方法（airbnb設定）","body":"# Rubocopとは\nRuby(Rails）のコードが、コーディング規約に則っているか解析し、修正までしてくれるgem（＝静的コード解析ツール）。\n*開発現場では、コードの可読性や統一性を保つために、企業やプロジェクト単位で「コードの書き方のルール（コーディング規約）」が設けられていることが多い。\n\n# Rubocopには様々な設定がある\nRubocopが解析する際の基準となるコーディング規約は、上述の通り、あくまで企業やプロジェクト単位で決められたルールなのでバラバラですよね。\n\nそんな中、今回はairbnbで使用されている設定を使用します。\n\n# 準備\n1. Gemfileに以下追記 + `bundle install`\n\n    ```ruby:Gemfile\n    group :development do\n    #中略\n      gem 'rubocop-airbnb'\n    end\n    ```\n2. 設定ファイルの作成\nアプリケーションフォルダ配下（appと同じ階層）に、.rubocop.yml、.rubocop_airbnb.ymlを作成。\n\n3. 設定ファイルの編集\n\n```ruby:.rubocop.yml\ninherit_from:\n  - .rubocop_airbnb.yml\n\n#ここにはrubocopでコード解析したくないファイルやフォルダを指定\nAllCops:\n  Exclude:\n    - 'db/**/*'\n    - 'bin/*'\n    - 'config/environments/*'\n    - 'config/application.rb'\n    - 'config/initializers/*'\n    - 'config/spring.rb'\n    - 'lib/tasks/*'\n    - 'vendor/**/*'\n    - 'path/ruby'\n```\n```ruby:rubocop_airbnb.yml\nrequire:\n  - rubocop-airbnb\n```\n\n# 実行\n#### 1. 違反箇所の解析\n\n`bundle exec rubocop —-require rubocop-airbnb`\n\n#### 2. 違反箇所の修正\n基本的には、検証で使用したコマンドに-aオプションをつけて、解析対象を指定すれば良いだけ。\n\n- ファイル・フォルダ指定：`bundle exec rubocop --require rubocop-airbnb -a {解析対象ファイルorフォルダ}`\n\n- origin/mainと差分があるファイルを指定：`bundle exec rubocop --require rubocop-airbnb -a $(git diff $(git merge-base origin/master HEAD) —diff-filter=d —name-only)`\n\n# 最後に\n-aオプションで自動修正してくれる違反は全てではありません。また、[公式ドキュメント](https://docs.rubocop.org/rubocop/usage/auto_correct.html#safe-auto-correct)でも-aは実験的オプションとありますので、使用には注意してください。\n","user":"kazuki_k","created_at":"2021-03-29T08:22:17+09:00","updated_at":"2021-03-29T08:22:17+09:00"},{"url":"https://qiita.com/hide6974/items/ac0c7724dca5735beea0","title":"仕事が年間3000時間みじかくなる（作成中）","body":"## 朝やることを決める\n\n## 後で書く\n・Google Notion\n・google caleder　に登録\n・探す時間をなくす。\n・メールは一度見たら削除するか、即返信する。\n\n","user":"hide6974","created_at":"2021-03-29T08:16:38+09:00","updated_at":"2021-03-29T08:16:38+09:00"},{"url":"https://qiita.com/baby-degu/items/e183b20dd20b20920e00","title":"すごいReactパッケージ5選","body":"本記事は、Varun Chilukuri氏による「[Five awesome React packages to check out](https://javascript.plainenglish.io/five-awesome-react-packages-to-check-out-1ee42f2c19f7)」（2020年9月8日公開）の和訳を、著者の許可を得て掲載しているものです。\n\n#すごいReactパッケージ5選\n\n>小さくてもインパクトのある変更で、あなたのアプリを競合他社から引き離します。\n\n![Image for post](https://miro.medium.com/max/700/1*I_JUZpOeDH29bn_YnhvvzQ.jpeg)\n\n##1. React Loader Spinner\n\n待つのが好きな人はいません。今やユーザーは最低限の条件として、ウェブサイトが高速であることを求めています。アプリが重いか遅い場合は、コンテンツの読み込み中、この最新のローディングアニメーションを表示しましょう。アプリの美観を向上させるだけでなく、ユーザーを維持するのにも役立ちます。\n\n![React Loader Spinner](https://miro.medium.com/max/700/1*2nJgZmFETW8dRuP75Ch9qw.gif)\n>このパッケージで提供する全ローディングアニメーション\n\n`npm`または`yarn`から直接インストールします。\n\n```javascript\nnpm i react-loader-spinner\n//or\nyarn add react-loader-spinner\n```\n\n[loader.js](https://gist.github.com/VarunChilukuri/4fa7841f76365cb9704bd5835c175ae6#file-loader-js)\n\n次に、必要なimport文を追加します。\n\n```javascript\nimport Loader from 'react-loader-spinner'\n```\n\n[loader.js](https://gist.github.com/VarunChilukuri/18c997b882a75285b238e009bab82e58#file-loader-js)\n\nそして、以下をプロジェクトに追加します。\n\n```javascript\n<Loader\n   type=\"Puff\"\n   color=\"#00BFFF\"\n   height={100}\n   width={100}\n   timeout={3000} //3 secs\n/>\n```\n\n[loader.js](https://gist.github.com/VarunChilukuri/e099b6af9751db6750a3d05076a497f5#file-loader-js)\n\n詳細については、ドキュメントを参照してください。\n\n>**react-loader-spinner**\n>react-spinner-loaderは、非同期の待機中の動作を実装できる、単純なReact SVGスピナーコンポーネントです。\n>[www.npmjs.com](https://www.npmjs.com/package/react-loader-spinner)\n\n##2. React Animated Burgers\n\nこのパッケージは、ナビゲーションバーにアニメーション付きメニューアイコンを追加します。無数のアイコンとアニメーションが用意されています。とても簡単に、カスタマイズとプロジェクトへの追加ができます。私は喜んで何度も使っています。\n\n![React Animated Burgers](https://miro.medium.com/max/581/1*zz_r_red15IrWgqlpkVfAw.gif)\n>このパッケージで提供するさまざまなアニメーションの例\n\n他の`npm`/`yarn`パッケージと同様に、1行で簡単にインストールできます。\n\n```javascript\nnpm i react-animated-burgers\n//or\nyarn add react-animated-burgers styled-components\n```\n\n[hamburger-menu.js](https://gist.github.com/VarunChilukuri/584c73dd7adc79fc3275a0bd2f72a152#file-hamburger-menu-js)\n\nアニメーションアイコンを1つ選択してimportするだけで、プロジェクトに追加できます。\n\n```javascript\nimport { HamburgerSpin } from 'react-animated-burgers'\n```\n\n[hamburger-menu.js](https://gist.github.com/VarunChilukuri/74fcdfc6ca0b2759416c075160cdcff2#file-hamburger-menu-js)\n\nそうすると、ヘッダーやナビゲーションバーに簡単に追加できます。\n\n```javascript\n<HamburgerSpin\n   buttonColor=\"red\" //optional\n   barColor=\"#F5F5F5\" //optional\n   {...{ isActive, toggleButton }}\n/>\n```\n\n[hamburger-menu.js](https://gist.github.com/VarunChilukuri/ec0195755d705fdbacb0b7526a8bdfc2#file-hamburger-menu-js)\n\n最も正確で新しい情報については、ドキュメントを参照してください。\n\n>**react-animated-burgers**\n>パッケージのインストールは、npm i -S react-animated-burgers styled-components またはyarn add react-animated-burgers...\n>[www.npmjs.com](https://www.npmjs.com/package/react-animated-burgers)\n\n##3. React Responsive Carousel\n\n多くのウェブサイトでは、カルーセルを設置して、商品、チームメンバー、会社に関する一般的な情報を表示しています。サイトにカルーセルを設置したいと思っているなら、おそらく多くの中途半端またはいまいちなパッケージを見たことがあるでしょう。これは、他のパッケージとは違い、インパクトがあり軽量、完全にカスタマイズ可能です。\n\n[React Responsive Carousel](https://miro.medium.com/max/700/1*9M_XBrGzaOS9-yfz3Ov4qg.gif)\n>カルーセルの動作デモ\n\nパッケージをインストールします。\n\n```javascript\nnpm i react-responsive-carousel\n//or\nyarn add react-responsive-carousel\n```\n\n[carousel.js](https://gist.github.com/VarunChilukuri/8843e6a24de4380234d8f8179fd84b2f#file-carousel-js)\n\nimport文を追加して、プロジェクトに追加します。\n\n```javascript\nimport { Carousel } from 'react-responsive-carousel'\nimport \"react-responsive-carousel/lib/styles/carousel.min.css\";\n```\n\n[carousel.js](https://gist.github.com/VarunChilukuri/2ed08a258ce978ed630d1df02582dcec#file-carousel-js)\n\n以下をウェブサイトに簡単に追加できます。\n\n```javascript\n<Carousel>\n   <div>\n      <img src=\"assets/1.jpeg\" />\n      <p className=\"legend\">Legend 1</p>\n   </div>\n   <div>\n      <img src=\"assets/2.jpeg\" />\n      <p className=\"legend\">Legend 2</p>\n   </div>\n   <div>\n      <img src=\"assets/3.jpeg\" />\n      <p className=\"legend\">Legend 3</p>\n   </div>\n</Carousel>\n```\n\n[carousel.js](https://gist.github.com/VarunChilukuri/7a693f61dc2f7816272ff63cce0f1156#file-carousel-js)\n\nこのパッケージは、制御方法が多く自由度が高いです。このプロジェクトを十分に活用するには、GitHubリポジトリなどを見てください。\n\n>**react-responsive-carousel**\n>インパクトがあり軽量、完全にカスタマイズ可能なReactアプリ用カルーセルコンポーネントです。レスポンシブモバイルフレンドリーです...\n>[www.npmjs.com](https://www.npmjs.com/package/react-responsive-carousel)\n\n##4. React CountUp\n\n企業の統計情報をウェブサイトに表示することは、かつてない程に簡単になりました。このパッケージでは、動的カウンターを使って、印象的な数字を目立たせて強調表示できます（溶け込んでしまう静的テキストとは違います）。\n\n![React CountUp](https://miro.medium.com/max/700/1*-_TmSXM8nqFW5aQENrduzw.gif)\n\nパッケージをインストールします。\n\n```javascript\nnpm i react-countup\n//or\nyarn add react-countup\n```\n\n[countup.js](https://gist.github.com/VarunChilukuri/4fa5059122cfbc36b1022a5f7b4b7b71#file-countup-js)\n\n以下をプロジェクトファイルの先頭に追加して、プロジェクトに追加します。\n\n```javascript\nimport CountUp from 'react-countup';\n```\n\n[countup.js](https://gist.github.com/VarunChilukuri/edd2061bf585f585ad71880ab2831ad4#file-countup-js)\n\n以下は、3つの簡単な使用例です。\n\n```javascript\n<CountUp end={100} />\n<CountUp delay={2} end={100} />\n<CountUp duration={5} end={100} />\n```\n\n[countup.js](https://gist.github.com/VarunChilukuri/591d267b12a8adcacded10907d53ae9c#file-countup-js)\n\nより高度な機能と自由度については、パッケージのページを参照してください。\n\n>**react-countup**\n>CountUp.jsのReactコンポーネントラッパーです。\n>[www.npmjs.com](https://www.npmjs.com/package/react-countup)\n\n##5. React Markdown\n\nMarkdown言語が提供する効率性とシンプルさが好きな人にとっては朗報です。ReactコードでMarkdownを使う簡単な方法があります。このパッケージを使うだけです！\n\n![React Markdown](https://miro.medium.com/max/700/1*elWqMU8tGjyGA2f7V1D7kw.png)\n\n`npm`でインストールします。\n\n```javascript\nnpm i react-markdown\n```\n\n[markdown.js](https://gist.github.com/VarunChilukuri/def21298c12f804c5390649273b989aa#file-markdown-js)\n>注：残念ながらこのパッケージは、yarnによるインストールをサポートしていません。\n\n必要な文をコードに追加します。\n\n```javascript\nconst ReactMarkdown = require('react-markdown')\n```\n\n[markdown.js](https://gist.github.com/VarunChilukuri/cdbeeddc6e66fd2d97cb2e64c9985248#file-markdown-js)\n\n使い始めましょう！\n\n```javascript\nconst React = require('react')\nconst ReactDOM = require('react-dom')\nconst ReactMarkdown = require('react-markdown')\n\nconst input = '# This is a header\\n\\nAnd this is a paragraph'\n\nReactDOM.render(<ReactMarkdown source={input} />, document.getElementById('container'))\n```\n\n[markdown.js](https://gist.github.com/VarunChilukuri/5aab3f4b75bb96e3b0b789ae48adef77#file-markdown-js)\n\n最も正確で新しい情報については、公式ページを参照してください。\n\n>**react-markdown**\n>Markdownを純粋なReactコンポーネントとしてレンダリングします。デモはこちらで見られます。https://rexxars.github.io/react-markdown/ react-markdown...\n>[www.npmjs.com](https://www.npmjs.com/package/react-markdown)\n\n##おわりに\n\nこの記事が参考になり、アプリに追加したいと思うパッケージが1つでもあったなら幸いです。\n\n![Image for post](https://miro.medium.com/max/700/1*fSjOzwpfshYIXc2iLDGwPQ.png)\n\nこの記事などで使われているコードはすべて、[私のGitHubレポジトリ](https://github.com/VarunChilukuri/Medium-Examples)にあります。\n\nこの記事が役に立った場合は、フォローをお願いします！React.jsに関する記事がもっとあります。フィードバックやコメントもお待ちしています。\n\n###JavaScriptを分かりやすく解説\n\n私たちが3つのパブリケーションとYouTubeチャンネルを持っていることを知っていますか？すべてのリンクはこちら[**plainenglish.io**](https://plainenglish.io/)！\n\n##翻訳協力\n\nこの記事は以下の方々のご協力により公開する事ができました。改めて感謝致します。\n\nOriginal Author: [Varun Chilukuri](https://medium.com/@varunch)\nOriginal Article: [Five awesome React packages to check out](https://javascript.plainenglish.io/five-awesome-react-packages-to-check-out-1ee42f2c19f7)\nThank you for letting us share your knowledge!\n\n選定担当: @gracen\n翻訳担当: @gracen\n監査担当: -\n公開担当: @gracen\n\n##ご意見・ご感想をお待ちしております\n今回の記事はいかがでしたか？\n・こういう記事が読みたい\n・こういうところが良かった\n・こうした方が良いのではないか\nなどなど、率直なご意見を募集しております。\n頂いたお声は、今後の記事の質向上に役立たせて頂きますので、お気軽に\nコメント欄にてご投稿ください。[Twitter](https://twitter.com/BabyDegu?lang=ja)でもご意見を受け付けております。\n皆様のメッセージをお待ちしております。\n\n","user":"baby-degu","created_at":"2021-03-29T08:11:43+09:00","updated_at":"2021-03-29T08:11:43+09:00"},{"url":"https://qiita.com/umihico/items/df88b5f6e799d99d5599","title":"税込から税抜を求めるには切り上げ？切り下げ？→ケースバイケースで要注意な件","body":"4月から税込み表示が義務化され、また世のエンジニアが苦労する中、逆に税込から税抜を求めるの思った以上に苦労した話です。\n一般的な小売では税込から税抜を求める状況はないと思いますが、相対取引で定価が無い場合は税込価格から決まることはザラです。\n\n具体例として`10096円〜10099円`の間の価格でお話ししますと\n10097円は÷1.1して**切り捨てた**9179円が正解です。\n10099円は÷1.1して**切り上げた**9181円が正解です。\n\nなぜなら双方とも誤って切り上げたり、切り下げると共に9180円になり、そこから税込価格を逆算すると10098円一択となってしまい元に値と矛盾するからです。ちなみに\n\n10098円は割り切れる整数なので、切り捨て切り上げ関係なく、9180円の一択になります。\n10096円は切り捨てて9178円、切り上げて9179円としてどちらでも良いのですが、それらからの税込み価格の計算は、端数の取扱次第で10095〜10097円まで幅広く解釈することができます。\n\nこれらを踏まえ実装としては、税抜価格netが最大化する按分になるceilでまず計算してみて、そこから税込の逆算が矛盾を起こす場合のみ、floorを採用する条件分岐が必要になります。\nMySQLなら以下の通りです。\n\n```sql\nmysql> SELECT\n    -> taxed,\n    -> case when floor(ceil(taxed/1.1)*1.1)=taxed or ceil(ceil(taxed/1.1)*1.1)=taxed then ceil(taxed/1.1) else floor(taxed/1.1) end as net\n    -> FROM (\n    -> SELECT 10096 AS taxed UNION\n    -> SELECT 10097 AS taxed UNION\n    -> SELECT 10098 AS taxed UNION\n    -> SELECT 10099 AS taxed\n    -> ) prices;\n+-------+------+\n| taxed | net  |\n+-------+------+\n| 10096 | 9179 |\n| 10097 | 9179 |\n| 10098 | 9180 |\n| 10099 | 9181 |\n+-------+------+\n4 rows in set (0.01 sec)\n```\n\nMySQLは問題ありませんでしたが、実装には浮動小数点の問題があり要注意です。\n端的に以下に例示すると100円の税込みは110円のはずですが、どちらも111円になります。体感的にはもはやバグです。\n\n```JavaScript:JavaScriptによる例\n\nMath.ceil(100*1.1) // 111\n```\n\n```Python:pythonによる例\nimport math\nmath.ceil(100*1.1) # 111\n```\n\nこのリスクに対応するため8桁以降を丸めた処理を挟んで以下のようになりました。\n\n```Python:pythonによる例\nfrom math import floor, ceil\n{taxed: ceil(round(taxed / 1.1, 8)) if floor(round(ceil(round(taxed / 1.1, 8)) * 1.1, 8)) == taxed or ceil(round(ceil(round(taxed / 1.1, 8)) * 1.1, 8)) == taxed else floor(round(taxed / 1.1, 8)) for taxed in [10096, 10097, 10098, 10099]}\n# {10096: 9179, 10097: 9179, 10098: 9180, 10099: 9181}\n```\n\n１万円までの全価格を走査して統計とったスクリプトを書いたので、貼っておきます。\n価格（整数）の集合全体の８割は割った後に切り上げ切り下げどちらでも良いのですが、残り１割ずつは切り上げ限定か切り下げ限定の困ったちゃん価格なのが分かります。\n\n```python\nfrom math import floor, ceil\nimport pprint\nresult = {}\n\nfor taxed in range(100, 10100):\n    recalc = {\n        \"FF\": floor(round(floor(round(taxed / 1.1, 8)) * 1.1, 8)),\n        \"CF\": floor(round(ceil(round(taxed / 1.1, 8)) * 1.1, 8)),\n        \"FC\": ceil(round(floor(round(taxed / 1.1, 8)) * 1.1, 8)),\n        \"CC\": ceil(round(ceil(round(taxed / 1.1, 8)) * 1.1, 8)),\n    }\n    key = tuple(k for k, v in recalc.items() if v == taxed)\n    if len(key) == 0:\n        print(taxed)\n        raise\n    result[key] = [*result.get(key, []), taxed]\n    print(taxed, key, recalc)\n\npprint.pprint({k: {\n    \"min\": min(v),\n    \"max\": max(v),\n    \"len\": len(v), } for k, v in result.items()})\n\n```\n\n\n\n税抜き価格の計算は税率で割って丸めるだけ、そんなふうに考えていた時期が俺にもありました。。。\n\n\nhttps://www.mof.go.jp/tax_policy/summary/consumption/sougaku.html\n\nhttps://www.mof.go.jp/tax_policy/summary/consumption/a_001.htm#9\n\nhttps://dic.nicovideo.jp/a/%E3%81%9D%E3%82%93%E3%81%AA%E3%81%B5%E3%81%86%E3%81%AB%E8%80%83%E3%81%88%E3%81%A6%E3%81%84%E3%81%9F%E6%99%82%E6%9C%9F%E3%81%8C%E4%BF%BA%E3%81%AB%E3%82%82%E3%81%82%E3%82%8A%E3%81%BE%E3%81%97%E3%81%9F\n","user":"umihico","created_at":"2021-03-29T08:07:36+09:00","updated_at":"2021-03-29T08:07:36+09:00"},{"url":"https://qiita.com/sitar-harmonics/items/076160ab2283491b0591","title":"Scikit-learn 青空を再現描画","body":"\n\n#始めに\n![sky.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/391380/657d0aad-1502-4863-306e-aec881dd9e83.png)\n\n画像などで、良く電線などが写っていて、何とかしたいと思うことがあります。\n上記画像で電線など余計なものを、機械学習などの応用で消すことはできないか？\nと思い、この鉄塔の右側を雲一つない晴天に書き換えることをScikit-learnを使って\nやってみたいと思います。\nScikit-learnを使って技術的なお遊びで、気楽にやっていますので、scoreを取ったりとか\n正解率がどうのということは記事中でははぶきます。\n\n\n#処理\n##処理概要\n処理としては下記のように行いました。\n\n1. 画像読み込み\n1. 学習用データを作成\n1. Pipelineで回帰計算インスタンスをRGBそれぞれ定義し学習させる。\n1. 回帰により推定値をR,G<Bそれぞれ取得\n1. 推定値で青空を描き、マスク処理で画像合成\n\n\n##回帰計算\n空のR,G,B値を求めて、空を描き直します。\n機械学習として、座標x, 座標yを入力し、R,G,Bを出力するように\nしたいですが求められる推定値は1つなので、R,G,B毎に1つづつ\n用意します。\n\n+ B ← f(座標x, 座標y)\n+ G ← f(座標x, 座標y)\n+ R ← f(座標x, 座標y)\n\n\n**f()**は**Pipeline()**でまとめられた回帰計算処理です。\n\n##サンプリング\nサンプリングは下記位置23か所で行います。\n![skymark.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/391380/936ff3d0-bd97-c57c-7f57-9349f2137639.jpeg)\n\n**Pythonコード**\n\n```python\nmes_pnts = np.array([\n    (174,  6),( 11, 12),(362, 24),(233, 28),( 66, 29),\n    (207, 32),(  9, 54),( 96, 62),(342, 73),(289, 92),\n    (375,112),(387,152),(172,155),(230,163),(191,168),\n    (176,188),(345,195),(  9,222),(383,230),(291,236),\n    (208,256),( 47,259),(156,262),])\n\n# 機械学習用データを作成\nrw,rh = 3, 3\nx_r,x_g,x_b = [],[],[]\nfor ps in mes_pnts:\n    x = int(ps[0]-1)\n    y = int(ps[1]-1)\n\n    # サンプリング座標を中心にして\n    # 3x3の9画素の平均を取得する\n    m = cv2.mean(img[y:y+rh, x:x+rw])\n    x_r.append(m[2])    # R平均\n    x_g.append(m[1])    # G平均\n    x_b.append(m[0])    # B平均\n```\n\nサンプリング値は指定座標を中心に3×3の領域の平均値を使用しています。\n画像処理で1画素で判断するのは危険です。\n\n\n##Pipelineの使用\nPipelineは下記機能を組み合わせて使用します。\n\n+ StandardScalerの標準化機能\n+ PolynomialFeaturesの多項式機能\n+ LinearRegressionの回帰分析機能\n\nこれを使うことで入力、学習の操作がいっぺんにできます。\n上記１つ１つで１記事が書けるほどなので説明がしきれず、本記事の守備範囲を\n超えてしまうと感じる為、詳細についてはインターネット、Qiita上に沢山あるので\n詳しく知りたい方はググって見て下さい。\n\n**参考**\n&emsp;&emsp;[scikit-learn.org - sklearn.pipeline.Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n&emsp;&emsp;[scikit-learn.org - sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html?highlight=polynomialfeatures#sklearn.preprocessing.PolynomialFeatures)\n&emsp;&emsp;[scikit-learn.org - sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linearregression#sklearn.linear_model.LinearRegression)\n&emsp;&emsp;[scikit-learn.org - sklearn.preprocessing.StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standardscaler#sklearn.preprocessing.StandardScaler)\n<br>\n**Rチャンネルを処理するPythonコード**\n\n```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\n\norder = 5\npf_r = Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"poly_features\", PolynomialFeatures(degree=order,include_bias=False)),\n        (\"linear_reg\", LinearRegression(fit_intercept=True)) ])\npf_r.fit(mes_pnts, x_r) # R学習\n\n# 推定\nprod_r = np.clip(pf_r.predict(wp),0,255).astype(np.int32)\n```\n\n##マスク処理\nマスク画像としては下記画像を使います。白い部分(255)に青空を描きます。\n![rchmask.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/391380/95f7719a-5458-9bd1-2bd6-70404811fded.png)\n\nマスク処理の流れ\n\n1. 反転マスク画像 ← NOT マスク画像\n1. 合成用画像 ← 入力画像 AND 反転マスク画像\n1. 結果画像 ← 生成青空画像 AND 合成用画像\n\n\n#Pythonコード\n\n```python\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np\nimport math\nimport cv2\n\ndef main():\n    # 鉄塔画像の読み込み\n    img = cv2.imread('sky.png', cv2.IMREAD_COLOR)\n    # マスク画像の読み込み\n    mask = cv2.imread('rchmask.png', cv2.IMREAD_GRAYSCALE)\n    mask = cv2.bitwise_not(mask)\n    height, width = img.shape[:2]\n    mes_pnts = np.array([   # サンプリング座標\n        (174,  6),( 11, 12),(362, 24),(233, 28),( 66, 29),\n        (207, 32),(  9, 54),( 96, 62),(342, 73),(289, 92),\n        (375,112),(387,152),(172,155),(230,163),(191,168),\n        (176,188),(345,195),(  9,222),(383,230),(291,236),\n        (208,256),( 47,259),(156,262),])\n\n    # 機械学習用データを作成\n    rw,rh = 3, 3\n    x_r,x_g,x_b = [],[],[]\n    for ps in mes_pnts:\n        x = int(ps[0]-1)\n        y = int(ps[1]-1)\n        # サンプリング座標を中心にして\n        # 3x3の9画素の平均を取得する\n        m = cv2.mean(img[y:y+rh, x:x+rw])\n        x_r.append(m[2])    # R平均\n        x_g.append(m[1])    # G平均\n        x_b.append(m[0])    # B平均\n\n    order = 5\n    pf_r = Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"poly_features\", PolynomialFeatures(degree=order,include_bias=False)),\n            (\"linear_reg\", LinearRegression(fit_intercept=True)) ])\n    pf_r.fit(mes_pnts, x_r) # R学習\n    pf_g = Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"poly_features\", PolynomialFeatures(degree=order,include_bias=False)),\n            (\"linear_reg\", LinearRegression(fit_intercept=True)) ])\n    pf_g.fit(mes_pnts, x_g) # G学習\n    pf_b = Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"poly_features\", PolynomialFeatures(degree=order,include_bias=False)),\n            (\"linear_reg\", LinearRegression(fit_intercept=True)) ])\n    pf_b.fit(mes_pnts, x_b) # B学習\n\n    # マスクより空を再描画する\n    ya, xa = np.where(mask == 0)\n    wp = np.hstack((xa.reshape(-1,1), ya.reshape(-1,1)))\n\n    # 推定\n    prod_r = np.clip(pf_r.predict(wp),0,255).astype(np.int32)\n    prod_g = np.clip(pf_g.predict(wp),0,255).astype(np.int32)\n    prod_b = np.clip(pf_b.predict(wp),0,255).astype(np.int32)\n\n    # 結果画像\n    result = cv2.bitwise_and(img, cv2.merge((mask,mask,mask)))\n    result[ya, xa, 0] = prod_b\n    result[ya, xa, 1] = prod_g\n    result[ya, xa, 2] = prod_r\n\n    # 表示\n    cv2.imshow(\"original\", img)\n    cv2.imshow(\"result\", result)\n    cv2.waitKey(0)\n\nif __name__ == '__main__':\n    main()\n```\n\nsky.pngファイルが入力画像です。\n\n\n#結果\n上記コードを実行することで、下記画像が得られます。\n\n![skyresult2.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/391380/4f2f7a42-671c-fa07-1f66-1aeff11b9498.jpeg)\n\n\n#おわりに\n画像としては、いいかんじにできたかなとは思います。際の部分ではイマイチ感ありますが。\nこの処理では、実は入力のサンプリング位置の確定や、マスク画像を作る方が\n難しかったりします。その辺の方法についても、今後いろいろ試したいなとは思います。\nお読み下さりありがとうございました。\n\n\n#参考\n[Emotion Explorer - 機械学習で空いっぱいの電線、鉄塔を消すことを試す](https://emotionexplorer.blog.fc2.com/blog-entry-330.html)\n[Emotion Explorer - Scikit-learn Pipelineを試す](https://emotionexplorer.blog.fc2.com/blog-entry-284.html)\n[Emotion Explorer - Scikit-learn 多項式回帰と交互作用項](https://emotionexplorer.blog.fc2.com/blog-entry-301.html)\n\n#写真引用\n鉄塔と青空 [photoAC](https://www.photo-ac.com)掲載 [ボッチ写真家](https://www.photo-ac.com/profile/2589747)さんの写真\n","user":"sitar-harmonics","created_at":"2021-03-29T08:04:09+09:00","updated_at":"2021-03-29T09:47:10+09:00"},{"url":"https://qiita.com/shinkai_/items/cfd93706bf2c5fc58f11","title":"モテる男になるためのPythonアプリケーション","body":"# はじめに\nごめんなさいタイトル**盛りました**。ただのPythonでのWEBスクレイピング記事です。\n（一応モテるための情報収集をしよう・・・というコンセプトです）\n\n<img width=\"150\" alt=\"pose_syazai_sliding_dogeza_man.png\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1203022/412cc898-c13a-d502-b94e-96ae8c5e5293.png\">\n\nこの記事で説明しているアプリケーションでは以下をポイントにしています。\n\n+ PythonでのWEBスクレイピングの実装\n+ Pythonでの非同期処理\n+ Pythonでの追加要望（スクレイピング対象の追加）に強い実装\n\n※ちなみに「WEBスクレイピング」とはWEBサイトから情報を抽出するコンピュータソフトウェア技術のことです。\n\n# アプリケーションを作ろうと思った経緯\n**`ここは読み飛ばしてもらっても構わないです。技術的な話は一切ないです。長い上にほぼ雑談です。`**\n\n## 何を作ろうか\n会社ではC#やJavaでの開発が多いので、プライベートでPythonで何か作りたいなーと思い立ちました。\nせっかくなので実際に使えるものがいいなと思い**「これがあったら便利だな」**を考えたのですが・・・\nやはり\n\n**「モテる男になるためのツール」**\n\nがあったら最高だなと。お遊びで作るアプリケーションだしそのくらいが気持ち的にも良いですよね？\nネタとして友達や同僚にも話しやすいですし。\n\nさて、どんなアプリケーションを作るか。まず方向性を**情報収集系のアプリケーション**か**記録系のアプリケーション**に絞りました。\nアイデアを書きだしてみたのですが、記録系のアプリケーションはありきたりのものしか思いつかなかったです。髪型管理とかスタイル管理とか。それってスマホアプリでありそうだなと。そんなこんなで割とすぐに**情報収集系のアプリケーション**に舵を切りました。\nPythonでWEBスクレイピングって定番ですし、一度作ってみたかったというのも理由のひとつです。\n\n## WEBスクレイピングの対象をどうするか\nやっぱり話題が豊富な男性はモテますよね？\n「女性との会話が弾む話題」を色々とネットで調べてみると**「休日の過ごし方」**、**「（相手の）趣味」**、**「グルメ・スイーツ」**、**「お互いの持ち物」**などが出てきました。なるほど。\n\n<img width=\"150\" alt=\"friend_advice_man.png\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1203022/482469b7-0d48-45ce-6b50-25a647474746.png\">\n\n熟考の末、以下の理由から**「グルメ・スイーツ」**をスクレイピング対象とすることに決定しました。\n\n**１．「とにかく無難。多くの人にとって共通の話題になる。」**\n　⇒とにかく無難です。食に興味のない人間は少ないです。\n**２．「知っていて損はない。」**\n　⇒ひとりでだって美味しい情報は使えます。\n**３．「私の周りの女性へのヒアリングの結果。」**\n　⇒休日の過ごし方とか聞くな。趣味の話とか面倒臭い。だそうです。\n**４．「リスクが少ない。」**\n　⇒これが一番大事だと思います。\n　　女性との会話について調べると共通してどのサイトにも　　\n　　**「仕事や趣味の自慢話や知識をひけらかすことはNG。」**\n　　と書いてありました。変な話をしてしまって印象を悪くするくらいなら無難な話題で盛り上がりましょう。\n**５．「女性はグルメ・スイーツの話が好き。」**\n　⇒はい。私の偏見です。\n\nふぅ。やっとやることが決まったので次に行こうと思います。\nそうです**「どのサイトを対象とするか」**です。お察しの通りまだまだ雑談は続きます。。。\n\n## どのサイトを対象とするか\nこれも色々と調べました。\n女性目線の情報を知っておいた方がいいよなーと考え、知人の女性に聞くと大半が**「インスタグラムかTwitterで調べる」**とのこと。\nインスタグラムもTwitterもWEBスクレイピングの定番かもしれませんが**「情報収集する軸」**が決められませんでした。\n\n+ いいね数が多い「グルメ・スイーツ」というキーワードの投稿でスクレイピングする\n+ インフルエンサ―と呼ばれる人の「グルメ・スイーツ」というキーワードの投稿でスクレイピングする\n+ 最新の「グルメ・スイーツ」というキーワードの投稿でスクレイピングする\n\n等を考えましたがイマイチまとまらなかったので今回は自分の中で却下としました。\n**「インフルエンサーの○○さんが渋谷の××ってお店紹介してたんだー」**とかおじさんに言われても困ると思いますし。\n\nヒアリングの結果と独自に調べた結果で対象サイトを以下としました。\n\n### 対象のサイト１：MERY\nヒアリングで名前があがった女性に人気のある（らしい）サイト。\n\nhttps://mery.jp/\n\n### 対象のサイト２：macaroni\n女性に人気のある（らしい）日本最大級の食特化型WEBメディア。\n\nhttps://macaro-ni.jp/\n\n### 対象のサイト３：LOCARI（ロカリ）\n女性向けキュレーションサイトで調べていたら色々なサイトで紹介されていたので。\n\nhttps://locari.jp/\n\n### 対象のサイト４：livedoor\n「グルメ　ニュース」でGoogle検索すると一番上位に表示されるため。\n\nhttps://news.livedoor.com/topics/category/gourmet/\n\n### 対象のサイト５：ロケットニュース24\nきっとモテる男に必要な情報はすべてここにあるはず。\n\nhttps://rocketnews24.com/\n\n上記５サイトは女性目線も面白系も網羅していて、オシャレなお店からコンビニスイーツまで幅広く紹介しているのでなかなか良い感じです。\n\n# アプリケーションの説明\nやっとアプリケーション自体の話です。\n順を追って説明したいと思います。\n\n## 現時点で何を作ったか\n実はまだまだ作成途中です。\nまずは、ローカルPCでPythonプログラムを実行してWEBスクレイピング結果をCSV出力するアプリケーションを作成しました。\n今後サーバレスで定期実行（AWSのLambda等）してデータを取得、それを表示するWEBサイトを作成する予定です。\n\n\n## WEBスクレイピングの注意点\nWEBスクレイピングを実装したことのある人ならわかると思いますが、情報を抽出するためのタグはサイトによってバラバラです。\n\n```html:サイト１\n<div class=\"list\">\n  <div class=\"item\">\n      <a href=\"https://xxxxxx/xxxxxx\">タイトル</a>\n  </div>\n  <div class=\"item\">\n      <a href=\"https://xxxxxx/xxxxxx\">タイトル</a>\n  </div>\n</div>\n```\n\n```html:サイト２\n<ul>\n  <li>\n      <a href=\"https://xxxxxx/xxxxxx\">\n        <h3>タイトル</h3>\n　    </a>\n  </li>\n  <li>\n      <a href=\"https://xxxxxx/xxxxxx\">\n        <h3>タイトル</h3>\n　    </a>\n  </li>\n</ul>\n```\n\nサイト１ではリストをdivで表していますが、サイト２ではulとliで表しています。\nそのため、要素の抽出処理を分ける必要があります。\nそこで何も考えずに実装をすると以下のようなコードが出来てしまいます。\n\n```python\nif url == サイト１:\n    サイト１の情報を抽出する処理\nelif url == サイト２:\n    サイト２の情報を抽出する処理\nelif url == サイト３:\n    サイト３の情報を抽出する処理\n```\n\n追加のサイトが増えるたびに分岐を追加するのは**密結合**で保守性が悪いなと感じます。\nそこで**「サイト単位でクラスを分け、サイトが追加されたらクラスを追加するだけで他のコードを一切修正しない方法」**を考えました。\n\n\n## クラスを追加するだけで他のコードを一切修正しない\nサイト単位でクラスを分け、サイトが追加されたらクラスを追加するだけで他のコードを一切修正しない方法とは何かを説明します。\n\n### フォルダ構成\nまず、フォルダ構成は以下のようにしました。\n\n```\nsrc\n├── news_site\n│   ├── livedoor.py\n│   ├── locari.py\n│   ├── macaroni.py\n│   ├── mery.py\n│   └── rocketnews24.py\n├── main.py\n└── news_get_common.py\n```\n\nフォルダ**「news_site」**が今回の実装のポイントです。\nスクレイピング対象の**「サイト名のファイル」**が格納されています。\nこのファイルを増やすだけで**自動的に**取得結果のニュース記事が（追加されたサイトの分）増える仕組みです。\n\n図にするとこんなイメージです。\n\n![2.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1203022/ef480c9a-2218-1f13-a7fc-28081ad81d04.png)\n\n・・・上手く図に出来てない。けどこんなイメージです。\n\n### サイト名のファイル（/news_site/xxxx.py）\n実際に**「サイト名のファイル」**の中身をいくつか見ていきます。\n\n```python：mery.py\nimport news_get_common\nfrom bs4 import BeautifulSoup\nimport requests\n\nclass mery:\n    \"\"\"\n    meryのグルメニュースを取得するクラス\n    \"\"\"\n\n    URL       = 'https://mery.jp/gourmet/'\n    QUERY     = '?page='\n    SITE      = 'mery'\n\n    def get_list(self, soup):\n        return soup.select('div.article_list > div.article_list_content')\n\n    def get_title(self, element):\n        return (element.select_one('h3 > a').text).strip()\n\n    def get_url(self, element):\n        return element.select_one('h3 > a').get(\"href\")\n\n    def get(self):\n        \"\"\"\n        ニュース取得のメイン関数を呼ぶだけ\n        \"\"\"\n\n        return news_get_common.get(self.URL, self.QUERY, self.SITE, self.get_list, self.get_title, self.get_url)\n```\n\n```python：livedoor.py\nimport news_get_common\nfrom bs4 import BeautifulSoup\nimport requests\n\nclass livedoor:\n    \"\"\"\n    livedoorのグルメニュースを取得するクラス\n    \"\"\"\n\n    URL       = 'https://news.livedoor.com/topics/category/gourmet/'\n    QUERY     = '?p='\n    SITE      = 'livedoor'\n\n    def get_list(self, soup):\n        return soup.select('ul.articleList > li')\n\n    def get_title(self, element):\n        return element.find('h3').text.strip()\n\n    def get_url(self, element):\n        return element.a['href']\n\n    def get(self):\n        \"\"\"\n        ニュース取得のメイン関数を呼ぶだけ\n        \"\"\"\n\n        return news_get_common.get(self.URL, self.QUERY, self.SITE, self.get_list, self.get_title, self.get_url)\n```\n\n```python：rocketnews24.py\nimport news_get_common\nfrom bs4 import BeautifulSoup\nimport requests\n\nclass rocketnews24:\n    \"\"\"\n    rocketnews24のグルメニュースを取得するクラス\n    \"\"\"\n\n    URL       = 'https://rocketnews24.com/category/%E3%82%B0%E3%83%AB%E3%83%A1/'\n    QUERY     = 'page/'\n    SITE      = 'rocketnews24'\n\n    def get_list(self, soup):\n        return soup.select('#main-content > div.post')\n\n    def get_title(self, element):\n        return (element.select_one('h2').text).strip()\n\n    def get_url(self, element):\n        return element.select_one('a').get(\"href\")\n\n    def get(self):\n        \"\"\"\n        ニュース取得のメイン関数を呼ぶだけ\n        \"\"\"\n\n        return news_get_common.get(self.URL, self.QUERY, self.SITE, self.get_list, self.get_title, self.get_url)\n```\n上記３つのクラスには共通して以下の関数を定義しています。\n\n+ def get_list(self, soup)\n+ def get_title(self, element)\n+ def get_url(self, element)\n+ def get(self)\n\nJavaやC#のインターフェイスですね。ポリモーフィズムってやつです。\n同じ名前の関数があることで、クラスの指定さえ切り替えれば「get()を実行する」コードはそのまま使えます。\nそれぞれのクラスに定義されている関数に独自の抽出処理を記載しています。\n\nPythonでは**「定義した関数をそのまま引数として渡し、渡した先で実行する」**ということが可能です。\n`news_get_common.get(self.URL, self.QUERY, self.SITE, self.get_list, self.get_title, self.get_url)`はまさに各クラス内で定義した関数を引数として渡しています。\n\n\n### 親処理（main.py）\n次に、各サイト名クラスを実際に呼び出している親処理を見てみます。\n\n```python:main.py\nimport importlib\nimport asyncio\nimport pathlib\nimport pandas\nimport csv\nimport itertools\n\nasync def get_news(loop, class_name):\n    \"\"\"\n    ニュース情報取得関数\n    \"\"\"\n\n    module = importlib.import_module('news_site.' + class_name)\n    class_obj = getattr(module, class_name)\n    return await loop.run_in_executor(None, class_obj().get)\n\n\ndef get_py_list(loop):\n    \"\"\"\n    pythonプログラムリスト取得関数（スクレイピング対象リスト取得）\n    \"\"\"\n\n    f_list = []\n    for py_file in pathlib.Path('news_site').glob('*.py'):\n        # ニュース情報取得\n        f_list.append(get_news(loop, py_file.name.replace('.py', '')))\n    return f_list\n\n\ndef main():\n    \"\"\"\n    ページ内のニュース情報取得関数\n    \"\"\"\n\n    loop = asyncio.get_event_loop()\n    result = loop.run_until_complete(asyncio.gather(*get_py_list(loop)))\n    df = pandas.io.json.json_normalize(sorted(list(itertools.chain.from_iterable(result)), key=lambda x:x['number']))\n    df.to_csv('data.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n\n\nif __name__ == \"__main__\":\n    main()\n\n```\n\nコードを読むだけだと何をしているかわかりにくいですよね。ひとつずつ説明します。\n\n#### メイン関数（エントリーポイント）\n\n**def main()**の内の話です。\n\nここではニュース情報取得処理の呼び出しと、CSV出力を行っています。\n\n```python\n    loop = asyncio.get_event_loop()\n    result = loop.run_until_complete(asyncio.gather(*get_py_list(loop)))\n```\n\n上記コードで、非同期にてニュース情報取得処理を呼び出しています。\n\n```python\n    df = pandas.io.json.json_normalize(sorted(list(itertools.chain.from_iterable(result)), key=lambda x:x['number']))\n    df.to_csv('data.csv', index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)\n\n```\n上記コードで、取得したニュースリストをCSV出力しています。\n\n#### スクレイピング対象のサイトクラスリスト取得\n\n**def get_py_list(loop)**内の話です。\n\n```python\ndef get_py_list(loop):\n    \"\"\"\n    pythonプログラムリスト取得関数（スクレイピング対象リスト取得）\n    \"\"\"\n\n    f_list = []\n    for py_file in pathlib.Path('news_site').glob('*.py'):\n        # ニュース情報取得\n        f_list.append(get_news(loop, py_file.name.replace('.py', '')))\n    return f_list\n```\n\n`for py_file in pathlib.Path('news_site').glob('*.py'):`にて、フォルダ「news_site」内のPythonファイルを抽出し、for文でそれぞれに処理を行っています。\n\n`f_list.append(get_news(loop, py_file.name.replace('.py', '')))`にて、ファイル名から拡張子を除去した文字列を引数として関数「get_news」を呼び出しています。\n\n#### ニュース情報を非同期で取得\n\n**async def get_news(loop, class_name)**内の話です。\n\n```python\nasync def get_news(loop, class_name):\n    \"\"\"\n    ニュース情報取得関数\n    \"\"\"\n\n    module = importlib.import_module('news_site.' + class_name)\n    class_obj = getattr(module, class_name)\n    return await loop.run_in_executor(None, class_obj().get)\n```\n\n`module = importlib.import_module('news_site.' + class_name)`にて、クラスを動的にimportしています。\nこの仕組みのおかげでサイトを追加するたびに「main.py」にimport文を書かなくて済みます。\n\n`class_obj = getattr(module, class_name)`にて、クラスのインスタンスを生成しています。\n\n`return await loop.run_in_executor(None, class_obj().get)`にて、生成したクラスのインスタンスの関数「get」を実行し、返却しています。\n\n図にするとこんなイメージです。\n\n![3.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1203022/50cf6258-1e47-38c8-54f6-922bd13f8048.png)\n\n※非同期処理を説明する予定でしたが長くなってきたので割愛します。というかあまり速度が出ていないので非同期処理を見直す必要があるかもしれません。。。\n\n### ニュース情報を取得する共通処理（news_get_common.py）\n最後に、ニュース情報を取得する共通処理のコードを載せておきます。\n\n**main.py　⇒　各サイトクラス.py　⇒　news_get_common.py**\n\nと流れる**news_get_common.py**です。\nrequestsとBeautifulSoupを使ってWEBスクレイピングを行い、各サイトクラスから渡された関数を用いて情報を取得しています。\n\n```python:news_get_common.py\nfrom bs4 import BeautifulSoup\nimport requests\n\nMAX_COUNT = 30\nMAX_PAGE  = 20\n\ndef get_news_on_page(site_name, get_list, get_title, get_url, soup, number):\n    \"\"\"\n    ページ内のニュース情報取得関数\n    \"\"\"\n\n    # ニュースリストの取得（各クラスのリスト取得関数を呼び出し）\n    news_list = get_list(soup)\n    result_list = []\n    for element in news_list:\n\n        # 取得情報の設定（各クラスのタイトル取得関数、URL取得関数の呼び出し）\n        news = {\n            'title'  : get_title(element),\n            'url'    : get_url(element),\n            'number' : number,\n            'site'   : site_name\n        }\n        result_list.append(news)\n        number += 1\n\n        if number > MAX_COUNT:\n            break\n\n    return result_list\n\ndef get(url, paging_query_string, site_name, get_list, get_title, get_url):\n    \"\"\"\n    ニュース取得のメイン関数\n    ページングも考慮\n    \"\"\"\n\n    result_list = []\n    number = 1\n    for num in range(1, MAX_PAGE):\n\n        target_url = url\n        if num != 1 :\n            # 次ページのURLを生成\n            target_url += paging_query_string + str(num)\n        \n        # ページ情報の取得\n        response = requests.get(target_url, headers = {\"User-Agent\": 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0'})\n        soup = BeautifulSoup(response.text, 'html.parser')\n        news = get_news_on_page(site_name, get_list, get_title, get_url, soup, number)\n        result_list.extend(news)\n\n        number = len(result_list) + 1\n\n        if number > MAX_COUNT:\n            break\n\n    return result_list\n```\n\n## 実行結果\n\nCSVで表示　※一部のみ表示\n\n```\n\"title\",\"url\",\"number\",\"site\"\n\"ブラックサンダーに公式ライバル現る　ネット民期待「只者ではない予感…」「勝てるかな！？」\",\"https://news.livedoor.com/topics/detail/19927731/\",\"1\",\"livedoor\"\n\"疲れもぶっ飛び縲懌劭シャトレーゼ＆コンビニでGET「夜の至福スイーツ」12選\",\"https://locari.jp/posts/1716617\",\"1\",\"locari\"\n\"ザクッと食感がクセになる。「ドトール ホワイトカフェ・ラテ」は本格的なコーヒーの風味が贅沢【365日アイス女子】\",\"https://macaro-ni.jp/98726\",\"1\",\"macaroni\"\n\"「何飲む縲怐H」って聞かれて、もう焦らない！初心者さん向け予備知識＋お酒LIST\",\"https://mery.jp/1101584\",\"1\",\"mery\"\n\"【怪魚】ベトナム産！ コストコの「パンガシウス」を食べてみた\",\"https://rocketnews24.com/2021/03/28/1471106/\",\"1\",\"rocketnews24\"\n\"高たんぱく・低糖質のカップヌードル発売「罪悪感薄まる」と反響\",\"https://news.livedoor.com/topics/detail/19928710/\",\"2\",\"livedoor\"\n\"ストックしておきたい！業務スーパーの冷凍フルーツおすすめ6選\",\"https://locari.jp/posts/1726309\",\"2\",\"locari\"\n\"簡単で本格的！業務スーパーのエビフライおすすめ3種を実食レビュー\",\"https://macaro-ni.jp/98761\",\"2\",\"macaroni\"\n\n```\n\nExcelで表示\n![1.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1203022/0b9418fb-feef-9746-68e9-913005bf1dfc.png)\n\n# さいごに\n**無事モテるための話題収集が出来ました。**\nこのアプリケーションではサイトクラスの中身を変えるだけで、抽出対象を政治ニュースやスポーツニュースに変更することも簡単に出来ます。\nなのでわりと汎用性が高く作れたかなと思います。\nしかし、Pythonはほぼ初心者なので変なコーディングを見つけたりこうした方が良いというアドバイスがございましたらコメントいただけると喜びます！\n\n今後、自分用にスクレイピング結果を一覧表示してリンクに飛べるWEBサイトを作成予定です。\nこの記事の反応が多少なりとも良かったら頑張ってみなさんにも公開するかもしれません。\n\n**モテる男になるためのPythonアプリケーション**・・・やっぱり盛りすぎましたね。\n\n読んでくださってありがとうございます！\n以上です。\n\nおわり。\n","user":"shinkai_","created_at":"2021-03-29T07:52:32+09:00","updated_at":"2021-03-29T07:52:32+09:00"},{"url":"https://qiita.com/sakiyama12/items/45d70e00cb29cd9c8ef9","title":"listに含まれる要素で組合せを作る","body":"リストの要素の組合せリスト作成時の備忘録_φ(･\\_･\n\n# 目的：listに含まれる要素で組合せを作る\n下記のリストを例にします。\n\n```python:\ndata = [0,1,2,3]\n```\n\n# 方法１：重複あり\n```python:sample1.py\nfor i in data:\n    for j in data:\n        print(i, j)\n\n# 出力結果\n# 0 0\n# 0 1\n# 0 2\n# 0 3\n# 1 0\n# 1 1\n# 1 2\n# 1 3\n# 2 0\n# 2 1\n# 2 2\n# 2 3\n# 3 0\n# 3 1\n# 3 2\n# 3 3\n```\n\n# 方法２：重複なし\n```python:sample2.py\nfor i in data:\n    for j in [x for x in data if x != i]:\n        print(i, j)\n\n# 出力結果\n# 0 1\n# 0 2\n# 0 3\n# 1 0\n# 1 2\n# 1 3\n# 2 0\n# 2 1\n# 2 3\n# 3 0\n# 3 1\n# 3 2\n```\n\n完全に自分の備忘録のため。\n","user":"sakiyama12","created_at":"2021-03-29T07:46:16+09:00","updated_at":"2021-03-29T07:46:16+09:00"},{"url":"https://qiita.com/yamamotomasa/items/5ae7d64a9ed30774e4e7","title":"baserCMS用のキャッシュプラグインを作りました","body":"![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/94360/910f120c-ad59-af92-de7e-7dcc7911237a.png)\n\n去年からbaserCMSの開発に関わっていますが、プラグインを一度も作ったことがないので練習を兼ねて作ってみました。\n\nhttps://github.com/yama/baser_simplecache/releases/tag/v0.5.0\n上記からダウンロードできます。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/94360/0d9a038a-8c2c-02cf-1e70-d4945c7472ff.png)\n\n表示に1.2秒かかるトップページ(なんでこんなに遅いの？)が、\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/94360/f0f9432d-597b-b244-d316-41d79444a43c.png)\n\n0.01～0.03秒くらいで表示されるようになります。\n\nログイン時・投稿時はキャッシュを読まないようにしています。\n","user":"yamamotomasa","created_at":"2021-03-29T07:23:52+09:00","updated_at":"2021-03-29T07:59:37+09:00"},{"url":"https://qiita.com/quryu/items/8570939260532a902193","title":"JavaScript 文字列を配列に変換する","body":"配列の要素がダブルクォーテーションで囲まれている場合\n\n```javascript\nlet arrayStr = '[\"A\", \"B\", \"C\"]';\nlet array = JSON.parse(arrayStr);\n```\n\n配列の要素がシングルクォーテーションで囲まている場合\n\n```javascript\nlet arrayStr = \"['A', 'B', 'C']\";\nlet array = JSON.parse(arrayStr.replace(/'/g, '\"'));\n```\n\n両方対応\n\n```javascript\nlet array = arrayStr.replace(/[\\[\\]\"' ]/g, '').split(',');\n```\n\n# 参考記事\n\nhttps://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse\n\nhttps://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/String/replace\n","user":"quryu","created_at":"2021-03-29T07:23:44+09:00","updated_at":"2021-03-29T07:28:46+09:00"},{"url":"https://qiita.com/kim-ho/items/99200da0ee2f821760d5","title":"try Swift：スケジュール画面の解析","body":"# はじめに\ntry Swiftのスケジュール画面を解析する。ゴールは登場するクラスの洗い出しと関連性のざっくりとした把握。\n\n#スケジュール画面のスクリーンショット\n<img src =\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1228348/7dcfdbe7-a9f2-5655-b0f0-dbae74be6abb.png\" width=\"250px\" height=\"300px\">\n\n#スケジュール画面の構成及び構成する主なクラス\n### 画面構成\n[SessionTableViewCell達]\n       ↑\n[SessionTableViewController1, SessionTableViewController2,  SessionTableViewController3]\n       ↑\nScheduleViewController\n### UI部分\nScheduleViewController：スケジュール画面の母体\nButtonBarView：画面上部のバーボタン（ボタンによって画面のコンテンツが表示される）\nSessionTableViewController：画面のコンテンツが表示される画面\nSessionTableViewCell：スケジュールコンテンツ画面\n### モデル部分\nConferenceDay：会議日付及びSession情報を含む構造体\nSessionBlock：Sessionsのスタート、エンド、Session情報達\nSession：Session情報\n","user":"kim-ho","created_at":"2021-03-29T07:16:39+09:00","updated_at":"2021-03-29T07:16:39+09:00"},{"url":"https://qiita.com/arata0520/items/6ef432fd48797cf7e3dd","title":"備忘録 - 変数の定義【VBA】","body":"##文法\nVBAで変数を定義するには、まず変数のデータ型を定義し、その後、その変数にデータを代入する\n\n```vb\n'変数の定義方法\nDim 変数名 As データ型\nLet 変数名 = 代入したいデータ\n```\n\nLetに関しては省略してもOK\n\n\n```vb\nDim 変数名 As データ型\n変数名 = 代入したいデータ\n```\n\n複数の変数を定義するときは、コンマで繋げて一度にデータ型を定義できる\n\n```vb\nDim 変数A As データ型, 変数B As データ型, 変数C As データ型\n\n変数A = 代入したいデータ\n変数B = 代入したいデータ\n変数C = 代入したいデータ\n```\n##データ型\n主なデータ型は以下の通り\n\nByte: 0 through 255までの整数\nInteger: -32,768 through 32,767の整数\nLong: -2,147,483,648 through 2,147,483,647の整数\nBoolean: True / False\nDouble:　少数点以下を含む数字\nString:文字列\nDate:日時\nVariant :どのデータ型でもOK（但しデータが重い）\n\n## Setを使う場合(オブジェクト変数）\nオブジェクトを変数に格納する場合は、Setを用いる\n\n```vb\nDim 変数名 as オブジェクト \nSet 変数名 = 代入したいデータ\n```\n\nおぶｙ##文法\nVBAで変数を定義するには、まず変数のデータ型を定義し、その後、その変数にデータを代入する\n\n```vb\n'変数の定義方法\nDim 変数名 As データ型\nLet 変数名 = 代入したいデータ\n```\n\nLetに関しては省略してもOK\n\n\n```vb\nDim 変数名 As データ型\n変数名 = 代入したいデータ\n```\n\n複数の変数を定義するときは、コンマで繋げて一度にデータ型を定義できる\n\n```vb\nDim 変数A As データ型, 変数B As データ型, 変数C As データ型\n\n変数A = 代入したいデータ\n変数B = 代入したいデータ\n変数C = 代入したいデータ\n```\n##データ型\n主なデータ型は以下の通り\n\nByte: 0 through 255までの整数\nInteger: -2,147,483,648 through 2,147,483,647の整数\nLong: -9,223,372,036,854,775,808 through 9,223,372,036,854,775,807の整数\nBoolean: True / False\nDouble:　少数を含む数字\nString:文字列\nDate:日時\nVariant :どのデータ型でもOK（但しデータが重い）\n\n##データ型備考\n\nデータ型を定義しなかった場合、データ型はVariantになる。\n\n```vb\nDim 変数名 \n変数名 = 代入したいデータ\n'変数のデータ型はVariantに！\n```\n## Setを使う場合\nオブジェクトを変数に格納する場合は、値を代入する際にSetを用いる\n\n```vb\nDim 変数名 as オブジェクト \nSet 変数名 = 代入したいデータ\n```\n\nオブジェクトとして、例えば、Workbook, Worksheet, Rangeなどが挙げられる。以下のように用いる。\n\n```vb\nDim myRange as Range\nSet myRange = Range(\"A1\")\n```\n\n##配列の定義\n配列を定義するには、変数名後にカッコを書き、その中に要素数を定義する。\n\n```vb\nDim SchoolEntranceMonth(1 To 3) As String\n    MyMonth(1) = \"Jan\"\n    MyMonth(2) = \"May\"\n    MyMonth(3) = \"Sep\"\n```\n##定数の定義\n代入する値が変わらない（変えるべきでない）場合、Constを用いて、定数を定義することができる\n\n```vb\nConst 変数名 as データ型　= 代入したい値\n```\n\n\n\n","user":"arata0520","created_at":"2021-03-29T07:14:14+09:00","updated_at":"2021-03-29T07:14:14+09:00"},{"url":"https://qiita.com/rtInamoriRyusei/items/20090eb0d8cab8da74f4","title":"はじめて1年で「Covid19鑑別精度90%越のAI」を作った話","body":"[**MediTech**](https://medicalai-student.com/)代表の稲森です。\n<img width=\"400\" alt=\"MediTech様_logo-yoko.jpg\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/fc3d4d63-8f8e-7936-74aa-652ebffd5215.jpeg\">\n\n◎自己紹介\n　➡21歳\n　➡鹿児島出身\n　➡診療放射線技術学科学生\n\n**MediTech**は、AIやプログラミングに対する敷居の高さを払拭するために\nAIやプログラミングについて自由に学ぶことのできる場所、\n多くの人と繋がることのできる場所を目的として立ち上げたコミュニティです。\nよろしくお願いします。\n\n# 0. はじめに\n\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/2309d82c-3c8d-6af7-98b3-437c99046ec3.png\" width=300px height=234px >　<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/310bd1c3-0a37-cc61-9653-378461713bb8.png\" width=300px height=234px >\n今回の記事は、**はじめて1年で「Covid19鑑別精度90%越のAI」を作った話**です！\n\n僕は、ちょうど1年前くらいにプログラミングをはじめました。\n\n僕が診療放射線技術学科の学生であるということで、**CTの画像からCovid19を予測するAI**を作りました。\n\n昨年から世界的に影響を与えているCovid19ですが、医師でない僕には画像を見ても\n\nCovid19を判断することは出来ません・・・\n\nしかし、今回90%を超える精度で鑑別することが出来ました🎉\n\n\n\n## 目次\n\n|章|タイトル|備考|\n|---|---|---|\n|0|[**はじめに**](#0-はじめに)||\n|1|[**データセットの準備**](#1-データセットの準備)||\n|2|[**環境構築(Google Colaboratory)**](#2-環境構築google-colaboratory)|初めてGoogleColaboを使う人向けです|\n|3|[**Python実装コード**](#3-python実装コード)|本記事のメインコンテンツです|\n|4|[**実装結果**](#4-実装結果)||\n|5|[**参考**](#5-参考)||\n|6|[**おわりに**](#6-おわりに)||\n|7|[**参照**](#7-参照)||\n\n# 1. データセットの準備\n精度の良いモデルを作成するには、大量のデータセットが必要です。\n\nそこで、今回はCT画像からCovid19の鑑別を行うにあたって、\n大量のデータセットを**Kaggle**からダウンロードしました。\n\n**データセットのKaggleリンクはこちら↓**\n[**SARS-COV-2 Ct-Scan Dataset**](https://www.kaggle.com/plameneduardo/sarscov2-ctscan-dataset)\n\n今回使ったデータセットのダウンロードは[**こちら**](https://drive.google.com/file/d/1jLXUO1HNF83LUyxyys8XeMzVSEY1ywBO/view?usp=sharing)\n\nこれからソースコードも記述していきますが、[**Github**](https://github.com/rtInamoriRyusei/CT-Covid19)にも載せています。\n\n# 2. 環境構築(Google Colaboratory)\n今回は、全ての方に簡単に実装していただくために\n**Google Colaboratory**を用いていきます。\n![colabo.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/74a830b5-7e04-c7a4-defe-0d3958ec6e99.png)\nこれから、初めてGoogle Colaboratoryを使う方向けに少し手順を書いていきます。\n\n① 新規ボタンを押す\n　　　　↓\n② その他の中にGoogle Colaboratoryがあればクリックして始める\n　　　　↓\n③ ない場合、アプリを追加を押してGoogle Colaboratoryと検索してインストール\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/2a6329f3-e49d-af70-21e0-dbdefca74198.png\" width=206px height=288px >　![colabo2.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/c523244e-c4ba-b32d-f616-238ba437efcd.png)　![colabo4.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/f7c2c859-7f90-f55a-29a0-091d3f520485.png)\n④ これでコードを書いていく場所の準備は出来ました。\n⑤ あとは、データセットをzip形式でGoogleDriveにアップロードしておきます。(ドラッグ&ドロップ)\n\n詳しいGoogle Colaboratoryの使い方はこちらの記事を参考にしてみてください。\n[【秒速で無料GPUを使う】深層学習実践Tips on Colaboratory](https://qiita.com/tomo_makes/items/b3c60b10f7b25a0a5935)\n\n# 3. Python実装コード\nこれから実際の**ソースコード**を書いていきたいと思います。\n**jyujyutukaisen.zip**をダウンロードしたら、\n**Google Drive**にアップロードしておきましょう。\n\n```python\n# Googleドライブをマウント\nfrom google.colab import drive\ndrive.mount('/content/drive')\n```\n**.zip**のまま**Google Drive**にアップロードしてください！\n\n```python\n# Google ColaboratoryでZipファイルを解凍\nfrom zipfile import ZipFile\nfile_name = '/content/drive/My Drive/jyujyutukaisen.zip'\n\nwith ZipFile(file_name, 'r') as zip:\nzip.extractall()\n```\nzipファイルのままアップロードして、ここで解凍した方が**時間短縮**になります。\n\n```python\n%tensorflow_version 1.x\nimport numpy as np\nimport keras\nfrom keras.utils import np_utils\nfrom keras.models import Sequential, Model, model_from_json\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, auc\nfrom PIL import Image\nimport glob\n%matplotlib inline\n```\n必要なライブラリを**import**します。\n\n```python\nfolder = [\"COVID\", \"non-COVID\"]\nimage_size = 120\n\nX_train = []\ny_train = []\nX_test = []\ny_test = []\n\n\nfor index, name in enumerate(folder):\n    dir = \"/content/Covid19/train/\" + name\n    files = glob.glob(dir + \"/*.png\")\n    for i, file in enumerate(files):\n        image = Image.open(file)\n        image = image.convert(\"RGB\")\n        image = image.resize((image_size, image_size))\n        data = np.asarray(image)\n        X_train.append(data)\n        y_train.append(index)\n        shuffle=True\n        \n        \nfor index, name in enumerate(folder):\n    dir = \"/content/Covid19/validation/\" + name\n    files = glob.glob(dir + \"/*.png\")\n    for i, file in enumerate(files):\n        image = Image.open(file)\n        image = image.convert(\"RGB\")\n        image = image.resize((image_size, image_size))\n        data = np.asarray(image)\n        X_test.append(data)\n        y_test.append(index)\n        shuffle=True\n        \n        \nX_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\nX_train = X_train.astype('float32')\nX_train = X_train / 255.0\n\nX_test = X_test.astype('float32')\nX_test = X_test / 255.0\n\n# 正解ラベルの形式を変換\ny_train = np_utils.to_categorical(y_train, 2)\ny_test = np_utils.to_categorical(y_test,2)\n```\nそれぞれフォルダ内の画像のリサイズ、正規化を行います。\nまた、\n**X_train**\n**y_train**\n**X_test**\n**y_test**\nにそれぞれ格納していきます。\n\n```python\ndef model_train(X_train, y_train):\n    model = Sequential()\n\n    model.add(Conv2D(32, (3, 3), padding='same',input_shape=X_train.shape[1:]))\n    model.add(Activation('relu'))\n    model.add(Conv2D(32, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.20))\n \n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.20))\n    \n    model.add(Conv2D(64, (3, 3), padding='same'))\n    model.add(Activation('relu'))\n    model.add(Conv2D(64, (3, 3)))\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.20)) \n \n    model.add(Flatten())\n    model.add(Dense(64))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(2))\n    model.add(Activation('softmax'))\n    opt = keras.optimizers.adam(lr=0.0001, decay=1e-6)\n    model.compile(loss='categorical_crossentropy',optimizer= opt,metrics=['accuracy'])\n    return model\n```\nモデルの作成を行います。\n以上のようなモデルにしています。\n\n```python\ndef plot_history(history):\n    plt.plot(history.history['accuracy'],\"o-\",label=\"accuracy\")\n    plt.plot(history.history['val_accuracy'],\"o-\",label=\"val_acc\")\n    plt.title('model accuracy')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n \n    plt.plot(history.history['loss'],\"o-\",label=\"loss\",)\n    plt.plot(history.history['val_loss'],\"o-\",label=\"val_loss\")\n    plt.title('model loss')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(loc='lower right')\n    plt.show()\n```\n**accuracy , validation_accuracy , loss , validation_loss**を描画する\nための定義を行います。\n\n```python\n#ROCを定義    \ndef plot_roc(pred,y):\n    fpr, tpr, _ = roc_curve(y, pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure()\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc) # %0.2fで小数点第2位まで表示を指示\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver Operating Characteristic (ROC)')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n```\nここで**ROC曲線**を描くための定義を行います。\n\n```python\nif __name__ == \"__main__\":\n    model = model_train(X_train, y_train)\n    history = model.fit(X_train, y_train, \n        epochs=100,\n        batch_size=128,\n        validation_data=(X_test, y_test),\n             )\n    json_string = model.to_json()\n    open('Covid19.json', 'w').write(json_string)\n    model.save_weights('Covid19hdf5')\n    model.save(\"Covid19.h5\")\n    score = model.evaluate(X_train, y_train)\n    \n    print(\"test loss\", score[0])\n    print(\"test acc\",  score[1])\n\n    plot_history(history)\n    \n    #ROC\n    pred = model.predict(X_test)\n    pred = np.argmax(pred,axis=1)\n    y_compare = np.argmax(y_test,axis=1)\n    pred = pred[:] # Only positive cases\n    plot_roc(pred,y_compare)\n```\n実際に、**学習**を行います。\nさらに、**学習曲線**、**ROC曲線**も描きます。\n\n# 4. 実装結果\n学習を終えた実装結果です。\n計算時間は30～40分くらいだったと思います。\n\n**test loss：0.029283724984364403**\n**test acc：0.9919354915618896**\n\n![acc.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/9af7a835-d391-6ce5-1c06-6b1dc562c2be.png)\n![loss.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/03022865-a218-7bbd-c57c-2d27dd9bd1c4.png)\n![roc.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/674876/cb67175c-1452-e34b-2ecf-71bccaec11d8.png)\n\n結構良い精度の物が出来たのではないかと思っています。\n\n# 5. 参考\n◎ **過学習を防ぐために行った工夫**\n\n元々のkaggleのデータセットを用いて、順番に画像を分割して学習を行った場合\nロバスト性が低い結果となり、過学習が起きてしまいました…\n\nそこで\n\n**ランダム**な **training  / Validation** の振り分けを行い、過学習が改善されました。\n\n似たようなデータが並んでいる場合、主観的に順番に分割するとtestとvalidationに\n**データの偏り**が出来てしまい過学習が起きてしまうと考えられます。\n\nランダムなデータの分割にはこちらを参考にしました。\n[画像ディレクトリをtrain_test_splitする関数](https://qiita.com/komiya-m/items/c37c9bc308d5294d3260)\n\n◎ **ROC曲線(その他評価関数)**\n\n こちらの記事を参考にしてみてください。\n　　　　　　　↓\n [機械学習で使われる評価関数まとめ](https://qiita.com/monda00/items/a2ee8e0da51953c24da8)\n\nモデルを評価するという事はとても重要な部分になるので、理解は重要です。\n\n◎ **機械学習について**\n\n機械学習については、\n[機械学習って何？](https://medicalai-student.com/%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%81%a3%e3%81%a6%e4%bd%95%ef%bc%9f/)という記事にも書いています。\nもし良ければ、読んでみてください。\n\n# 6. おわりに\n今回は、**はじめて1年で「Covid19鑑別精度90%越のAI」を作った話**\nについての記事を書きました。\n\n僕自身、まだプログラミングを初めて1年程です。\n\n今回の記事にも間違い等や不足があるかと思います。\nその場合は、教えていただけるとありがたいです。\n\nしかし、はじめて1年の初学者でも作れるAIもあるということが伝えられたのではないかと思います。\n\nまた、**MediTech**を立ち上げプログラミングをもっと世の中に広めていきたいと思っています。\n\nLGTMもしてくださると嬉しいです！\n\nぜひMediTechの方もよろしくお願いします。\n\n# 7. 参照\n\n- [【秒速で無料GPUを使う】深層学習実践Tips on Colaboratory](https://qiita.com/tomo_makes/items/b3c60b10f7b25a0a5935)\n- [機械学習で使われる評価関数まとめ](https://qiita.com/komiya-m/items/c37c9bc308d5294d3260)\n- [見て試してわかる機械学習アルゴリズムの仕組み 機械学習図鑑](https://www.amazon.co.jp/%E8%A6%8B%E3%81%A6%E8%A9%A6%E3%81%97%E3%81%A6%E3%82%8F%E3%81%8B%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%A2%E3%83%AB%E3%82%B4%E3%83%AA%E3%82%BA%E3%83%A0%E3%81%AE%E4%BB%95%E7%B5%84%E3%81%BF-%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%9B%B3%E9%91%91-%E7%A7%8B%E5%BA%AD-%E4%BC%B8%E4%B9%9F/dp/4798155659)\n- [機械学習で使われる評価関数まとめ](https://qiita.com/monda00/items/a2ee8e0da51953c24da8)\n- [機械学習って何？](https://medicalai-student.com/%e6%a9%9f%e6%a2%b0%e5%ad%a6%e7%bf%92%e3%81%a3%e3%81%a6%e4%bd%95%ef%bc%9f/)\n\n\n\n\n\n\n\n\n\n\n\n","user":"rtInamoriRyusei","created_at":"2021-03-29T07:13:54+09:00","updated_at":"2021-03-29T10:07:25+09:00"},{"url":"https://qiita.com/wkamuy/items/641ff058ff352bc77fce","title":"[GitHub Actions] TOEIC試験までのカントダウンツイートを自動化","body":"# はじめに\n\nエンジニアをやっていると、さまざまな試験を受験する機会があります（情報処理試験、TOEICなどなど）。試験日までの残り日数を気軽に確認したいなと思い、GitHub ActionsとTwitter APIを利用して、作成して見ました。\n\n## 1. 作成物\n\nhttps://github.com/wkamuy/tweet-countdown\n\n## 2. 利用方法\n\n`.github/workflows/main.yml` をお好きなように、編集し利用できます。\n\n```main.yml\nname: 'tweet-coutdown'\non:\n  schedule:\n    - cron: '30 22 * * *'\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v2\n      - run: |\n          npm install && npm run build && npm run package\n      - uses: ./\n        with:\n          consumer_key: ${{ secrets.TWITTER_API_KEY }}\n          consumer_secret: ${{ secrets.TWITTER_API_SECRET_KEY }}\n          access_token_key: ${{ secrets.TWITTER_ACCESS_TOKEN }}\n          access_token_secret: ${{ secrets.TWITTER_ACCESS_TOKEN_SECRET }}\n          first_message: |\n            🕑 カウントダウン\n            📝 TOEIC試験 2021/02/28 まで\n          target_date: '2021/02/28'\n          last_message: |\n            あと少し頑張りましょう🙋🏻🙋🏻‍♀️\n            ※毎日 7:30 に更新(Github Actionsより)\n            #TOEIC\n            #カウントダウン\n            #勉強\n```\n\n結果は以下の通り。\n\n\n![tweet_image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/984188/eec509ca-8a01-f371-7567-da5a69910494.png)\n\n## 3. TOEICの結果\n\nちなみに、結果は 705点 でした。まあ700目標だからOKです。\n\n## 4. Javascriptアクションのテンプレート\n\n以下に、Javascriptのtemplateが用意されています。こちらをベースに作成しました。\n\nhttps://github.com/actions/typescript-action\n\n## 5. 所感\n\n* アクションが時間通りに動かない。大体15分程度のラグがあるようです。\n  * 参考/引用：[GitHub Actions のスケジュール実行はスケジュール通りには動いてくれないようだ\n](https://qiita.com/tommy_aka_jps/items/5f4fe384008ffc9fa794)\n* 気軽に無料でお試しできます。\n\n\n\n\n\n\n\n\n","user":"wkamuy","created_at":"2021-03-29T07:01:51+09:00","updated_at":"2021-03-29T07:02:56+09:00"},{"url":"https://qiita.com/ToaruEngineer/items/d1c87637cbdbf6167d52","title":"netlifyにReactプロジェクトをデプロイ","body":"最近書いたコードはGithubにプッシュをして何かしらのツールでデプロイすることを心がけています。\n\n折角毎日朝起きてコードを書いているのにも関わらず、それを証明するものがTwitterしかないのは心許ないですよね。\n\nそれであれば普通に使ったことのあるGithubに草を生やし、作ったアプリは誰でも触れるようにしていきたいと思いました。\n\n今回はGithub経由でNetlifyにデプロイしたいと思います。\n\n\n#netlifyのコマンドをインストールする\nまずコマンドをインストールします。\n\n```sh\nnpm install -g netlify-cli\n```\n\nインストール出来たか確認するためバージョンを見ます\n\n```sh\nnetlify -v\n```\n\n#Reactのプロジェクトを立ち上げる\n次にデプロイするReactの準備をします。\n定番の方法でやります。\n\n```sh\nnpm create-react-app ~~~~~\n````\n\nそれから今作ったディレクトリに移動します\n\n```sh\ncd ~~~~~\n```\n\n一応インストール出来ているか立ち上げて確認します。\n\n```sh\nnpm start\n```\nこれでReactの公式ページが見れたらここまで問題ないです。\n\n#gitに上げる準備\nここは簡潔にまとめてしまいます。\n\n```sh\ngit init\ngit add -A\ngit commit -m \"first commit\"\ngit remote add origin https://github.com/ユーザー名/プロジェクト名.git\ngit push -u origin master\n```\n\nこれでgitへのpushは成功しました。\n\n#netlifyでプロジェクトを立ち上げ\n[ここから](https://app.netlify.com)netlifyにログイン/サインアップしてください。\ngithubアカウントで登録するのが楽だと思います。\n\nログインするとトップページの真ん中に\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/481470/119dbad9-64f2-6007-dbbe-33d9f96be78a.png)\nがあると思うので、ここをクリックします。\n\nそれからGithubとnetliryを連携します。\n\n**New site from Git**をクリックした後のページに\n- Github\n- GitLab\n- BitBuchet\nの3つから連携する画面になるので今回はGithubを選択してインストールまで進めていってください。\n\n完了したらもう一度同じ手順でGitHubでプロジェクトを立ち上げて下さい。\n\n次は3つの中からGithubを選択するとGItHubにあるリモートリポジトリが表示されるので、先ほど作ったプロジェクト名のリポジトリを選択してください。\n\nそしたら**Create a new site**と表示され、色々いじれる画面に遷移したと思います。\n\nしかし今回はどこもいじらず**Deploy Site**をクリックしてください。\n\n#完了\nそしたら次の画面で\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/481470/4c6844a8-c540-5039-57e2-132197d41576.png)\n\nこのような場所があると思います。\n立ち上げた直後は緑の**Published**が黄色で表示されるので緑なるまで待ちます。\n\n緑になったら**eloquent-~~~~~.netlify.app**をクリックして下さい。\n\nこれで無事Reactのサイトを表示出来たら成功です。\n\n\n# まとめ\n\nどうでしたでしょうか？\nFirebaseなどよりも簡単に立ち上げる事が出来たのではないでしょか？\n\n少しセットアップを加えるだけでGithubに草を生やしつつプロジェクトを公開できるのでオススメです！\n\n\n今後はGit操作なしでnetlifyに立ち上げたりFIrebaseで立ち上げる方法を書いていきたいと思います！\n","user":"ToaruEngineer","created_at":"2021-03-29T06:49:13+09:00","updated_at":"2021-03-29T06:49:13+09:00"},{"url":"https://qiita.com/tkdtty/items/87b0967b0601b340cc89","title":"(SouceTree)ローカルで作成したgitリポジトリをGitHub上のリモートリポジトリと紐付ける","body":"\n## 手順\n1.ローカルに作業用リポジトリを作成。SouceTree上で開く。\n2.(GitHub上)リモートリポジトリを新規で作成する。（紐付けの対象）\n3.(SouceTree)対象のローカルリポジトリの、「設定」を選ぶ。\n4.「リモート」タブを選択。\n5.「追加」を選ぶ。\n6.リモートの名前:の欄に「origin」と入力。URL/パス：の欄にGitHub上でコピーできるリポジトリのアドレスを入力してOKする。\n7.紐付けたリモートリポジトリにプッシュする。\n\n***\n\n\n","user":"tkdtty","created_at":"2021-03-29T06:19:41+09:00","updated_at":"2021-03-29T06:19:41+09:00"},{"url":"https://qiita.com/e99h2121/items/cf6532f7fdce0fc38975","title":"有害な頑張りというアンチパターン - 不幸なリモートワーク、我慢のリモートワーク","body":"## 概要\n\n真面目にやると損をする不思議？\n不幸なリモートワーク、我慢のリモートワークは有害なのでやめようという話です。リモートワーク下。\n\n- がんばって生活時間を削って対応する。ギリギリ問題がないように見せる。\n    - 最初は「頑張っている/頑張ってくれているのだな」との相互理解があっても、1ヶ月もすぎればそれは「普通」。\n    - 周りは次第に、それは彼/彼女の「当たり前」であると勘違いさせられてしまう。\n- 一方頑張っている側は相変わらず「頑張っている」つもりに勘違いしてしまう。\n\n姿が見えないからです。タチが悪い。\n\n### 結果いつの間にか\n\n- 仕事を頼まれた側: 相変わらず頑張っているのにそれが当たり前に思われてしまう。ので、感謝されない。\n- 仕事を頼む側: 相手が頑張っていることに気づけない。ので、感謝できない。\n\nたいへん不幸なミスマッチが発生する。\n\n### 一線で水が溢れ出た時 \n\n- 仕事を頼まれた側: 無理です (というか元々無理目に頑張っていたし)\n- 仕事を頼む側: どうしてこうなるまで何も言わないの？ (普通にやれていたように見えていたし)\n\nというもっと不幸なすれ違いが発生する。\n[大事な言葉・HRT～「Humility（謙虚）」、「Respect（尊敬）」、「Trust（信頼）」。ああなんて難しい](https://qiita.com/developer-kikikaikai/items/9e08fe0f8ee0eebaccab) にもちょっとした話が書いてありました。これ、人間関係に発展したら目も当てられません。落ち着きましょう。頼む側も、頼まれた側も、悪くないのです。これを有害な頑張りと名付けタイトルにしました。\n\n\n### なのでどうする？\n\n負のサイクルをやめます。とりあえず「頑張っているあなた」の側から原因を断つ方法です。\n我慢の対応は持って1ヶ月（それでも長い）と心得ます。\n\n- メールやSlackは見ない。\n- 仮に見ても、中途半端な返答をすると、わかったと勘違いされるので、誤解を回避するためには返答しないが相手へのマナー。\n- **中途半端な気遣いの返答、対応は無視より有害**。\n\n\n## 基本 (当たり前のことです)\n\n- 有給をちゃんと取る。\n- 勤務時間を決め、そのとおりに勤務する。\n- 好きなこと（好きな勉強）をする時間もその時間内に確保する。\n- 寝る。\n\n勉強は [70:20:10の法則](https://note.com/sazawe/n/n628beed7d803) - 成長しないとお仕事できない。\nそして蛇足ですがもちろん。もしこれを読んでいるあなたが「仕事を頼む側」だったら、部下が頑張り屋かどうかを気遣うのはマネジメント責任ですよね。\n\n\n## ちょうどわかりやすかったので参考\n\n「リモートワークで心得たい5つのTips」\nhttps://catalins.tech/5-tips-you-want-to-see-if-you-work-remotely\n* 以下、DeepL翻訳の整形です。\n\n### 1. ワークライフバランス\n- 健康、生活、家族、友人を大切にするなら、健康的なワーク・ライフ・バランスをとることが何よりも重要。\n\n- 自宅に職場があると、ついつい頑張りすぎてしまいます。一線を越えてワーカホリックになるのは簡単です。あと1つのタスク、あと1つの機能、あと1つのメール...と自分に嘘をついてしまうのです。そして、振り返ってみると、時間の大半を仕事に費やしていたことに気づくのです。\n\n- 仕事が終わったら、仕事に関連するすべてのものを閉じて無視することを恐れないでください。24時間365日、仕事ができる状態である必要はありません。契約では（ほとんどの場合）8時間の勤務時間が定められていますから。\n\n- 自分や大切な人との時間を作る。**明日、あなたに何かあったとしても、あなたの面倒を見てくれるのは会社ではありません。**自分の家族、友人、愛する人たちです。彼らは、どんな仕事よりも貴重な存在です。\n\n- 勤務時間の設定 - 午前8時から午後4時まで働く？しかし、その勤務時間を超えてはいけません。メールに返信したり、次のプロジェクトのことを考えたりするのは、次の仕事の日にしましょう。\n\n- 休みを楽しむ - **IT業界はクレイジーな世界です**（時々）。技術の世界についていくためには、仕事をするか、空いた時間に勉強するかのどちらかしかないように感じます。これは燃え尽き症候群とストレスへの片道切符です。\n\n- 空き時間に勉強したりコーディングしたりするのは構いませんが、そればかりではいけません。ストレスを解消し、リラックスし、充電するために休みを取りましょう。\n\n-上記はすべてを網羅しているわけではなく、ワークライフバランスを構築・改善する方法はたくさんあります。しかし、これらは私のワーク・ライフ・バランスの柱となっています。\n\n### 2. 気が散るものをブロックして生産性を最大限に高める\n\n- オフィスでは、チームメイトや上司と一緒に仕事をしていました。そのため、ソーシャルメディアを閲覧する「無駄な時間」を過ごしていると、周囲から見られてしまいます。なのでできるだけ無駄な時間を使わないようにしていました。\n\n- しかし、リモートワークではそれが変わりました。同僚や上司に囲まれているわけではありません。私たちは一人で行動しているのです。そうなると、時間の無駄遣いに陥りやすくなり、多くの時間を費やすことになります。**誰も私たちを見ることはできませんからね。**\n\n- 仕事場をきれいにする。整理整頓をして、仕事場を気が散らないようにすることです。携帯電話、財布、タブレット、ゲーム機など、気が散るものは何でも取り除きましょう。\n\n- ソーシャルメディアを何十分、何時間も見続けてしまうことはよくあることです。ソーシャルメディアを見ていると、信じられないくらい時間が経つのが早く感じられる。\n\n- ソーシャルメディアをブロックしましょう。ありがたいことに、このような気晴らしをブロックするためのオプションはたくさんあります。デスクトップアプリケーションやブラウザの拡張機能など。\n\n### 3. スケジュールを立てる\n\n- 自分に合ったスケジュールを立てましょう。朝のほうが仕事がはかどるという人は、朝の時間を増やすようにしましょう。夜のほうが得意な人は、夜にやればいい。重要なのは、自分が最高の状態で集中して仕事ができる時間を見つけることです。\n\n- ベストな状態であることに加えて、中断せずに仕事ができる時間を見つけてください。邪魔されにくい時間帯を見つけることは非常に重要です。他の人に邪魔されればされるほど、仕事ができなくなってしまいます。これは人によって異なります。\n\n- 最終的には、自分で試してみて、自分に合うものを見つけなければなりません。すべての人に通用する普遍的な道はありません。要するに、スケジュールを立てることで、集中して邪魔されない時間を仕事に使えるということです。\n\n\n### 4. タスクリストと日誌を作る\n\n- 頭の中を整理することは、自分のためにできる最善の方法のひとつです。すべてを頭の中で整理しようとすると、ストレスがたまり、情報を忘れやすくなります。\n\n- Notionのようなアプリケーションを利用すればメモを取り、脳のリソースを解放することができます。\n\n- つまり、脳から不要な情報を取り除き、そのエネルギーをより重要な仕事に使うということです。\n\n### 5. 時間管理能力を高める\n\n- 時間管理のスキルは、主にリモートで仕事をする際には欠かせません。時間管理能力を高めるためにまずできることは、タスクに優先順位をつけることです。タスクの優先順位は、次のように考えることができます。\n    - 重要度の高いタスク - 最も困難であり、かつ、影響度が高いため、最初に行うべきタスクです。\n    - 重要度が中程度のタスク - 重要度が高いタスクよりは重要度が低いが、重要度が低いタスクよりは重要度が高いタスク。\n    - 重要度の低いタスク - 緊急性がなく、影響度も高くないため、いつでもできるタスクです。\n- もうひとつの方法は、**他の人ができる仕事を任せることです。**自分の負担を減らして仕事を任せることができるのに、すべてをやろうとする必要はありません。言うは易し、行うは難しですが、仕事を任せることは素晴らしいことです。\n\n- 3つ目は、まず1つのタスクに集中することです。マルチタスクは、いろいろなことをやっても終わらない。あるいは質の悪いものを作ってしまう。マルチタスクが称賛される世の中だからこそ、シングルタスクに徹するようにしましょう。1つの仕事を終わらせてから別の仕事に移る。\n\n\n## まとめ\n\n「[オンコールは一朝一夕にはいかない。高度なスキルが必要だが、属人化してはダメだ](https://qiita.com/san-tak/items/c62e691a6955dc7de37b)」も読んだ。\n\n自分はオンコールばかりではないのだが、それでも自分向けに書いたら、[休んでいいですよ](https://nlab.itmedia.co.jp/nl/articles/2103/12/news147.html) チャートよりちょっと厳し目な物言いになった。裁量があるお仕事にはリモートワーク、高難度過ぎます。\n\nでなくてもソフトウェア業界の過重労働、あるいは人による偏りって、大事な人間関係問題になってしまうまえにどうにかしたいですよね。以前みたいに一杯や、メシさそうこともできないし。だからせめて「当たり前のこと」を皆が共通に、常識だと思えるやさしい世界になりますように。\n\nなにがしかの参考になればさいわいです。\n","user":"e99h2121","created_at":"2021-03-29T06:17:02+09:00","updated_at":"2021-03-29T07:55:30+09:00"},{"url":"https://qiita.com/tomo-IR/items/224d33f14561e759dd16","title":"【docker】db:createすると、Plugin caching_sha2_password could not be loaded...のエラーハマった話","body":"# 背景\nrailsで作成中のアプリに、開発環境にDockerを導入していました。\n\n\n# DBをcreateしようとするも下記エラー\n\nコンテナのビルドは問題なく出来たので、次にDBを作成するべくこのコマンドを実行したら、下記のエラーに遭遇しました。\n\n```terminal\n$ docker-compose run web bundle exec rake db:create\n\n\nCreating network \"golfscore_default\" with the default driver\nCreating golfscore_db_1 ... done\nCreating golfscore_web_run ... done\nPlugin caching_sha2_password could not be loaded: /usr/lib/x86_64-linux-gnu/mariadb19/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory\nCouldn't create 'golfscore_development' database. Please check your configuration.\nrake aborted!\nMysql2::Error::ConnectionError: Plugin caching_sha2_password could not be loaded: /usr/lib/x86_64-linux-gnu/mariadb19/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory\n```\n\n# 原因と対策\nMysql 8以降、認証プラグインの仕様が変わったためのようです。\nユーザーのプラグインをmysql_native_passwordに変更していきます。\n\n# docker内のmysqlにログインし、plugin変更\nまずはコンテナ内のMysqlにログインするため、コンテナIDを調べます。\n\n```\n$ docker ps                                            \nCONTAINER ID   IMAGE          COMMAND                  CREATED         STATUS         PORTS                               NAMES\nbcc91696ca70   mysql:8.0.23   \"docker-entrypoint.s…\"   3 minutes ago   Up 3 minutes   33060/tcp, 0.0.0.0:4306->3306/tcp   golfscore_db_1\n```\n\nコンテナIDがわかったので、入ります。\n\n```\n$ docker exec -it bcc91696ca70 bash\n```\n\n入れました。Mysqlに入ります。\n\n```\nroot@bcc91696ca70:/# mysql -uroot -p\n```\n\nMysqlのパスワードを入力します。\n\n```\nEnter password: \nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 9\nServer version: 8.0.23 MySQL Community Server - GPL\n\nCopyright (c) 2000, 2021, Oracle and/or its affiliates.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n```\n\nこのコマンドを実行して、現在のプラグインの状況を確認します。\n\n```sql\nmysql> SELECT user, host, plugin FROM mysql.user; \n```\n\nやはり、caching_sha2_passwordになっています。今回はこれが悪さしているようですので、変更していきます。\n![スクリーンショット 2021-03-29 5.53.45.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/693502/1c5dc6f9-ceb1-10de-ad9c-1bc8fe0d08ae.png)\n\n下記、2コマンド実行して、root user部分の2箇所を変更します。\n('password'部分は各自DBのパスワードを入力)\n\n```sql\nmysql> ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n```sql\nmysql> ALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY 'password';\nQuery OK, 0 rows affected (0.01 sec)\n```\n\n変更できたか確認してみます。\n\n```sql\nmysql> SELECT user, host, plugin FROM mysql.user;\n```\n無事、mysql_native_passwordに変更されています。\n![スクリーンショット 2021-03-29 5.53.35.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/693502/d4e93dfb-ccba-835f-34a0-42abdf6ddc00.png)\n\n\n再度、DBを作成し、無事に成功しました。\n\n```terminal\n$ docker-compose run web bundle exec rake db:create    \nCreating golfscore_web_run ... done\nCreated database 'golfscore_development'\nCreated database 'golfscore_test'\n```\n\n\n# 参考\nhttps://yamasey712.hatenablog.com/entry/2019/08/28/213507\n\nhttps://qiita.com/majorboy/items/9fbfc78fc7bbc1f35e77\n\nhttps://qiita.com/shungo_m/items/5363c16b698ef6310014\n","user":"tomo-IR","created_at":"2021-03-29T06:14:57+09:00","updated_at":"2021-03-29T06:14:57+09:00"},{"url":"https://qiita.com/yakitatata/items/c432522a865f534b769e","title":"SSLの独自ドメイン静的Webサイトを低コストで15分で立ち上げる (Route53 + S3 + CloudFront + AWS Certificate Manager)","body":"\n\n# こんな人向け\n+ VPSよりAWS使うのが好きな人\n+ 静的WebサイトなのにわざわざEC2立てて運用している人\n+ 現在S3で静的Webサイトを公開しているけどSSLに対応していない人\n+ AWS使ってみたいけどハードルが高そうと思っている人\n+ そもそもwebサイトをインターネットに公開するのが初めてな人\n\n今回、タイトル通りの構成で静的Webサイトをネット上に公開するやり方を紹介していきます。\n高可用性・高耐久性の爆速Webサイトが多分15分くらいでできちゃいます。\n\nこの構成は世の中に沢山記事が出ていますが、\n独自にハマったこともあるため防備録として記事にすることにしました。\n\n\n\n# この記事でやらないこと\n+ お名前.com等での独自ドメインの取得方法、ネームサーバーの変更方法\n+ awsのアカウント作成\n+ awsのIAMの設定\n+ 各サービスの詳細な説明\n+ 各種チューニング\n\n\n# 前準備\n独自ドメインの取得。\n今回はRoute53で取得しました。\n\n\n# 本題\n以下、順番にやっていきます。\n## Route53でホストゾーンを作成する（Route53でドメインを取得した場合は省略）\n\nRoute53 >> ホストゾーン\nに入り「ホストゾーンの作成」をクリックします。\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/a7eaa929-c29a-91bb-2930-96261b7253d4.png)|\n|:--|\n\nドメイン名に取得した独自ドメインを入力し、他はデフォルトのまま「ホストゾーンを作成」を押下。\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/33811d2e-e080-f859-198d-07c44acf8cd1.png)|\n|:--|\n\nこのように2件のレコードが入った状態で作成されます。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/b5c61ed8-e15c-6c4b-a86a-6d1569814e37.png)\n\nRoute53でドメインを取得した場合、この状態が自然と出来上がっています。\n\n\n## 独自ドメインのネームサーバーをRoute53に向ける\n当記事はRoute53でドメイン取得しちゃったので省略しますが、\nお名前.com等でドメインを取得している場合、\nドメインの管理画面からネームサーバーを変更する必要があります。\nドメインを取得した会社のデフォルトのネームサーバーになっていると思いますので、\nホストゾーンのNSレコードに表示されている4件のネームサーバーに変更します。\n\n変更のやり方はネットに情報が溢れていますので、\n「お名前.com　DNS変更」とかでググってください。\n\n## S3バケットの作成\n実際のコンテンツをいれるバケットを作成します。\nS3に入り「バケットの作成」をクリック\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/66515162-e914-aad0-24bf-f173f0844ccd.png)|\n|:--|\n\nバケット名に独自ドメインを入力\nリージョンは日本で運用するなら東京か大阪を選択したいところですが、\n初めてのお試し段階では段階ではバージニア北部を選択するのが無難です（※理由は後述）\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/12f1652e-f36a-5c50-6391-4b4867180eb2.png)\n\n他はすべてデフォルトのまま作成します。\nS3を静的Webサイトとしてホスティングする場合、\nパブリックアクセスを有効にしたりしますが、今回の構成ではパブリックアクセスはブロックのままで大丈夫です（むしろブロックしててください）\n\n## S3にファイルをアップロード\n作成したバケットを選択して、ページから簡単にアップロードできます\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/992571f2-2eb4-26a4-867e-7dfe7c459ac1.png)|\n|:--|\n\n\n\n## SSL証明書の作成\nCertificateManagerに入り、リージョンをバージニア北部に変更します。\n*このリージョン変更は必ず行います*\nS3のバケットが東京や大阪にある場合でも、SSL証明書の作成はバージニア北部で行います。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/7756af15-badf-6cf5-d1a8-9da94a2e6735.png)\n\nパブリック証明書のリクエスト　で次へ\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/0c0929d5-2eeb-30ef-3774-ec5f2d924ce6.png)|\n|:--|\n\n\nドメイン名に独自ドメインを。\n別名に*.独自ドメインを設定し次へ\n今回「www.独自ドメイン」でもアクセスさせたいので別名を追加しています。\n*.独自ドメインでも単にwww.独自ドメインでも大丈夫です。\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/e0f1ea6f-38aa-0144-c7fb-ecda3929193d.png)|\n|:--|\n\nDNSの検証で次へ\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/a4e398cc-142e-94f7-18bd-c43e45c9669b.png)|\n|:--|\n\nタグは別にいらないのでそのまま次へ\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/0c3475cb-4182-c061-4403-13e2a8cd5cf1.png)|\n|:--|\n\nそのまま確定とリクエスト\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/3addbb1e-59b8-4da8-1104-c8f81bf15a1a.png)|\n|:--|\n\n\nここでそのまま続行せずに表示されているドメイン名をクリックします。\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/e85630d5-2a87-85ce-a2e4-c29255f48ca0.png)|\n|:--|\n\nここでRoute53でのレコード作成をします。\n別名が複数ある場合はすべてに対して行います。\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/64f14714-0843-1e83-fa83-42925734e899.png)|\n|:--|\n\n少し待って、このように、お客様によるアクションは必要ありませんと表示されたらラッキーです。\nすべてがうまく行っています。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/cd0d1a8a-aa9b-2029-b10a-6b7f55f87263.png)\n\n以下のように追加のアクションが必要ですと表示された場合は、ガイドに従って必要なアクションをしてください。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/f7bae1f1-34d6-72ff-4c2c-8209c04a7731.png)\n\n\nドメイン管理サイトのネームサーバーの変更に時間がかかっている場合もこうなります。\n間違っている気がしない場合は少し時間を置いてみましょう。\n\n続行してしばらく待つとこのようにステータスが発行済になります。\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/ad1ef211-dbe0-ead3-1384-c36f28582cd8.png)|\n|:--|\n\nRoute53でホストゾーンを見るとCNAMEレコードが追加されています。\n\n\n## CroudFrontの作成\nサービス一覧からCloudFrontに入りCreateDistributionをクリック\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/51833b97-e3dc-511c-5ccf-9becb48e7d6b.png)\n\n\n\n以下のように設定します。\n>Origin Domain Name：作成したs3バケットを選択\nRestrict Bucket Access:Yes\nOrigin Access Identity:Create a New Identity\nGrant Read Permissions on Bucket: Yes,Update Bucket Policy\nViewer Protocol Policy：Redirect HTTP to HTTPS\nCache Policy：Managed-ChathingDisabled\nAlternate Domain Names(CNAMEs):独自ドメインと、独自ドメインの別名\nSSL Certificate:Customを選択し、作成したSSL証明書を選択\nDefault Root Object:index.html\n\nOrigin IDは自動で入ります。\n\n※CloudFrontの売りであるキャッシュをここで無効にしているのは、理由があります。\n初めての構築でハマることもあると思います。\n他の設定も色んなところを弄って遊んでみることもあると思います。\nその時に、キャッシュが効いていたら設定した内容の動きをしているのか、していないのかさっぱりわからない状況になってしまいます。\n変にイジって動かなくなって、頑張って戻してやっと成功したと思って時間が立ったらまた動かなくなってる。みたいなこともあるかと思います。\nいつぞやのたまたまうまくいっている設定がキャッシュされているパターンですね。\n\nですので、スタートアップ時はキャッシュを無効にしておいて、運用開始直前でキャッシュを有効にするのがいいです。\n\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/dbd9b5f1-ebdf-b7ba-c052-91947a5be426.png)|\n|:--|\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/180795d2-17a8-3d10-456d-ddcefd8eba9a.png)|\n|:--|\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/30b0f4d0-5671-9bf8-a5b6-dcd383a3854e.png)|\n|:--|\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/4f45b964-2c39-ccda-85ff-a40c7dcdb031.png)|\n|:--|\n\n\nここで選択するSSL証明書はバージニア北部のリージョンで作成したものしかリストアップされません。\nSSL証明書をバージニア北部で作成する必要があったのはこのためです。\n\nRestrict Bucket Accessで作成したアクセスポリシーがs3バケットに反映されていると思います。\n見てみましょう。\nサービスからS3 -> 作成したバケット -> アクセス許可\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/8d109dc7-fb68-75c9-5e3f-1ff9dd44cddc.png)\n|:--|\n\nこれでS3自体はパブリックアクセスをすべてブロックしていて、静的ウェブサイトホスティングも有効にしていませんが、\nCloudFrontからはアクセスできるようになります。\n\n\n## Route53の設定（独自ドメインへのアクセスをCloudFrontに向ける）\n作成したホストゾーンに入り、「レコードの作成」をクリック\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/cbbb3ce8-1553-b657-3fd8-de962fa78fc6.png)|\n|:--|\n\n以下のように作成\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/dad7baad-61d7-1b4f-006b-33438e602ce1.png)|\n|:--|\n\nエイリアスで作成したCloudFrontが選択できるようになっています。\n\nwwwも受ける。CNAMEとかではエイリアスが出てこないのでAレコードでwwwなしを指定してます。\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/a6242827-97a5-4dce-15f4-ef2628c28692.png)|\n|:--|\n\n\n以上で終わりです。\nスムーズにいけばおそらく15分〜30分程度で完了したんではないでしょうか？\n独自ドメインでweb上に公開されているか確認しましょう。\n\n大丈夫そうなら運用開始前に忘れずにCloudFrontのキャッシュを有効化してください。\n以下のようにキャッシュポリシーを変更します。\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/0e8b4226-6af0-6891-72d7-b292eda88130.png)|\n|:--|\n\n|![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/71a21e03-8c66-abac-c968-b91ab1245f8b.png)|\n|:--|\n\n\n\n# 料金について\nそれぞれのサービスで従量課金の利用料がかかりますが、\nアクセスの少ない個人営業飲食店などのサイトだったらほとんど無料枠でいけちゃうと思います。\n行っても月1000円程度？もっと安いか。\nアフィリエイト入れているサイトなら仮に運用費が高くついても収入と比べて赤字になることは無いと思います。\nちゃんと試算していませんので気になる方は公式の料金表や試算している方のサイトをご覧ください。\n\n公式の料金表ページを貼っておきます。\n\nhttps://aws.amazon.com/jp/s3/pricing/\n\nhttps://aws.amazon.com/jp/route53/pricing/\n\nhttps://aws.amazon.com/jp/cloudfront/pricing/\n\nhttps://aws.amazon.com/jp/certificate-manager/pricing/\n\ncertificate-managerは無料です。つまりSSLは無料。\n\n\n10年前ならコストが高いリッチな構成が今ではただみたいな料金でできます。\n時代の進化はすごいですね。\n\n# おまけ\n## CloudFrontのキャッシュクリア方法\nInvalidationsからキャッシュを削除したいパスを入力します。\nすべて削除するなら　/* のように入力します。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/238561/0c0883f6-b220-10fd-8c5f-b5d7391d3f5d.png)\n\nこちらは無料枠がありますが、無料枠を超えるとファイル毎に料金がかかりますのでお気をつけください。\n悲しいお話を見つけました。\n\nhttps://techblog.gmo-ap.jp/2016/09/30/amazoncloudfront%E3%81%AEinvaridation%E6%A9%9F%E8%83%BD%E3%81%A720%E4%B8%87%E5%86%86%E3%81%B6%E3%81%A3%E9%A3%9B%E3%81%B0%E3%81%97%E3%81%9F%E8%A9%B1/\n\n## S3を北部バージニアで作成した理由\n詳しくは[S3+CloudFrontでS3のURLにリダイレクトされてしまう場合の対処法](https://dev.classmethod.jp/articles/s3-cloudfront-redirect/)をご参照ください。\n\n自分も一回ハマりました。\n\n別にすぐ解決できるから好きなリージョンで作ればいいと思いますが、\nチュートリアルであまりコケて諦めてほしくないのでS3のリージョンをバージニア北部に指定しました。\nSSLがバージニア北部で作成する必要があるので合わせた方がわかり良いかなという思いもあります。\n\n日本での運用では大阪か東京にすると思いますが、\n正直CloudFrontが前にいるので別にバージニアでいい気がします。\n\n# 最後に\n簡単でしたか？\nS3のホスティング機能でWebサイトを公開している方は沢山いると思いますが\nS3ってsslつけれないんですよね。\n最近のブラウザはsslじゃないとすぐ煽ってくるのでSSL化が当たり前の時代になっています。\nこの機会にチャレンジしてみてはいかがでしょうか。\n\n## 気に入った所\n・すごい構成なのに安い\n・簡単（いらんことしてハマらなければ）\n\n## 気に入らない所\n・www有りはwww無しにリダイレクトしたいけど、このままの構成ではできない\n・S3へのアップロードが昔ながらのFTPで上げているみたいでなんかいやだしめんどくさい（上げ漏れとか起きそう）\n　でもWebデザイナーさんにも使えるようになってほしい構成なのでAWS CLIを使わせるのは気が引ける\n\nこのあたりは解決策がありますのでまた記事をあげようと思います。\n\n## その他\nモザイク処理が面倒くさかった。次はしない（かも）\n\n# 特に参考にさせていただきました。\n\nhttps://blog.s0014.com/posts/2018-12-03-s3-https/\n\nhttps://dev.classmethod.jp/articles/static-contents-delivery-patterns/\n\nhttps://dev.classmethod.jp/articles/s3-cloudfront-redirect/\n","user":"yakitatata","created_at":"2021-03-29T05:58:27+09:00","updated_at":"2021-03-29T06:00:09+09:00"},{"url":"https://qiita.com/Rahariku/items/4b85815a4369782512b2","title":"Pytorchで学習処理をパッケージ化","body":"# はじめに\n\n画像分類問題の練習のために友人と5人で[Signateの練習問題](https://signate.jp/competitions/108)に投稿したのですが、その時に自作した機能を紹介します。\n\n# 機能自作の経緯\n\n### 1. 実装開始の前に\n集まったメンバはAIについて勉強はしていましたが普段からプログラミングしているわけではなかっので、画像分類問題は初めてのメンバもいたり、スキルレベルもまちまちでした。\nなので、お互い教え合いながらやっていく方針で取り組みました。\nまた、色々事情もあり取り組む期間は2週間という特殊な制約もありました。\n\n5人で同じ問題に取り組むにあたって同じ設定で実装をしないと教え合うことが難しいので、まず以下のことを決めました。\n\n- 開発言語はPython\n- DL用FWはPytorch\n- Google Colaboratoryで実行\n\nFWについては私がPytorchを使っていたこと、もう2人が練習中であっためTensorflowではなくPytorchを使うことにしました。\n\n### 2. 各メンバで学習処理を実装開始\n\nResnetを転移学習してベースモデルを作ることをまずは目指して実装を始めました。\nPytorchを使ったことある方はご存知と思いますが、以下のことを実装する必要があります。\n\n- Datasetの作成\n- DataLoaderの作成\n- Model定義\n- 誤差関数、最適化関数の定義\n- 学習ループの作成\n- バリデーション\n\n意気揚々と取り組み始めましたが、最初のデータセット用のリストや画像読込、ちょっとした前処理などで結構苦戦しました。\nみんな早く学習処理回したかったのですが、相談しながらやってるとModel定義まで中々時間がかかってしまいました。\n\n### 3. 学習処理のパッケージ化\n\nこのままだと2週間の期間内に終わらなさそうだったので学習処理部分をクラス化してチームメンバに配布することにしました。\nということで、実装する機能についての要件を簡単に検討して作成しました。\n\n# 機能要件\n\nメンバの状況を見つつ、取り合えず以下のような要件を決めました。\n\n- ソースコードをコピペじゃなくって、パッケージ化してimportさせる\n- 学習処理は隠ぺいしてパラメータ与えてメソッド一発で学習してくれる\n- モデルは色々選びたいので別クラスにして入力にする\n- モデル保存、バリデーションといっためんどくさい処理もやってくれる\n\nとにかく色々めんどくさいをまとめて、処理してくれてくれるものとしました。\nまた、pytorch-ligntningとかcatalystなどの充実したパッケージもあるんですが、機能が多いのと使い方を覚えないといけないので必要な機能のみを自作するということとしました。\n\nその結果、myTorchLib.pyというファイルにTrainerクラスを実装して共有しました。\n\n# 実装したコード紹介\n\n以下がTrainerクラスの実装です。\n急いで作ったので微妙な部分あるかもですが、甘い目で見て頂けたらと思います。\n\n```python\n\nclass Trainer():\n  def __init__(self, model, criterion, optimizer, params=None ):\n    \n    if params is None:\n      params = {\n          \"EPOCH\" : 5\n      }\n\n    self.__model = model\n    self.__criterion = criterion\n    self.__optimizer = optimizer\n    self.__params = params\n\n    # model 保存用\n    self.__current_loss = None\n\n    # デフォルトはCPU設定\n    self.__device = \"cpu\"\n\n  # gpuへ転送されたtorch.tensorのデータをnumpy（cpu）形式に変換\n  def __to_numpy(self, x):\n    return x.to(\"cpu\").detach().numpy().copy()\n\n  # バッチ単位のlossのaverage計算のため\n  def __avarage_loss(self, loss):\n    return np.sum(loss) / len(np.ravel(loss))\n\n  # モデルの保存\n  def __save_model(self, epoch, loss=None, save_model_name=\"model\", save_dir=\"./\", save_method = \"best_model\"):\n    # モデル保存用のパス作成\n    if save_method == \"best_model\":\n      file_name = save_dir + save_model_name + \"_best.pth\"\n      # lossが一番低いモデルを保存\n      if self.__current_loss is None:\n        torch.save(self.__model.state_dict(), file_name)\n        self.__current_loss = loss\n      elif loss < self.__current_loss:\n        torch.save(self.__model.state_dict(), file_name)\n        self.__current_loss = loss\n    elif save_method == \"epoch\":\n      file_name = save_dir + save_model_name + \"_E_\" + str(epoch) + \".pth\"\n      # Epoch毎に保存\n      torch.save(self.__model.state_dict(), file_name)\n\n  # 1 ループの処理\n  def __training_step(self, inputs, labels):\n    outputs = self.__model(inputs)\n    loss = self.__criterion(outputs, labels)\n    loss.backward()\n    return outputs, loss.item()\n\n  # バリデーション\n  def __validation_step(self, inputs, labels):\n    with torch.no_grad():\n      outputs = self.__model(inputs)\n      loss = self.__criterion(outputs, labels)\n    return outputs, loss.item()\n\n  # 1 epoch の処理\n  def __train_valid_loop(self, loader: data.DataLoader, phase: str =\"train\"):\n    loss_data = []\n\n    for inputs, labels in tqdm(loader):\n\n      inputs = inputs.to(self.__device)\n      labels = labels.to(self.__device)\n    \n      if phase == \"train\":\n        self.__optimizer.zero_grad()\n        preds, loss = self.__training_step(inputs, labels)\n        self.__optimizer.step()\n      else:\n        preds, loss = self.__validation_step(inputs, labels)\n\n      loss_data.append(loss)\n    \n    out_loss = self.__avarage_loss(loss_data)\n    return out_loss\n\n  # デバイス設定：（device = \"cuda\" if torch.cuda.is_available() else \"cpu\"）の結果を渡す\n  def to(self, device):\n    self.__device = device\n\n  # 学習処理実行用メソッド（外部公開用）\n  def train(self, train_loader: data.DataLoader, valid_loader: data.DataLoader=None, save_model_name=\"model\", save_dir=\"./\", save_method = \"best_model\"):\n    train_loss_log = []\n    valid_loss_log = []\n    for epoch in range(self.__params[\"EPOCH\"]):\n      # training\n      self.__model.train()\n      train_loss = self.__train_valid_loop(train_loader)\n      train_loss_log.append(train_loss)\n      print(\"EPOCH : \", epoch, \" training loss : \", train_loss)\n\n      # validation\n      if valid_loader != None:\n        self.__model.eval()\n        valid_loss = self.__train_valid_loop(valid_loader, phase=\"valid\")\n        valid_loss_log.append(valid_loss)\n        print(\"EPOCH : \", epoch, \" validation loss : \", valid_loss)\n      \n      self.__save_model(epoch, train_loss, save_model_name, save_dir, save_method)\n    return train_loss_log, valid_loss_log\n```\n\n# コード解説\n\nまず、別ファイル（myTorchLib.py）として共有したので以下のように配置してnotebookからTrainerクラスをインポートするようにしました。\n\n```\n┣ Lib\n┃　┗ myTorchLib.py\n┗ basemodel.ipynb\n```\n\nインポートするときは以下のようにします。\n\n``` python\nimport Lib.myTorchLib as mylib\n```\n\nTrainerクラスが公開する機能は以下の2つです。\n\n- train()：学習処理\n- to()：gpu, cpu設定\n\n学習処理の実行部分のみを公開して、学習ループの実処理部分は非公開にしました。\nこれによってDataset, DataLoader, modelを作ってtrainメソッドを呼び出せば学習、バリデーションが回ってくれるようになります。\n学習処理を実行するときは、Trainerクラスのインスタンスをを作成します。\nこの時、モデル（model）、誤差関数（criterion）、最適化関数（optimizer）、パラメータ（params）を指定します。\n今のところparamsにはEPOCH（エポック数）しか対応していません。\nそして、train_dataloader, valid_dataloader等を指定してtrainメソッドを実行すると学習処理が回ります。\n\n```python\nparams = {\n    \"EPOCH\": 10 # epoch数を指定\n}\ntrainer = mylib.Trainer(model=model, criterion=criterion, optimizer=optimizer, params=params)\ntrainer.to(device)\ntrainer.train(\n    train_dataloader, # 学習データ用のDataLoader（必須）\n    valid_dataloader, # バリデーション用のDataLoader(未指定であればバリデーションなし)\n    save_model_name=\"resnet\", # 保存モデル名\n    save_dir=\"./model/\", # 保存場所\n    save_method=\"best_model\" # 保存方法（'best_model' : lossが一番低いモデルを保存, \"epoch\"：毎エポック保存、それ以外の文字列はモデル保存なし）\n    )\n```\n\n共有後は自分でも使いつつ、モデル保存処理や各エポック毎のlossの出力などの機能を追加しました。\ntrainメソッドについてですが、\n必須なのはtrain_dataloaderのみです。\nvalid_dataloader未設定の場合はバリデーションなしで動きます。\nsave_model_name、save_dir、save_methodはモデル保存のための設定なので、未設定の場合はデフォルト設定で処理されます。\n\nこれによって学習処理部分はメソッドを呼び出すだけとなり、一緒に取り組んだメンバはmodelや前処理の実装に集中できるようになりました。\n\n# 使ってみた感想\n\n今回は画像分類問題に対して転移学習で学習する利用ケースだけだったので限定した機能だけの実装で作ることができましたし、使うことができました。\nこれによって、各メンバが色んなモデルを試すことが出来ましたし短期的ですが役立つことができたと思います。\n機能が少ないことが逆に良かったのかもしれません。\n\n正直なところ、catalystなどを超絶に劣化させたようなものなのでこれから使うのであればcatalystやpytorch-lightningを使った方が良いと思います。\nただ、自分の作ったものを人に使ってもらえて感想をもらって改造していけるのはとてもありがたく嬉しいことだなと思いました。\n\n最後に、私の実装したことが何かお役に立てば幸いです。\n\n# 参考情報\n\n- [pytroch-lightning](https://github.com/PyTorchLightning/pytorch-lightning)\n- [catalyst](https://catalyst-team.github.io/catalyst/)\n- 各フレームワークの比較は以下の記事がとても参考になりました\n    - [PyTorch 三国志（Ignite・Catalyst・Lightning）](https://qiita.com/fam_taro/items/c32e0a21cec5704d9a92)\n\n","user":"Rahariku","created_at":"2021-03-29T05:52:29+09:00","updated_at":"2021-03-29T05:52:29+09:00"},{"url":"https://qiita.com/white_tiger/items/db3cc6a6cfdd75bd4b78","title":"2重登録制御","body":"#### トーク制御\nトークン制御は登録、更新、検索処理をボタンなどに対して、ボタンの二重クリックを防止する。\n\n### 代表的な制御方法\n#### 1.javaScript\n更新処理を行うボタンを押下した際に、JavaScriptによるボタン制御を行うことで、2度押しされた際にリクエストが送信されないようにします。\n\n- ボタンやリンクを非活性化することで、ボタンやリンクを押下できないように制御します。\n- 処理状態をフラグとして保持しｍ処理中にボタンやリンクが押された場合に処理中であることを通知するメッセージを表示します。\nなどがあげられます。\n\n#### 2.\tPRG(Post-Redirect-Get)パターン\n更新処理を行うリクエスト(POSTメソッドによるリクエスト)に対する応答としてリダイレクトを返却し、その後ブラウザから自動的にリクエストされるGETメソッドの応答として遷移先の画面を返却するようにします。\nPRGパターンを適用することで、画面表示後にページの再読み込みを行った場合に発生するリクエストがGETメソッドになるため、更新処理の再実行を防ぐことができます。\n\n\t\n#### 3.トランザクショントークンチェック\n画面遷移毎にトークン値を払い出し、ブラウザから送信されたトークン値とサーバ上で保持しているトークン値を比較することで、トランザクション内で不正な画面操作が行われないようにします。\nトランザクショントークンチェックを適用することで、ブラウザの戻るボタンを使ってページを移動した後の更新処理の再実行を防ぐことが出来る。\nまた、トークン値のチェックを行った後にサーバで管理しているトークン値を破棄することで、サーバ側の処理として二重送信を防ぐこともできます、\n\n- サーバは、クライアントからリクエストが来た際に、サーバ上にトランザクションを一意に識別するための値（トークン）を保持します。\n- サーバは、クライアントへトークンを送信します。画面を提供するWebアプリケーションの場合は、formのhiddenタグを使用してクライアントにトークンを保持させます。\n- クライアントは次のリクエストを送信する際に、サーバから渡されたトークンを送信します。サーバは、クライアントから受け取ったトークンと、サーバ上で管理しているトークンを比較します。\n\n#### トークの生成例\n#### 1.無意味な文字列\n```java\nimport java.security.NoSuchAlgorithmException;\nimport java.security.SecureRandom;\n\nimport javax.xml.bind.DatatypeConverter;\n\npublic class RandomToken {\n    \n    private static int TOKEN_LENGTH = 16;  //16*2=32バイト\n    \n    public static void main(String[] args) {\n        byte token[] = new byte[TOKEN_LENGTH];\n        StringBuffer buf = new StringBuffer();\n        SecureRandom random = null;\n        String tokenString = null;\n        \n        try {\n            random = SecureRandom.getInstance(\"SHA1PRNG\");\n            random.nextBytes(token);\n            \n            for(int i = 0; i < token.length; i++) {\n                buf.append(String.format(\"%02x\", token[i]));\n            }\n            tokenString = buf.toString();\n            \n            System.out.println(\"String.format： \" + tokenString);\n            System.out.println(\"DatatypeConverter： \" + DatatypeConverter.printHexBinary(token));\n            \n        } catch(NoSuchAlgorithmException e) {\n            e.printStackTrace();\n        }\n    }\n}\n```\n\n#### 2.ユーザーIDや有効期限などの情報をエンコード\n使用ライブラリ : JJWT\n\n```xml\n<!-- pom.xml -->\n<dependency>\n  <groupId>io.jsonwebtoken</groupId>\n  <artifactId>jjwt</artifactId>\n  <version>0.7.0</version>\n</dependency>\n```\n\n\n```java\nimport java.security.Key;\nimport java.time.LocalDateTime;\nimport java.time.ZoneId;\nimport java.time.ZonedDateTime;\nimport java.util.Base64;\nimport java.util.Date;\n\nimport io.jsonwebtoken.Jwts;\nimport io.jsonwebtoken.SignatureAlgorithm;\nimport io.jsonwebtoken.SignatureException;\nimport io.jsonwebtoken.impl.crypto.MacProvider;\n\npublic class JsonWebToken {\n\n    public static void main(String[] args) {\n        \n        Key key = MacProvider.generateKey();\n        \n        LocalDateTime now = LocalDateTime.now();\n        System.out.println(\"Current Timestamp: \" + now);\n        \n        //7日後の日時\n        ZonedDateTime expirationDate = now.plusDays(7).atZone(ZoneId.systemDefault());\n        \n        //JWTを生成\n        System.out.println(\"*** JWT Create ***\");\n        String compactJws = Jwts.builder()\n                .setSubject(\"hoge\")\n                .setExpiration(Date.from(expirationDate.toInstant()))\n                .signWith(SignatureAlgorithm.HS512, key)\n                .compact();\n        System.out.println(\"JWT: \" + compactJws);\n        \n        //Base64でデコード\n        System.out.println(\"*** Base64 decode ***\");\n        String[] jwtSections = compactJws.split(\"\\\\.\");\n        String header = new String(Base64.getDecoder().decode(jwtSections[0]));\n        String claim = new String(Base64.getDecoder().decode(jwtSections[1]));\n        System.out.println(\"JWT Header: \" + header);\n        System.out.println(\"JWT Claim: \" + claim);\n        \n        //クレームの確認\n        System.out.println(\"*** Claim ***\");\n        Date exp = Jwts.parser().setSigningKey(key).parseClaimsJws(compactJws).getBody().getExpiration();\n        String sub = Jwts.parser().setSigningKey(key).parseClaimsJws(compactJws).getBody().getSubject();\n        System.out.println(\"exp(Expiration Time): \" + LocalDateTime.ofInstant(exp.toInstant(), ZoneId.systemDefault()));\n        System.out.println(\"sub(Subject): \" + sub);\n        \n        //署名の検証\n        System.out.println(\"*** Signature Validation ***\");\n        try {\n            Jwts.parser().setSigningKey(key).parseClaimsJws(compactJws);\n            System.out.println(\"Use Correct Key: Validation Success\");\n        } catch(SignatureException e) {\n            System.out.println(\"Use Correct Key: Validation Fail - \" + e.getMessage());\n        }\n        \n        Key wrongKey = MacProvider.generateKey();\n        try {\n            //生成時とは別のキーを使用\n            Jwts.parser().setSigningKey(wrongKey).parseClaimsJws(compactJws);\n            System.out.println(\"Use Wrong Key: Validation Success\");\n        } catch(SignatureException e) {\n            System.out.println(\"Use Wrong Key: Validation Fail - \" + e.getMessage());\n        }\n    }\n}\n```\n","user":"white_tiger","created_at":"2021-03-29T05:46:54+09:00","updated_at":"2021-03-29T05:47:59+09:00"},{"url":"https://qiita.com/tanaka3nday/items/0d99ad4730b78bf58702","title":"村田ジャイロセンサSCC2230をRaspberry Piに接続","body":"　SCC2230は低ドリフトの1軸ジャイロ＋３軸加速度センサである。インターフェースがSPIなのでSPIのインターフェースを持つマイコンであれば簡単に利用できると安易に考えたが実に大変だった。\n　データシートによると３２ビット（４バイト分）の同期型データ伝送が求められているので、raspberry pi の標準的なpython モジュールspidev.SpiDev()を用いて通信を行った。CSを下げてから４バイトを送信してCSを上げるという動作を行うxfer2を用いる。送信するデータはデータシートにあるStatus Summaryを読み出す命令である。\n送信データ[0x7c,0x00,0x00,0xb3]\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/290990/f1ae92db-b1c5-ffaf-1de5-66e25f571ca1.png)\n\n　残念ながらこれはうまくいっていない。いくら送信してもレジスタ選択エラーの応答しか返ってこない。通信時間は２ｍ秒なので決して早くない。推奨インターバルの０．５ｍ秒に比べても遅いぐらいである。速度を早くしても、ディレイやCSまでの間隔を変えても応答は全く変化がなかった。\n\n　波形をよく見ると、８ビットのCLKの間に少し隙間が空いている。このICのステータスマシンはクロックパルスが等間隔で現れることを想定して動いているためにうまくいかないのではないか。\n　この隙間をなくする方法を模索したがRaspberry Piで可能なのかどうかもはっきりしなかった。\n　ではSPIのポートの使用をやめてGPIOを4本使ってプログラムでポートを操作する方法に変えることにした。\n　このICでは通信データのワードのチェックにCRC8を使用するのでカスタムなCRCを計算できるモジュールが必要である。pythonに標準のcrcでは対応していなかったので、<a href=\"https://github.com/Nicoretti/crc\">こちら</a>を使用した。\n\n\n\n\\#scc-2230 module gpio\n\n\\# CS GPIO05   OUT\n\\# MISO GPIO06 IN\n\\# MOSI GPIO13 OUT\n\\# CLK  GPIO19 OUT\n\nimport sys\nimport os\nimport time\nimport datetime\nimport RPi.GPIO as GPIO\nfrom crc.crc import CrcCalculator, Configuration\n   \nclass scc2230():\n    def __init__(self):\n        BCM2708_PERI_BASE=0x20000000\n        GPIO_BASE=(BCM2708_PERI_BASE + 0x00200000)\n        BLOCK_SIZE=4096\n\n        self.CS = 5\n        self.MISO=6\n        self.MOSI=13\n        self.CLK=19\n\n        self.comdata={\n            \"RATE\":0x040000f7,\n            \"ACCX\":0x100000e9,\n            \"ACCY\":0x140000ef,\n            \"ACCZ\":0x180000e5,\n            \"TEMP\":0x1c0000e3,\n            \"RATE1\":0x240000c7,\n            \"RATE2\":0x280000cd,\n            \"ACC\":0x3c0000d3,\n            \"HARDRESET\":0xd8000431,\n            \"MONITOR\":0xd80008ad,\n            \"ID0\":0x600000a1,\n            \"ID1\":0x640000a7,\n            \"STAT\":0x6c0000ab,\n            \"SUMMARY\":0x7c0000b3,\n            \"FLT60\":0xfc200006,\n            \"FLT10\":0xfc1000c7,\n            \"READID\":0x740000bf\n        }\n\n        GPIO.setmode(GPIO.BCM)\n        GPIO.setwarnings(False)\n        GPIO.setup(self.CS, GPIO.OUT)\n        GPIO.setup(self.MISO, GPIO.IN)\n        GPIO.setup(self.MOSI, GPIO.OUT)\n        GPIO.setup(self.CLK, GPIO.OUT)\n\n        GPIO.output(self.CS, 1)\n        GPIO.output(self.MOSI, 0)\n        GPIO.output(self.CLK, 0)\n\n        #CRC checker\n        width = 8\n        poly=0x1d\n        init_value=0xff\n        final_xor_value=0xff\n        reverse_input=False\n        reverse_output=False\n        configuration = Configuration(width, poly, init_value, final_xor_value, reverse_input, reverse_output)\n        use_table = True\n        self.crc_calculator = CrcCalculator(configuration, use_table)\n\n        #acc-2230 setup\n\n        time.sleep(0.02)\n        self.sendcom(self.comdata[\"FLT60\"])\n        time.sleep(0.73)\n\n        self.sendcom(self.comdata[\"RATE1\"])\n        #self.sendcom(self.comdata[\"STAT\"])\n        self.sendcom(self.comdata[\"RATE2\"])\n        #self.sendcom(self.comdata[\"STAT\"])\n        self.sendcom(self.comdata[\"ACC\"])\n        #self.sendcom(self.comdata[\"STAT\"])\n        self.sendcom(self.comdata[\"SUMMARY\"])\n        #self.sendcom(self.comdata[\"STAT\"])\n        self.sendcom(self.comdata[\"READID\"])\n        #self.sendcom(self.comdata[\"STAT\"])\n        self.sendcom(self.comdata[\"SUMMARY\"])\n\n        #wait for ready\n\n        while True:\n            flag,readByteArray = self.sendcom(self.comdata[\"SUMMARY\"])\n            print(u\"stat {0}\".format(flag),hex(readByteArray))\n            flag,readByteArray = self.sendcom(self.comdata[\"STAT\"])\n            print(u\"summary {0}\".format(flag),hex(readByteArray))\n\n            if flag and readByteArray&0x4900 == 0x4900:\n                break\n            time.sleep(0.1)\n            \n    def BinToint(self,data):\n        val=(data>>8)&0xffff\n        if val>32767:\n            val-=65536\n        return val\n\n    def rateconv(self,data):\n        val=self.BinToint(data)\n        rate=val/50.0 #deg/sec\n        return rate\n\n    def accconv(self,data):\n        val=self.BinToint(data)\n        acc=val/5886.0 #g\n        return acc\n\n    def tempconv(self,data):\n        val=self.BinToint(data)\n        temp=val/14.7+60.0 #°C\n        return temp\n\n\n    def sendcom(self,comdata):\n        cnt=0\n        indata=0b0\n        #print(u\"send\",hex(comdata))\n        GPIO.output(self.CS, 0) #CS assert\n        while cnt < 32:\n        #CS\n            if comdata & 0x80000000:\n                GPIO.output(self.MOSI, 1)\n            else:\n                GPIO.output(self.MOSI, 0)\n\n            indata<<=1\n\n            GPIO.output(self.CLK, 1) #CLK assert\n\n            indata+=GPIO.input(self.MISO)\n\n            GPIO.output(self.CLK, 0) #CS negate\n\n            comdata<<=1\n            cnt+=1\n\n        GPIO.output(self.CS, 1) #CS assert\n\n        #print(u\"recv\",hex(indata))\n\n        # check crc8\n        csum=indata&0xff\n        dat2=(indata>>8)&0xff\n        dat1=(indata>>16)&0xff\n        dat0=(indata>>24)&0xff\n\n        checksum = self.crc_calculator.calculate_checksum([dat0,dat1,dat2])\n        if checksum != csum:\n            print(\"crc error \",hex(dat0),hex(dat1),hex(dat2),hex(csum))\n            return False,indata\n\n        return True,indata\n\n    def readdata(self):\n    \n        flag,stat = self.sendcom(self.comdata[\"RATE\"])\n        if flag==False:\n            print(\"flag1 error\",stat)\n            return False\n        flag,rate = self.sendcom(self.comdata[\"ACCX\"])\n        if flag==False:\n            print(\"flag2 error\",rate)\n            return False\n        flag,accx = self.sendcom(self.comdata[\"ACCY\"])\n        if flag==False:\n            print(\"flag3 error\",accx)\n            return False\n        flag,accy = self.sendcom(self.comdata[\"ACCZ\"])\n        if flag==False:\n            print(\"flag4 error\",accy)\n            return False\n        flag,accz = self.sendcom(self.comdata[\"TEMP\"])\n        if flag==False:\n            print(\"flag5 error\",accz)\n            return False\n        flag,temp = self.sendcom(self.comdata[\"STAT\"])\n        if flag==False:\n            print(\"flag6 error\",temp)\n            return False\n        return (rate,accx,accy,accz,temp)\n\n    def __del__(self):\n        GPIO.cleanup(self.CS)\n        GPIO.cleanup(self.MOSI)\n        GPIO.cleanup(self.MISO)\n        GPIO.cleanup(self.CLK)\n\nif __name__=='__main__':\n    # main program\n\n    scc=scc2230()\n\n    while True:\n        values=scc.readdata()\n        if isinstance(values,bool):\n            print(u\"data error \")\n        else:\n            rate=scc.rateconv(values[0])\n            accx=scc.accconv(values[1])\n            accy=scc.accconv(values[2])\n            accz=scc.accconv(values[3])\n            temp=scc.tempconv(values[4])\n            print(u\"values {0} {1} {2} {3} {4}\".format(rate,accx,accy,accz,temp))\n        time.sleep(0.01)\n        \n        \n    del scc\n    sys.exit()\n\n\nこの書き換えにより通信が安定しデータが取り出せるようになった。\n\n　ソフトウエア処理によりクロックに隙間がなくなったために解決したのだろうか。測定したところ、８ビットごとの隙間はなくなったが、OSのディスパッチもあるのでクロックパルスにあちこちに隙間がある。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/290990/7add84a8-640c-2a65-2401-7570b68c7eae.png)\n\n　それでも安定しているということは、８ビットごとの隙間の繰り返しこそ問題が発生する要因となっていると推測される。\n\n　GPIOのアクセス速度が遅いので通信は1.2ミリ秒くらいはかかる。このあたりはC言語を用いてレジスタを直接アクセスすれば早くなるだろう。通信のためのCPUの負荷はかなりのものなので使いにくいICではある。\n","user":"tanaka3nday","created_at":"2021-03-29T05:36:03+09:00","updated_at":"2021-03-29T05:47:05+09:00"},{"url":"https://qiita.com/kyokucho1989/items/3001d3bf4c67511be4d8","title":"thisなきJS エラーあり","body":"# はじめに\n　JSでTODOアプリをつくり、そのやり方を教材として書き起こしていた。教材の仕様に沿ってアロー関数をつかったらうまく動作しなくなった。なんだこれは。少しだけ考えた。\n\n# 問題\n　問題が発生したのはTODOの内容をクリックして、既存のタスクを編集する箇所。今までのfunctionではOKだったが、アロー関数にするとなんだかおかしい。\n\n\n# コード\n　問題点を明らかにするためにその箇所だけを抜き出して別にコードを書いた。「テスト」をクリックするとアロー関数のやつが実行されて、「テスト２」だと普通の関数が実行される。\n　テストをクリックして、入力フォームのカーソルを外すと\n\n　「Uncaught TypeError: Cannot read property 'classList' of null」\n\n　というエラーが出てくる。\n　\n\n```html:test.html\n<!DOCTYPE html>\n<html lang=\"ja\">\n<head>\n    <meta charset=\"utf-8\"/>\n    <link rel =\"stylesheet\" href=\"todo.css\">\n    <title>イベントハンドラテスト</title>\n</head>\n<body>\n  <header>\n    <h1>TODOテスト</h1>\n  </header>\n  <div class=\"container\">\n    <div class=\"todo-container\">\n      <ul class=\"todo-list\">\n        <li>\n          <span class=\"todo-content1\">テスト</span>\n        </li>\n        <li>\n          <span class=\"todo-content2\">テスト2</span>\n        </li>\n      </ul>\n    </div>\n  </div>\n    <script src = \"test.js\"></script>\n</body>\n</html> \n```\n\n```javascript\nconst editTodo = (e) => {\n  let itemToEdit = e.target;\n  if(!itemToEdit.classList.contains('on')) {\n    itemToEdit.classList.add('on');\n    let contentBeforeEdit = itemToEdit.textContent;\n    itemToEdit.innerHTML = '<input type=\"text\" class=\"editbox1\" value=\"'+contentBeforeEdit+'\" />';\n    const editContent1 = document.querySelector('.editbox1');\n    \n    const saveTodoContent  = (e) => {\n        let itemToSave = e.target;\n        itemToSave.parentNode.classList.remove('on');\n        let txtvalue = itemToSave.value;\n        if (txtvalue ==''){\n         txtvalue = itemToSave.defaultValue;\n        }\n        itemToSave.parentNode.innerHTML = txtvalue;\n        \n    }\n    editContent1.addEventListener('blur',saveTodoContent);\n  }\n}\n\nfunction editTodo2(e) {\n  if(!this.classList.contains(\"on\")) {\n    this.classList.add(\"on\");\n    let contentBeforeEdit = this.textContent\n    this.innerHTML = '<input type=\"text\" class=\"editbox2\" value=\"'+contentBeforeEdit+'\" />'\n    const editContent2 = document.querySelector(\".editbox2\")\n\n    let saveTodoContent = function(){\n      this.parentNode.classList.remove('on')\n      let txtvalue = this.value\n      if (txtvalue ==\"\"){\n       txtvalue = this.defaultValue\n      }\n      this.parentNode.innerHTML = txtvalue\n    \n    }\n    editContent2.addEventListener(\"blur\",saveTodoContent)\n  }\n}\n\n//Select DOM\nconst todoContent = document.querySelector('.todo-content1');\ntodoContent.addEventListener('click', editTodo);\nconst todoContent2 = document.querySelector('.todo-content2');\ntodoContent2.addEventListener('click', editTodo2);\n\n```\n\n# 問題を追う\n\n　カーソルを外した時に「classListがnullですよ」というエラーが発生する。ちょうどこの行である。\n\n```javascript\n const saveTodoContent  = (e) => {\n//\n      itemToSave.parentNode.classList.remove('on');\n//\n```\n\n　Chromeのデベロッパーモードで少しずつ検証していった。そうするとカーソルを外す時に実行されるイベント`saveTodoContent`が２回実行されていることがわかった。そして２回目の実行時にエラーが発生していた。なぜだ。\n\n　だいたいはthisが原因だった。\n\n# 原因\n　この機能では項目の状態を知る必要がある。つまり「タスクが現在入力モードなのか否か」ということを知りたいのだ。コード上ではclasslistにonというclassを付与したり外したりしてそれを操作している。\n　今まではその検知にthisを用いていたが、今回アロー関数に書き換えたことによってthisが使えなくなり、別の記法で書き換えた。そこがよくなかったのだ。\n\n　ここである。\n\n```javascript:変更前\nfunction editTodo2(e) {\n  if(!this.classList.contains(\"on\")) {\n// ..　クリックときに編集モードでなければ以下を実行\n```\n\n```javascript:変更後\nconst editTodo = (e) => {\n  let itemToEdit = e.target;\n  if(!itemToEdit.classList.contains('on')) {\n// ..　クリックときに編集モードでなければ以下を実行\n```\n\n# this/e.target\n\nthisとe.targetはなにが違うのか。thisは場面によってさまざまに容態を変化させるが、ここでは以下の記事を参考にするならば「関数を呼び出している元のオブジェクト」である。\n\nhttps://qiita.com/takkyun/items/c6e2f2cf25327299cf03\n\n　e.targetとはクリックしたときの物体である。テキスト文字であったり、入力フォームであったりする。\n\n　thisの中身はタスクが編集モードか否かでも変わらない。しかしe.targetは中身が変わる。ためしにconsole.logで読んでみよう。\n\n\n```javascript\nconst editTodo = (e) => {\n  let itemToEdit = e.target;\n  console.log(e.target);\n  console.log(this);\n\n//\n\n\nfunction editTodo2(e) {\n  console.log(e.target);\n  console.log(this);\n```\n　\n![スクリーンショット 2021-03-29 5.25.11.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/104211/f239f2ae-37e3-a5c3-7671-efe6c4184489.png)\n\n上4行はアロー関数のほう。下はいままでの関数だ。たしかになんか違っていた。\n\n# どうしたか\n\n　アロー関数にはイベントが実行される条件を増やした。\n\n```javascript\nconst editTodo = (e) => {\n  let itemToEdit = e.target;\n  if(!itemToEdit.classList.contains('todo-content1')){\n    return;\n  }\n  if(!itemToEdit.classList.contains('on')) {\n//....\n\n```\n\n　これで問題は解決した。\n\n\n# おわりに\n\n　文章がまとまらないままこれを書き出してしまった。それでもどこかに残しておかないと、後々自分が困ってしまう。\n\n　もしかしたら追記するかもしれないししないかもしれない。\n\n　\n","user":"kyokucho1989","created_at":"2021-03-29T05:30:32+09:00","updated_at":"2021-03-29T05:30:32+09:00"},{"url":"https://qiita.com/john_smith628/items/1f7527dbbc34a207f3a3","title":"化物語の予告風デザインのホームページを作った","body":"# はじめに\nタイトルの通りです。\nなんとなく思いついたのでそれっぽいデザインで作ってみました。\nモバイル用の実装はしていないのでPCのみです。\nコードの書き方とかディレクトリ構成とか色々適当なので分かりにくかったらすみません。\nそれぞれのページにダミーデータみたいなのを入れてあります。\n\nGitHubにありますので良かったら。\n[ソースコード](https://github.com/jonsumisu628/bakemonogatari-ish)\n\n![2021-03-29-050426_1366x768_scrot.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/543602/cea3479b-ca59-f8a4-eef6-118d1ae0c884.png)\nこんな感じ\n\n# 参考\n今回作ったものの中身などは特に解説はしませんので、GitHubを見てください。\nですが、制作過程で参考にしたサイトなどを紹介します。\n\n## ブログページ関連\n\n- マークダウンファイルをブログ記事として表示する\n  - https://code-log.hatenablog.com/entry/2020/02/28/113323\n- ページネーション\n  - [公式ドキュメント](https://www.gatsbyjs.com/docs/adding-pagination/)\n  - https://code-log.hatenablog.com/entry/2020/02/28/113323\n  - https://rpf-noblog.com/2021-01-11/gatsby-awesome-pagination/\n  - https://ryokatsu.dev/blog/2020/0524/\n- 記事内のコードブロック\n  - https://littlebylittle.work/2020/01/gatsby-syntax-highlighting/\n  - https://nekoniki.com/blog/gatsby-syntax-highlight/\n\n## CSS\n- アニメーション\n  - https://qiita.com/junya/items/1347238456c88f9dc43a\n- 画像の色を変える際filterでの色指定でめちゃ便利だったやつ\n  - https://codepen.io/sosuke/pen/Pjoqqp\n- CSS Color Code\n  - https://www.colordic.org/\n\n## その他\n- 画像透過\n  - https://www.peko-step.com/tool/alphachannel.html\n- 使用させていただいた無料画像サイト\n  - https://www.silhouette-illust.com/\n","user":"john_smith628","created_at":"2021-03-29T05:28:42+09:00","updated_at":"2021-03-29T05:30:17+09:00"},{"url":"https://qiita.com/neonemo/items/74fd4c28abd7b1817a44","title":"【Java】ハッシュユーティリティを列挙型とチェーンな感じで書いてみた","body":"# 0. INDEX\n- 概要\n- ハッシュユーティリティを書いてみた\n- あとがき\n\n# 1. 概要\n列挙型を使ってtypoしないぞ計画！\nってそこまで大層なものじゃないけど、いつものようにあれば使うよなって奴です。\n\n# 2. ハッシュユーティリティを書いてみた\n\n## 2.1. 動作サンプル\nhttps://paiza.io/projects/l7JLOgpc_dJpGXJ75gFhqA\n\n## 2.2. 使い方\nこんな感じでupdate関数を繰り返せるチェーンメソッド仕様です。\n\n```java\nString result = MessageDigestUtil.SHA256\n    .update(\"hello\".getBytes())\n    .update(\"everyone\".getBytes())\n    .toHexString();\n        \nSystem.out.println(result);\n```\n\n\n## 2.3. ソースコード\n```java:MessageDigestUtil.java\npackage jp.go.mahny_conf.junk_memo;\n\nimport java.nio.ByteBuffer;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\n\n/**\n * SHA-256とか生成するユーティリティ\n * @author mahny\n */\npublic enum MessageDigestUtil {\n\tMD2(\"MD2\"),\n\tMD5(\"MD5\"),\n\tSHA1(\"SHA-1\"),\n\tSHA256(\"SHA-256\"),\n\tSHA384(\"SHA-384\"),\n\tSHA512(\"SHA-512\"),\n\t;\n\n\tprivate MessageDigest digest;\n\n\t/**\n\t * 初期化。使う側は意識しない箇所\n\t * @param algorithm アルゴリズム文字列\n\t */\n\tprivate MessageDigestUtil(String algorithm) {\n\t\ttry {\n\t\t\tdigest = MessageDigest.getInstance(algorithm);\n\t\t} catch (NoSuchAlgorithmException e) {\n\t\t\t// 引数のnull指定以外では出ないハズ\n\t\t\tthrow new IllegalArgumentException(\"algorithmの指定が無い\", e);\n\t\t}\n\t}\n\n\t/**\n\t * ハッシュに使用するデータを追加する\n\t * @param input 使用するデータ\n\t * @return ユーティリティオブジェクト\n\t */\n\tpublic MessageDigestUtil update(byte input) {\n\t\tdigest.update(input);\n\t\treturn this;\n\t}\n\n\t/**\n\t * ハッシュに使用するデータを追加する\n\t * @param input 使用するデータ\n\t * @return ユーティリティオブジェクト\n\t */\n\tpublic MessageDigestUtil update(byte[] input) {\n\t\tdigest.update(input);\n\t\treturn this;\n\t}\n\n\t/**\n\t * ハッシュに使用するデータを追加する\n\t * @param input 使用するデータ\n\t * @return ユーティリティオブジェクト\n\t */\n\tpublic MessageDigestUtil update(ByteBuffer input) {\n\t\tdigest.update(input);\n\t\treturn this;\n\t}\n\n\t/**\n\t * ハッシュを生成する\n\t * @return ハッシュデータ\n\t */\n\tpublic byte[] toBytes() {\n\t\treturn digest.digest();\n\t}\n\n\t/**\n\t * ハッシュを生成し、16進数文字列で取得する\n\t * @return ハッシュデータ（16進数文字列）\n\t */\n\tpublic String toHexString() {\n\t\tStringBuilder result = new StringBuilder();\n\t\tfor (byte data : toBytes()) {\n\t\t\tresult.append(Integer.toHexString((data >> 4) & 0x0f));\n\t\t\tresult.append(Integer.toHexString(data & 0x0f));\n\t\t}\n\t\treturn result.toString();\n\t}\n}\n```\n\n\n# 3. あとがき\n列挙型ネタが続いていますが、今回は過去ネタの3番煎じくらいですが、もうちょっと使い勝手に踏み込んだユーティリティを作ってみました。\n\nちなみに、過去ネタ執筆時の[列挙型の理解が浅かった頃](http://ciablo.blog70.fc2.com/blog-entry-48.html)は、文字列で定義して…\n\n```java:アルゴリズム定義\npublic static final String ALG_SHA256 = \"SHA-256\";\n```\n\n```java:想定した使い方\nbyte[] hash = HashUtil.getHash(HashUtil.ALG_SHA256);\n```\n\nみたいな使い方を想定するんですが、これだと使い方を浸透させないと↓みたいにチームメイトが好き勝手しちゃうんですよね＞＜\n\n```java:ッ！これは想定外ッ！！\nbyte[] hash = HashUtil.getHash(\"SHA-256\");\n```\n\n使いたい時に直感的に使えるようにしておくのは、他人（未来の自分含む）の為にも大切だなと思う今日この頃です。\n\nではﾉｼ\n","user":"neonemo","created_at":"2021-03-29T05:24:26+09:00","updated_at":"2021-03-29T05:31:59+09:00"},{"url":"https://qiita.com/ttabata/items/0828cc78b29e5e9b9ac1","title":"量子振幅増幅と量子振幅増幅シミュレーター","body":"## :crown: この記事の目的\n\n量子コンピューティングの理論の一つに量子振幅増幅があります。\n量子振幅増幅とは、**Quantum Amplitude Amplifier(QAA)**と呼ばれます。\n本記事では量子振幅増幅の原理と、実際にどのように振幅されるのかをグラフで確認できるシミュレータの使い方を紹介します。\n※本記事は、令和3年3月29日に執筆しています。\n\n## :crown: 量子振幅増幅とは\n\n量子振幅増幅とは、書いて文字の通り振幅を増幅させるものです。\n増幅させるものは**確率振幅**です。確率振幅とは以下の(式1)の$\\alpha$,$\\beta$を指します。\n\n```math\n|\\psi〉=\\alpha|0〉+\\beta|1〉\\quad...\\;(式1)\n```\n\n上記の式は1量子ビットの例です。確率振幅は自身の2乗が確率を表し、全ての確率振幅の絶対値の2乗を合計すると1となります。これを確率原則と言います。\n\n```math\n|\\alpha|^2+|\\beta|^2=1\\quad...\\;(式2)\n```\n\n2量子ビットの場合を見てみましょう。\n2量子ビットの場合の一般的な量子状態は\n\n```math\n|\\psi〉=\\alpha|00〉+\\beta|01〉+\\gamma|10〉+\\delta|11〉\\quad...\\;(式3)\n```\n\nと表されます。\n確率振幅$\\alpha$,$\\beta$,$\\gamma$,$\\delta$は確率原則より以下となります。\n\n```math\n|\\alpha|^2+|\\beta|^2+|\\gamma|^2+|\\delta|^2=1\\quad...\\;(式4)\n```\n\n確率振幅の増幅とは$\\alpha$,$\\beta$,$\\gamma$,$\\delta$のうち、どれか一つを増幅させます。つまり、値を大きくします。\n値を大きくすることでその絶対値の2乗も大きくなります。すなわち確率が大きくなります。\n確率が大きくなることで、最終的に測定を行った際にその確率振幅項が解として現れることを期待するものです。\n\n## :crown: 振幅増幅の仕方\n\nでは、実際に振幅を増幅させてみましょう。\n例として、2量子ビットを取り上げます。\n2量子ビットの場合は(式3)より項数が4つであるとわかっていますので、具体的に$\\alpha$,$\\beta$,$\\gamma$,$\\delta$を以下のように決定します。\n\n```math\n|\\psi〉=\\frac{1}{2}|00〉+\\frac{1}{2}|01〉+\\frac{1}{2}|10〉+\\frac{1}{2}|11〉\\quad...\\;(式5)\n```\n\n次に、増幅させたい確率振幅項に**印を付けます**。\n印を付けるとは、具体的には位相を反転させることを意味します。今回の例として、|10〉の確率振幅項に印を付けてみます。\n\n```math\n|\\psi〉=\\frac{1}{2}|00〉+\\frac{1}{2}|01〉\\color{red}{-}\\frac{1}{2}|10〉+\\frac{1}{2}|11〉\\quad...\\;(式6)\n```\n\n量子ゲート回路において、この印を付ける方法は以下の操作で行うことができます。\nなお、以下の回路では(式5)の状態を生成する手順も含んでおり、そのように回路中に記載しています。\n\n**|10〉に印を付ける場合**\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/399135/14eb2a2e-af99-ca80-7847-8dffa3809507.png)\nまた|01〉以外の場合のついても印を付ける操作は以下となります。\n\n**|00〉に印を付ける場合**\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/399135/012af0f3-a5d0-8e28-885a-ab52dfb6c2d0.png)\n**|01〉に印を付ける場合**\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/399135/5c658641-c5ae-82b0-06fc-a0aa0cfc8d31.png)\n**|11〉に印を付ける場合**\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/399135/416c0d6b-d287-01c9-a49c-6a4e9456a750.png)\n\n振幅させたい確率振幅項に印を付けたら、次は確率振幅の**平均値＜av＞**を計算します。\n(式6)より以下となります。\n\n```math\n\\begin{align}\n<av>&=\\frac{\\frac{1}{2}+\\frac{1}{2}-\\frac{1}{2}+\\frac{1}{2}}{4}\\\\\n&=\\frac{1}{4}\n\\end{align}\n```\n\nこの場合の確率振幅項の値と平均値をグラフにしてみます。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/399135/ca273269-d289-5fd6-a690-707d95fb7f19.png)\n平均値を求めたら、平均値を軸にして各振幅値を反転させます。これを**拡散変換**と言います。\nグラフで確認すると以下のようになります。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/399135/09c50d1a-f6a0-8302-7a3a-dd2f94b9cf67.png)\n\n上記のように拡散変換を行うことで、印の付いた確率振幅が増幅されることがわかります。\nこれが確率振幅の仕組みです。\n拡散変換を行った後で観測を行うことで、**印の付いた確率振幅項が|10〉であることがわかります**。\n\n本記事では2量子ビットの例を示しましたが、3量子ビットやそれ以上の量子ビットも同様に計算できます。\n以下に確率振幅増幅をシミュレーションできるツールをWEB上に公開しました。\n増幅させたい確率振幅項に印を付けて拡散変換させ、グラフを表示させることができるツールで、2～5量子ビットで確率振幅増幅を試すことができます。\nぜひお試し頂けると幸いです。\n\n:large_blue_diamond: **量子振幅増幅シミュレーター**\nhttps://amplitude-amplifier.herokuapp.com/index.html\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/399135/5ab08f52-0ba5-395a-3b3f-7dad0d44bea2.png)\n\n\n\n## :crown: 関連情報\n\n量子振幅増幅シミュレーター\nhttps://amplitude-amplifier.herokuapp.com/index.html\n\n## :crown: ご意見など\n\nご意見、間違い訂正などございましたらお寄せ下さい。\n","user":"ttabata","created_at":"2021-03-29T05:00:46+09:00","updated_at":"2021-03-29T05:00:46+09:00"},{"url":"https://qiita.com/ndraketm/items/24e1bebf654d2426e8a5","title":"GodzillaVsKong","body":"昨夜#GodzillaVsKongに参加してくれたすべての伝説に感謝します\nファンスクリーニング体験！\n\nここで映画を見る：https：//tvtoday.uk/\n\n![Profile Godzila.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1249651/153711ab-0e08-b966-4c3f-7d0873478320.jpeg)\n","user":"ndraketm","created_at":"2021-03-29T03:54:13+09:00","updated_at":"2021-03-29T03:54:13+09:00"},{"url":"https://qiita.com/ezratmp/items/bfe722ab76d04215763f","title":"GodzillaVsKong","body":"昨夜#GodzillaVsKongに参加してくれたすべての伝説に感謝します\nファンスクリーニング体験！\n\nここで映画を見る：https：//tvtoday.uk/\n![Godzila.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1249625/2e89d35f-e4ba-a1ef-1d9c-87a39aaaf7fb.jpeg)\n\n","user":"ezratmp","created_at":"2021-03-29T03:48:31+09:00","updated_at":"2021-03-29T03:48:31+09:00"},{"url":"https://qiita.com/R_R/items/fc2efc1a6f3c6b7947fe","title":"SAMでSlack通知Lambdaをデプロイ","body":"## はじめに\n[AWS Lambda Container Image Support](https://aws.amazon.com/jp/blogs/news/new-for-aws-lambda-container-image-support/) や EventBridgeのcron設定、Secrets Managerからシークレット情報の取得を試してみたかったので、以下のような構成図で一気に試してみます。\n\n## 構成図\n\n- SAMでSlackにメッセージを通知するLambdaをデプロイする\n- Lambdaはイメージ化してECRで管理する\n- LambdaはEventBridgeで定期実行する\n- SlackのWebhook URLをSecrets Managerで管理する\n\n![sam.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/917499/eed96002-2bda-33c2-64bf-cfdac785faed.png)\n\n## 手順\n1. ECRにリポジトリを作成しておく\n2. Secrets ManagerにSlackのWebhook URLを設定する\n3. sam initでテンプレート作成\n4. template.yamlの修正\n5. Slackにメッセージ通知するLambda関数を作成\n6. デプロイ\n7. テスト\n\n## 1. ECRにリポジトリを作成しておく\n\nイメージのプッシュ先のリポジトリを事前に登録しておきます。\n![screencapture-ap-northeast-1-console-aws-amazon-ecr-repositories-private-901071604628-notify-slack-edit-2021-03-29-02_14_19.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/917499/6192880b-d2b2-cc3b-ce8b-2f4863628afe.png)\n\n## 2. Secrets ManagerにSlackのWebhook URLを設定する\n\nSlackのWebhook URLをSecrets Managerに登録します。\n![スクリーンショット_2021-03-29_2_18_58（3）.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/917499/bb5c797f-9050-70e7-2279-338e780302cd.png)\n\n設定が完了すると、シークレット情報取得のサンプルコードが確認できるので、後でこれをベースにLambda関数を実装します。\n![スクリーンショット 2021-03-29 2.24.31（3）.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/917499/f1b1b94e-db76-1cf8-37d3-9af26bf0d4c7.png)\n\n## 3. sam initでテンプレート作成\n事前準備ができたので、次はSAMのテンプレートを作成していきます。\n\n適当にディレクトリを作成し、`$ sam init` を実行します。\n\n```bash\n$ sam init\nWhich template source would you like to use?\n\t1 - AWS Quick Start Templates\n\t2 - Custom Template Location\nChoice: 1\nWhat package type would you like to use?\n\t1 - Zip (artifact is a zip uploaded to S3)\n\t2 - Image (artifact is an image uploaded to an ECR image repository)\nPackage type: 2\n\nWhich base image would you like to use?\n\t1 - amazon/nodejs14.x-base\n\t2 - amazon/nodejs12.x-base\n\t3 - amazon/nodejs10.x-base\n\t4 - amazon/python3.8-base\n\t5 - amazon/python3.7-base\n\t6 - amazon/python3.6-base\n\t7 - amazon/python2.7-base\n\t8 - amazon/ruby2.7-base\n\t9 - amazon/ruby2.5-base\n\t10 - amazon/go1.x-base\n\t11 - amazon/java11-base\n\t12 - amazon/java8.al2-base\n\t13 - amazon/java8-base\n\t14 - amazon/dotnet5.0-base\n\t15 - amazon/dotnetcore3.1-base\n\t16 - amazon/dotnetcore2.1-base\nBase image: 10\n\nProject name [sam-app]: notification\n\nCloning app templates from https://github.com/aws/aws-sam-cli-app-templates\n\n    -----------------------\n    Generating application:\n    -----------------------\n    Name: notification\n    Base Image: amazon/go1.x-base\n    Dependency Manager: mod\n    Output Directory: .\n\n    Next steps can be found in the README file at ./notification/README.md\n```\n\n先ほど作成したECRにイメージをプッシュしたいので、 `What package type would you like to use?` は `2 - Image (artifact is an image uploaded to an ECR image repository)` を選択します。\nランタイムについては、goを選択しました。\n\n`$ sam init` 実行後のディレクトリ構成は以下です。（notificationディレクトリを作成し、その配下で `$ sam init` を実行しています。）\n\n```bash\nnotification/\n├── README.md\n├── samconfig.toml\n├── hello-world\n│   ├── Dockerfile\n│   ├── go.mod\n│   ├── go.sum\n│   ├── main.go\n│   └── main_test.go\n└── template.yaml\n```\n\npackage typeにimageを選択したため、Dockerfileが作成されています。\n中身は以下のようになっています。\n\n```bash:Dockerfile\nFROM golang:1.14 as build-image\n\nWORKDIR /go/src\nCOPY go.mod main.go ./\n\nRUN go build -o ../bin\n\nFROM public.ecr.aws/lambda/go:1\n\nCOPY --from=build-image /go/bin/ /var/task/\n\n# Command can be overwritten by providing a different command in the template directly.\nCMD [\"hello-world\"]\n```\n\n## 4. template.yamlの修正\n\n次に、`$ sam init` で作成されたtemplate.yamlに修正を加え、以下のようになりました。\n\n\n```yaml\nAWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: notify slack\n\nGlobals:\n  Function:\n    Timeout: 5\n\nResources:\n  SlackRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: \"2012-10-17\"\n        Statement:\n          - Effect: Allow\n            Principal:\n              Service: lambda.amazonaws.com\n            Action: \"sts:AssumeRole\"\n      Policies:\n        - PolicyName: \"GetSecretsPolicy\"\n          PolicyDocument:\n            Version: \"2012-10-17\"\n            Statement:\n              - Effect: Allow\n                Action:\n                  - \"logs:CreateLogGroup\"\n                  - \"logs:CreateLogStream\"\n                  - \"logs:PutLogEvents\"\n                  - \"secretsmanager:GetSecretValue\"\n                Resource: \"*\"\n  SlackFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Role: !GetAtt SlackRole.Arn\n      PackageType: Image\n      Events:\n        Notification:\n          Type: Schedule\n          Properties:\n            Schedule: cron(0 0 * * ? *) # JST 9:00\n    Metadata:\n      DockerTag: go1.x-v1\n      DockerContext: ./slack\n      Dockerfile: Dockerfile\n\nOutputs:\n  SlackFunction:\n    Description: \"Notify Slack Lambda Function ARN\"\n    Value: !GetAtt SlackFunction.Arn\n  SlackFunctionIamRole:\n    Description: \"Implicit IAM Role created for Slack function\"\n    Value: !GetAtt SlackRole.Arn\n```\n\n大きな修正点としては以下です。\n\n- Role\n- 実行スケジュール\n\n**Role**\nデフォルトで生成されるCloudWatch用のポリシーに、 Secrets Managerからシークレット情報取得用の`secretsmanager:GetSecretValue`を加えたロールを作成します。\n（ロールの設定をここで記述しない場合、デフォルトでLambda実行に必要なロールが付与されます。）\n\n```yaml\nResources:\n  SlackRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: \"2012-10-17\"\n        Statement:\n          - Effect: Allow\n            Principal:\n              Service: lambda.amazonaws.com\n            Action: \"sts:AssumeRole\"\n      Policies:\n        - PolicyName: \"GetSecretsPolicy\"\n          PolicyDocument:\n            Version: \"2012-10-17\"\n            Statement:\n              - Effect: Allow\n                Action:\n                  - \"logs:CreateLogGroup\"\n                  - \"logs:CreateLogStream\"\n                  - \"logs:PutLogEvents\"\n                  - \"secretsmanager:GetSecretValue\"\n                Resource: \"*\"\n  SlackFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Role: !GetAtt SlackRole.Arn\n```\n\n**実行スケジュール**\n\nEventBridgeのスケジュールをトリガーにしたいので、以下のように設定します。\n\n```yaml\nEvents:\n  Notification:\n    Type: Schedule\n    Properties:\n      Schedule: cron(0 0 * * ? *) # JST 9:00\n```\n\n## 5. Slackにメッセージ通知するLambda関数を作成\nSecrets ManagerからSlackのWebhook URLを取得して、Slackにメッセージを送信します。\n\n```golang\npackage main\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"net/http\"\n\t\"net/url\"\n\n\t\"github.com/aws/aws-lambda-go/lambda\"\n\t\"github.com/aws/aws-sdk-go/aws\"\n\t\"github.com/aws/aws-sdk-go/aws/session\"\n\t\"github.com/aws/aws-sdk-go/service/secretsmanager\"\n)\n\n// Secrets Managerで設定したキーとリージョン\nvar (\n\tsecretName string = \"SlackWebhookUrl\"\n\tregion     string = \"ap-northeast-1\"\n)\n\ntype SlackEvent struct {\n\tText string `json:\"text\"`\n}\n\nfunc Modify(se *SlackEvent) {\n\tse.Text = \"test message\"\n}\n\n// シークレット情報取得用function\nfunc getSecret() (string, error) {\n\tsvc := secretsmanager.New(session.New(),\n\t\taws.NewConfig().WithRegion(region))\n\n\tinput := &secretsmanager.GetSecretValueInput{\n\t\tSecretId:     aws.String(secretName),\n\t\tVersionStage: aws.String(\"AWSCURRENT\"),\n\t}\n\n    // GetSecretValue関数にキー名を渡して、値を取得\n\tresult, err := svc.GetSecretValue(input)\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\n    // SecretString配下にJSON形式でシークレット情報がレスポンスされます\n\tsecretString := aws.StringValue(result.SecretString)\n\tres := make(map[string]interface{})\n\tif err := json.Unmarshal([]byte(secretString), &res); err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn res[\"WEBHOOK_URL\"].(string), nil\n}\n\nfunc handler() error {\n\twebhoolUrl, err := getSecret()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tse := &SlackEvent{}\n\tModify(se)\n\n\tparams, err := json.Marshal(se)\n\tif err != nil {\n\t\treturn err\n\t}\n\n    // slackにメッセージ送信\n\tresp, err := http.PostForm(\n\t\twebhoolUrl,\n\t\turl.Values{\"payload\": {string(params)}},\n\t)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tbody, _ := ioutil.ReadAll(resp.Body)\n\n\tdefer resp.Body.Close()\n\n\tfmt.Printf(\"response code:%s, response body:%s, hook:%s\\n\", resp.Status, body, webhoolUrl)\n\n\treturn nil\n}\n\nfunc main() {\n\tlambda.Start(handler)\n}\n```\n\n## 6. デプロイ\nここまで設定ができたら、デプロイしていきます。\n`$ sam build` → `$ sam deploy` の順に実行します。\n\n修正内容に不備がなければ、以下のように`$ sam build` が成功します。\n\n```bash\nBuild Succeeded\n\nBuilt Artifacts  : .aws-sam/build\nBuilt Template   : .aws-sam/build/template.yaml\n\nCommands you can use next\n=========================\n[*] Invoke Function: sam local invoke\n[*] Deploy: sam deploy --guided\n```\n\nビルドが完了したら、`$ sam deploy` を実行してデプロイします。\nはじめての実行の場合、以下のように `--guided` オプションを付けることで、対話形式でデプロイの設定ができるので便利です。\n\n```bash\n$ sam deploy --guided\n\nConfiguring SAM deploy\n======================\n\n\tLooking for config file [samconfig.toml] :  Found\n\tReading default arguments  :  Success\n\n\tSetting default arguments for 'sam deploy'\n\t=========================================\n\tStack Name [notify-slack]:\n\tAWS Region [ap-northeast-1]:\n\tImage Repository for SlackFunction [xxxxxxxxxxxx.dkr.ecr.ap-northeast-1.amazonaws.com/notify-slack]:\n\t  slackfunction:go1.x-v1 to be pushed to xxxxxxxxxxxx.dkr.ecr.ap-northeast-1.amazonaws.com/notify-slack:slackfunction-eb1817a25a39-go1.x-v1\n\n\t#Shows you resources changes to be deployed and require a 'Y' to initiate deploy\n\tConfirm changes before deploy [Y/n]: Y\n\t#SAM needs permission to be able to create roles to connect to the resources in your template\n\tAllow SAM CLI IAM role creation [Y/n]: Y\n\tSave arguments to configuration file [Y/n]: Y\n\tSAM configuration file [samconfig.toml]:\n\tSAM configuration environment [default]:\n```\n\nこれで、CloudFormationにスタックが作成されます。\n\n## 7. テスト\n\nScheduleを適当な時間に調整し、Webhook URLに設定したSlackチャンネルにメッセージが届けば確認完了です。\n\n```yaml\nEvents:\n  Notification:\n    Type: Schedule\n    Properties:\n      Schedule: cron(0 0 * * ? *) # JST 9:00\n```\n\n## 備考\n\nコンソールのLambda関数の画面からテスト実行することもできます。\n![スクリーンショット 2021-03-29 3.35.41（3）.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/917499/9112b882-db5b-8638-528a-90c7125fefdc.png)\n\n\n`secretsmanager:GetSecretValue`のポリシーをロールにアタッチしていない場合、エラーとなりAPIが呼び出せないので注意が必要です。\n\n```\nAccessDeniedException: User: arn:aws:sts::901071604628:assumed-role/notify-slack-SlackFunctionRole-1IND13I9826OF/notify-slack-SlackFunction-AL8RRMO0EQ8H is not authorized to perform: secretsmanager:GetSecretValue on resource: SlackWebhookUrl\n```\n","user":"R_R","created_at":"2021-03-29T03:41:07+09:00","updated_at":"2021-03-29T03:41:07+09:00"},{"url":"https://qiita.com/lengtmp/items/1e45df30c58918a1dc71","title":"GodzillaVsKong","body":"昨夜#GodzillaVsKong!\nに参加してくれたすべての伝説に感謝します\nファンスクリーニング体験！\n\nここで映画を見る：https://tvtoday.uk/\n\n![Profile Godzila.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1249584/84633dc0-895f-1b95-d0c1-47dd9a484cc0.jpeg)\n","user":"lengtmp","created_at":"2021-03-29T03:37:37+09:00","updated_at":"2021-03-29T03:37:37+09:00"},{"url":"https://qiita.com/kazushi1222/items/3a31031a0e9e36497255","title":"AWS EC2の利用メモ","body":"#AWS EC2を用いてSSH接続するまでの流れ（メモ）\n\nAWS初心者がつまづいた点を自分用としてメモ書きとして残します。\n環境はMac Windowsは違った内容になります。\n\n\n##AWS起動までの流れ\n\nAWSの登録に関してはこちらの記事を参照\nURLを貼る\n\nまとめるとAWSのアカウントを登録、EC2を起動する\nSSH接続するところまでは参照先と同じ操作\n\n\n##EC2インスタンスを起動後、SSH接続することについて\n\nAWSのSSH接続に関してはこちらの記事を参照\nhttps://qiita.com/ai-2723/items/eb156cd4dd3ccfac8791\n\nまとめるとMacのターミナルを起動して、コマンドを入力\nターミナルでセキュリティを弱くする。（400とか600とか）\nキーのディレクトリと同じディレクトリで実行すること\n\nSSH接続はAWS公式サイトに準拠した\nEC2 -> インスタンス -> インスタンスを選択 -> インスタンスに接続を選択\n\nログは以下の通りとなった。（秘密鍵はmykey.pem）\n\n     ohata@oohatakazushinoMacBook-Pro Downloads % ssh -i \"mykey1.pem\" ec2-user@ec2-13-231-201-108.ap-northeast-1.compute.amazonaws.com\n\n\n       __|  __|_  )\n       _|  (     /   Amazon Linux 2 AMI\n      ___|\\___|___|\n\n    https://aws.amazon.com/amazon-linux-2/\n    No packages needed for security; 10 packages available\n    Run \"sudo yum update\" to apply all updates.\n    [ec2-user@ip-172-31-46-110 ~]$ client_loop: send disconnect: Broken pipe\n\n\nSSH解除はexitと入力\n\n    ohata@oohatakazushinoMacBook-Pro Downloads % exit\n    Saving session...\n    ...copying shared history...\n    ...saving history...truncating history files...\n    ...completed.\n    Deleting expired sessions...none found.\n\n    [プロセスが完了しました]\n\n##編集はここまで\n\n今後追加する可能性あり\n\n\n\n\n\n\n\n","user":"kazushi1222","created_at":"2021-03-29T03:32:39+09:00","updated_at":"2021-03-29T04:22:28+09:00"},{"url":"https://qiita.com/Gmailnator/items/60f9991c0bf9358d30d2","title":"GodzillaVsKong","body":"昨夜#GodzillaVsKongに参加してくれたすべての伝説に感謝します\nファンスクリーニング体験！\n\nここで映画を見る：https：//tvtoday.uk/\n","user":"Gmailnator","created_at":"2021-03-29T03:28:11+09:00","updated_at":"2021-03-29T03:28:11+09:00"},{"url":"https://qiita.com/miyaseinto/items/3e7f38af08cc8687dab6","title":"ボクとPHP・Laravel・Dockerとの約200時間","body":"#始まりは突然に…\nあれは、ある企業に面接したときの事でした。それまで、私はRubyでの開発を行っており、ポートフォリオもRailsで作成していました。その面接で、ポートフォリオの説明を行い面接終了時に次のようなお言葉を頂いた時から始まりました。\n**あなたに課題を出します。それを期限を決めませんが行ってください。**とのことでした。課題とは以下の通りです。\n[![Image from Gyazo](https://i.gyazo.com/d8831f7d2e8311d2bea7480b0cc4a1ed.png)](https://gyazo.com/d8831f7d2e8311d2bea7480b0cc4a1ed)\n##:fire:それを成し遂げた理由:fire:\nそれは、至って単純な話です。\n**やってみたい・挑戦してみたい**と思ったかです！\nやりたいやってみせるという気持ちで望みました！\n\n#で、一体何から着手したのか\nプロセスは以下の通りです。\n①プロゲートの初級（PHP基礎学習）\n↓\n②ドットインストールPHPに関するもの全て（PHP基礎学習）\n↓\n③ドットインストールDockerに関するもの全て（Docker基礎学習）\n↓\n④ドットインストールLaravel基礎の部分のみ（Laravel基礎学習）\n↓\n⑤Docker環境下でLaravel立ち上げYouTube等の動画を元に実践（Laravel実践学習）\n↓\n⑥ちょっとした掲示板を作成（Laravel実践学習）\n↓\n⑦ポートフォリオ作成（ErrorStocker作成）\nこの様な流れで実施\n以下が着手時間です。学習管理に関しては、[Studyplus](https://apps.apple.com/jp/app/studyplus-%E3%82%B9%E3%82%BF%E3%83%87%E3%82%A3%E3%83%97%E3%83%A9%E3%82%B9-%E6%97%A5%E3%80%85%E3%81%AE%E5%AD%A6%E7%BF%92%E7%AE%A1%E7%90%86%E3%81%AB/id505410049)を利用しました。\n・PHP基礎学習に費やした時間：31時間11分（2月6日〜2月11日）\n・Docker基礎学習に費やした時間：8時間10分(2月7・11・12日)\n・Laravel基礎学習に費やした時間：31時間24分(2月11〜18日)\n・ErrorStocker作成に費やした時間：130時間4分(2月18日〜3月18日)\n合計時間：約200時間\n\n#📚作成したポートフォリオ\n###題名：ErrorStocker\nURL:http://error-st.com\nGitHub:https://github.com/miyaseinto/ErrorStokcer\n\n###何を目的に作成したのか??の前に軸を話させてください！\n少し私の話になりますが少々お付き合いください！（どうでもいいんだよテメェの話なんかと思った人は飛ばしてください笑）\nこれは、私がエンジニアを目指した軸にあります。\n【不便に感じたものをデジタル化でより楽ができるように便利に変えたい】これが私がエンジニアを目指した軸です。\nなぜその様な軸ができたかというと、前職での公務員経験からこの様な考えが生じたからです。\n前職の公務員は超田舎で勤務していました。そのため、デジタル化が都会より著しく劣っており何をするにもアナログで不効率でした。何より住民の方が大変な思いをすることが多々ありました。回覧物だったり、各種手続きだったり、仕方がないことだと考えていました。ですが、エンジニアという職業がそれらを解決に導く職業であるのでは無いかと調べるうちに、それを担ってやりたいという思いが日に日に増していきました。\nで、それを勉強したいと思い勉強していく中で自分が書いたコードがブラウザ画面で変化していくことにとてもやりがいを感じ、これを仕事にしたいと考え公務員を退職しエンジニアを目指そうと思い勉強に励みました。\n退職した職場には申し訳なかったのですが、自分の腹の中を上司の方々に話すとそれならば挑戦してみろと背中を強く押してくれました。ですので、その思いを全部背負っとるじゃいと思いながらエンジニアになりたいと考えてます。これがエンジニアを目指した軸のお話です。（長々と申し訳ないです笑）\n\n###作成背景&目的\n上記の軸を基に、プログラミングの勉強をしている時に不便に感じたことを便利に変えるために作成しました。\n私が、エラーと遭遇した時にリファレンスサイトやQiitaの内容からエラー解決に導こうとします。そこで、いつもは一度エラーした内容をGoogleのブックマークの中にファイルごとに保存して、もう一度確認をしたい時に見直しをしておりました。しかし、情けない話そのファイルをどこに保存したのかがわからなくなり、探すことに時間を掛けることがありました。そこで、検索をかけてその内容を短時間で探せることはできないかと考え作成に至りました。\n\n###工夫した・苦労したPOINT\n・投稿内容をマークダウンで投稿できるようにしたこと（リンクを文字列内に入れたいと考えたため）\n・上記と同じだが、コメント機能にもマークダウンを使用したこと(上記と同じ)\n・投稿した時間を表記させたこと\n・コメントした時間を表記させたこと\n・Bootstrapを使用したが、Bootstrap感を排除したこと\n・写真の圧縮を行ったこと\n・タグを一覧でも表示させたこと\n・閲覧用としてログイン簡略化させたこと（通常のログインと表示は異なる）\n・ページネーションを導入したこと\n・キーワード検索をタイトルの内容と本文の内容で検索できるようにしたこと\n・キーワード検索で検索件数を表示させたこと\n\n\n#📗機能一覧\n**ユーザー機能**\n・ユーザー登録（投稿用ログイン）\n・ゲストログイン（閲覧用ログイン）\n・マイページにて以下の投稿の一覧表示\n・自分の投稿内容\n**投稿機能**\n・エラーのストックをログインアカウントが投稿・編集・削除\n・一覧表示、詳細表示\n・投稿一覧表示で10個の投稿数をページネーションを実施\n・写真投稿及び圧縮（intervention/image）\n・タグ付け（タグ検索）\n・キーワード検索（タイトル・内容）\n・投稿内容にマークダウンを採用（cebe/markdown）\n**コメント機能**\n・投稿にコメントを投稿・編集・削除\n・投稿詳細ページにコメント一覧表示\n・コメント内容にマークダウンを採用（cebe/markdown）\n\n#📓使用技術\n**フロントエンド**\n・HTML / CSS / Bootstrap\n**バックエンド**\n・PHP 8.0.2\n・Laravel 8.28.1\n**データベース**\n・Mysql 8.0\n**開発環境**\n・Docker 20.10.2\n・docker-compose 1.27.4\n**本番環境**\n・AWS(VPC、EC2、S3、Route53)\n・Nginx\n\n#:computer:各種解説内容投稿\n・[Dockerの内容解説](https://qiita.com/miyaseinto/items/0e30af8346d8df1a980d)\n・[マークダウン導入内容解説](https://qiita.com/miyaseinto/items/f760d72b9998e55f4af1)\n・[投稿内容の解説](https://qiita.com/miyaseinto/items/428c199ee6cad17aab51)\n","user":"miyaseinto","created_at":"2021-03-29T03:03:45+09:00","updated_at":"2021-03-29T03:05:50+09:00"},{"url":"https://qiita.com/miyaseinto/items/428c199ee6cad17aab51","title":"ポートフォリオの解説投稿（自分なりのアウトプットです！！）","body":"#自分が書いたコードを説明できないのは恥だよ!!\nこれは、あるYouTuberの言葉です。\n確かにそうですよね…\nはい、やります。やらせてください！\n解説やらせてください！\nてな感じで始めます笑\nと、その前にこちらがポートフォリオの内容です。\n\n#三部構成でいきます！\nController・Model・Viewの三部構成で解説していきます。\n主にTweetの内容からです。\n\n\n###まずControllerから行きます！\n```php:app/Http/Controllers/TweetController.php\nnamespace App\\Http\\Controllers;\n#namespaceとは、名前空間といい、こちらを使用してクラス被りをしないようにする。というもの。\n\nuse App\\Models\\Tweet;\nuse App\\Models\\Tag;\nuse App\\Models\\Comment;\n#各種のModelを読み込む際の記述\nuse Storage;\nuse Illuminate\\Support\\Str;\n#ストレージファイルの読み込む際の記述\nuse InterventionImage;\nuse Image;\n#写真の編集ライブラリ(Intervention Image)を使用したため、その読み込みの記述\nuse Illuminate\\Http\\Request;\nuse App\\Http\\Requests\\TweetRequest;\n#Requestファイル(バリデーションのルールが書いてあるファイル)を読み込む際の記述\n\nclass TweetController extends Controller\n{\n    /**\n     * Display a listing of the resource.\n     *\n     * @return \\Illuminate\\Http\\Response\n     */\n    public function index()\n    {\n\n        $q = \\Request::query();\n        #$qにリクエストのクエリストリングを入れる。\n\n        if(isset($q['tag_name'])){#もし、$qの中のtag_nameに値があればtrueを実行する\n            $tweets = Tweet::with(['user', 'tags'])->latest()->where('tag_box', 'like', \"%{$q['tag_name']}%\")->paginate(10);\n            #$tweetsにN+1問題を解決するためにwithを使用し[userとtags]のModel情報を取得し、最新の情報を取得し、カラム名tag_boxを文字列検索で$q['tag_name']を取得し、ページネーションで10ページを表示させる。\n            #withとはリレーションを解決したい時に使用する。\n            #whereの引数について、第１引数はカラム名です。第２引数はデータベースがサポートしているオペレーターです。第３引数はカラムに対して比較する値である。\n            $tags = \\DB::table('tags')->get();\n　　　　　　　#$tagsにtagsテーブルの情報を取得する。\n\n            return view('tweets.index', [\n                'tweets' => $tweets,\n                'tags' => $tags,\n                'tag_name' => $q['tag_name']\n            ]);\n　　　　　　　#返り値でViewに値を渡す。\n        }else {\n\n            $tweets = Tweet::with(['user', 'tags'])->latest()->paginate(10);\n            $tags = \\DB::table('tags')->get();\n\n            $tags_name = [];\n            foreach ($tags as $tag) {\n                array_push($tags_name, $tag->tag_name);\n            }\n            #tags_nameに配列として値を渡す。foreachで値を回し、タグテーブルの情報からtag_nameを配列に追加していく。\n\n            return view('tweets.index', [\n                'tweets' => $tweets,\n                'tags' => $tags\n            ]);\n\n\n        }\n    }\n\n    /**\n     * Show the form for creating a new resource.\n     *\n     * @return \\Illuminate\\Http\\Response\n     */\n    public function create()\n    {\n        return view('tweets.create'\n        );\n    }\n\n    /**\n     * Store a newly created resource in storage.\n     *\n     * @param  \\Illuminate\\Http\\Request  $request\n     * @return \\Illuminate\\Http\\Response\n     */\n    public function store(TweetRequest $request)\n    {\n        $tweet = new Tweet;\n        $tweet->user_id = $request->user_id;\n        $tweet->content = $request->content;\n        $tweet->tag_box = $request->tag_box;\n        $tweet->title = $request->title;\n        #$tweetにパラメーターで取得した情報をそれぞれ値を入れていく。\n      \n        if($request->hasFile('image')){#パラメーターの中にimageが入っていたらtrueで値を返す。\n            $filename = $request->file('image');#リクエストでimageファイルとして$filenameに入れる。\n            $name = $filename->getClientOriginalName(); #$filenameの画像の名前を取得する\n            $ext = strtolower(substr($filename->getClientOriginalName(), strrpos($filename->getClientOriginalName(), '.')+1));#strtolowerで大文字を小文字に戻し、substrで文字を切り出す。これで、写真の拡張子を取得する。\n            if(!in_array($ext, ['png', 'jpg', 'gif', 'jpeg'], true)) {#['png', 'jpg', 'gif', 'jpeg']の配列に$extの値があるかチェックする。\n                $tag_view = '画像以外のファイルが指定されています。画像ファイル(png/jpg/jpeg/gif)を指定して下さい';\n                return view('tweets.tag', compact('tag_view'));\n                #tweets.tagのViewにcompactでtag_viewの情報を渡して表示させる。\n            }\n\n            $imageFile = time(). '_' . $name;\n            $imagePath = storage_path('app/public/') . $imageFile;\n            $image = Image::make($filename)#imageを作成する\n                ->resize(1000, null, function ($constraint) {\n                    $constraint->aspectRatio();#横幅を1000にして縦横比を保持したまま変更を行う。\n                    $constraint->upsize();#小さい写真を無理やり1000にすることをせずにそのままのサイズを維持する。\n                })\n                ->orientate()#画像の向きを自動的に調整する。\n                ->save($imagePath);#その情報を一旦ローカルに保存する。\n\n            $path = Storage::disk('s3')->putFile('myprefix',$imagePath, 'public');#config/filesystems.phpの中に設定した情報からawsのs3にファイル名は自動で生成し保存する。\n            $tweet->image = Storage::disk('s3')->url($path);\n\n            Storage::disk('local')->delete('app/public/' . $imageFile);#ローカルの情報を削除する。\n        } \n\n        preg_match_all('/#([a-zA-Z0-9０-９ぁ-んァ-ヶー一-龠]+)/u', $request->tag_box, $match);#ハッシュタグで始まる単語を取得。結果は、$matchに多次元配列で代入される。\n\n　　　　 # $match[0]に#(ハッシュタグ)あり、$match[1]に#(ハッシュタグ)なしの結果が入ってくるので、$match[1]で#(ハッシュタグ)なしの結果のみを使う。\n        $tags = [];\n        foreach ($match[1] as $tag) {\n            $found = Tag::firstOrCreate(['tag_name' => $tag]);#firstOrCreateメソッドで、tags_tableのnameカラムに該当のない$tagは新規登録される。\n            array_push($tags, $found);#$foundを配列に追加します(=$tags)\n        }\n\n        #投稿に紐付けされるタグのidを配列化\n        $tag_ids = [];\n        foreach ($tags as $tag) {\n            array_push($tag_ids, $tag['id']);\n        }\n\n        $tag_count = count($tag_ids);#tagの数を取得する。\n        if ($tag_count <= 5){#もしtagの数が5以下ならtrueを実施\n            $tweet->save();\n            $tweet->tags()->attach($tag_ids);#投稿ににタグ付するために、attachメソッドをつかい、モデルを結びつけている中間テーブルにレコードを挿入\n\n            return redirect('/top');\n        } else{\n            $tag_view = 'タグ数が５つ以上ですので変更してください。';\n            $tweet_id = $id;\n            return view('tweets.tag-edit', compact('tag_view','tweet_id'));\n        }\n    }\n\n    /**\n     * Display the specified resource.\n     *\n     * @param  \\App\\Models\\Tweet  $tweet\n     * @return \\Illuminate\\Http\\Response\n     */\n    public function show(Tweet $tweet)\n    {\n\n        $tweetid = $tweet->id;\n        $comments = Comment::where('tweet_id', '=', $tweetid)->get();#commentの情報をtweet_idと$tweetidの情報が同じならその情報を取得する。\n\n        return view('tweets.show',[\n            'tweet' => $tweet,\n            'comments' => $comments,\n        ]);\n\n    }\n\n    /**\n     * Show the form for editing the specified resource.\n     *\n     * @param  \\App\\Models\\Tweet  $tweet\n     * @return \\Illuminate\\Http\\Response\n     */\n    public function edit($id)\n    {\n        $tweet = Tweet::with(['user','comments'])->findOrFail($id);#[userとcomments]のModel情報を取得し、$id(パラメーター)の情報から取得する。\n        return view('tweets.edit',[\n            'tweet' => $tweet,\n        ]);\n    }\n\n    /**\n     * Update the specified resource in storage.\n     *\n     * @param  \\Illuminate\\Http\\Request  $request\n     * @param  \\App\\Models\\Tweet  $tweet\n     * @return \\Illuminate\\Http\\Response\n     */\n    public function update(Request $request)\n    {\n        #ここはstoreクラスとほとんど同じ\n        $id = $request->tweet_id;\n        $tweet = Tweet::findOrFail($id);\n        $tweet->content = $request->content;\n        $tweet->title = $request->title;\n        $tweet->user_id = $request->user_id;\n        $tweet->tag_box = $request->tag_box;\n\n        if($request->hasFile('image')){\n            $filename = $request->file('image');\n            $name = $filename->getClientOriginalName(); \n            $ext = strtolower(substr($filename->getClientOriginalName(), strrpos($filename->getClientOriginalName(), '.')+1));\n            if(!in_array($ext, ['png', 'jpg', 'gif', 'jpeg'], true)) {\n                $tag_view = '画像以外のファイルが指定されています。画像ファイル(png/jpg/jpeg/gif)を指定して下さい';\n                return view('tweets.tag', compact('tag_view'));\n            }\n\n            $imageFile = time(). '_' . $name;\n            $imagePath = storage_path('app/public/') . $imageFile;\n            $image = Image::make($filename)\n                ->resize(1000, null, function ($constraint) {\n                    $constraint->aspectRatio();\n                    $constraint->upsize();\n                })\n                ->orientate()\n                ->save($imagePath);\n\n            $path = Storage::disk('s3')->putFile('myprefix',$imagePath, 'public');\n            $tweet->image = Storage::disk('s3')->url($path);\n\n            Storage::disk('local')->delete('app/public/' . $imageFile);\n        }\n\n        preg_match_all('/#([a-zA-Z0-9０-９ぁ-んァ-ヶー一-龠]+)/u', $request->tag_box, $match);\n\n        $tags = [];\n        foreach ($match[1] as $tag) {\n            $found = Tag::firstOrCreate(['tag_name' => $tag]);\n            array_push($tags, $found);\n        }\n\n        $tag_ids = [];\n        foreach ($tags as $tag) {\n            array_push($tag_ids, $tag['id']);\n        }\n\n\n        $tag_count = count($tag_ids);\n        if ($tag_count <= 5){\n            $tweet->save();\n            $tweet->tags()->sync($tag_ids);\n\n            return redirect('/top');\n        } else{\n            $tag_view = 'タグ数が５つ以上ですので変更してください。';\n            $tweet_id = $id;\n            return view('tweets.tag-edit', compact('tag_view','tweet_id'));\n        }\n\n    }\n\n    /**\n     * Remove the specified resource from storage.\n     *\n     * @param  \\App\\Models\\Tweet  $tweet\n     * @return \\Illuminate\\Http\\Response\n     */\n    public function destroy($id)\n    {\n        #Tweetモデルから$idを見つけ出す。\n        $tweet = TWeet::find($id);\n\n\n        preg_match_all('/#([a-zA-Z0-9０-９ぁ-んァ-ヶー一-龠]+)/u', $tweet->tag_box, $match);\n\n        $tags = [];\n        foreach ($match[1] as $tag) {\n            $found = Tag::firstOrCreate(['tag_name' => $tag]);\n            array_push($tags, $found);\n        }\n\n        $tag_ids = [];\n        foreach ($tags as $tag) {\n            array_push($tag_ids, $tag['id']);\n        }\n\n\n        $tweet->tags()->delete($tag_ids);#deleteで削除する。\n        $tweet->delete();#上記と同じ\n        return redirect('/top');\n\n    }\n\n    public function search(Request $request)\n    {\n\n        $tweets = Tweet::where('title' ,'like', \"%{$request->search}%\")\n        ->orwhere('content' ,'like', \"%{$request->search}%\")\n        ->paginate(10);#Tweetモデルから情報を取得し、where句を使用してパラメータで取得した値をtitleカラムとcontentカラムの中に同じ値があるかを取得する。でそのページネーションを10で表示させる。ものを$tweetsに入れる。\n\n        $search_result = '【'. $request->search. '】の検索結果は'.$tweets->total().'件';#検索情報と検索にヒットした数を$search_resultに入れる。\n\n        $tags = \\DB::table('tags')->get();\n        return view('tweets.index',[\n            'tweets' => $tweets,\n            'search_result' => $search_result,\n            'search_query'  => $request->search,\n            'tags' => $tags,\n        ]);\n    }\n}\n```\n\n###次はModelの解説していきます！\n\n```php:app/Models/Tweet.php\nnamespace App\\Models;\n\nuse Illuminate\\Database\\Eloquent\\Factories\\HasFactory;\nuse Illuminate\\Database\\Eloquent\\Model;\n\n\nclass Tweet extends Model\n{\n    protected $table = 'tweets';\n\n    protected $fillable = [\n        'title', 'user_id','tag_box','content', 'image',\n    ];\n\n    public function user(){\n        return $this->belongsTo(\\App\\Models\\User::class,'user_id');\n    }#tweetとuserとの１対多の関係\n\n    public function tags(){\n        return $this->belongsToMany('App\\Models\\Tag');\n    }#tweetとtagとの多対多の関係\n\n    public function comments(){\n        return $this->hasMany(\\App\\Models\\Comment::class,'tweet_id', 'id');\n    }#tweetとcommentとの１対多の関係\n}\n```\n\n###最後にViewの解説をします！\n\n```php:resources/views/tweets/index.blade.php\n@extends('layouts.app')#部分テンプレート\n\n@section('content')\n\n<h2 class=\"card-header\" style=\"text-align: center;\">\n  投稿一覧\n</h2>\n\n\n    @isset($search_result)#$search_resultの情報が入っていればtrueで実施\n    <h5 class=\"card-title\" style=\"text-align: center; padding-top: 30px; font-size: 20px; color: #55c500\">{{ $search_result }}</h5>\n    @endisset\n\n<div class=\"row m-3\">\n        <div class=\"col-sm-3\">\n        <h5 class=\"card-title\"><i class=\"fas fa-tags\"></i>タグ一覧</h5>\n            @foreach($tags as $tag)#Controllerから$tagsの情報を取得して$tagに入れて回す。\n                <a href=\"{{ route('tweets.index', ['tag_name' => $tag->tag_name]) }}\" class=\"btn btn-outline-success m-1\">\n                    {{ $tag->tag_name }}#tag_nameを表示させる\n                </a>\n            @endforeach\n        </div>\n        <div class=\"col-sm-9\">\n            @if (session('status'))\n                <div class=\"alert alert-success\" role=\"alert\">\n                    {{ session('status') }}\n                </div>\n            @endif\n            @foreach ($tweets as $tweet)\n            <div class=\"toast fade show\" role=\"alert\" aria-live=\"assertive\" aria-atomic=\"true\">\n                <div class=\"toast-header\">\n                    <strong class=\"mr-auto\">\n                        <a href=\"{{ route('users.show', $tweet->user_id) }}\" class=\"btn btn-outline-primary btn-sm\">{{ \"@\".$tweet->user->name }}</a>\n                        が\n                        <span class=\"text-muted\" style=\"font-size:15px;\">{{ $tweet->created_at->format('Y年m月d日')  }}にストック</span>\n                    </strong>\n                </div>\n                <div class=\"toast-body\">\n                    <h5 class=\"card-title\">\n                        <i class=\"fas fa-tags\"></i>\n                        @foreach($tweet->tags as $tag)\n                            <a href=\"{{ route('tweets.index', ['tag_name' => $tag->tag_name]) }}\" class=\"badge badge-success\">\n                                #{{ $tag->tag_name }}\n                            </a>\n                        @endforeach\n                    </h5>\n                    <a href=\"{{ route('tweets.show', $tweet->id) }}\" class=\"text-dark\">\n                        <h2 class=\"card-title\">{{ $tweet->title }}</h2>\n                    </a>\n                </div>\n            </div>\n            @endforeach\n\n\n            @if(isset($tag_name))#もし$tag_nameに情報があればtrueで実施\n                {{ $tweets->appends(['tag_name' => $tag_name])->links() }}#tag_nameを基にペジネーションリンクにクエリ文字列を付け加えたいときは、appendsメソッドを使用する。linksメソッドは結果の残りのページヘのリンクをレンダーする。\n            @elseif(isset($search_query))#もし$search_queryの値が入っていればtrueを実施\n                {{ $tweets->appends(['search' => $search_query])->links() }}\n            @else\n                {{ $tweets->links() }}\n            @endif\n\n        </div>\n</div>\n@endsection\n```\n\nとりあえず、これでアウトプットとします。\n自分なりのアウトプットですので間違い等はあるかもしれませんが、自分のための投稿しています。\n","user":"miyaseinto","created_at":"2021-03-29T03:03:28+09:00","updated_at":"2021-03-29T03:03:28+09:00"},{"url":"https://qiita.com/miyaseinto/items/f760d72b9998e55f4af1","title":"Laravelでマークダウンを導入するには??","body":"#ポートフォリオにMarkdownを導入したい\nポートフォリオになぜMarkdownを導入するに至った経緯は、[こちら](https://qiita.com/miyaseinto/items/3e7f38af08cc8687dab6#%E5%B7%A5%E5%A4%AB%E3%81%97%E3%81%9F%E8%8B%A6%E5%8A%B4%E3%81%97%E3%81%9Fpoint)を読んでください！笑\nで、どの様にMarkdownを導入したのかは今回はこれを使用しました。\n\n```\ncomposer require cebe/markdown\n```\n\nのライブラリをcomposerでインストールして使用しました。\n\n\n#実際の記述解説\n\n\n```php:app/Models/Tweet.php\nuse cebe\\markdown\\Markdown as Markdown;\n#useでインポートを行う。\nclass Tweet extends Model\n{\n    public function parse(){\n        $parser = new Markdown();\n        #$parserにMarkdownを使用する記述を行う\n        return $parser->parse($this->content);\n        #返り値としてtweetのcontentの内容にparse()メソッドを追加を行う。\n    }\n    #パース（コンピュータプログラムの機能・処理の一つで、一定の書式や文法に従って記述されたデータを解析し、\n    #プログラムで扱えるようなデータ構造の集合体に変換することをパースという）\n\n\n    public function getMarkdownBodyAttribute(){\n        return $this->parse();\n        #返り値としてparse()を実施する。\n    }\n}\n```\n\n```php:resources/views/tweets/show.blade.php\n        <div>\n          {!! $tweet->markdown_body !!}\n          #これでtweetの中で保存したcontentの内容をmarkdownで表示させる。\n        </div>\n```\n参考にしたサイトは以下のとおりです。\n・cebe/markdownのGitHub:https://github.com/cebe/markdown\n・[上の情報を簡略化されたQiita投稿内容](https://qiita.com/ohida/items/f5280ccbb10f9b43f92c#markdown%E3%81%AB%E5%AF%BE%E5%BF%9C%E3%81%99%E3%82%8B)\n\n#実際に使用して\nmarkdownの導入を行う前は、かなり難しそうで手を出しにくいと考えていましたが、使用してみたらハードルは低いと感じました。しかし、これをライブラリなしで導入できる様に勉強に励まないとなと考えます！\n","user":"miyaseinto","created_at":"2021-03-29T03:03:11+09:00","updated_at":"2021-03-29T03:06:56+09:00"},{"url":"https://qiita.com/miyaseinto/items/0e30af8346d8df1a980d","title":"Dockerって何からスタート！(自分なりのアウトプット)","body":"#Dockerって何??\n開発者やシステム管理者が、コンテナでアプリケーションを **構築（build）、実行（run）、共有（share）**するためのプラットフォームのことを指します。\n###イメージとコンテナについて\nコンテナとは、ホストマシン(例: 自分のpc)の上に仮想的に利用する箱みたいなもの。ホストマシンとは別の世界を作る感じ。\nイメージとは、コンテナの実行に必要な概念としてのパッケージ（ファイルやメタ情報の集合体）である。\n[参考サイトイメージとコンテナの違いについて](https://blog.codecamp.jp/programming-docker-image-container)\n文字より下記の写真の内容のほうがわかるかもです!!\n![Dockerの内容.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/670418/0a581c26-9b23-b9d6-3d59-b833e1c567ea.png)\n\n\n#実際のコードを利用して\n今回はPHPのDockerファイルとdocker-compose.ymlの情報を解説していきます！\nその前にDockerfileとdocker-compose.ymlの違いについて\n・Dockerfileには個々のコンテナを構築するために必要な細かい手順（どんなツールをインストールするかなど）を記載する場所\n・docker-compose.yamlには個々のコンテナの起動定義（どんな感じで起動していくか）を記載する場所\n・要は、Dockerfileは個々のコンテナに関する説明書、docker-compose.ymlはコンテナ全体に関する説明書\nコマンド操作については、他の方の投稿内容を参考サイトとして使用します。\n[Dockerコマンド一覧](https://qiita.com/nimusukeroku/items/72bc48a8569a954c7aa2)\n\n##Dockerfileの記述\n\n```Dockerfile:info/php/Dockerfile\nFROM php:8.0-fpm-buster\n#この記述でphp8.0のベースイメージを指定して利用しますよといった命令文\nLABEL maintainer=\"ucan-lab <yes@u-can.pro>\"\n#LABEL命令はイメージに対してメタデータを追加します。\nSHELL [\"/bin/bash\", \"-oeux\", \"pipefail\", \"-c\"]\n#シェル形式のコマンドに使用\n\n# timezone environment\nENV TZ=UTC \\\n  # locale\n  LANG=en_US.UTF-8 \\\n  LANGUAGE=en_US:en \\\n  LC_ALL=en_US.UTF-8 \\\n  # composer environment\n  COMPOSER_ALLOW_SUPERUSER=1 \\\n  COMPOSER_HOME=/composer\n#ENV命令は環境変数を設定します。\n\nCOPY --from=composer:2.0 /usr/bin/composer /usr/bin/composer\n#新しいファイルまたはディレクトリをコンテナのパスにコピーします。--from オプションを付けると別のイメージのファイルを指定できます。(マルチステージビルド)composer のインストールがとてもシンプルになっています。\n\nRUN apt-get update && \\\n  apt-get -y install git libicu-dev libonig-dev libzip-dev unzip locales libfreetype6-dev libjpeg62-turbo-dev libpng-dev && \\\n  apt-get clean && \\\n  rm -rf /var/lib/apt/lists/* && \\\n  locale-gen en_US.UTF-8 && \\\n  localedef -f UTF-8 -i en_US en_US.UTF-8 && \\\n  mkdir /var/run/php-fpm && \\\n  docker-php-ext-install intl pdo_mysql zip bcmath && \\\n  docker-php-ext-configure gd --with-freetype --with-jpeg &&\\\n  composer config -g process-timeout 3600 && \\\n  composer config -g repos.packagist composer https://packagist.org && \\\n  docker-php-ext-install -j$(nproc) gd exif\n#RUN命令は現在のイメージの上に任意のコマンドを実行した結果をコミットします。Laravelに必要なライブラリー等のインストールを行っています。\n\n\nCOPY ./infra/php/php-fpm.d/zzz-www.conf /usr/local/etc/php-fpm.d/zzz-www.conf\nCOPY ./infra/php/php.ini /usr/local/etc/php/php.ini\n#ホスト側に置いているPHPの設定ファイルのコピーをしているだけです。\n\nWORKDIR /work/laravel\n#WORKDIR命令はワークディレクトリを設定します。\n```\n\n\n##docker-compose.ymlの記述\n\napp, web, db の3つのコンテナを定義しています。\n\n```docker-compose.yml\nversion: \"3.3\"\n#docker-composeのバージョン\nvolumes:\n  php-fpm-socket:\n  db-store:\n#名前付きボリューム(ボリュームとは、データを永続化できる場所のことである。外部HDDのようなイメージ。)をマウント(利用できる状態にすること)しています。\n#unixソケット(php-fpm-socket)のボリュームは app コンテナと web コンテナで共用したいのでマウントしてます。\n#unixソケットとは、まず、ソケットの意味「受け口、接合部」の意味。「UNIXドメインソケット」とは、LinuxなどのUNIX系OS（オペレーティングシステム）で実行されるプロセス間のデータ通信の終点に使われるインターフェースのことをいう。\n#データベース(db-store)のデータはコンテナを破棄しても残しておきたいのでボリュームとして定義しています。\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: ./infra/php/Dockerfile\n    volumes:\n      - php-fpm-socket:/var/run/php-fpm\n      - ./laravel:/work/laravel\n    environment:\n      - DB_CONNECTION=mysql\n      - DB_HOST=db\n      - DB_PORT=3306\n      - DB_DATABASE=${DB_NAME:-laravel_local}\n      - DB_USERNAME=${DB_USER:-phper}\n      - DB_PASSWORD=${DB_PASS:-secret}\n#app(アプリケーションサーバ)コンテナの定義です。PHPを実行します。\n#build で ./infra/php/Dockerfile を指しています。\n#volumes で名前付きボリュームとホストパスをコンテナにマウントしてます。\n#../Laravel:/work/backendはLaravelのソースコードをマウントしてます。\n#environmentで環境変数を定義している。 \n\n  web:\n    build:\n      context: .\n      dockerfile: ./infra/nginx/Dockerfile\n    ports:\n      - ${WEB_PORT:-80}:80\n    volumes:\n      - php-fpm-socket:/var/run/php-fpm\n      - ./laravel:/work/laravel\n#web(ウェブサーバ)コンテナの定義です。PHP以外の静的コンテンツを返却します。\n#ports ポートを公開します。(HOST:CONTAINER)\n#volumes で名前付きボリュームとホストパスをコンテナにマウントしてます。\n#nginxのデフォルトのポート番号は 80 番です。\n\n  db:\n    build:\n      context: .\n      dockerfile: ./infra/mysql/Dockerfile\n    ports:\n      - ${DB_PORT:-3306}:3306\n    volumes:\n      - db-store:/var/lib/mysql\n    environment:\n      - MYSQL_DATABASE=${DB_NAME:-laravel_local}\n      - MYSQL_USER=${DB_USER:-phper}\n      - MYSQL_PASSWORD=${DB_PASS:-secret}\n      - MYSQL_ROOT_PASSWORD=${DB_PASS:-secret}\n#db(データベース)コンテナの定義です。\n#build で ./infra/mysql/Dockerfile を指しています\n#ports ポートを公開します。\n#volumes で名前付きボリュームとホストパスをコンテナにマウントしてます。\n#MySQLのデフォルトのポート番号は 3306 番です。\n#environmentで環境変数を定義している。 \n```\n\n#参考にしたサイト\n[この方](https://qiita.com/ucan-lab/items/5fc1281cd8076c8ac9f4#docker-composeyml)の内容で解説していただいており、そちらを主に参考に使用しました。\nほとんど、この方の情報を基に書いたので感謝しかないですが、これを自分のものにしていきたいです。\n","user":"miyaseinto","created_at":"2021-03-29T03:02:31+09:00","updated_at":"2021-03-29T03:02:31+09:00"},{"url":"https://qiita.com/yu17/items/501219c5b67de5df26e2","title":"初心者がmacにRuby on Rails環境を構築した話","body":"#この記事で書くこと\nmacにRuby on Rails環境を構築したときのメモ。\n途中、webpacker, Node.js, yarn がインストールされていない等の問題が発生したが、これらの解決策についても記載。\n\n\n#対象読者 ( = 筆者のレベル）\nProgate１周したばかり、くらいの初心者。\n\n\n#環境\nmacOS Catalina 10.15.7\nMacBook Pro (13-inch, 2020, Four Thunderbolt 3 ports)\n　2GHz クアッドコアIntel Core i5\n　16GB 3733 MHz LPDDR4X\nシェル zsh\nターミナル iTerm2 Build 3.4.4\nRuby 2.7.2\nHomebrew 3.0.7\nrbenv 1.1.2\n\n\n#事前準備\nHomebrew, rbenv をインストールしておく。\n私が上記インストールを実施した際に遭遇したエラーの解決方法は[この記事](https://qiita.com/yu17/items/3b42d269e265b9fc14fb)に記載した。\n\n\n#実施事項\n##1. rails のインストール\n###インストール\n\n```zsh:zsh\n% gem install rails\n```\n\n###インストールが完了したかどうかを確認\n正常にインストールできていない模様。\n本来はバージョンが表示されるはず。\n\n```zsh:zsh\n% rails -v\nRails is not currently installed on this system. To get the latest version, simply type:\n\n    $ sudo gem install rails\n\nYou can then rerun your \"rails\" command. \n```\n\n###パスを通す\n\n```zsh:zsh\n% export PATH=\"$HOME/.rbenv/shims:$PATH\"\n```\n\n###再度 rails のインストールが完了したか確認\n今度は問題なし。\n\n```zsh:zsh\n% rails -v\nRails 6.1.3\n```\n\n##2. サンプルアプリを作成する\n\n```zsh:zsh\n% rails new sample_app\n```\n\n##3. railsサーバーの起動 (1回目)\nどうやらrailsサーバーを起動できていない模様。\nターミナル上に表記された文字列を確認すると、\n`/Users/username/Documents/Rails/sample_app/config/webpacker.yml`\nが存在しないらしい。\n\n```zsh:zsh\n% rails s\n```\n\n<details>\n<summary>結果はここをクリックして確認</summary>\n<div>\n\n```zsh:結果\n=> Booting Puma\n=> Rails 6.1.3 application starting in development \n=> Run `bin/rails server --help` for more startup options\nExiting\nTraceback (most recent call last):\n\t76: from bin/rails:2:in `<main>'\n\t75: from bin/rails:2:in `load'\n\t74: from /Users/username/Documents/Rails/sample_app/bin/spring:7:in `<top (required)>'\n\t73: from /Users/username/Documents/Rails/sample_app/bin/spring:7:in `tap'\n\t72: from /Users/username/Documents/Rails/sample_app/bin/spring:10:in `block in <top (required)>'\n\t71: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/rubygems/core_ext/kernel_require.rb:72:in `require'\n\t70: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/rubygems/core_ext/kernel_require.rb:72:in `require'\n\t69: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/binstub.rb:11:in `<top (required)>'\n\t68: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/binstub.rb:11:in `load'\n\t67: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/bin/spring:49:in `<top (required)>'\n\t66: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/client.rb:30:in `run'\n\t65: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/client/command.rb:7:in `call'\n\t64: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/client/rails.rb:28:in `call'\n\t63: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/client/rails.rb:28:in `load'\n\t62: from /Users/username/Documents/Rails/sample_app/bin/rails:5:in `<top (required)>'\n\t61: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:31:in `require'\n\t60: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:22:in `require_with_bootsnap_lfi'\n\t59: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/loaded_features_index.rb:92:in `register'\n\t58: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `block in require_with_bootsnap_lfi'\n\t57: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `require'\n\t56: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands.rb:18:in `<main>'\n\t55: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/command.rb:50:in `invoke'\n\t54: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/command/base.rb:69:in `perform'\n\t53: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/thor-1.1.0/lib/thor.rb:392:in `dispatch'\n\t52: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/thor-1.1.0/lib/thor/invocation.rb:127:in `invoke_command'\n\t51: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/thor-1.1.0/lib/thor/command.rb:27:in `run'\n\t50: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:135:in `perform'\n\t49: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:135:in `tap'\n\t48: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:144:in `block in perform'\n\t47: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:37:in `start'\n\t46: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:77:in `log_to_stdout'\n\t45: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/server.rb:422:in `wrapped_app'\n\t44: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/server.rb:249:in `app'\n\t43: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/server.rb:349:in `build_app_and_options_from_config'\n\t42: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/builder.rb:66:in `parse_file'\n\t41: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/builder.rb:105:in `load_file'\n\t40: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/builder.rb:116:in `new_from_string'\n\t39: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/builder.rb:116:in `eval'\n\t38: from config.ru:3:in `block in <main>'\n\t37: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:53:in `require_relative'\n\t36: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/activesupport-6.1.3/lib/active_support/dependencies.rb:332:in `require'\n\t35: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/activesupport-6.1.3/lib/active_support/dependencies.rb:299:in `load_dependency'\n\t34: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/activesupport-6.1.3/lib/active_support/dependencies.rb:332:in `block in require'\n\t33: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/zeitwerk-2.4.2/lib/zeitwerk/kernel.rb:34:in `require'\n\t32: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:31:in `require'\n\t31: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:22:in `require_with_bootsnap_lfi'\n\t30: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/loaded_features_index.rb:92:in `register'\n\t29: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `block in require_with_bootsnap_lfi'\n\t28: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `require'\n\t27: from /Users/username/Documents/Rails/sample_app/config/environment.rb:5:in `<main>'\n\t26: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/application.rb:384:in `initialize!'\n\t25: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/initializable.rb:60:in `run_initializers'\n\t24: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:205:in `tsort_each'\n\t23: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:226:in `tsort_each'\n\t22: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:347:in `each_strongly_connected_component'\n\t21: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:347:in `call'\n\t20: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:347:in `each'\n\t19: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:349:in `block in each_strongly_connected_component'\n\t18: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:431:in `each_strongly_connected_component_from'\n\t17: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:350:in `block (2 levels) in each_strongly_connected_component'\n\t16: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:228:in `block in tsort_each'\n\t15: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/initializable.rb:61:in `block in run_initializers'\n\t14: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/initializable.rb:32:in `run'\n\t13: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/initializable.rb:32:in `instance_exec'\n\t12: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/railtie.rb:41:in `block in <class:Engine>'\n\t11: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker.rb:35:in `bootstrap'\n\t10: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/commands.rb:47:in `bootstrap'\n\t 9: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/manifest.rb:18:in `refresh'\n\t 8: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/manifest.rb:83:in `load'\n\t 7: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:51:in `public_manifest_path'\n\t 6: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:47:in `public_output_path'\n\t 5: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:43:in `public_path'\n\t 4: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:88:in `fetch'\n\t 3: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:92:in `data'\n\t 2: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:96:in `load'\n\t 1: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:96:in `read'\n/Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:96:in `read': No such file or directory @ rb_sysopen - /Users/username/Documents/Rails/sample_app/config/webpacker.yml (Errno::ENOENT)\n\t75: from bin/rails:2:in `<main>'\n\t74: from bin/rails:2:in `load'\n\t73: from /Users/username/Documents/Rails/sample_app/bin/spring:7:in `<top (required)>'\n\t72: from /Users/username/Documents/Rails/sample_app/bin/spring:7:in `tap'\n\t71: from /Users/username/Documents/Rails/sample_app/bin/spring:10:in `block in <top (required)>'\n\t70: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/rubygems/core_ext/kernel_require.rb:72:in `require'\n\t69: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/rubygems/core_ext/kernel_require.rb:72:in `require'\n\t68: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/binstub.rb:11:in `<top (required)>'\n\t67: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/binstub.rb:11:in `load'\n\t66: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/bin/spring:49:in `<top (required)>'\n\t65: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/client.rb:30:in `run'\n\t64: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/client/command.rb:7:in `call'\n\t63: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/client/rails.rb:28:in `call'\n\t62: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/spring-2.1.1/lib/spring/client/rails.rb:28:in `load'\n\t61: from /Users/username/Documents/Rails/sample_app/bin/rails:5:in `<top (required)>'\n\t60: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:31:in `require'\n\t59: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:22:in `require_with_bootsnap_lfi'\n\t58: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/loaded_features_index.rb:92:in `register'\n\t57: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `block in require_with_bootsnap_lfi'\n\t56: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `require'\n\t55: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands.rb:18:in `<main>'\n\t54: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/command.rb:50:in `invoke'\n\t53: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/command/base.rb:69:in `perform'\n\t52: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/thor-1.1.0/lib/thor.rb:392:in `dispatch'\n\t51: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/thor-1.1.0/lib/thor/invocation.rb:127:in `invoke_command'\n\t50: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/thor-1.1.0/lib/thor/command.rb:27:in `run'\n\t49: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:135:in `perform'\n\t48: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:135:in `tap'\n\t47: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:144:in `block in perform'\n\t46: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:37:in `start'\n\t45: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/commands/server/server_command.rb:77:in `log_to_stdout'\n\t44: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/server.rb:422:in `wrapped_app'\n\t43: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/server.rb:249:in `app'\n\t42: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/server.rb:349:in `build_app_and_options_from_config'\n\t41: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/builder.rb:66:in `parse_file'\n\t40: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/builder.rb:105:in `load_file'\n\t39: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/builder.rb:116:in `new_from_string'\n\t38: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/rack-2.2.3/lib/rack/builder.rb:116:in `eval'\n\t37: from config.ru:3:in `block in <main>'\n\t36: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:53:in `require_relative'\n\t35: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/activesupport-6.1.3/lib/active_support/dependencies.rb:332:in `require'\n\t34: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/activesupport-6.1.3/lib/active_support/dependencies.rb:299:in `load_dependency'\n\t33: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/activesupport-6.1.3/lib/active_support/dependencies.rb:332:in `block in require'\n\t32: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/zeitwerk-2.4.2/lib/zeitwerk/kernel.rb:34:in `require'\n\t31: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:31:in `require'\n\t30: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:22:in `require_with_bootsnap_lfi'\n\t29: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/loaded_features_index.rb:92:in `register'\n\t28: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `block in require_with_bootsnap_lfi'\n\t27: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/bootsnap-1.7.2/lib/bootsnap/load_path_cache/core_ext/kernel_require.rb:23:in `require'\n\t26: from /Users/username/Documents/Rails/sample_app/config/environment.rb:5:in `<main>'\n\t25: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/application.rb:384:in `initialize!'\n\t24: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/initializable.rb:60:in `run_initializers'\n\t23: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:205:in `tsort_each'\n\t22: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:226:in `tsort_each'\n\t21: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:347:in `each_strongly_connected_component'\n\t20: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:347:in `call'\n\t19: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:347:in `each'\n\t18: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:349:in `block in each_strongly_connected_component'\n\t17: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:431:in `each_strongly_connected_component_from'\n\t16: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:350:in `block (2 levels) in each_strongly_connected_component'\n\t15: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/2.7.0/tsort.rb:228:in `block in tsort_each'\n\t14: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/initializable.rb:61:in `block in run_initializers'\n\t13: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/initializable.rb:32:in `run'\n\t12: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/initializable.rb:32:in `instance_exec'\n\t11: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/railtie.rb:41:in `block in <class:Engine>'\n\t10: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker.rb:35:in `bootstrap'\n\t 9: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/commands.rb:47:in `bootstrap'\n\t 8: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/manifest.rb:18:in `refresh'\n\t 7: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/manifest.rb:83:in `load'\n\t 6: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:51:in `public_manifest_path'\n\t 5: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:47:in `public_output_path'\n\t 4: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:43:in `public_path'\n\t 3: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:88:in `fetch'\n\t 2: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:92:in `data'\n\t 1: from /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:95:in `load'\n/Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/webpacker/configuration.rb:99:in `rescue in load': Webpacker configuration file not found /Users/username/Documents/Rails/sample_app/config/webpacker.yml. Please run rails webpacker:install Error: No such file or directory @ rb_sysopen - /Users/username/Documents/Rails/sample_app/config/webpacker.yml (RuntimeError)\n```\n</div>\n</details>\n\n##4. webpacker のインストール (1回目)\n[このQiita記事](https://qiita.com/NaokiIshimura/items/8203f74f8dfd5f6b87a0 \"Rails6 開発時につまづきそうな webpacker, yarn 関係のエラーと解決方法\")を参考にして、webpackerインストールを試したが、失敗。\nターミナル上の文字列を確認すると、`Node.js`がインストールされていない模様。\n\n```zsh:zsh\n% rails webpacker:install\nsh: node: command not found\nsh: nodejs: command not found\nNode.js not installed. Please download and install Node.js https://nodejs.org/en/download/\nExiting!\n```\n\n##5. Node.js のインストール\n[このQiita記事](https://qiita.com/kyosuke5_20/items/c5f68fc9d89b84c0df09 \"MacにNode.jsをインストール\")を参考にして、Node.jsをインストール。\n記事内では、下記の流れで説明があったが、私はHomebrewについては既にインストール済みなので、２，３を実施した。\n>1. Homebrewのインストール\n>2. nodebrewのインストール\n>3. Node.jsのインストール\n\n###(1) nodebrewのインストール\n\n```zsh:zsh\n% brew install nodebrew\nUpdating Homebrew...\n==> Auto-updated Homebrew!\nUpdated 2 taps (homebrew/core and homebrew/cask).\n==> New Formulae\nopenmodelica                             sqlancer\n==> Updated Formulae\nUpdated 32 formulae.\n==> New Casks\nn1ghtshade\n==> Updated Casks\nUpdated 17 casks.\n\n==> Downloading https://github.com/hokaccha/nodebrew/archive/v1.0.1.tar.gz\n==> Downloading from https://codeload.github.com/hokaccha/nodebrew/tar.gz/v1.0.1\n##O#- #                                                                       \n==> Caveats\nYou need to manually run setup_dirs to create directories required by nodebrew:\n  /usr/local/opt/nodebrew/bin/nodebrew setup_dirs\n\nAdd path:\n  export PATH=$HOME/.nodebrew/current/bin:$PATH\n\nTo use Homebrew's directories rather than ~/.nodebrew add to your profile:\n  export NODEBREW_ROOT=/usr/local/var/nodebrew\n\nzsh completions have been installed to:\n  /usr/local/share/zsh/site-functions\n==> Summary\n🍺  /usr/local/Cellar/nodebrew/1.0.1: 8 files, 38.7KB, built in 3 seconds\n```\n\n####インストール完了したか確認\n正常にインストール完了していることを確認。\n\n```zsh:zsh\n% nodebrew -v\nnodebrew 1.0.1\n\nUsage:\n    nodebrew help                         Show this message\n    nodebrew install <version>            Download and install <version> (from binary)\n    nodebrew compile <version>            Download and install <version> (from source)\n    nodebrew install-binary <version>     Alias of `install` (For backword compatibility)\n    nodebrew uninstall <version>          Uninstall <version>\n    nodebrew use <version>                Use <version>\n    nodebrew list                         List installed versions\n    nodebrew ls                           Alias for `list`\n    nodebrew ls-remote                    List remote versions\n    nodebrew ls-all                       List remote and installed versions\n    nodebrew alias <key> <value>          Set alias\n    nodebrew unalias <key>                Remove alias\n    nodebrew clean <version> | all        Remove source file\n    nodebrew selfupdate                   Update nodebrew\n    nodebrew migrate-package <version>    Install global NPM packages contained in <version> to current version\n    nodebrew exec <version> -- <command>  Execute <command> using specified <version>\n\nExample:\n    # install\n    nodebrew install v8.9.4\n\n    # use a specific version number\n    nodebrew use v8.9.4\n```\n\n###(2) Node.jsのインストール\n####インストール可能なバージョンを確認\n\n```zsh:zsh\n% nodebrew ls-remote\n```\n\n<details>\n<summary>結果はここをクリックして確認</summary>\n<div>\n\n```zsh:結果\nv0.0.1    v0.0.2    v0.0.3    v0.0.4    v0.0.5    v0.0.6    \n\nv0.1.0    v0.1.1    v0.1.2    v0.1.3    v0.1.4    v0.1.5    v0.1.6    v0.1.7\nv0.1.8    v0.1.9    v0.1.10   v0.1.11   v0.1.12   v0.1.13   v0.1.14   v0.1.15\nv0.1.16   v0.1.17   v0.1.18   v0.1.19   v0.1.20   v0.1.21   v0.1.22   v0.1.23\nv0.1.24   v0.1.25   v0.1.26   v0.1.27   v0.1.28   v0.1.29   v0.1.30   v0.1.31\nv0.1.32   v0.1.33   v0.1.90   v0.1.91   v0.1.92   v0.1.93   v0.1.94   v0.1.95\nv0.1.96   v0.1.97   v0.1.98   v0.1.99   v0.1.100  v0.1.101  v0.1.102  v0.1.103\nv0.1.104  \n\nv0.2.0    v0.2.1    v0.2.2    v0.2.3    v0.2.4    v0.2.5    v0.2.6    \n\nv0.3.0    v0.3.1    v0.3.2    v0.3.3    v0.3.4    v0.3.5    v0.3.6    v0.3.7\nv0.3.8    \n\nv0.4.0    v0.4.1    v0.4.2    v0.4.3    v0.4.4    v0.4.5    v0.4.6    v0.4.7\nv0.4.8    v0.4.9    v0.4.10   v0.4.11   v0.4.12   \n\nv0.5.0    v0.5.1    v0.5.2    v0.5.3    v0.5.4    v0.5.5    v0.5.6    v0.5.7\nv0.5.8    v0.5.9    v0.5.10   \n\nv0.6.0    v0.6.1    v0.6.2    v0.6.3    v0.6.4    v0.6.5    v0.6.6    v0.6.7\nv0.6.8    v0.6.9    v0.6.10   v0.6.11   v0.6.12   v0.6.13   v0.6.14   v0.6.15\nv0.6.16   v0.6.17   v0.6.18   v0.6.19   v0.6.20   v0.6.21   \n\nv0.7.0    v0.7.1    v0.7.2    v0.7.3    v0.7.4    v0.7.5    v0.7.6    v0.7.7\nv0.7.8    v0.7.9    v0.7.10   v0.7.11   v0.7.12   \n\nv0.8.0    v0.8.1    v0.8.2    v0.8.3    v0.8.4    v0.8.5    v0.8.6    v0.8.7\nv0.8.8    v0.8.9    v0.8.10   v0.8.11   v0.8.12   v0.8.13   v0.8.14   v0.8.15\nv0.8.16   v0.8.17   v0.8.18   v0.8.19   v0.8.20   v0.8.21   v0.8.22   v0.8.23\nv0.8.24   v0.8.25   v0.8.26   v0.8.27   v0.8.28   \n\nv0.9.0    v0.9.1    v0.9.2    v0.9.3    v0.9.4    v0.9.5    v0.9.6    v0.9.7\nv0.9.8    v0.9.9    v0.9.10   v0.9.11   v0.9.12   \n\nv0.10.0   v0.10.1   v0.10.2   v0.10.3   v0.10.4   v0.10.5   v0.10.6   v0.10.7\nv0.10.8   v0.10.9   v0.10.10  v0.10.11  v0.10.12  v0.10.13  v0.10.14  v0.10.15\nv0.10.16  v0.10.17  v0.10.18  v0.10.19  v0.10.20  v0.10.21  v0.10.22  v0.10.23\nv0.10.24  v0.10.25  v0.10.26  v0.10.27  v0.10.28  v0.10.29  v0.10.30  v0.10.31\nv0.10.32  v0.10.33  v0.10.34  v0.10.35  v0.10.36  v0.10.37  v0.10.38  v0.10.39\nv0.10.40  v0.10.41  v0.10.42  v0.10.43  v0.10.44  v0.10.45  v0.10.46  v0.10.47\nv0.10.48  \n\nv0.11.0   v0.11.1   v0.11.2   v0.11.3   v0.11.4   v0.11.5   v0.11.6   v0.11.7\nv0.11.8   v0.11.9   v0.11.10  v0.11.11  v0.11.12  v0.11.13  v0.11.14  v0.11.15\nv0.11.16  \n\nv0.12.0   v0.12.1   v0.12.2   v0.12.3   v0.12.4   v0.12.5   v0.12.6   v0.12.7\nv0.12.8   v0.12.9   v0.12.10  v0.12.11  v0.12.12  v0.12.13  v0.12.14  v0.12.15\nv0.12.16  v0.12.17  v0.12.18  \n\nv4.0.0    v4.1.0    v4.1.1    v4.1.2    v4.2.0    v4.2.1    v4.2.2    v4.2.3\nv4.2.4    v4.2.5    v4.2.6    v4.3.0    v4.3.1    v4.3.2    v4.4.0    v4.4.1\nv4.4.2    v4.4.3    v4.4.4    v4.4.5    v4.4.6    v4.4.7    v4.5.0    v4.6.0\nv4.6.1    v4.6.2    v4.7.0    v4.7.1    v4.7.2    v4.7.3    v4.8.0    v4.8.1\nv4.8.2    v4.8.3    v4.8.4    v4.8.5    v4.8.6    v4.8.7    v4.9.0    v4.9.1\n\n\nv5.0.0    v5.1.0    v5.1.1    v5.2.0    v5.3.0    v5.4.0    v5.4.1    v5.5.0\nv5.6.0    v5.7.0    v5.7.1    v5.8.0    v5.9.0    v5.9.1    v5.10.0   v5.10.1\nv5.11.0   v5.11.1   v5.12.0   \n\nv6.0.0    v6.1.0    v6.2.0    v6.2.1    v6.2.2    v6.3.0    v6.3.1    v6.4.0\nv6.5.0    v6.6.0    v6.7.0    v6.8.0    v6.8.1    v6.9.0    v6.9.1    v6.9.2\nv6.9.3    v6.9.4    v6.9.5    v6.10.0   v6.10.1   v6.10.2   v6.10.3   v6.11.0\nv6.11.1   v6.11.2   v6.11.3   v6.11.4   v6.11.5   v6.12.0   v6.12.1   v6.12.2\nv6.12.3   v6.13.0   v6.13.1   v6.14.0   v6.14.1   v6.14.2   v6.14.3   v6.14.4\nv6.15.0   v6.15.1   v6.16.0   v6.17.0   v6.17.1   \n\nv7.0.0    v7.1.0    v7.2.0    v7.2.1    v7.3.0    v7.4.0    v7.5.0    v7.6.0\nv7.7.0    v7.7.1    v7.7.2    v7.7.3    v7.7.4    v7.8.0    v7.9.0    v7.10.0\nv7.10.1   \n\nv8.0.0    v8.1.0    v8.1.1    v8.1.2    v8.1.3    v8.1.4    v8.2.0    v8.2.1\nv8.3.0    v8.4.0    v8.5.0    v8.6.0    v8.7.0    v8.8.0    v8.8.1    v8.9.0\nv8.9.1    v8.9.2    v8.9.3    v8.9.4    v8.10.0   v8.11.0   v8.11.1   v8.11.2\nv8.11.3   v8.11.4   v8.12.0   v8.13.0   v8.14.0   v8.14.1   v8.15.0   v8.15.1\nv8.16.0   v8.16.1   v8.16.2   v8.17.0   \n\nv9.0.0    v9.1.0    v9.2.0    v9.2.1    v9.3.0    v9.4.0    v9.5.0    v9.6.0\nv9.6.1    v9.7.0    v9.7.1    v9.8.0    v9.9.0    v9.10.0   v9.10.1   v9.11.0\nv9.11.1   v9.11.2   \n\nv10.0.0   v10.1.0   v10.2.0   v10.2.1   v10.3.0   v10.4.0   v10.4.1   v10.5.0\nv10.6.0   v10.7.0   v10.8.0   v10.9.0   v10.10.0  v10.11.0  v10.12.0  v10.13.0\nv10.14.0  v10.14.1  v10.14.2  v10.15.0  v10.15.1  v10.15.2  v10.15.3  v10.16.0\nv10.16.1  v10.16.2  v10.16.3  v10.17.0  v10.18.0  v10.18.1  v10.19.0  v10.20.0\nv10.20.1  v10.21.0  v10.22.0  v10.22.1  v10.23.0  v10.23.1  v10.23.2  v10.23.3\nv10.24.0  \n\nv11.0.0   v11.1.0   v11.2.0   v11.3.0   v11.4.0   v11.5.0   v11.6.0   v11.7.0\nv11.8.0   v11.9.0   v11.10.0  v11.10.1  v11.11.0  v11.12.0  v11.13.0  v11.14.0\nv11.15.0  \n\nv12.0.0   v12.1.0   v12.2.0   v12.3.0   v12.3.1   v12.4.0   v12.5.0   v12.6.0\nv12.7.0   v12.8.0   v12.8.1   v12.9.0   v12.9.1   v12.10.0  v12.11.0  v12.11.1\nv12.12.0  v12.13.0  v12.13.1  v12.14.0  v12.14.1  v12.15.0  v12.16.0  v12.16.1\nv12.16.2  v12.16.3  v12.17.0  v12.18.0  v12.18.1  v12.18.2  v12.18.3  v12.18.4\nv12.19.0  v12.19.1  v12.20.0  v12.20.1  v12.20.2  v12.21.0  \n\nv13.0.0   v13.0.1   v13.1.0   v13.2.0   v13.3.0   v13.4.0   v13.5.0   v13.6.0\nv13.7.0   v13.8.0   v13.9.0   v13.10.0  v13.10.1  v13.11.0  v13.12.0  v13.13.0\nv13.14.0  \n\nv14.0.0   v14.1.0   v14.2.0   v14.3.0   v14.4.0   v14.5.0   v14.6.0   v14.7.0\nv14.8.0   v14.9.0   v14.10.0  v14.10.1  v14.11.0  v14.12.0  v14.13.0  v14.13.1\nv14.14.0  v14.15.0  v14.15.1  v14.15.2  v14.15.3  v14.15.4  v14.15.5  v14.16.0\n\n\nv15.0.0   v15.0.1   v15.1.0   v15.2.0   v15.2.1   v15.3.0   v15.4.0   v15.5.0\nv15.5.1   v15.6.0   v15.7.0   v15.8.0   v15.9.0   v15.10.0  v15.11.0  \n\nio@v1.0.0 io@v1.0.1 io@v1.0.2 io@v1.0.3 io@v1.0.4 io@v1.1.0 io@v1.2.0 io@v1.3.0\nio@v1.4.1 io@v1.4.2 io@v1.4.3 io@v1.5.0 io@v1.5.1 io@v1.6.0 io@v1.6.1 io@v1.6.2\nio@v1.6.3 io@v1.6.4 io@v1.7.1 io@v1.8.1 io@v1.8.2 io@v1.8.3 io@v1.8.4 \n\nio@v2.0.0 io@v2.0.1 io@v2.0.2 io@v2.1.0 io@v2.2.0 io@v2.2.1 io@v2.3.0 io@v2.3.1\nio@v2.3.2 io@v2.3.3 io@v2.3.4 io@v2.4.0 io@v2.5.0 \n\nio@v3.0.0 io@v3.1.0 io@v3.2.0 io@v3.3.0 io@v3.3.1 \n```\n</div>\n</degails>\n\n####インストール\n・バージョンを直接指定するときは `version名`\n・最新版を取得する時は `latest`\n・安定版を取得する時は `stable`\n今回は `stable` とした。\n\n```zsh:zsh\n% nodebrew install-binary stable\nFetching: https://nodejs.org/dist/v14.16.0/node-v14.16.0-darwin-x64.tar.gz\nWarning: Failed to create the file \nWarning: /Users/username/.nodebrew/src/v14.16.0/node-v14.16.0-darwin-x64.tar.\nWarning: gz: No such file or directory\n\ncurl: (23) Failed writing body (0 != 978)\ndownload failed: https://nodejs.org/dist/v14.16.0/node-v14.16.0-darwin-x64.tar.gz\n```\n上記のとおりディレクトリが存在しないというエラーが出たので、作成。\n\n```zsh:zsh\n% mkdir -p ~/.nodebrew/src\n```\nディレクトリ作成後、再度インストールし、成功した。\n\n```zsh:zsh\n% nodebrew install-binary stable\nFetching: https://nodejs.org/dist/v14.16.0/node-v14.16.0-darwin-x64.tar.gz\n######################################################################### 100.0%\nInstalled successfully\n```\n\n####インストール後の処理① 有効化\n[上記の記事](https://qiita.com/kyosuke5_20/items/c5f68fc9d89b84c0df09 \"MacにNode.jsをインストール\")と同じだが、一応私の実施内容とその結果も掲載。\nインストールバージョンの確認。\n\n```zsh:zsh\n% nodebrew ls\nv14.16.0\n\ncurrent: none\n```\n\n`current: none` 有効化されているバージョンはない、の意味。\n下記にてバージョンを指定して有効化する。\n\n```zsh:zsh\n% nodebrew use v14.16.0\n```\n\n有効化されているか確認。\n\n```zsh:zsh\n% nodebrew ls\nv14.16.0\n\ncurrent: v14.16.0\n```\n\n####インストール後の処理② 環境パスを通す\n\n```zsh:zsh\n% echo 'export PATH=$HOME/.nodebrew/current/bin:$PATH' >> ~/.zprofile\n```\n\n####インストール後の処理③ 最終確認\nnodeが使用可能か確認。\n\n```zsh:zsh\n% node -v\nv14.16.0\n```\n\n##6. webpacker のインストール (2回目)\n7.の時とは異なるエラーメッセージ。\n`Yarn` がインストールされていない模様。\n\n```zsh:zsh\n% rails webpacker:install\nYarn not installed. Please download and install Yarn from https://yarnpkg.com/lang/en/docs/install/\nExiting!\n```\n\n##7. yarn のインストール\n[このQiita記事](https://qiita.com/NaokiIshimura/items/8203f74f8dfd5f6b87a0 \"Rails6 開発時につまづきそうな webpacker, yarn 関係のエラーと解決方法\")に基本的には従って実施。\n\n###(1) インストールされているか確認\nインストールされていない。\n\n```zsh:zsh\n% yarn -v\nzsh: command not found: yarn\n```\n\n###(2) インストール\n\n```zsh:zsh\n% brew install yarn\nUpdating Homebrew...\n==> Auto-updated Homebrew!\nUpdated 1 tap (homebrew/cask).\n==> Updated Casks\nUpdated 6 casks.\n\n==> Downloading https://homebrew.bintray.com/bottles/icu4c-68.2.catalina.bottle.\n==> Downloading from https://d29vzk4ow07wi7.cloudfront.net/fdc2f15705175478dc166\n######################################################################## 100.0%\n==> Downloading https://homebrew.bintray.com/bottles/node-15.11.0.catalina.bottl\n==> Downloading from https://d29vzk4ow07wi7.cloudfront.net/1dc4ea77c4196c8376eb6\n######################################################################## 100.0%\n==> Downloading https://yarnpkg.com/downloads/1.22.10/yarn-v1.22.10.tar.gz\n==> Downloading from https://github-releases.githubusercontent.com/49970642/30fd\n######################################################################## 100.0%\n==> Installing dependencies for yarn: icu4c and node\n==> Installing yarn dependency: icu4c\n==> Pouring icu4c-68.2.catalina.bottle.tar.gz\n==> Caveats\nicu4c is keg-only, which means it was not symlinked into /usr/local,\nbecause macOS provides libicucore.dylib (but nothing else).\n\nIf you need to have icu4c first in your PATH, run:\n  echo 'export PATH=\"/usr/local/opt/icu4c/bin:$PATH\"' >> ~/.zshrc\n  echo 'export PATH=\"/usr/local/opt/icu4c/sbin:$PATH\"' >> ~/.zshrc\n\nFor compilers to find icu4c you may need to set:\n  export LDFLAGS=\"-L/usr/local/opt/icu4c/lib\"\n  export CPPFLAGS=\"-I/usr/local/opt/icu4c/include\"\n\nFor pkg-config to find icu4c you may need to set:\n  export PKG_CONFIG_PATH=\"/usr/local/opt/icu4c/lib/pkgconfig\"\n\n==> Summary\n🍺  /usr/local/Cellar/icu4c/68.2: 259 files, 72.5MB\n==> Installing yarn dependency: node\n==> Pouring node-15.11.0.catalina.bottle.tar.gz\n🍺  /usr/local/Cellar/node/15.11.0: 3,298 files, 56.5MB\n==> Installing yarn\n🍺  /usr/local/Cellar/yarn/1.22.10: 15 files, 5MB, built in 3 seconds\n==> Caveats\n==> icu4c\nicu4c is keg-only, which means it was not symlinked into /usr/local,\nbecause macOS provides libicucore.dylib (but nothing else).\n\nIf you need to have icu4c first in your PATH, run:\n  echo 'export PATH=\"/usr/local/opt/icu4c/bin:$PATH\"' >> ~/.zshrc\n  echo 'export PATH=\"/usr/local/opt/icu4c/sbin:$PATH\"' >> ~/.zshrc\n\nFor compilers to find icu4c you may need to set:\n  export LDFLAGS=\"-L/usr/local/opt/icu4c/lib\"\n  export CPPFLAGS=\"-I/usr/local/opt/icu4c/include\"\n\nFor pkg-config to find icu4c you may need to set:\n  export PKG_CONFIG_PATH=\"/usr/local/opt/icu4c/lib/pkgconfig\"\n```\n\n###(3) インストールされたか確認\n正常にインストールされていることを確認。\n\n```zsh:zsh\n% yarn -v          \n1.22.10\n```\n\n###(4) `yarn install` を実行\n[このQiita記事](https://qiita.com/NaokiIshimura/items/8203f74f8dfd5f6b87a0 \"Rails6 開発時につまづきそうな webpacker, yarn 関係のエラーと解決方法\")によると、\n> `yarn install` を実行して、package.json にリスト化されている全ての依存関係を node_modules 内にインストールする。\n\nことが必要なようだ。\n今の私の知識では意味が理解できていないが、とりあえず実行しておく。\n\n```zsh:zsh\n% yarn install\nyarn install v1.22.10\ninfo No lockfile found.\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\n✨  Done in 1.30s.\n```\n\n##8. webpacker のインストール (3回目)\n3回目にしてようやくインストール完了。\n\n```zsh:zsh\n% rails webpacker:install\n```\n\n<details>\n<summary>結果はここから確認</summary>\n<div>\n\n```zsh:結果\n      create  config/webpacker.yml\nCopying webpack core config\n      create  config/webpack\n      create  config/webpack/development.js\n      create  config/webpack/environment.js\n      create  config/webpack/production.js\n      create  config/webpack/test.js\nCopying postcss.config.js to app root directory\n      create  postcss.config.js\nCopying babel.config.js to app root directory\n      create  babel.config.js\nCopying .browserslistrc to app root directory\n      create  .browserslistrc\nThe JavaScript app source directory already exists\n       apply  /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/webpacker-5.2.1/lib/install/binstubs.rb\n  Copying binstubs\n       exist    bin\n      create    bin/webpack\n      create    bin/webpack-dev-server\n      append  .gitignore\nInstalling all JavaScript dependencies [5.2.1]\n         run  yarn add @rails/webpacker@5.2.1 from \".\"\nyarn add v1.22.10\n[1/4] 🔍  Resolving packages...\nwarning @rails/webpacker > node-sass > request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142\nwarning @rails/webpacker > node-sass > node-gyp > request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142\nwarning @rails/webpacker > node-sass > request > har-validator@5.1.5: this library is no longer supported\nwarning @rails/webpacker > webpack > watchpack > watchpack-chokidar2 > chokidar@2.1.8: Chokidar 2 will break on node v14+. Upgrade to chokidar 3 with 15x less dependencies.\nwarning @rails/webpacker > webpack > watchpack > watchpack-chokidar2 > chokidar > fsevents@1.2.13: fsevents 1 will break on node v14+ and could be using insecure binaries. Upgrade to fsevents 2.\nwarning @rails/webpacker > webpack > micromatch > snapdragon > source-map-resolve > resolve-url@0.2.1: https://github.com/lydell/resolve-url#deprecated\nwarning @rails/webpacker > webpack > micromatch > snapdragon > source-map-resolve > urix@0.1.0: Please see https://github.com/lydell/urix#deprecated\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\nsuccess Saved 606 new dependencies.\ninfo Direct dependencies\n└─ @rails/webpacker@5.2.1\ninfo All dependencies\n├─ @babel/code-frame@7.12.13\n├─ @babel/compat-data@7.13.8\n├─ @babel/core@7.13.8\n├─ @babel/helper-builder-binary-assignment-operator-visitor@7.12.13\n├─ @babel/helper-compilation-targets@7.13.8\n├─ @babel/helper-explode-assignable-expression@7.13.0\n├─ @babel/helper-get-function-arity@7.12.13\n├─ @babel/helper-hoist-variables@7.13.0\n├─ @babel/helper-replace-supers@7.13.0\n├─ @babel/helper-wrap-function@7.13.0\n├─ @babel/helpers@7.13.0\n├─ @babel/highlight@7.13.8\n├─ @babel/parser@7.13.9\n├─ @babel/plugin-proposal-async-generator-functions@7.13.8\n├─ @babel/plugin-proposal-class-properties@7.13.0\n├─ @babel/plugin-proposal-dynamic-import@7.13.8\n├─ @babel/plugin-proposal-export-namespace-from@7.12.13\n├─ @babel/plugin-proposal-json-strings@7.13.8\n├─ @babel/plugin-proposal-logical-assignment-operators@7.13.8\n├─ @babel/plugin-proposal-nullish-coalescing-operator@7.13.8\n├─ @babel/plugin-proposal-numeric-separator@7.12.13\n├─ @babel/plugin-proposal-object-rest-spread@7.13.8\n├─ @babel/plugin-proposal-optional-catch-binding@7.13.8\n├─ @babel/plugin-proposal-optional-chaining@7.13.8\n├─ @babel/plugin-proposal-private-methods@7.13.0\n├─ @babel/plugin-proposal-unicode-property-regex@7.12.13\n├─ @babel/plugin-syntax-class-properties@7.12.13\n├─ @babel/plugin-syntax-top-level-await@7.12.13\n├─ @babel/plugin-transform-arrow-functions@7.13.0\n├─ @babel/plugin-transform-async-to-generator@7.13.0\n├─ @babel/plugin-transform-block-scoped-functions@7.12.13\n├─ @babel/plugin-transform-block-scoping@7.12.13\n├─ @babel/plugin-transform-classes@7.13.0\n├─ @babel/plugin-transform-computed-properties@7.13.0\n├─ @babel/plugin-transform-destructuring@7.13.0\n├─ @babel/plugin-transform-dotall-regex@7.12.13\n├─ @babel/plugin-transform-duplicate-keys@7.12.13\n├─ @babel/plugin-transform-exponentiation-operator@7.12.13\n├─ @babel/plugin-transform-for-of@7.13.0\n├─ @babel/plugin-transform-function-name@7.12.13\n├─ @babel/plugin-transform-literals@7.12.13\n├─ @babel/plugin-transform-member-expression-literals@7.12.13\n├─ @babel/plugin-transform-modules-amd@7.13.0\n├─ @babel/plugin-transform-modules-commonjs@7.13.8\n├─ @babel/plugin-transform-modules-systemjs@7.13.8\n├─ @babel/plugin-transform-modules-umd@7.13.0\n├─ @babel/plugin-transform-named-capturing-groups-regex@7.12.13\n├─ @babel/plugin-transform-new-target@7.12.13\n├─ @babel/plugin-transform-object-super@7.12.13\n├─ @babel/plugin-transform-property-literals@7.12.13\n├─ @babel/plugin-transform-regenerator@7.12.13\n├─ @babel/plugin-transform-reserved-words@7.12.13\n├─ @babel/plugin-transform-runtime@7.13.9\n├─ @babel/plugin-transform-shorthand-properties@7.12.13\n├─ @babel/plugin-transform-spread@7.13.0\n├─ @babel/plugin-transform-sticky-regex@7.12.13\n├─ @babel/plugin-transform-template-literals@7.13.0\n├─ @babel/plugin-transform-typeof-symbol@7.12.13\n├─ @babel/plugin-transform-unicode-escapes@7.12.13\n├─ @babel/plugin-transform-unicode-regex@7.12.13\n├─ @babel/preset-env@7.13.9\n├─ @babel/preset-modules@0.1.4\n├─ @babel/runtime@7.13.9\n├─ @npmcli/move-file@1.1.2\n├─ @rails/webpacker@5.2.1\n├─ @types/json-schema@7.0.7\n├─ @types/node@14.14.31\n├─ @types/parse-json@4.0.0\n├─ @types/q@1.5.4\n├─ @webassemblyjs/floating-point-hex-parser@1.9.0\n├─ @webassemblyjs/helper-code-frame@1.9.0\n├─ @webassemblyjs/helper-fsm@1.9.0\n├─ @webassemblyjs/helper-wasm-section@1.9.0\n├─ @webassemblyjs/wasm-edit@1.9.0\n├─ @webassemblyjs/wasm-opt@1.9.0\n├─ @xtuc/ieee754@1.2.0\n├─ abbrev@1.1.1\n├─ acorn@6.4.2\n├─ aggregate-error@3.1.0\n├─ ajv-errors@1.0.1\n├─ ajv-keywords@3.5.2\n├─ ajv@6.12.6\n├─ amdefine@1.0.1\n├─ ansi-styles@3.2.1\n├─ anymatch@3.1.1\n├─ are-we-there-yet@1.1.5\n├─ argparse@1.0.10\n├─ arr-flatten@1.1.0\n├─ array-find-index@1.0.2\n├─ asn1.js@5.4.1\n├─ asn1@0.2.4\n├─ assert@1.5.0\n├─ assign-symbols@1.0.0\n├─ async-each@1.0.3\n├─ async-foreach@0.1.3\n├─ asynckit@0.4.0\n├─ atob@2.1.2\n├─ autoprefixer@9.8.6\n├─ aws-sign2@0.7.0\n├─ aws4@1.11.0\n├─ babel-loader@8.2.2\n├─ babel-plugin-macros@2.8.0\n├─ base@0.11.2\n├─ base64-js@1.5.1\n├─ bcrypt-pbkdf@1.0.2\n├─ binary-extensions@2.2.0\n├─ bindings@1.5.0\n├─ block-stream@0.0.9\n├─ bluebird@3.7.2\n├─ boolbase@1.0.0\n├─ brace-expansion@1.1.11\n├─ braces@2.3.2\n├─ brorand@1.1.0\n├─ browserify-aes@1.2.0\n├─ browserify-cipher@1.0.1\n├─ browserify-des@1.0.2\n├─ browserify-rsa@4.1.0\n├─ browserify-sign@4.2.1\n├─ browserify-zlib@0.2.0\n├─ buffer-xor@1.0.3\n├─ buffer@4.9.2\n├─ builtin-status-codes@3.0.0\n├─ cache-base@1.0.1\n├─ caller-callsite@2.0.0\n├─ caller-path@2.0.0\n├─ callsites@2.0.0\n├─ camelcase-keys@2.1.0\n├─ camelcase@5.3.1\n├─ caniuse-lite@1.0.30001196\n├─ case-sensitive-paths-webpack-plugin@2.4.0\n├─ caseless@0.12.0\n├─ chokidar@3.5.1\n├─ chrome-trace-event@1.0.2\n├─ class-utils@0.3.6\n├─ clean-stack@2.2.0\n├─ cliui@5.0.0\n├─ clone-deep@4.0.1\n├─ coa@2.0.2\n├─ code-point-at@1.1.0\n├─ collection-visit@1.0.0\n├─ color-convert@1.9.3\n├─ color-name@1.1.3\n├─ color-string@1.5.5\n├─ color@3.1.3\n├─ combined-stream@1.0.8\n├─ compression-webpack-plugin@4.0.1\n├─ concat-map@0.0.1\n├─ concat-stream@1.6.2\n├─ console-browserify@1.2.0\n├─ console-control-strings@1.1.0\n├─ constants-browserify@1.0.0\n├─ convert-source-map@1.7.0\n├─ copy-concurrently@1.0.5\n├─ copy-descriptor@0.1.1\n├─ core-js-compat@3.9.1\n├─ core-js@3.9.1\n├─ core-util-is@1.0.2\n├─ create-ecdh@4.0.4\n├─ create-hmac@1.1.7\n├─ cross-spawn@3.0.1\n├─ crypto-browserify@3.12.0\n├─ css-blank-pseudo@0.1.4\n├─ css-color-names@0.0.4\n├─ css-declaration-sorter@4.0.1\n├─ css-has-pseudo@0.10.0\n├─ css-loader@3.6.0\n├─ css-prefers-color-scheme@3.1.1\n├─ css-select-base-adapter@0.1.1\n├─ css-select@2.1.0\n├─ css-tree@1.0.0-alpha.37\n├─ css-what@3.4.2\n├─ cssdb@4.4.0\n├─ cssnano-preset-default@4.0.7\n├─ cssnano-util-raw-cache@4.0.1\n├─ cssnano-util-same-parent@4.0.1\n├─ cssnano@4.1.10\n├─ csso@4.2.0\n├─ currently-unhandled@0.4.1\n├─ cyclist@1.0.1\n├─ dashdash@1.14.1\n├─ debug@4.3.1\n├─ decamelize@1.2.0\n├─ decode-uri-component@0.2.0\n├─ delayed-stream@1.0.0\n├─ delegates@1.0.0\n├─ des.js@1.0.1\n├─ detect-file@1.0.0\n├─ diffie-hellman@5.0.3\n├─ dom-serializer@0.2.2\n├─ domain-browser@1.2.0\n├─ domelementtype@1.3.1\n├─ domutils@1.7.0\n├─ dot-prop@5.3.0\n├─ duplexify@3.7.1\n├─ ecc-jsbn@0.1.2\n├─ electron-to-chromium@1.3.681\n├─ emoji-regex@7.0.3\n├─ enhanced-resolve@4.5.0\n├─ entities@2.2.0\n├─ errno@0.1.8\n├─ error-ex@1.3.2\n├─ es-to-primitive@1.2.1\n├─ escalade@3.1.1\n├─ escape-string-regexp@1.0.5\n├─ eslint-scope@4.0.3\n├─ esprima@4.0.1\n├─ esrecurse@4.3.0\n├─ estraverse@4.3.0\n├─ esutils@2.0.3\n├─ events@3.3.0\n├─ expand-brackets@2.1.4\n├─ expand-tilde@2.0.2\n├─ extend@3.0.2\n├─ extglob@2.0.4\n├─ extsprintf@1.3.0\n├─ fast-deep-equal@3.1.3\n├─ fast-json-stable-stringify@2.1.0\n├─ file-loader@6.2.0\n├─ file-uri-to-path@1.0.0\n├─ fill-range@4.0.0\n├─ findup-sync@3.0.0\n├─ flatted@3.1.1\n├─ flatten@1.0.3\n├─ flush-write-stream@1.1.1\n├─ for-in@1.0.2\n├─ forever-agent@0.6.1\n├─ form-data@2.3.3\n├─ from2@2.3.0\n├─ fs.realpath@1.0.0\n├─ fsevents@2.3.2\n├─ fstream@1.0.12\n├─ gauge@2.7.4\n├─ gaze@1.1.3\n├─ gensync@1.0.0-beta.2\n├─ get-caller-file@2.0.5\n├─ get-intrinsic@1.1.1\n├─ get-value@2.0.6\n├─ getpass@0.1.7\n├─ glob-parent@5.1.1\n├─ glob@7.1.6\n├─ global-modules@2.0.0\n├─ global-prefix@3.0.0\n├─ globule@1.3.2\n├─ har-schema@2.0.0\n├─ har-validator@5.1.5\n├─ has-ansi@2.0.0\n├─ has-bigints@1.0.1\n├─ has-unicode@2.0.1\n├─ has-value@1.0.0\n├─ hash.js@1.1.7\n├─ hex-color-regex@1.1.0\n├─ hmac-drbg@1.0.1\n├─ hosted-git-info@2.8.8\n├─ hsl-regex@1.0.0\n├─ hsla-regex@1.0.0\n├─ html-comment-regex@1.1.2\n├─ http-signature@1.2.0\n├─ https-browserify@1.0.0\n├─ icss-utils@4.1.1\n├─ ieee754@1.2.1\n├─ import-cwd@2.1.0\n├─ import-fresh@2.0.0\n├─ import-from@2.1.0\n├─ import-local@2.0.0\n├─ in-publish@2.0.1\n├─ indent-string@4.0.0\n├─ infer-owner@1.0.4\n├─ inflight@1.0.6\n├─ ini@1.3.8\n├─ interpret@1.4.0\n├─ is-absolute-url@2.1.0\n├─ is-accessor-descriptor@1.0.0\n├─ is-arrayish@0.2.1\n├─ is-bigint@1.0.1\n├─ is-binary-path@2.1.0\n├─ is-boolean-object@1.1.0\n├─ is-callable@1.2.3\n├─ is-color-stop@1.1.0\n├─ is-core-module@2.2.0\n├─ is-data-descriptor@1.0.0\n├─ is-date-object@1.0.2\n├─ is-descriptor@1.0.2\n├─ is-directory@0.3.1\n├─ is-extglob@2.1.1\n├─ is-finite@1.1.0\n├─ is-glob@4.0.1\n├─ is-negative-zero@2.0.1\n├─ is-number-object@1.0.4\n├─ is-obj@2.0.0\n├─ is-plain-obj@1.1.0\n├─ is-plain-object@2.0.4\n├─ is-regex@1.1.2\n├─ is-resolvable@1.1.0\n├─ is-svg@3.0.0\n├─ is-symbol@1.0.3\n├─ is-typedarray@1.0.0\n├─ is-utf8@0.2.1\n├─ is-windows@1.0.2\n├─ is-wsl@1.1.0\n├─ isarray@1.0.0\n├─ isexe@2.0.0\n├─ isstream@0.1.2\n├─ jest-worker@26.6.2\n├─ js-base64@2.6.4\n├─ js-tokens@4.0.0\n├─ jsesc@2.5.2\n├─ json-parse-better-errors@1.0.2\n├─ json-parse-even-better-errors@2.3.1\n├─ json-schema-traverse@0.4.1\n├─ json-schema@0.2.3\n├─ json-stringify-safe@5.0.1\n├─ jsprim@1.4.1\n├─ last-call-webpack-plugin@3.0.0\n├─ lines-and-columns@1.1.6\n├─ load-json-file@1.1.0\n├─ loader-runner@2.4.0\n├─ locate-path@3.0.0\n├─ lodash.debounce@4.0.8\n├─ lodash.get@4.4.2\n├─ lodash.has@4.5.2\n├─ lodash.memoize@4.1.2\n├─ lodash.template@4.5.0\n├─ lodash.templatesettings@4.2.0\n├─ lodash.uniq@4.5.0\n├─ lodash@4.17.21\n├─ loud-rejection@1.6.0\n├─ lru-cache@6.0.0\n├─ make-dir@3.1.0\n├─ map-obj@1.0.1\n├─ map-visit@1.0.0\n├─ mdn-data@2.0.4\n├─ memory-fs@0.4.1\n├─ meow@3.7.0\n├─ merge-stream@2.0.0\n├─ micromatch@3.1.10\n├─ miller-rabin@4.0.1\n├─ mime-db@1.46.0\n├─ mime-types@2.1.29\n├─ mini-css-extract-plugin@0.9.0\n├─ minimatch@3.0.4\n├─ minimist@1.2.5\n├─ minipass-collect@1.0.2\n├─ minipass-flush@1.0.5\n├─ minipass-pipeline@1.2.4\n├─ minizlib@2.1.2\n├─ mississippi@3.0.0\n├─ mixin-deep@1.3.2\n├─ mkdirp@0.5.5\n├─ move-concurrently@1.0.1\n├─ ms@2.1.2\n├─ nan@2.14.2\n├─ nanomatch@1.2.13\n├─ neo-async@2.6.2\n├─ nice-try@1.0.5\n├─ node-gyp@3.8.0\n├─ node-libs-browser@2.2.1\n├─ node-releases@1.1.71\n├─ node-sass@4.14.1\n├─ nopt@3.0.6\n├─ normalize-package-data@2.5.0\n├─ normalize-range@0.1.2\n├─ normalize-url@1.9.1\n├─ npmlog@4.1.2\n├─ nth-check@1.0.2\n├─ num2fraction@1.2.2\n├─ number-is-nan@1.0.1\n├─ oauth-sign@0.9.0\n├─ object-copy@0.1.0\n├─ object-inspect@1.9.0\n├─ object.assign@4.1.2\n├─ object.getownpropertydescriptors@2.1.2\n├─ object.values@1.1.3\n├─ optimize-css-assets-webpack-plugin@5.0.4\n├─ os-browserify@0.3.0\n├─ os-homedir@1.0.2\n├─ os-tmpdir@1.0.2\n├─ osenv@0.1.5\n├─ p-limit@2.3.0\n├─ p-locate@3.0.0\n├─ p-map@4.0.0\n├─ p-try@2.2.0\n├─ pako@1.0.11\n├─ parallel-transform@1.2.0\n├─ parent-module@1.0.1\n├─ parse-asn1@5.1.6\n├─ parse-json@4.0.0\n├─ parse-passwd@1.0.0\n├─ pascalcase@0.1.1\n├─ path-browserify@0.0.1\n├─ path-complete-extname@1.0.0\n├─ path-dirname@1.0.2\n├─ path-exists@3.0.0\n├─ path-is-absolute@1.0.1\n├─ path-key@2.0.1\n├─ path-parse@1.0.6\n├─ path-type@4.0.0\n├─ performance-now@2.1.0\n├─ picomatch@2.2.2\n├─ pinkie@2.0.4\n├─ pnp-webpack-plugin@1.6.4\n├─ posix-character-classes@0.1.1\n├─ postcss-attribute-case-insensitive@4.0.2\n├─ postcss-calc@7.0.5\n├─ postcss-color-functional-notation@2.0.1\n├─ postcss-color-gray@5.0.0\n├─ postcss-color-hex-alpha@5.0.3\n├─ postcss-color-mod-function@3.0.3\n├─ postcss-color-rebeccapurple@4.0.1\n├─ postcss-colormin@4.0.3\n├─ postcss-convert-values@4.0.1\n├─ postcss-custom-media@7.0.8\n├─ postcss-custom-properties@8.0.11\n├─ postcss-custom-selectors@5.1.2\n├─ postcss-dir-pseudo-class@5.0.0\n├─ postcss-discard-comments@4.0.2\n├─ postcss-discard-duplicates@4.0.2\n├─ postcss-discard-empty@4.0.1\n├─ postcss-discard-overridden@4.0.1\n├─ postcss-double-position-gradients@1.0.0\n├─ postcss-env-function@2.0.2\n├─ postcss-flexbugs-fixes@4.2.1\n├─ postcss-focus-visible@4.0.0\n├─ postcss-focus-within@3.0.0\n├─ postcss-font-variant@4.0.1\n├─ postcss-gap-properties@2.0.0\n├─ postcss-image-set-function@3.0.1\n├─ postcss-import@12.0.1\n├─ postcss-initial@3.0.2\n├─ postcss-lab-function@2.0.1\n├─ postcss-load-config@2.1.2\n├─ postcss-loader@3.0.0\n├─ postcss-logical@3.0.0\n├─ postcss-media-minmax@4.0.0\n├─ postcss-merge-longhand@4.0.11\n├─ postcss-merge-rules@4.0.3\n├─ postcss-minify-font-values@4.0.2\n├─ postcss-minify-gradients@4.0.2\n├─ postcss-minify-params@4.0.2\n├─ postcss-minify-selectors@4.0.2\n├─ postcss-modules-extract-imports@2.0.0\n├─ postcss-modules-local-by-default@3.0.3\n├─ postcss-modules-scope@2.2.0\n├─ postcss-modules-values@3.0.0\n├─ postcss-nesting@7.0.1\n├─ postcss-normalize-charset@4.0.1\n├─ postcss-normalize-display-values@4.0.2\n├─ postcss-normalize-positions@4.0.2\n├─ postcss-normalize-repeat-style@4.0.2\n├─ postcss-normalize-string@4.0.2\n├─ postcss-normalize-timing-functions@4.0.2\n├─ postcss-normalize-unicode@4.0.1\n├─ postcss-normalize-url@4.0.1\n├─ postcss-normalize-whitespace@4.0.2\n├─ postcss-ordered-values@4.1.2\n├─ postcss-overflow-shorthand@2.0.0\n├─ postcss-page-break@2.0.0\n├─ postcss-place@4.0.1\n├─ postcss-preset-env@6.7.0\n├─ postcss-pseudo-class-any-link@6.0.0\n├─ postcss-reduce-initial@4.0.3\n├─ postcss-reduce-transforms@4.0.2\n├─ postcss-replace-overflow-wrap@3.0.0\n├─ postcss-safe-parser@4.0.2\n├─ postcss-selector-matches@4.0.0\n├─ postcss-selector-not@4.0.1\n├─ postcss-svgo@4.0.2\n├─ postcss-unique-selectors@4.0.1\n├─ prepend-http@1.0.4\n├─ process-nextick-args@2.0.1\n├─ process@0.11.10\n├─ prr@1.0.1\n├─ pseudomap@1.0.2\n├─ psl@1.8.0\n├─ public-encrypt@4.0.3\n├─ pump@3.0.0\n├─ pumpify@1.5.1\n├─ punycode@2.1.1\n├─ q@1.5.1\n├─ qs@6.5.2\n├─ query-string@4.3.4\n├─ querystring-es3@0.2.1\n├─ querystring@0.2.0\n├─ randomfill@1.0.4\n├─ read-cache@1.0.0\n├─ read-pkg-up@1.0.1\n├─ read-pkg@1.1.0\n├─ readable-stream@2.3.7\n├─ readdirp@3.5.0\n├─ redent@1.0.0\n├─ regenerate-unicode-properties@8.2.0\n├─ regenerator-runtime@0.13.7\n├─ regenerator-transform@0.14.5\n├─ regexpu-core@4.7.1\n├─ regjsgen@0.5.2\n├─ regjsparser@0.6.7\n├─ remove-trailing-separator@1.1.0\n├─ repeat-element@1.1.3\n├─ repeating@2.0.1\n├─ request@2.88.2\n├─ require-directory@2.1.1\n├─ require-main-filename@2.0.0\n├─ resolve-cwd@2.0.0\n├─ resolve-dir@1.0.1\n├─ resolve-url@0.2.1\n├─ resolve@1.20.0\n├─ ret@0.1.15\n├─ rgb-regex@1.0.1\n├─ rgba-regex@1.0.0\n├─ run-queue@1.0.3\n├─ sass-graph@2.2.5\n├─ sass-loader@8.0.2\n├─ sax@1.2.4\n├─ scss-tokenizer@0.2.3\n├─ semver@6.3.0\n├─ set-blocking@2.0.0\n├─ set-value@2.0.1\n├─ setimmediate@1.0.5\n├─ shallow-clone@3.0.1\n├─ shebang-command@1.2.0\n├─ shebang-regex@1.0.0\n├─ simple-swizzle@0.2.2\n├─ snapdragon-node@2.1.1\n├─ snapdragon-util@3.0.1\n├─ sort-keys@1.1.2\n├─ source-list-map@2.0.1\n├─ source-map-resolve@0.5.3\n├─ source-map-support@0.5.19\n├─ source-map-url@0.4.1\n├─ spdx-correct@3.1.1\n├─ spdx-exceptions@2.3.0\n├─ split-string@3.1.0\n├─ sprintf-js@1.0.3\n├─ sshpk@1.16.1\n├─ ssri@8.0.1\n├─ stable@0.1.8\n├─ static-extend@0.1.2\n├─ stdout-stream@1.4.1\n├─ stream-browserify@2.0.2\n├─ stream-each@1.2.3\n├─ stream-http@2.8.3\n├─ strict-uri-encode@1.1.0\n├─ string_decoder@1.3.0\n├─ string.prototype.trimend@1.0.4\n├─ string.prototype.trimstart@1.0.4\n├─ strip-bom@2.0.0\n├─ strip-indent@1.0.1\n├─ style-loader@1.3.0\n├─ stylehacks@4.0.3\n├─ svgo@1.3.2\n├─ tar@6.1.0\n├─ terser-webpack-plugin@4.2.3\n├─ terser@5.6.0\n├─ through2@2.0.5\n├─ timers-browserify@2.0.12\n├─ timsort@0.3.0\n├─ to-arraybuffer@1.0.1\n├─ to-fast-properties@2.0.0\n├─ to-object-path@0.3.0\n├─ to-regex-range@2.1.1\n├─ tough-cookie@2.5.0\n├─ trim-newlines@1.0.0\n├─ true-case-path@1.0.3\n├─ ts-pnp@1.2.0\n├─ tslib@1.14.1\n├─ tty-browserify@0.0.0\n├─ tunnel-agent@0.6.0\n├─ tweetnacl@0.14.5\n├─ typedarray@0.0.6\n├─ unbox-primitive@1.0.0\n├─ unicode-canonical-property-names-ecmascript@1.0.4\n├─ unicode-match-property-ecmascript@1.0.4\n├─ unicode-match-property-value-ecmascript@1.2.0\n├─ unicode-property-aliases-ecmascript@1.1.0\n├─ union-value@1.0.1\n├─ unique-slug@2.0.2\n├─ unquote@1.1.1\n├─ unset-value@1.0.0\n├─ upath@1.2.0\n├─ uri-js@4.4.1\n├─ urix@0.1.0\n├─ url@0.11.0\n├─ use@3.1.1\n├─ util-deprecate@1.0.2\n├─ util.promisify@1.0.1\n├─ util@0.11.1\n├─ uuid@3.4.0\n├─ v8-compile-cache@2.3.0\n├─ validate-npm-package-license@3.0.4\n├─ vendors@1.0.4\n├─ verror@1.10.0\n├─ vm-browserify@1.1.2\n├─ watchpack-chokidar2@2.0.1\n├─ watchpack@1.7.5\n├─ webpack-assets-manifest@3.1.1\n├─ webpack-cli@3.3.12\n├─ webpack@4.46.0\n├─ which-boxed-primitive@1.0.2\n├─ which-module@2.0.0\n├─ which@1.3.1\n├─ wide-align@1.1.3\n├─ worker-farm@1.7.0\n├─ wrap-ansi@5.1.0\n├─ xtend@4.0.2\n├─ yaml@1.10.0\n├─ yargs-parser@13.1.2\n└─ yocto-queue@0.1.0\n✨  Done in 21.85s.\nInstalling dev server for live reloading\n         run  yarn add --dev webpack-dev-server from \".\"\nyarn add v1.22.10\n[1/4] 🔍  Resolving packages...\n[2/4] 🚚  Fetching packages...\n[3/4] 🔗  Linking dependencies...\nwarning \"webpack-dev-server > webpack-dev-middleware@3.7.3\" has unmet peer dependency \"webpack@^4.0.0 || ^5.0.0\".\nwarning \" > webpack-dev-server@3.11.2\" has unmet peer dependency \"webpack@^4.0.0 || ^5.0.0\".\n[4/4] 🔨  Building fresh packages...\nsuccess Saved lockfile.\nsuccess Saved 102 new dependencies.\ninfo Direct dependencies\n└─ webpack-dev-server@3.11.2\ninfo All dependencies\n├─ @types/glob@7.1.3\n├─ @types/minimatch@3.0.3\n├─ accepts@1.3.7\n├─ ansi-colors@3.2.4\n├─ ansi-html@0.0.7\n├─ array-flatten@1.1.1\n├─ array-union@1.0.2\n├─ array-uniq@1.0.3\n├─ async-limiter@1.0.1\n├─ async@2.6.3\n├─ batch@0.6.1\n├─ body-parser@1.19.0\n├─ bonjour@3.5.0\n├─ buffer-indexof@1.1.1\n├─ compressible@2.0.18\n├─ compression@1.7.4\n├─ connect-history-api-fallback@1.6.0\n├─ content-disposition@0.5.3\n├─ cookie-signature@1.0.6\n├─ cookie@0.4.0\n├─ deep-equal@1.1.1\n├─ default-gateway@4.2.0\n├─ del@4.1.1\n├─ destroy@1.0.4\n├─ detect-node@2.0.4\n├─ dns-equal@1.0.0\n├─ dns-packet@1.3.1\n├─ dns-txt@2.0.2\n├─ ee-first@1.1.1\n├─ eventemitter3@4.0.7\n├─ eventsource@1.0.7\n├─ execa@1.0.0\n├─ express@4.17.1\n├─ finalhandler@1.1.2\n├─ follow-redirects@1.13.3\n├─ forwarded@0.1.2\n├─ get-stream@4.1.0\n├─ globby@6.1.0\n├─ handle-thing@2.0.1\n├─ hpack.js@2.1.6\n├─ html-entities@1.4.0\n├─ http-deceiver@1.2.7\n├─ http-parser-js@0.5.3\n├─ http-proxy-middleware@0.19.1\n├─ http-proxy@1.18.1\n├─ internal-ip@4.3.0\n├─ ip-regex@2.1.0\n├─ ip@1.1.5\n├─ ipaddr.js@1.9.1\n├─ is-absolute-url@3.0.3\n├─ is-arguments@1.1.0\n├─ is-path-cwd@2.2.0\n├─ is-path-in-cwd@2.1.0\n├─ is-path-inside@2.1.0\n├─ is-stream@1.1.0\n├─ json3@3.3.3\n├─ killable@1.0.1\n├─ loglevel@1.7.1\n├─ media-typer@0.3.0\n├─ merge-descriptors@1.0.1\n├─ methods@1.1.2\n├─ mime@2.5.2\n├─ multicast-dns-service-types@1.1.0\n├─ multicast-dns@6.2.3\n├─ negotiator@0.6.2\n├─ node-forge@0.10.0\n├─ npm-run-path@2.0.2\n├─ object-is@1.1.5\n├─ obuf@1.1.2\n├─ on-headers@1.0.2\n├─ opn@5.5.0\n├─ original@1.0.2\n├─ p-finally@1.0.0\n├─ p-retry@3.0.1\n├─ path-is-inside@1.0.2\n├─ path-to-regexp@0.1.7\n├─ portfinder@1.0.28\n├─ proxy-addr@2.0.6\n├─ querystringify@2.2.0\n├─ raw-body@2.4.0\n├─ regexp.prototype.flags@1.3.1\n├─ retry@0.12.0\n├─ select-hose@2.0.0\n├─ selfsigned@1.10.8\n├─ serve-index@1.9.1\n├─ serve-static@1.14.1\n├─ sockjs-client@1.5.0\n├─ sockjs@0.3.21\n├─ spdy-transport@3.0.0\n├─ spdy@4.0.2\n├─ strip-eof@1.0.0\n├─ thunky@1.1.0\n├─ type-is@1.6.18\n├─ unpipe@1.0.0\n├─ url-parse@1.5.1\n├─ utils-merge@1.0.1\n├─ wbuf@1.7.3\n├─ webpack-dev-middleware@3.7.3\n├─ webpack-dev-server@3.11.2\n├─ websocket-driver@0.7.4\n├─ websocket-extensions@0.1.4\n└─ ws@6.2.1\n✨  Done in 10.22s.\nWebpacker successfully installed 🎉 🍰\n```\n</div>\n</details>\n\n##9. railsサーバーの起動 (2回目)\n問題なく起動。ようやく完了。。お疲れ様。\n\n```zsh:zsh\n% rails s\n=> Booting Puma\n=> Rails 6.1.3 application starting in development \n=> Run `bin/rails server --help` for more startup options\nPuma starting in single mode...\n* Puma version: 5.2.2 (ruby 2.7.2-p137) (\"Fettisdagsbulle\")\n*  Min threads: 5\n*  Max threads: 5\n*  Environment: development\n*          PID: 93566\n* Listening on http://127.0.0.1:3000\n* Listening on http://[::1]:3000\nUse Ctrl-C to stop\nStarted GET \"/\" for ::1 at 2021-03-06 10:44:39 +0900\n   (2.7ms)  SELECT sqlite_version(*)\nProcessing by Rails::WelcomeController#index as HTML\n  Rendering /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/templates/rails/welcome/index.html.erb\n  Rendered /Users/username/.rbenv/versions/2.7.2/lib/ruby/gems/2.7.0/gems/railties-6.1.3/lib/rails/templates/rails/welcome/index.html.erb (Duration: 6.9ms | Allocations: 445)\nCompleted 200 OK in 33ms (Views: 20.0ms | ActiveRecord: 0.0ms | Allocations: 3882)\n\n\n^C- Gracefully stopping, waiting for requests to finish\n=== puma shutdown: 2021-03-06 10:45:03 +0900 ===\n- Goodbye!\nExiting\n```\n\nと思いきや、DBが sqlite のまま。明日以降対応する。\n","user":"yu17","created_at":"2021-03-29T02:42:35+09:00","updated_at":"2021-03-29T02:58:15+09:00"},{"url":"https://qiita.com/s_t_maru/items/72669a44060b886fd870","title":"Rubyとは","body":"##Rubyとは\nプログラミング言語の一種です。\n作者がまつもとひろゆきさんという日本人であることもあり、\n日本語のドキュメントが豊富で、プログラミングを学んだことのない方でも比較的学びやすい\n言語といえます。\n\n##Rubyのメリット\nRubyはインタプリタ型言語です。コードはコンピューターが理解できるように翻訳した後実行されますが、\nインタプリタ型言語はコードを一つずつ随時翻訳してくれます。（コンパイル型言語は実行前に全てを翻訳して実行します）\nインタープリタ方式であるRubyはコードを手軽に実行し確認することができます。\nRubyはオブジェクト指向な言語であり、あらゆるものがオブジェクトとして扱われ\n開発効率が良いと定評があります。\nまたRubyは他の言語に比べ記述量が少なく、初学者にも学びやすい言語です。\n\n##Rubyのデメリット\nRubyはインタプリタ型言語の為、コンパイル型言語に比べると実行速度が遅くなってしまいます。\nまた記述の自由度が高く、ある機能に対して様々記述ができる為、記述者のレベルによって\n記述の仕方に差が出てしまいます。\n\n##まとめ\nRubyは日本人が作った言語であり、比較的学習ハードルの低い言語だと思います。\nデメリットはあるものの、WebサイトやWebアプリなど様々な開発に利用でき、\n利用者の多いメジャーな言語でもあるので、プログラミング初心者が学ぶ最初の言語に適していると思います。\n","user":"s_t_maru","created_at":"2021-03-29T02:30:33+09:00","updated_at":"2021-03-29T02:30:33+09:00"},{"url":"https://qiita.com/t13801206/items/cf61c5e62ade2f2e12ed","title":"ネットワークプログラミングをしてみたい","body":"# Software Designネットワークプログラミング\n\ntwitterでSoftware Design3月号が話題になっていた。\nオブジェクト指向の特集だった。\n\nそのオブジェクト指向特集とは別で、**Rustをつかったネットワークプログラミング**の記事があった。\nこの記事を書いているのは「電気ひつじ (teru0x1) · Twitter」様です。\n電子書籍も出版されているようで、つまりは**神クラスの御仁**です。\n\n![gihyo00.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/272511/8d340724-ace0-06e3-43f5-425a95e0548c.png)\n\n登大遊氏がメディアに多く出演していて、ネットワークプログラミングのスバラシさについて説いているのを見ると\nネットワークプログラミングの触りくらいは体験してみたくなる。\n\nというわけで、この記事では**Software Designのネットワークプログラミングの記事をなぞらえてみる**ことをします。\nネットワークプログラミングの記事は連載記事であり、1月号から始まったらしい。\n\n※私の使っているPCはWindows 10です。\n\n## 参考にした記事\n\nいつもお世話になっております。\n\n- [Rustのお勉強 - Dockerで環境構築](https://qiita.com/toully/items/1b652bec2048eefd3130)\n\n## Software Design1月号のサンプルコードをダウンロードする\n\nサンプルコードをダウンロードする権利は、雑誌を購入した人にしかないのだろうか。\nおもむろに技術評論社のサポートページで「ネットワークプログラミグ」を検索してみる。\n\n![gihyo01.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/272511/ae683517-9450-0975-13ca-ffb550dcd1dd.png)\n\n\n検索結果の一覧に2021年1月号のリンクが出現するので、おもむろにクリックする。\nその先にサンプルコードのダウンロードリンクのようなものがあったような、なかったような・・・。\n\n![gihyo02.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/272511/5401b0fc-5720-5bbb-e5ea-80729b734d06.png)\n\n## Dcoker Desktopをインストールする\n\nネットワークプログラミングは**Rust**を使って実行する。\n新しいプログラミング環境をさくっと実行するには、**Docker**という技術が便利らしい。\n\nまずはDockerの環境をつくる。\n\n[Docker Desktopダウンロードサイト](https://www.docker.com/products/docker-desktop)\n\nダウンロードしたら動作確認をかねてバージョンを表示する。\n以後、Rustの操作も含めすべてPowerShell上で完結する。\n\n``` PowerShell\n> docker --version\nDocker version 20.10.2, build 2291f61\n```\n\n### イメージをプルする\n\nDockerが何者かよくわかっていませんが・・・\nGoogle検索の上位のリンクをたどっていけば、わからなくてもなんとかなるものです。\n\n「rust docker」で検索し、[docker hub](https://hub.docker.com/_/rust)に行きます。\n`docker pull rust`をせよ、と書いてあるので従います。\n\n![rust-dockerhub.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/272511/367e08e5-eb12-1d53-7576-efbb5174f149.png)\n\n``` PowerShell\n# docker pull rustする前\n# イメージが何もない。\n> docker images\nREPOSITORY   TAG       IMAGE ID   CREATED   SIZE\n\n# イメージをプルする\n# 完了するまでに3分くらいかかりました\n> docker pull rust\nUsing default tag: latest\nlatest: Pulling from library/rust\n8bf9c589d5f9: Pull complete\n4c70e46d8b5f: Pull complete\nea848ad42f0d: Pull complete\n48fe137f8d26: Pull complete\n4b13f6ed9b0c: Pull complete\n8a08deff2c33: Pull complete\nDigest: sha256:e57a7b85bcbabb5bebbbd8e900e21fbdd014408347c37fc789485469f6bd7595\nStatus: Downloaded newer image for rust:latest\ndocker.io/library/rust:latest\n\n# docker pull rustした後\n# イメージ一覧にrustが追加されました\n> docker images\nREPOSITORY   TAG       IMAGE ID       CREATED        SIZE\nrust         latest    68fa8c8b027f   20 hours ago   1.25GB\n\n```\n\n## Dockerコンテナーの中でRustを体験する\n\nコンテナーの意味もよくわかりませんが、中に入れるそうです。\n\nCドライブ直下に`workspace`フォルダーを作成しておきます。\nコンテナーの中のあちら側の世界と、ふだんエクスプローラーで開いているこちら側の世界を行き来するためのフォルダーです。\nあちら側とこちら側の共有フォルダーであると認識しています。\n\nあちら側とこちら側で思い出しましたが。シャーマンキングが4月から放送されるようです。懐かしいです。\n\n## コンテナーの中に入る\n\n参考サイトによると、書きコマンドを打つとコンテナーに入れるようです。\n`docker run -itv /C/workspace:/workspace --name rust-env rust`\n\n名前が`rust-env`という`rust`イメージのコンテナーを`run`しているようです。\n`run`するだけで中に入れるのか、`-itv`あたりの何かが入らせてくれているのか、不明です。あとで勉強します。\n\n### あちら側の世界で作業をする\n\nあちら側（コンテナーの中）で作業ディレクトリに移動し、そこでさらに新しいフォルダーを`new`します。\n\n``` PowerShell\n> cd workspace\n# この時点でworkspace内はからっぽ\n\n> cargo new echo-server\n> cargo new echo-client\n# workspace内にふたつのフォルダーが生成されています\n# >/workspace# ls\n# echo-client  echo-server\n```\n\n`cargo new`の操作をすると「Created binary (application) `echo-server` package」という文字列とともに、新しいフォルダーが生成されます。\n\nさらにそのフォルダーの中に`src`フォルダーと`Cargo.toml`ファイルがあります。\n`src`の中には`main.rs`が入っています。\n\nデフォルトのmain.rsの中身\n``` rust\nfn main() {\n    println!(\"Hello, world!\");\n}\n```\n\n### こちら側の世界で作業をする\n\n自動生成された`main.rs`と`Cargo.toml`をサンプルコードの中身で置き換えます。\nCドライブ直下につくった`workspace`フォルダーの中にある`main.rs`ファイル2つと、`Cargo.toml`ファイルを書き換えます。\n\nコンテナーの中で`cat echo-client/src/main.rs`を打って、`main.rs`の中身が書き変わったことを確認します。\n\n（結果はここには書きません。なにか悪いことのような気がするので・・・）\n\n## いざ、通信させてみる\n\nサーバーとクライアントの両方をつかうので、プロセスがふたつ必要です。\nプロセスをふたつ・・・？\nよくわかりませんが、面倒なのでDocker Desktopさんの力を借ります\n\nCLIを2回クリックして窓をふたつ用意します。\n片方がサーバー役、もう片方がクライアント役です。\n\n![docker-cli.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/272511/f79bb45e-713f-5b26-fb43-2b844690e883.png)\n\n\n先にサーバー役の窓（左）で`cargo run`をしてサーバーを起動します。\n次にクライアント役の窓（右）で同じく`cargo run`、つづけて`Hello`を打ちエンター、つづけて`World`を打ちエンターしました。\n\n結果、左のサーバーへメッセージが2回分けて届いたことがわかります。\nまた、クライアント側にもサーバーへ送ったメッセージがそのまま返された結果、同じ文字列が2重で表示されています（上は自分の送信、下はサーバーからの受信）\n\n![cli-connection.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/272511/cd6d1c9c-6319-0f5f-d612-15e77f30cdcd.png)\n\n\n## つづきは本書で\n\n本書ではこの先で、意図的にパケットロスを引き起こしたときの挙動をWiresharkを使って監視したりします。\n\n残念ながらdockerコンテナーの中でグラフィカルなWiresharkを動かく術を知らないので\nこの記事はここまでです。\n","user":"t13801206","created_at":"2021-03-29T02:21:06+09:00","updated_at":"2021-03-29T02:21:06+09:00"},{"url":"https://qiita.com/takuya-ohno/items/ae0d6991adc75063b2e5","title":"【備忘録】telnetとssh違い","body":"#違い\n+ telnet\n通信内容が暗号化されない\n\n+ ssh\n通信内容が暗号化される\n\n\n#用語の意味\n+ telnet\nネットワークを経由して他のコンピュータ（主にサーバ）に接続し、遠隔操作するための仕組み\n\n+ ssh\nネットワークを経由して他のコンピュータ（主にサーバ）に接続し、遠隔操作するための仕組み。通信途中の情報は全部暗号化される。\n\n\n# 参考サイト\nhttps://wa3.i-3-i.info/diff30telnet.html\n","user":"takuya-ohno","created_at":"2021-03-29T02:20:07+09:00","updated_at":"2021-03-29T02:20:07+09:00"},{"url":"https://qiita.com/cony0413/items/1f90b95bb9ebde22a218","title":"パスからidを取得したい","body":"#背景\ndreddでapiテストを作成している。\nテストデータを作成するときに使用するidを取得したい。\nそのためにパスからidを取得する。\n\n#環境\nPHP 7.3.22\n\n#末尾のidを取得する\n\n```\n$path = '/users/30';\n$id = intval(basename($path));\n\nvar_dump($id);\n```\n\n結果\n\n```\nint(30)\n```\n\nやっていること\nbasenaemでパスの末尾の文字列を取得する\nintvalで整数型に変換する\n\n#idがパスの途中にある場合\nidが末尾になるようにパスから末尾の文字列をトリムすればいい\n\n```\n$path = '/users/30/admin';\n$id = intval(basename(rtrim($path, '/admin')));\n\nvar_dump($id);\n```\n\n結果\n\n\n```\nint(30)\n```\n\n#ちょっと沼ったのでメモ\nbasename()の第２引数にsuffixを指定できる。\nこれを指定することで、指定した文字列を除いて末尾の文字列を取得できる。\n参考\nhttps://www.php.net/manual/ja/function.basename.php\n\nそこで最初は以下のようにしていた\n\n```\n$path = '/users/30/admin';\n$id = intval(basename($path, '/admin'));\n\nvar_dump($id);\n```\n\nその結果は以下のようになった。\n\n```\nint(0)\n```\n\n###問題点\n* basenameのsuffixは'/'で区切った最末尾の文字列（'admin'）から'/admin'がその末尾にあれば、除くことになるので、この場合'admin'がbasenameした結果になる\n* intvalは失敗するとint(0)を返す\n\nその結果、idが0のテストデータを作成していたため、テスト結果がエラーも出さず望んだ結果にならずに沼ってしまった。\n","user":"cony0413","created_at":"2021-03-29T02:17:36+09:00","updated_at":"2021-03-29T02:17:36+09:00"},{"url":"https://qiita.com/hibohiboo/items/4e5fd8c723e0f70c12b1","title":"lambda + typescript + s3のリファクタリングをしてテストケースを書いたメモ","body":"## 概要\n[前回はS3をローカルで立ち上げた。](https://qiita.com/hibohiboo/items/e81573744466343aec2c)\n今回は、[ローカル環境でLambda+S3のテストをする](https://qiita.com/billthelizard/items/22d2457f3d6386d21796)を参考に、リファクタリングをしてテストを行う。\n\n[ソースコード](https://github.com/hibohiboo/develop/tree/481815420c60a0933e51483ded6ed53d1da64c03/tutorial/lesson/aws/typescript/projects/cdk_sample)\n\n## 構造\n\n```\nsrc\n  - lambda\n    - handlers\n      - s3-sample.ts\n    - service\n      - s3-sample.ts\ntest\n  - fixture\n    - s3\n      - message.txt\n  - lambda\n    - service\n      - s3-sample.test.ts\n```\n\n## ソース\n\n* 処理をgeteS3Objectに移し、インスタンスを作って渡すようにする。\n\n```ts:src/lambda/hendler/s3-sample.ts\nimport { S3 } from 'aws-sdk';\nimport { Handler } from 'aws-lambda';\nimport { getS3Object } from '../service/s3-sample';\n\nconst s3 = new S3();\nconst { S3_BUCKET } = process.env;\nif (!S3_BUCKET) throw Error('env S3_BUCKET is empy')\n\nexport const lambdaHandler: Handler = async (event, context, callback) => {\n  try {\n    const message = getS3Object({ s3, key: event.Key, bucket: S3_BUCKET, callback });\n    console.log(message)\n  } catch (err) {\n    console.log(err);\n    return err;\n  }\n};\n```\n\n* getS3Objectでは、使用するインスタンスは外部から受け取る。DI。\n\n```ts:src/lambda/service/s3-sample.ts\nimport type { S3 } from 'aws-sdk';\nimport { Callback } from 'aws-lambda';\ninterface Payload {\n  s3: S3\n  key: string\n  bucket: string\n  callback: Callback\n}\nexport const getS3Object: (o: Payload) => Promise<string> = async ({ s3, bucket, key, callback }) => {\n  const params = {\n    Bucket: bucket,\n    Key: key\n  };\n  const ret = await s3.getObject(params).promise();\n  if (!ret.Body) throw Error(`s3 object is empty. Bucket: ${bucket}, Key: ${key}`)\n  const message = ret.Body.toString();\n  console.log(message);\n  callback(null, `access ${key}`)\n  return message;\n}\n```\n\n* テストではs3オブジェクトを作成して渡してやる。\n\n```ts:test/lambda/service/s3-sample.test.ts\nimport * as fs from 'fs';\nimport * as path from 'path';\nimport { S3 } from 'aws-sdk';\nimport { getS3Object } from '@/lambda/service/s3-sample';\n// localstack\nconst config = {\n  endpoint: 'http://localhost:4566',\n  s3ForcePathStyle: true,\n};\n\nconst s3 = new S3(config);\n\n/*\n * test suits\n */\ndescribe('core/getS3Object test suit #1', () => {\n  // shared variables over the test suit\n  let bucket: string;\n  let key: string;\n  const callback = () => { }\n\n  /*\n   * starup\n  */\n  beforeEach(async () => {\n    // generate test resource sequence code from timestamp\n    const now = new Date().getTime();\n    bucket = `test-bucket-${now}`;\n    key = `message_${now}.txt`;\n    // create bucket & bucket key\n    await s3.createBucket({ Bucket: bucket }).promise();\n    await s3.putObject({\n      Bucket: bucket,\n      Key: key,\n      ContentType: 'text/plain',\n      Body: fs.readFileSync(path.join(__dirname, '..', '..', 'fixture', 's3', 'message.txt')),\n    }).promise();\n  });\n\n  /*\n   * test cases\n  */\n  it('successfully get an object from S3 bucket', async () => {\n    const message = await getS3Object({ s3, bucket, key, callback });\n    expect(message).toBe('Hi, there.\\n');\n  });\n\n  it('throw error if access to non-existent key', async () => {\n    try {\n      await getS3Object({ s3, bucket, key: 'non-existent', callback })\n      fail()\n    } catch (error) {\n      expect(error.name).toBe('NoSuchKey');\n      expect(error.message).toBe('The specified key does not exist.');\n    }\n  });\n\n  it('throw error if access to non-existent bucket', async () => {\n    try {\n      await getS3Object({ s3, bucket: 'non-existent', key: 'non-existent', callback })\n      fail()\n    } catch (error) {\n      expect(error.name).toBe('NoSuchBucket');\n      expect(error.message).toBe('The specified bucket does not exist');\n    }\n\n  });\n\n  /*\n   * tear-down\n   */\n  afterEach(async () => {\n    // delete bucket key & bucket\n    await s3.deleteObject({\n      Bucket: bucket,\n      Key: key,\n    }).promise();\n    await s3.deleteBucket({ Bucket: bucket }).promise();\n  });\n});\n```\n\n\n\n\n## 参考\n[Testable - lambda : 和田卓人](https://speakerdeck.com/twada/testable-lambda-working-effectively-with-legacy-lambda)\n[ローカル環境でLambda+S3のテストをする](https://qiita.com/billthelizard/items/22d2457f3d6386d21796)\n[github aws-sam-localstack-example](https://github.com/bilzard/aws-sam-localstack-example)\n[DI・DIコンテナ、ちゃんと理解出来てる・・？](https://qiita.com/ritukiii/items/de30b2d944109521298f)\n","user":"hibohiboo","created_at":"2021-03-29T02:10:47+09:00","updated_at":"2021-03-29T02:10:47+09:00"},{"url":"https://qiita.com/Sam/items/a1b92e38148688b2fe92","title":"Golang 入門 #1","body":"## <font color=\"#7fd5ea\">Golangとは</font>\n\n[公式ドキュメント](https://golang.org/doc/) に書いてあることをまとめると、Golangとは...\n\n* オープンソース\n* シンプルな言語仕様\n* 並行プログラミングに強い\n* コンパイル型言語\n* コンパイルや実行が速い\n\n2021年3月の時点でGolangの最新バージョンは [1.16](https://golang.org/doc/go1.16)\nGo1.16 は、macOS 10.12 Sierraで実行される最後のリリースになっており、Go1.17 ではmacOS 10.13 HighSierra以降が必要になる。\n\n## <font color=\"#7fd5ea\">Goの需要</font>\n\nまず国内におけるGoの需要はどうだろうか\nTECH Street（テックストリート）によるアンケートの調査結果は次の通り\nGoは国内における需要は増えているという話は聞きますが、Perlと同じ15位にランクイン\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/33505/a5e36ab8-5a43-f675-0515-dc54311cc8d4.png\" width=50%>\n引用元） [ITエンジニアが 2021年に学びたい（強化したい）プログラミング言語ランキング](https://www.tech-street.jp/entry/research-2021programminglang)\n\nでは国外、ワールドワイドでのGoの需要はどうだろうか\nPYPLの2021年3月時点での去年と比較したランキングは次の通り\n去年から伸びてなくね？\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/33505/9457deef-128c-2499-957e-a9d6a4a533da.png\" width=50%>\n引用元） [PYPL PopularitY of Programming Language](https://pypl.github.io/PYPL.html)\n\nGo大丈夫なのか\n　：\n　：\n安心してください\n同じくPYPLが公表している人気言語ランキングでは、ついにRubyとも逆転し、他の言語が下がる中Goは確実に伸びていることがわかります。\n![chart.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/33505/da71f463-cad5-2336-da83-6f8f776349a1.png)\n\nこれで安心して、Goを勉強できますね！\n\n## <font color=\"#7fd5ea\">最初に手をつけたところ</font>\n\nどの言語にも言えますが、まずは言語の特徴を知るところから始めます。\n\n### <font color=\"#008cff\">はじめてのGo</font>\nhttps://gihyo.jp/dev/feature/01/go_4beginners\n\n技術評論社の開発者向けGo特集の記事、Go1.3にフォーカスしているので少し古いですが基本となる学習に関しては問題ありません。\n各章では次の内容がソースコード付きでわかりやすく説明されています。\n\n* 第１章では「Go言語の特徴と環境構築」について\n* 第２章では、Goの特徴である「シンプルな言語仕様や型システム」について\n* 第３章では「構造体やインターフェース」について\n* 第４章では、標準パッケージで「JSON、ファイル、HTTP、HTML」を扱う\n* 第５章では、スレッド「ゴルーチン（Goroutine）」、並行実行されるごルーチン間でデータのやり取りをおこなう「チャネル（channel）」について\n\n### <font color=\"#008cff\">A Tour of Go</font>\nhttps://go-tour-jp.appspot.com/list\n\n[A Tour of Go](https://tour.golang.org/list)を日本語訳したものです。変数の宣言方法や関数の呼び出し方、基本となる言語構造から、メソッドやインターフェース、Goの特徴である「ゴルーチン（Goroutine）」と「チャネル（channel）」について学ぶことができます。\nただし、丁寧に書かれているわけではないので、初学者向けではなかったのかもしれません。\n\n### <font color=\"#008cff\">Go Web プログラミング</font>\nhttps://astaxie.gitbooks.io/build-web-application-with-golang/content/ja/\n\nGo言語の基礎 〜 Webアプリケーションに対する実装例をコードを添えて解説してくれています。またセキュリティから暗号化など幅広く、もしGoでWebアプリケーションを開発することを考えているなら、このサイトは見ておくべきです。\n\n## <font color=\"#7fd5ea\">シンプルな言語仕様や型システム</font>\n\nGoは次が基本となっています\n\n* セミコロンなし\n* try-catchがサポートされていない\n\n### <font color=\"#008cff\">変数</font>\n\nGoは変数を `var` で定義します\n\n```go\n// Goでは型を変数の後に置きます。ここでは string型の text という変数を宣言しています。\nvar text string\n\n// 複数の変数も定義できます。\nvar text1, text2 string\n```\n\n変数の初期化は次の通りです\n\n```go\n// 宣言した型の後に初期化します\nvar text string = \"message\"\n\n// 複数の変数を同時に初期化できます\nvar text1, text2 string = \"message1\", \"message2\"\n```\n\nGoでは短縮宣言 `:=` も用意されています\n\n```go\n// := の記号は var と 型 に変わるものです。\ntext1, text2 := \"message1\", \"message2\"\n```\n\nただし短縮宣言は関数の内部でしか使用できません。関数の外から使おうとするとコンパイルが通らなくなります。そのため、一般的には `var` をグローバル変数として定義します。\n\n### <font color=\"#008cff\">定数</font>\n\nいわゆる定数、オワリ\n\n```go\n// 他の言語と似たような宣言方法\nconst name = \"keyword\"\n\n// 型を明示できます\nconst name string = \"keyword\"\n```\n\n### <font color=\"#008cff\">型</font>\n\n#### Boolean型\n\n```go\n// デフォルトは false\nvar isBool = true\n```\n\n#### 整数型と小数型\n\n```go\n// 整数、Goは int 以外にも uint もサポートしています。\nvar x int = 1\n\n// 小数、float型はないです、float32とfloat64の二種類で、デフォルトはfloat64\nvar y float64 = 1.234\n```\n\n#### 文字列型\n\n```go\n// Goの文字列はすべてUTF-8\nvar text = \"message\"\n\n// バッククォートを使うと\\rや\\nなど、改行コードを含めることが出来ます\nvar text = `message`\n```\n\n#### エラー型\n\n```go\n// 他の言語でいうと Exception に近いですかね\nerr := errors.New(\"エラー\")\n```\n\n#### グループ化\n\n```go\n// 複数の型違いの変数を同時に定義\nvar (\n  c int\n  d string\n)\n\n// 定数も同じくグループ化できます\nconst(\n    i  := 100\n    pi := 3.1415\n)\n```\n\n#### 配列型\n\n```go\n// int型の配列\nvar arr [10]int\n\n// 要素は 0 からスタート\narr[0] = 1\narr[1] = 2\n\n// 初期化も宣言できます\na := [3]int{1, 2, 3}\n```\n\n#### スライス型\n\n`slice`はいわゆる「動的な配列」で、参照型のデータになります。\n\n```go\n// arrayの宣言と同じだが、長さの宣言は不要\nvar slice []int\n\n// 初期化\nslice := []int {1, 2, 3}\n```\n\n#### マップ型\n\n```go\n// keyは文字列(string)、valueは整数(int)\nvar numbers map[string]int\nnumbers[\"one\"] = 1\nnumbers[\"two\"] = 2\n\n// 初期化することもできます\nnumbers := map[string]int{\"one\":1, \"two\":2}\n```\n\n#### ポインタ型\n\n```go\na := 5\n\n// int型を格納する領域を準備\nvar pa *int\n// ポインタの割り当て\npa = &a\n```\n\n","user":"Sam","created_at":"2021-03-29T02:09:38+09:00","updated_at":"2021-03-29T10:24:04+09:00"},{"url":"https://qiita.com/ochimusha01/items/fd8e51940b5e0e1a28c5","title":"【Python演算処理】単位円筒(Unit Cylinder)の描画","body":"これまでの投稿内容から浮かび上がってきた**単位円筒**(Unit Cylinder)の概念についてまとめておきたいと思います。\n\n#加法整数群(<font color=blue>Additive Integer Group</font>)\n[【初心者向け】群論概念(Group Theory Concept)①基本定義](https://qiita.com/ochimusha01/items/208dc0e68db64805e4f7)\n\n```math\nZ_n(n=-\\infty→-1→0→1→+\\infty)\\\\=(-\\infty,…,-3,-2,-1,0,1,2,3,…,+\\infty)\n```\n**群論**(Group Theory)における基本中の基本。\n\n##自然数集合(<font color=blue>Natulal Set</font>)の準備\n\nまず元(Element) として**自然数集合**(Natulal Set)、すなわち**初項**(First Term)$α=1$,**公差**(Common Difference)$d=1$,**一般項**(General Term)$α+(n-1)d$の**等差数列**(Arithmetic Sequence=算術数列)を準備する。\n\n```math\nN_n(n=1→\\infty)\\\\\n=(1+(1-1)×1=1,1+(2-1)×1=2,1+(3-1)×1=3,…,1+(\\infty-1)×1=\\infty)\\\\\n=(1,2,3,…,Inf(inity))\n```\nこれは以下の様に再帰的に考えても良い。\n\n```math\nN_n(n=1→\\infty)\\\\\n=(1,1+1=2,(1+1)+1=3,…,\\infty+1=\\infty)\\\\\n=(1,2,3,…,Inf(inity))\n```\nどちらの場合も範囲に**加法単位元**(Additive Identity)0を加えても添字範囲が拡張されるだけで**演算の連続性**(Operation Continuity)そのものは維持され(結合法則((Associative Law))の成立)、**演算結果**(Operation Result)も閉じている(整数以外の数が登場する余地がない)。\n![image.gif](https://cdn-ak.f.st-hatena.com/images/fotolife/o/ochimusha01/20210329/20210329060015.gif)\n\n```python\n%matplotlib nbagg\nimport math as m\nimport cmath as c\nimport numpy as num\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.animation as animation\n\n#円柱データ作成\nc0=num.linspace(0,m.pi*120,1201,endpoint = True)\ns0=[]\nfor nm in range(len(c0)):\n    s0.append(complex(m.cos(c0[nm]),m.sin(c0[nm])))\ns1=num.array(s0)\nz0=num.linspace(0,2,1201,endpoint = True)\n\n#単位円データ作成\nu0=num.linspace(0,m.pi*2,61,endpoint = True)\nu1=[]\nfor nm in range(len(u0)):\n    u1.append(complex(m.cos(u0[nm]),m.sin(u0[nm])))\nuc=num.array(u1)\nuz0=num.repeat(0,61)\nuz1=num.repeat(1,61)\nuz2=num.repeat(2,61)\n\n#グラフ表示\nplt.style.use('default')\nfig = plt.figure()\nax = Axes3D(fig)\n\n#関数定義\ndef unit_cylinder(n):\n    plt.cla()\n    #円柱描画\n    ax.plot(s1.real,s1.imag,z0,color=\"gray\",lw=0.5)\n    #スポーク描画\n    #for num in range(len(uc)):\n    #    ax.plot([0,uc[num].real],[0,uc[num].imag],[0,0],color=\"gray\",lw=0.5)\n    #for num in range(len(uc)):\n    #    ax.plot([0,uc[num].real],[0,uc[num].imag],[1,1],color=\"gray\",lw=0.5)\n    for num in range(len(uc)):\n        ax.plot([0,uc[num].real],[0,uc[num].imag],[0,0],color=\"olivedrab\",lw=0.5)\n    #単位円描画\n    ax.plot(uc.real,uc.imag,uz0,color=\"green\",lw=1)\n    ax.plot(uc.real,uc.imag,uz1,color=\"blue\",lw=1)\n    ax.plot(uc.real,uc.imag,uz2,color=\"blue\",lw=1)\n    #実数線追加\n    ax.plot([1,1],[0,0],[0,2],color=\"blue\",lw=1)\n    ax.plot([0,1],[0,0],[0,0],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[1,1],color=\"blue\",lw=1)\n    ax.plot([0,1],[0,0],[2,2],color=\"blue\",lw=1)\n    ax.plot([0,0],[0,0],[0,2],color=\"black\",lw=1)\n    #諸元追加\n    ax.set_ylim([-1.1,1.1])\n    ax.set_xlim([-1.1,1.1])\n    ax.set_zlim([0.1,2.1])\n    ax.set_title(\"Unit Cylinder\")\n    ax.set_xlabel(\"Real\")\n    ax.set_ylabel(\"Imaginal\")\n    ax.set_zlabel(\"Cycle\")\n    # グラフを回転\n    ax.view_init(elev=45, azim=Time_code[n])\n\nTime_code=num.arange(0,360,6)    \n#unit_cylinder(len(s1))\n#plt.show()\n\nani = animation.FuncAnimation(fig, unit_cylinder, interval=50,frames=len(Time_code))\nani.save(\"output322.gif\", writer=\"pillow\")\n```\n##逆元(<font color=blue>Inverse Element</font>)の準備\n\n上掲の**拡張自然数集合**(?)$N_n(n=0→\\infty)(0,1,2,3,…,\\infty)$について**逆元**(Inverse Element)$-N_n(n=-\\infty→0)=(-\\infty,…,-3,-2,-1,0)$を準備する。この場合も「**結合法則成立による演算の連続性の担保**」は成立し、**演算結果**も閉じている。\n![image.gif](https://cdn-ak.f.st-hatena.com/images/fotolife/o/ochimusha01/20210329/20210329060809.gif)\n\n```python\n%matplotlib nbagg\nimport math as m\nimport cmath as c\nimport numpy as num\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.animation as animation\n\n#円柱データ作成\nc0=num.linspace(0,m.pi*120,1201,endpoint = True)\ns0=[]\nfor nm in range(len(c0)):\n    s0.append(complex(m.cos(c0[nm]),m.sin(c0[nm])))\ns1=num.array(s0)\nz0=num.linspace(-2,0,1201,endpoint = True)\n\n#単位円データ作成\nu0=num.linspace(0,m.pi*2,61,endpoint = True)\nu1=[]\nfor nm in range(len(u0)):\n    u1.append(complex(m.cos(u0[nm]),m.sin(u0[nm])))\nuc=num.array(u1)\nuz0=num.repeat(-2,61)\nuz1=num.repeat(-1,61)\nuz2=num.repeat(0,61)\n\n#グラフ表示\nplt.style.use('default')\nfig = plt.figure()\nax = Axes3D(fig)\n\n#関数定義\ndef unit_cylinder(n):\n    plt.cla()\n    #円柱描画\n    ax.plot(s1.real,s1.imag,z0,color=\"gray\",lw=0.5)\n    #スポーク描画\n    #for num in range(len(uc)):\n    #    ax.plot([0,uc[num].real],[0,uc[num].imag],[0,0],color=\"gray\",lw=0.5)\n    #for num in range(len(uc)):\n    #    ax.plot([0,uc[num].real],[0,uc[num].imag],[1,1],color=\"gray\",lw=0.5)\n    for num in range(len(uc)):\n        ax.plot([0,uc[num].real],[0,uc[num].imag],[0,0],color=\"olivedrab\",lw=0.5)\n    #単位円描画\n    ax.plot(uc.real,uc.imag,uz0,color=\"red\",lw=1)\n    ax.plot(uc.real,uc.imag,uz1,color=\"red\",lw=1)\n    ax.plot(uc.real,uc.imag,uz2,color=\"green\",lw=1)\n    #実数線追加\n    ax.plot([0,0],[0,0],[-2,0],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[-0,0],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[-1,-1],color=\"red\",lw=1)\n    ax.plot([0,1],[0,0],[-2,-2],color=\"red\",lw=1)\n    ax.plot([1,1],[0,0],[-2,0],color=\"red\",lw=1)\n    #諸元追加\n    ax.set_ylim([-1.1,1.1])\n    ax.set_xlim([-1.1,1.1])\n    ax.set_zlim([-2.1,0.1])\n    ax.set_title(\"Unit Cylinder\")\n    ax.set_xlabel(\"Real\")\n    ax.set_ylabel(\"Imaginal\")\n    ax.set_zlabel(\"Cycle\")\n    # グラフを回転\n    ax.view_init(elev=45, azim=Time_code[n])\n\nTime_code=num.arange(0,360,6)    \n#unit_cylinder(len(s1))\n#plt.show()\n\nani = animation.FuncAnimation(fig, unit_cylinder, interval=50,frames=len(Time_code))\nani.save(\"output323.gif\", writer=\"pillow\")\n```\n#元と逆元の合成\n\n上掲二つの**演算結果集合**(Operation Result Set)を一つの集合に**射影**(Projection)した**積**(Product)が**加法整数群**となる。この場合も「**結合法則成立による演算の連続性の担保**」は成立し、**演算結果**も閉じている。\n![image.gif](https://cdn-ak.f.st-hatena.com/images/fotolife/o/ochimusha01/20210329/20210329061524.gif)\n\n```python\n%matplotlib nbagg\nimport math as m\nimport cmath as c\nimport numpy as num\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.animation as animation\n\n#円柱データ作成\nc0=num.linspace(0,m.pi*120,1201,endpoint = True)\ns0=[]\nfor nm in range(len(c0)):\n    s0.append(complex(m.cos(c0[nm]),m.sin(c0[nm])))\ns1=num.array(s0)\nz0=num.linspace(-1,1,1201,endpoint = True)\n\n#単位円データ作成\nu0=num.linspace(0,m.pi*2,61,endpoint = True)\nu1=[]\nfor nm in range(len(u0)):\n    u1.append(complex(m.cos(u0[nm]),m.sin(u0[nm])))\nuc=num.array(u1)\nuz0=num.repeat(-1,61)\nuz1=num.repeat(-0,61)\nuz2=num.repeat(1,61)\n\n#グラフ表示\nplt.style.use('default')\nfig = plt.figure()\nax = Axes3D(fig)\n\n#関数定義\ndef unit_cylinder(n):\n    plt.cla()\n    #円柱描画\n    ax.plot(s1.real,s1.imag,z0,color=\"gray\",lw=0.5)\n    #スポーク描画\n    #for num in range(len(uc)):\n    #    ax.plot([0,uc[num].real],[0,uc[num].imag],[0,0],color=\"gray\",lw=0.5)\n    #for num in range(len(uc)):\n    #    ax.plot([0,uc[num].real],[0,uc[num].imag],[1,1],color=\"gray\",lw=0.5)\n    for num in range(len(uc)):\n        ax.plot([0,uc[num].real],[0,uc[num].imag],[0,0],color=\"olivedrab\",lw=0.5)\n    #単位円描画\n    ax.plot(uc.real,uc.imag,uz0,color=\"red\",lw=1)\n    ax.plot(uc.real,uc.imag,uz1,color=\"green\",lw=1)\n    ax.plot(uc.real,uc.imag,uz2,color=\"blue\",lw=1)\n    #実数線追加\n    ax.plot([0,0],[0,0],[-1,1],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[-1,-1],color=\"red\",lw=1)\n    ax.plot([0,1],[0,0],[0,0],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[1,1],color=\"blue\",lw=1)\n    ax.plot([1,1],[0,0],[-1,0],color=\"red\",lw=1)\n    ax.plot([1,1],[0,0],[0,1],color=\"blue\",lw=1)\n    #諸元追加\n    ax.set_ylim([-1.1,1.1])\n    ax.set_xlim([-1.1,1.1])\n    ax.set_zlim([-1.1,1.1])\n    ax.set_title(\"Unit Cylinder\")\n    ax.set_xlabel(\"Real\")\n    ax.set_ylabel(\"Imaginal\")\n    ax.set_zlabel(\"Cycle\")\n    # グラフを回転\n    ax.view_init(elev=45, azim=Time_code[n])\n\nTime_code=num.arange(0,360,6)    \n#unit_cylinder(len(s1))\n#plt.show()\n\nani = animation.FuncAnimation(fig, unit_cylinder, interval=50,frames=len(Time_code))\nani.save(\"output324.gif\", writer=\"pillow\")\n```\n#偶数群(<font color=blue>Even Group</font>)と奇数群(<font color=blue>Odd Group</font>)\nここにいわゆる「**ピッチ問題**」が加わってくる訳です。\n\n##ピッチ1の場合の増減\n以下の無限級数に対応。ここでは仮に**ラップ級数**(Rap Series)と呼ぶ。**加法整数群**の増減幅を1に定める案外重要な**演算**(Opreation)。\n\n```math\n1^n(n=-\\infty→+\\infty)=(1,…,1,1,1,…,1)\n```\n![image.gif](https://cdn-ak.f.st-hatena.com/images/fotolife/o/ochimusha01/20210329/20210329065821.gif)\n\n```python\n%matplotlib nbagg\nimport math as m\nimport cmath as c\nimport numpy as num\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.animation as animation\n\n#円柱データ作成\nc0=num.linspace(0,m.pi*4,121,endpoint = True)\ns0=[]\nfor nm in range(len(c0)):\n    s0.append(complex(m.cos(c0[nm]),m.sin(c0[nm])))\ns1=num.array(s0)\nz0=num.linspace(-1,1,121,endpoint = True)\n\n#単位円データ作成\nu0=num.linspace(0,m.pi*2,61,endpoint = True)\nu1=[]\nfor nm in range(len(u0)):\n    u1.append(complex(m.cos(u0[nm]),m.sin(u0[nm])))\nuc=num.array(u1)\nuz0=num.repeat(-1,61)\nuz1=num.repeat(-0,61)\nuz2=num.repeat(1,61)\n\n#グラフ表示\nplt.style.use('default')\nfig = plt.figure()\nax = Axes3D(fig)\n\n#関数定義\ndef unit_cylinder(n):\n    plt.cla()\n    #円柱描画\n    ax.plot(s1.real,s1.imag,z0,color=\"black\",lw=0.5)\n    #スポーク描画\n    for nm in range(len(s1)):\n        ax.plot([0,s1[nm].real],[0,s1[nm].imag],z0[nm],color=\"gray\",lw=0.5)\n    #単位円描画\n    ax.plot(uc.real,uc.imag,uz0,color=\"red\",lw=1)\n    ax.plot(uc.real,uc.imag,uz1,color=\"green\",lw=1)\n    ax.plot(uc.real,uc.imag,uz2,color=\"blue\",lw=1)\n    #実数線追加\n    ax.plot([0,0],[0,0],[-1,1],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[-1,-1],color=\"red\",lw=1)\n    ax.plot([0,1],[0,0],[0,0],color=\"green\",lw=1)\n    ax.plot([0,1],[0,0],[1,1],color=\"blue\",lw=1)\n    ax.plot([1,1],[0,0],[-1,0],color=\"red\",lw=1)\n    ax.plot([1,1],[0,0],[0,1],color=\"blue\",lw=1)\n    #諸元追加\n    ax.set_ylim([-1.1,1.1])\n    ax.set_xlim([-1.1,1.1])\n    ax.set_zlim([-1.1,1.1])\n    ax.set_title(\"Unit Cylinder\")\n    ax.set_xlabel(\"Real\")\n    ax.set_ylabel(\"Imaginal\")\n    ax.set_zlabel(\"Cycle\")\n    # グラフを回転\n    ax.view_init(elev=10, azim=Time_code[n])\n\nTime_code=num.arange(0,360,6)    \n#unit_cylinder(len(s1))\n#plt.show()\n\nani = animation.FuncAnimation(fig, unit_cylinder, interval=50,frames=len(Time_code))\nani.save(\"output327.gif\", writer=\"pillow\")\n```\nその水平位置からの観測結果(cos波/sin波の検出)\n![image.gif](https://cdn-ak.f.st-hatena.com/images/fotolife/o/ochimusha01/20210329/20210329071623.gif)\n\n```python\n%matplotlib nbagg\nimport math as m\nimport cmath as c\nimport numpy as num\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.animation as animation\n\n#円柱データ作成\nc0=num.linspace(0,m.pi*4,121,endpoint = True)\ns0=[]\nfor nm in range(len(c0)):\n    s0.append(complex(m.cos(c0[nm]),m.sin(c0[nm])))\ns1=num.array(s0)\nz0=num.linspace(-1,1,121,endpoint = True)\n\n#単位円データ作成\nu0=num.linspace(0,m.pi*2,61,endpoint = True)\nu1=[]\nfor nm in range(len(u0)):\n    u1.append(complex(m.cos(u0[nm]),m.sin(u0[nm])))\nuc=num.array(u1)\nuz0=num.repeat(-1,61)\nuz1=num.repeat(-0,61)\nuz2=num.repeat(1,61)\n\n#グラフ表示\nplt.style.use('default')\nfig = plt.figure()\nax = Axes3D(fig)\n\n#関数定義\ndef unit_cylinder(n):\n    plt.cla()\n    #円柱描画\n    ax.plot(s1.real,s1.imag,z0,color=\"black\",lw=0.5)\n    #スポーク描画\n    for nm in range(len(s1)):\n        ax.plot([0,s1[nm].real],[0,s1[nm].imag],z0[nm],color=\"gray\",lw=0.5)\n    #単位円描画\n    ax.plot(uc.real,uc.imag,uz0,color=\"red\",lw=1)\n    ax.plot(uc.real,uc.imag,uz1,color=\"green\",lw=1)\n    ax.plot(uc.real,uc.imag,uz2,color=\"blue\",lw=1)\n    #実数線追加\n    ax.plot([0,0],[0,0],[-1,1],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[-1,-1],color=\"red\",lw=1)\n    ax.plot([0,1],[0,0],[0,0],color=\"green\",lw=1)\n    ax.plot([0,1],[0,0],[1,1],color=\"blue\",lw=1)\n    ax.plot([1,1],[0,0],[-1,0],color=\"red\",lw=1)\n    ax.plot([1,1],[0,0],[0,1],color=\"blue\",lw=1)\n    #諸元追加\n    ax.set_ylim([-1.1,1.1])\n    ax.set_xlim([-1.1,1.1])\n    ax.set_zlim([-1.1,1.1])\n    ax.set_title(\"Unit Cylinder\")\n    ax.set_xlabel(\"Real\")\n    ax.set_ylabel(\"Imaginal\")\n    ax.set_zlabel(\"Cycle\")\n    # グラフを回転\n    ax.view_init(elev=0, azim=Time_code[n])\n\nTime_code=num.arange(0,360,6)    \n#unit_cylinder(len(s1))\n#plt.show()\n\nani = animation.FuncAnimation(fig, unit_cylinder, interval=50,frames=len(Time_code))\nani.save(\"output328.gif\", writer=\"pillow\")\n```\n一見単純極まりない数理に見えるが、ここから突如として**ガンマ関数**(Γ Function)の概念が派生するから要注意。\n[【Python演算処理】階乗と順列と組み合わせ](https://qiita.com/ochimusha01/items/90d9ef0a224bdd604721)\n[【Python演算処理】「N次球概念導入による円/球関係の数理の統合」？](https://qiita.com/ochimusha01/items/f7c9077eccfdbd0dd47a)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/597772/dd2a94ec-dfc7-2a91-e9fc-613bc4dcf639.png)\n\n##ピッチ1/2の場合の増減\n**交代級数**(Alternating Series)概念に対応。\n\n```math\n-1^n(n=-\\infty→+\\infty)=(-1,…,1,-1,1,…,-1)\n```\n[【数理考古学】解析学史に「虚数概念」をもたらした交代級数](https://qiita.com/ochimusha01/items/a338ea75855fcb4ff6f8)\n\n![image.gif](https://cdn-ak.f.st-hatena.com/images/fotolife/o/ochimusha01/20210329/20210329072441.gif)\n\n```python\n%matplotlib nbagg\nimport math as m\nimport cmath as c\nimport numpy as num\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.animation as animation\n\n#円柱データ作成\nc0=num.linspace(0,m.pi*2,121,endpoint = True)\ns0=[]\nfor nm in range(len(c0)):\n    s0.append(complex(m.cos(c0[nm]),m.sin(c0[nm])))\ns1=num.array(s0)\nz0=num.linspace(-1,1,121,endpoint = True)\n\n#単位円データ作成\nu0=num.linspace(0,m.pi*2,61,endpoint = True)\nu1=[]\nfor nm in range(len(u0)):\n    u1.append(complex(m.cos(u0[nm]),m.sin(u0[nm])))\nuc=num.array(u1)\nuz0=num.repeat(-1,61)\nuz1=num.repeat(-0,61)\nuz2=num.repeat(1,61)\n\n#グラフ表示\nplt.style.use('default')\nfig = plt.figure()\nax = Axes3D(fig)\n\n#関数定義\ndef unit_cylinder(n):\n    plt.cla()\n    #円柱描画\n    ax.plot(s1.real,s1.imag,z0,color=\"black\",lw=0.5)\n    #スポーク描画\n    for nm in range(len(s1)):\n        ax.plot([0,s1[nm].real],[0,s1[nm].imag],z0[nm],color=\"gray\",lw=0.5)\n    #単位円描画\n    ax.plot(uc.real,uc.imag,uz0,color=\"red\",lw=1)\n    ax.plot(uc.real,uc.imag,uz1,color=\"green\",lw=1)\n    ax.plot(uc.real,uc.imag,uz2,color=\"blue\",lw=1)\n    #実数線追加\n    ax.plot([0,0],[0,0],[-1,1],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[-1,-1],color=\"red\",lw=1)\n    ax.plot([0,-1],[0,0],[0,0],color=\"green\",lw=1)\n    ax.plot([0,1],[0,0],[1,1],color=\"blue\",lw=1)\n    ax.plot([1,1],[0,0],[-1,0],color=\"red\",lw=1)\n    ax.plot([1,1],[0,0],[0,1],color=\"blue\",lw=1)\n    #諸元追加\n    ax.set_ylim([-1.1,1.1])\n    ax.set_xlim([-1.1,1.1])\n    ax.set_zlim([-1.1,1.1])\n    ax.set_title(\"Unit Cylinder\")\n    ax.set_xlabel(\"Real\")\n    ax.set_ylabel(\"Imaginal\")\n    ax.set_zlabel(\"Cycle\")\n    # グラフを回転\n    ax.view_init(elev=10, azim=Time_code[n])\n\nTime_code=num.arange(0,360,6)    \n#unit_cylinder(len(s1))\n#plt.show()\n\nani = animation.FuncAnimation(fig, unit_cylinder, interval=50,frames=len(Time_code))\nani.save(\"output329.gif\", writer=\"pillow\")\n```\nその水平位置からの観測(cos波/sin波の検出)\n![image.gif](https://cdn-ak.f.st-hatena.com/images/fotolife/o/ochimusha01/20210329/20210329073245.gif)\n\n```python\n%matplotlib nbagg\nimport math as m\nimport cmath as c\nimport numpy as num\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.animation as animation\n\n#円柱データ作成\nc0=num.linspace(0,m.pi*2,121,endpoint = True)\ns0=[]\nfor nm in range(len(c0)):\n    s0.append(complex(m.cos(c0[nm]),m.sin(c0[nm])))\ns1=num.array(s0)\nz0=num.linspace(-1,1,121,endpoint = True)\n\n#単位円データ作成\nu0=num.linspace(0,m.pi*2,61,endpoint = True)\nu1=[]\nfor nm in range(len(u0)):\n    u1.append(complex(m.cos(u0[nm]),m.sin(u0[nm])))\nuc=num.array(u1)\nuz0=num.repeat(-1,61)\nuz1=num.repeat(-0,61)\nuz2=num.repeat(1,61)\n\n#グラフ表示\nplt.style.use('default')\nfig = plt.figure()\nax = Axes3D(fig)\n\n#関数定義\ndef unit_cylinder(n):\n    plt.cla()\n    #円柱描画\n    ax.plot(s1.real,s1.imag,z0,color=\"black\",lw=0.5)\n    #スポーク描画\n    for nm in range(len(s1)):\n        ax.plot([0,s1[nm].real],[0,s1[nm].imag],z0[nm],color=\"gray\",lw=0.5)\n    #単位円描画\n    ax.plot(uc.real,uc.imag,uz0,color=\"red\",lw=1)\n    ax.plot(uc.real,uc.imag,uz1,color=\"green\",lw=1)\n    ax.plot(uc.real,uc.imag,uz2,color=\"blue\",lw=1)\n    #実数線追加\n    ax.plot([0,0],[0,0],[-1,1],color=\"black\",lw=1)\n    ax.plot([0,1],[0,0],[-1,-1],color=\"red\",lw=1)\n    ax.plot([0,-1],[0,0],[0,0],color=\"green\",lw=1)\n    ax.plot([0,1],[0,0],[1,1],color=\"blue\",lw=1)\n    ax.plot([1,1],[0,0],[-1,0],color=\"red\",lw=1)\n    ax.plot([1,1],[0,0],[0,1],color=\"blue\",lw=1)\n    #諸元追加\n    ax.set_ylim([-1.1,1.1])\n    ax.set_xlim([-1.1,1.1])\n    ax.set_zlim([-1.1,1.1])\n    ax.set_title(\"Unit Cylinder\")\n    ax.set_xlabel(\"Real\")\n    ax.set_ylabel(\"Imaginal\")\n    ax.set_zlabel(\"Cycle\")\n    # グラフを回転\n    ax.view_init(elev=0, azim=Time_code[n])\n\nTime_code=num.arange(0,360,6)    \n#unit_cylinder(len(s1))\n#plt.show()\n\nani = animation.FuncAnimation(fig, unit_cylinder, interval=50,frames=len(Time_code))\nani.save(\"output330.gif\", writer=\"pillow\")\n```\n数年がかりで試行錯誤しながら理解を進めてきましたが、全体像を俯瞰するとたったこれだけの事なんですね。以降も逐次追記していきます。\n\n\n","user":"ochimusha01","created_at":"2021-03-29T02:06:01+09:00","updated_at":"2021-03-29T08:12:10+09:00"},{"url":"https://qiita.com/kan_itani/items/aed646221e66fb1ff8e6","title":"オンプレデータをクラウドに階層化するONTAP FabricPoolカンタンCLI設定ガイド","body":"\n#雑談\nNetApp ONTAPの階層化機能であるFabricPoolを検証する際に、コピペで簡単に設定できるようにCLIをまとめます。\nFabricPoolの技術的な詳細は、「3. 関連情報」をご確認ください。\nProxyを経由したFabricPool設定は少しややこしいので、別記事で紹介予定です。\n\n#目次\n1. FabricPoolの前提条件\n2. 設定手順\n    2.1. 時刻同期\n2.2．ONTAPのhosts/DNS設定\n2.3. 名前解決の確認と疎通確認\n2.4. FabricPool設定\n2.5. 簡易性能テスト\n2.6. 各種運用コマンド\n\n3. 関連情報\n\n#1. FabricPoolの前提条件\n- NetAppストレージの対応機種\n    - FAS2600シリーズ、FAS2700シリーズ\n    - FAS8000シリーズ\n　(FAS8040/FAS8060/FAS8080/FAS8200/FAS8300/FAS8700/FAS9000)\n    - AFFシリーズ\n　(C190/A200/A220/A250/A300/A400/A700/A800/AFF8040/AFF8060/AFF8080)\n**※FAS25xxシリーズとFAS/AFF8020はCPUコア数の関係で非対応**\n\n- ONTAPバージョン\n    - ONTAP9.2以上\n\n- オブジェクトストレージの設定\n    - 階層化先のバケットを手動で作成済であること。\n    - FAS/AFFシリーズからPUT/GET等を受けられること。  \n**※AWS S3はONTAP OSにAccess KeyとSecret Access Keyを設定するので、以下の権限を付けること。**  \n　\"s3:ListAllMyBuckets\",  \n　\"s3:ListBucket\",  \n　\"s3:GetBucketLocation\",  \n　\"s3:GetObject\",  \n　\"s3:PutObject\",  \n　\"s3:DeleteObject  \n\n- 本手順でカバーしないONTAPに必要な事前設定\n    - オブジェクトストレージと通信するInterCluster LIFの作成  \n(SnapMirror用途のLIFをFabricPool用に流用可能。)\n    - FabricPoolライセンスの投入  \n評価ライセンスキーの入手は、以下の情報を添えてNetApp社の営業・SEまで依頼。  \n::> cluster identify show  \n::> system node show -node NODE_NAME　(HA構成の場合は2コントローラ分)  \n**※ 階層化先のオブジェクトストレージがStorageGRIDの場合はライセンス不要。**  \n**※ 階層化元のストレージがNetApp CVO(Cloud Volumes ONTAP)の場合は、階層化先オブジェクトストレージの種類にかかわらずライセンス不要。**\n\n#2. 設定手順  \n##2.1. 時刻同期\n\n```\n(1) タイムゾーン設定\n::> time -timezone Japan\n::> date\n\n(2) NTPサーバ指定\n::> cluster time-service ntp server show\n::> cluster time-service ntp server create -server ntp.nict.jp\n\n(3) もしくは、手動設定\n::> date –u YYYYMMDDHHMM.SS\n::> cluster date modify -u YYYYMMDDHHMM.SS\n```\n\n##2.2. ONTAPのhosts/DNS設定\nONTAPがオブジェクトストレージのFQDNを名前解決するために必要です。\n\n```\n(1) Hostsを使う場合\n::> vserver services name-service dns hosts show\n::> vserver services name-service dns hosts create -vserver <AdminSVM> -address <解決先IPアドレス> -hostname <CloudTierのFQDN>\n\n(2) DNSを使う場合\n::> vserver services name-service dns show\n::> vserver services name-service dns create -vserver <AdminSVM> -domains <任意の文字列> -name-servers <DNSサーバIP1>,<DNSサーバIP2>\n```\n\n##2.3. 名前解決の確認と疎通確認\n名前解決の確認は必須で行います。\n疎通確認は対向のオブジェクトストレージがPingに応答しないこともあるので、応答が無くても正常な場合もあります。この場合はInterCluster LIFからtracerouteで途中まで通信できているかを確認すると同時に、InterCluster LIFと同じセグメントに仮想サーバを立てて、S3ブラウザ等でPUT/GETのテストをすると確実です。\n\n```\n(1) 名前解決の確認\n::> ping -lif <InterCluster_LIF-A> –vserver <AdminSVM> -destination <CloudTierのFQDN>\n::> traceroute -lif <InterCluster_LIF-A> -vserver <AdminSVM> -destination <CloudTierのFQDN>\n\n(2) 疎通確認\n::> ping -lif <InterCluster_LIF-A> –vserver <AdminSVM> -destination <CloudTierのIPアドレス>\n::> ping -lif <InterCluster_LIF-B> –vserver <AdminSVM> -destination <CloudTierのIPアドレス>\n::> traceroute -lif <InterCluster_LIF-A> -vserver <AdminSVM> -destination <CloudTierのIPアドレス>\n::> traceroute -lif <InterCluster_LIF-B> -vserver <AdminSVM> -destination <CloudTierのIPアドレス>\n```\n\n##2.4. FabricPool設定\n実際の設定コマンドを順に記載しますが、(2)の手順で一度アグリゲートにバケットを登録すると後で解除するにはアグリゲートを壊す必要があるため、以下の(1)の操作が終わって(2)を行う前に手順の「2.5. 簡易性能テスト」を行うことをおすすめします。\n\n```\n(1) オブジェクトストレージのクラスタへの登録\n::> storage aggregate object-store config show\n::> storage aggregate object-store config create -object-store-name <CloudTier名(=任意の文字列)> -provider-type SGWS -server <オブジェクトストレージのFQDN> -is-ssl-enabled true -port 443 -container-name bucket01 -ipspace Default -use-http-proxy false -access-key <ACCESS_KEY> -secret-password <SECRET_ACCESS_KEY> -is-certificate-validation-enabled false\n\n(2) アグリゲートとオブジェクトストレージの紐づけ\n::> storage aggregate object-store attach -aggregate <アグリゲート名> -object-store-name <CloudTier名(前の手順で付けたobject-store-name)> -allow-flexgroup false\n::> storage aggregate object-store show\n\n(3) FlexVolumeの階層化をONにする設定 (これを設定しないとnone(=OFF)の状態です。)\n::> volume modify -vserver <SVM名> -volume <対象Volume名> -tiering-policy auto\n::> volume object-store tiering show    <---ONTAP9.8以降で追加されました\n```\n\nアグリゲートのFabricPool関連の各種オプションの説明は以下に記載があります。\n(ONTAP9.8マニュアル)\nhttps://docs.netapp.com/ontap-9/index.jsp?topic=%2Fcom.netapp.doc.dot-cm-cmpr-980%2Fstorage__aggregate__object-store__config__create.html\n\n-provider-typeはAWS_S3, Azure_Cloud, SGWS, IBM_COS, AliCloud, GoogleCloud, ONTAP_S3, 等を指定できますが、SGWSとONTAP_S3以外はFabricPoolライセンスを入力しないとCLIの引数の候補すら表示されません。また、S3互換ストレージ(Ceph, EMC ECS, Scality, Cloudian等)を使う場合には、ONTAP9.7では`s3_compliant`を指定しますが、ONTAP9.8でも同じか確かめていませんのでトライしてみてください。\n\nFlexVolumeのFabricPool関連の各種オプションの説明は以下です。\n(ONTAP9.8マニュアル)\nhttp://docs.netapp.com/ontap-9/topic/com.netapp.doc.dot-cm-cmpr-980/volume__modify.html\n　\n　-tiering-policy {snapshot-only|auto|none|all} \n　-cloud-retrieval-policy {default|on-read|never|promote}  <--ONTAP9.8以降\n　-tiering-minimum-cooling-days {2..183} \n　-tiering-object-tags <text>, ... \n\nこのあたりの設定を変更します。\n\n##2.5. 簡易性能テスト\n以下のコマンドを実行すると、数分かけてオブジェクトストレージにPUT/GETを繰り返します。object-store profiler showを何度か実行して、途中経過を確認してみてください。\n\n```\nSR-A200-03::*> set advanced\nSR-A200-03::*> storage aggregate object-store profiler start -object-store-name sgws_985 -node SR-A200-03-01\nSR-A200-03::*> storage aggregate object-store profiler show\nObject store config name: sgws_985\nNode name: SR-A200-03-01\nStatus: Done\nStart time: 11/19/2019 18:06:25\n\nOp      Size       Total     Failed             Latency(ms)          Throughput\n                                        min       max       avg\n-------------------------------------------------------------------------------\nPUT     4MB        1137      0         1112      7391      2677      73.98MB\nGET     4KB        35836     0         88        1398      333       3.08MB\nGET     8KB        35192     0         155       1408      753       6.00MB\nGET     32KB       30038     0         81        2123      1400      20.21MB\nGET     256KB      12173     0         347       9038      2313      65.47MB\n5 entries were displayed.\n```\n\nここでFailedが多発する、もしくはスループットが途中経路の回線速度に比べて極端に低い場合は実用に耐えられない場合があるので、実運用を始める前に原因を調査して安定してオブジェクトストレージと通信できるようにすることを推奨します。\n\n##2.6. 各種運用コマンド\n\n###Aggregateコマンド\n\n```\n::*> storage aggregate object-store show –aggregate *\n\n  (storage aggregate object-store show)\nAggregate      Object Store Name Availability   Mirror Type\n-------------- ----------------- -------------  -----------\naggr1          sgws_001          available      primary\n```\n\n```\n::> storage aggregate object-store show-space –aggregate *\n　　　　　　　　　　　　　　　　　　　　　　　　　　　　License \nAggregate    Object Store Name Provider Type Used Space Space Used% \n------------ ----------------- ------------- ---------- ------------ \naggr1        aws_bucket        AWS_S3        423.3GB    41% \n```\n\n```\n::*> node run –node <ノード名> aggr status -v\n```\n\n↑「tier_unavailable」となっていないことを確認。\n\n```\n::*> aggr show-space\n\nAggregate : aggr1\nPerformance Tier\nFeature                                          Used      Used%\n--------------------------------           ----------     ------\nVolume Footprints                              6.53TB        49%\nAggregate Metadata                                 0B         0%\nSnapshot Reserve                                   0B         0%\nTotal Used                                     5.30TB        40%\n\nTotal Physical Used                            5.24TB        39%\n\nAggregate : aggr1\nObject Store: SGWS-FabricPool\nFeature                                          Used      Used%\n--------------------------------           ----------     ------\nReferenced Capacity                            2.96TB          -\nMetadata                                           0B          -\nUnreclaimed Space                             20.08MB          -\nSpace Saved by Storage Efficiency             356.8GB          -\n\nTotal Physical Used                            2.61TB          -\n```\n\n↑ 物理的に消費しているのが2.61TB。\nPerformance Tierから参照されているデータ量は2.96TB\n＝356.8GBはPerformance Tier側で複数のブロックが参照している。\n\n###FlexVolume系のコマンド\n\n```\n::> volume object-store tiering show   <---ONTAP9.8以降\n                                                  Policy\nVserver Volume Aggregate State   %Complete  Tiering   CloudRetrieve LastStatus\n------- ------ --------- -------- --------- --------- ------------- ----------\nvs1     vol    aggr1     waiting          - snapshot-only\n                                                      default       completed\n```\n\n\n```\n::> volume show-footprint \n　Vserver : svm1\n　Volume  : volume_fabricpool_on\n　\n　Feature                                          Used    Used%\n　--------------------------------           ----------    -----\n　Volume Data Footprint                         364.9GB       2%\n　Footprint in Performance Tier                  7.01GB       2%\n　Footprint in sgws_304                         360.0GB      98%\n　Volume Guarantee                                   0B       0%\n　Flexible Volume Metadata                       2.09GB       0%\n　Deduplication                                  2.12GB       0%\n　Delayed Frees                                  2.11GB       0%\n　\n　Total Footprint                               371.2GB       2%\n```\n\n###その他コマンド\n\n```\n::*> event log show -event *object.store.full*\nTime                Node             Severity      Event\n------------------- ---------------- ------------- ---------------------------\n7/28/2019 18:01:15  cluster-01        ALERT         object.store.full: Failed to write to object store sgws_985 because it is out of space.\n```\n\n```\n::*> statistics show -object wafl_comp_aggr_bin -counter cloud_bin_operation –raw\n\nObject: wafl_comp_aggr_bin\nInstance: aggr1_bin_1\nStart-time: 11/21/2018 11:00:50\nEnd-time: 11/21/2018 11:00:50\nScope: anilt-vsim1\n \n    Counter                                                     Value\n    -------------------------------- --------------------------------\n    cloud_bin_operation                                             -\n                                 GET                            21271\n                                 PUT                              570\n                              DELETE                              274\n```\n\n\n##2.7. トラブルシュートのログ\n基本的には以下のevent log showで概要がわかりますが、\n\n```\n::> event log show –node * –message-name *\n```\n\n根が深い場合やもっとオブジェクトストレージからの応答を確認したい場合は、以下の方法でmgwd.logとsktrace.logも確認してみてください。\n\nブラウザで以下にアクセスし、クラスタ管理者でログインすると、\n　　**https://クラスタ管理IP/spi/**\nノード単位でlogs -> mlog下にログが格納されているのでそのままローカルにログファイルをダウンロードできます。\n\n\n#3. 関連情報\n＜追記中＞\nProxyを経由したFabricPool通信は少し長くなるので別記事にします。\n\n\nhttps://licensecounter.jp/engineer-voice/blog/articles/20200408_fabricpool.html\n\nhttps://licensecounter.jp/engineer-voice/blog/articles/20200423_fabricpool1.html\n\nhttps://licensecounter.jp/engineer-voice/blog/articles/20200511_fabricpool2.html\n\nhttps://licensecounter.jp/engineer-voice/blog/articles/20200601_fabricpool3.html\n\nhttps://licensecounter.jp/engineer-voice/blog/articles/20200703__azure_blob1.html\n\nhttps://licensecounter.jp/engineer-voice/blog/articles/20200708__azure_blob2.html\n\nhttps://licensecounter.jp/engineer-voice/blog/articles/20200727_azure_blobfabricpool1.html\n\n","user":"kan_itani","created_at":"2021-03-29T02:03:53+09:00","updated_at":"2021-03-29T10:32:07+09:00"},{"url":"https://qiita.com/zigenin/items/724b2d09fda1b8cce7a2","title":"FlutterでPopupMenuを表示する","body":"Flutterで以下のようなPopupMenuを表示する方法を記す。\n\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/196890/534b82c8-f674-6b2c-1079-fe6b6ba5d2a1.png\" width=\"120\" />\n↓タップ\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/196890/dd851a11-268f-004a-2185-b06a7efdb9a4.png\" width=\"120\" />\n\n\"Signed in as John Smith\"の部分はただのラベル。選択不可。\n\"Sign out\"の部分は、選択可。\n\n## 実現のポイント\n\n- Menu全体には、PoupMenuButtonを使う\n- Menuの各項目にはPopupMenuItem、罫線にはPopupMenuDividerを使う\n- PoupMenuItemにenabled=falseを指定すると、選択不可項目を作れる\n  - ただし、子Textがグレーアウトされるので、TextStyle#colorを指定する必要がある\n\n## コードサンプル\n\n```dart\nPopupMenuButton<MenuCommand>(\n    onSelected: (MenuCommand value) {},\n    // ボタンの見た目を指定。省略すると\"...\"になる。\n    child: CircleAvatar(\n        child: Icon(Icons.person),\n    ),\n    itemBuilder: (BuildContext context) => <PopupMenuEntry<MenuCommand>>[\n      PopupMenuItem(\n        enabled: false,\n        child: Column(\n          crossAxisAlignment: CrossAxisAlignment.start,\n          children: [\n            Text(\n              'Signed in as',\n              style: TextStyle(\n                color: Colors.black87,\n              ),\n            ),\n            Text(\n              'John Smith',\n              style: TextStyle(\n                fontWeight: FontWeight.bold,\n                color: Colors.black87,\n              ),\n            ),\n          ],\n        ),\n      ),\n      const PopupMenuDivider(),\n      const PopupMenuItem(\n        value: MenuCommand.signOut,\n        child: Text('Sign out'),\n      ),\n    ],\n  ),\n```\n\nMenuCommandは自分で定義したenumで、Menuの項目選択時のvalueの型に対応している。\nサンプルコードでは定義を省略している。\n\n最初に示した図のようにタイトルバーにボタンを置くなら、AppBar#actionsにPopupMenuButtonを於けばOK。\n","user":"zigenin","created_at":"2021-03-29T01:54:36+09:00","updated_at":"2021-03-29T01:56:02+09:00"},{"url":"https://qiita.com/Doshi/items/1ea1515e614ef8287096","title":"【CentOS8に最新バージョンのRedmineとGitLabを構築する】GitLab構築","body":"# GitLab構築\nこの記事では、[Official Linux package (recommended installation)][InstallCentos] をベースにして、CentOS8上に最新バージョンのGitLabを構築する。\n\n[InstallCentos]: https://about.gitlab.com/install/#centos-8\n\n| ソフトウェア | バージョン |\n|:--|:--|\n| OS | CentOS 8.3 |\n| gitlab-ee | 13.9.4-ee.0.el8 |\n\n## 関連記事\n\n[【CentOS8に最新バージョンのRedmineとGitLabを構築する】事前調査][事前調査]\n[【CentOS8に最新バージョンのRedmineとGitLabを構築する】Redmine構築][Redmine構築]\n\n[事前調査]: https://qiita.com/Doshi/items/7b69b0f12946b9de4cfe\n[Redmine構築]: https://qiita.com/Doshi/items/293442ef0ea3999010fb\n\n# １．依存パッケージのインストールと設定\n\n```\n[doshi@centos8 ~]$ sudo dnf install -y curl policycoreutils openssh-server perl\n```\n\n# ２．Omnibus GitLabパッケージのインストール\nGitLabパッケージのリポジトリへの追加。\n\n```\n[doshi@centos8 ~]$ sudo curl https://packages.gitlab.com/install/repositories/gitlab/gitlab-ee/script.rpm.sh | sudo bash\n```\nリポジトリを確認すると、`gitlab_gitlab-ee`が追加されている。\n\n```\n[doshi@centos8 ~]$ dnf repolist\nrepo id                                                             repo の名前\nappstream                                                           CentOS Linux 8 - AppStream\nbaseos                                                              CentOS Linux 8 - BaseOS\nepel                                                                Extra Packages for Enterprise Linux 8 - x86_64\nepel-modular                                                        Extra Packages for Enterprise Linux Modular 8 - x86_64\nextras                                                              CentOS Linux 8 - Extras\ngitlab_gitlab-ee                                                    gitlab_gitlab-ee\ngitlab_gitlab-ee-source                                             gitlab_gitlab-ee-source\npowertools                                                          CentOS Linux 8 - PowerTools\n```\nGitLabパッケージをインストールする。指定したURL`http://centos8-dev/gitlab`でGitLabが起動するように設定する。\n\n```\n[doshi@centos8 ~]$ sudo EXTERNAL_URL=\"http://centos8-dev/gitlab\" dnf install -y gitlab-ee\n```\nインストールに成功したら、以下が表示される。\n\n```\n\n       *.                  *.\n      ***                 ***\n     *****               *****\n    .******             *******\n    ********            ********\n   ,,,,,,,,,***********,,,,,,,,,\n  ,,,,,,,,,,,*********,,,,,,,,,,,\n  .,,,,,,,,,,,*******,,,,,,,,,,,,\n      ,,,,,,,,,*****,,,,,,,,,.\n         ,,,,,,,****,,,,,,\n            .,,,***,,,,\n                ,*,.\n\n\n\n     _______ __  __          __\n    / ____(_) /_/ /   ____ _/ /_\n   / / __/ / __/ /   / __ `/ __ \\\n  / /_/ / / /_/ /___/ /_/ / /_/ /\n  \\____/_/\\__/_____/\\__,_/_.___/\n\n\nThank you for installing GitLab!\n```\n\n# ３．nginxのポート番号変更\n\nApacheが80番ポートで起動しているため、nginxは8081番ポートで起動させる。\n\n`/etc/gitlab/gitlab.rb`を開く。\n\n```\n[doshi@centos8 ~]$ sudo vi /etc/gitlab/gitlab.rb\n```\nlisten_portに8081を設定する。\n\n```:/etc/gitlab/gitlab.rb\nnginx['listen_port'] = 8081\n```\nGitLabの再構成を実行する。\n\n```\n[doshi@centos8 ~]$ sudo gitlab-ctl reconfigure\n```\n\n\n\n# ４．Apacheのリバースプロキシ設定\nApahceへの80番ポートでのアクセス`http://centos8-dev/gitlab/`を、nginxへの8081番ポートでのアクセス`http://localhost:8081/gitlab/`にプロキシする。\n\n`/etc/httpd/conf.d/gitlab.conf`を開く。\n\n```\n[doshi@centos8 ~]$ sudo vi /etc/httpd/conf.d/gitlab.conf\n```\n以下を設定する。\n\n```:/etc/httpd/conf.d/gitlab.conf\n<Location /gitlab>\n ProxyPass http://localhost:8081/gitlab\n ProxyPassReverse http://localhost:8081/gitlab\n</Location>\n<Location /assets>\n ProxyPass http://localhost:8081/assets\n ProxyPassReverse http://localhost:8081/assets\n</Location>\n```\nApacheを再起動する。\n\n```\n[doshi@centos8 ~]$ sudo systemctl restart httpd.service\n```\n\n\n# ５．運用\n\n## Redmineのログローテーション\n[logrotate][logrotate] のとおり、デフォルトでログローテートの設定がされている。\n[logrotate]: https://docs.gitlab.com/omnibus/settings/logs.html#logrotate\n\n## Omnibus GitLabのバックアップとリストア\n\n[Backup and restore Omnibus GitLab configuration][backups] を参考にする。\n\n[backups]: https://docs.gitlab.com/omnibus/settings/backups.html\n\n## アップグレード\n\n[Update GitLab installed with the Omnibus GitLab package][update] を参考にする。\n[update]: https://docs.gitlab.com/omnibus/update/README.html\n\n\n## ディレクトリ\nデータの蓄積するディレクトリは以下のとおり。\n\n| ディレクトリ | 用途 |\n|:--|:--|\n| /var/opt/gitlab/ | GitLabのデータが配置されるディレクトリ |\n\n# おわりに\nご指摘・アドバイス等あればご遠慮なくお願いいたします。\n\n## 参考文献\nこの記事は以下の情報を参考にした。\n\n* [GitLab公式サイト][about.gitlab.com]\n\n[about.gitlab.com]: https://about.gitlab.com/\n","user":"Doshi","created_at":"2021-03-29T01:48:51+09:00","updated_at":"2021-03-29T02:18:40+09:00"},{"url":"https://qiita.com/Doshi/items/293442ef0ea3999010fb","title":"【CentOS8に最新バージョンのRedmineとGitLabを構築する】Redmine構築","body":"# はじめに\nこの記事では、[Redmine 3.4をCentOS 7.3にインストールする手順][InstallCentos] をベースにして、CentOS8上に最新バージョンのRedmineを構築する。\n\n[InstallCentos]: http://blog.redmine.jp/articles/3_4/install/centos/\n\n| ソフトウェア | バージョン |\n|:--|:--|\n| OS | CentOS 8.3 |\n| Redmine | Redmine 4.1.2 |\n| WEB | Apache 2.4.37 |\n| DB | PostgreSQL 10.15 |\n| Ruby | ruby 2.5.5 |\n\n## 関連記事\n\n[【CentOS8に最新バージョンのRedmineとGitLabを構築する】事前調査][事前調査]\n[【CentOS8に最新バージョンのRedmineとGitLabを構築する】GitLab構築][GitLab構築]\n\n[事前調査]: https://qiita.com/Doshi/items/7b69b0f12946b9de4cfe\n[GitLab構築]: https://qiita.com/Doshi/items/1ea1515e614ef8287096\n\n\n\n\n\n# １．SELinux無効化\n`/etc/sysconfig/selinux`を開く。\n\n```\n[doshi@centos8 ~]$ sudo vi /etc/sysconfig/selinux\n```\n\n`SELINUX=`の値を`disabled`に変更する。\n\n```:/etc/sysconfig/selinux\n#SELINUX=enforcing\nSELINUX=disabled\n```\n変更後、CentOSを再起動する。\n\n```\n[doshi@centos8 ~]$ sudo reboot\n```\n\n`getenforce`コマンドを実行してSELinuxが無効`Disabled`になったことを確認する。\n\n```\n[doshi@centos8 ~]$ getenforce\nDisabled\n```\n\n# ２．firewalldでhttpを許可 \n\nデフォルトzoneにhttpを追加する。\n\n```\n[doshi@centos8 ~]$ sudo firewall-cmd --zone=public --add-service=http --permanent\nsuccess\n```\n追加した設定を反映する。\n\n```\n[doshi@centos8 ~]$ sudo firewall-cmd --reload\nsuccess\n```\nhttpでのアクセスが許可されたことを確認する。\n\n```\n[doshi@centos8 ~]$ sudo firewall-cmd --zone=public --list-services\ncockpit dhcpv6-client http ssh\n```\n\n# ３．必要なパッケージのインストール\n## EPELとPowerToolsリポジトリの有効化\nCentOS8ではEPELとPowerToolsリポジトリを有効化しておく必要がある。\n\n```\n[doshi@centos8 ~]$ sudo dnf install -y epel-release\n[doshi@centos8 ~]$ sudo dnf config-manager --set-enabled powertools\n```\n## 開発ツール(Cコンパイラ等)のインストール\n\n```\n[doshi@centos8 ~]$ sudo yum -y groupinstall \"Development Tools\"\n```\n## RubyとPassengerのビルドに必要なヘッダファイルなどのインストール\n[Redmine.JP Blogの手順][InstallCentos] と異なる点として、CentOS8では`curl-devel`は`libcurl-devel`という名称になる。また、`libyaml-devel`はPowerToolsリポジトリからインストールされる。\n\n```\n[doshi@centos8 ~]$ sudo dnf -y install openssl-devel readline-devel zlib-devel libffi-devel libcurl-devel libyaml-devel\n```\n\n## PostgreSQLとヘッダファイルのインストール\n```\n[doshi@centos8 ~]$ sudo dnf -y install postgresql-server postgresql-devel\n```\n[Redmine.JP Blogの手順][InstallCentos] にはないが、ここでPostgreSQLをインストールした際に作成されるOSユーザ`postgres`のパスワードを設定しておく。\n\n```\n[doshi@centos8 ~]$ sudo passwd postgres\n```\n\n## Apacheとヘッダファイルのインストール\n```\n[doshi@centos8 ~]$ sudo dnf -y install httpd httpd-devel\n```\n\n## ImageMagickとヘッダファイルのインストール\n[Redmine.JP Blogの手順][InstallCentos] と異なる点として、`ImageMagick`と`ImageMagick-devel`はEPELリポジトリからインストールされる。\n\n```\n[doshi@centos8 ~]$ sudo dnf -y install ImageMagick ImageMagick-devel\n```\n\n## 日本語フォントのインストール\n[Redmine.JP Blogの手順][InstallCentos] と異なる点として、CentOS8ではIPAフォントのパッケージがリポジトリに存在しないため、Web上のrpmをインストールする。\n\n```\n[doshi@centos8 ~]$ sudo dnf install https://pkgs.dyn.su/el8/base/x86_64/ipa-pgothic-fonts-003.03-14.el8.noarch.rpm\n```\n\nIPAのフォントが追加されていることを確認する。\n\n```\n[doshi@centos8 ~]$ ls /usr/share/fonts | grep ipa\nipa-pgothic\n```\n\n# ４．Rubyのインストール\n[Redmine.JP Blogの手順][InstallCentos] ではソースコードからインストールする手順になっているが、最新のRubyをインストールするメリットが見出せないので、パッケージでインストールする。\n後にある[gemパッケージのインストール](#gemパッケージのインストール)`bundle install`の際に、ヘッダーファイルが見つからずエラーになるのを避けるため、`ruby-devel`もインストールする。\n\n```\n[doshi@centos8 ~]$ sudo dnf -y install ruby ruby-devel\n```\n`ruby -v`を実行してRubyのバージョンを表示させ、インストールできたことを確認する。\n\n```\n[doshi@centos8 ~]$ ruby -v\nruby 2.5.5p157 (2019-03-15 revision 67260) [x86_64-linux]\n```\n\n## bundlerのインストール\nRuby用のパッケージ管理ツールであるbundlerをインストールする。Redmineが使用するgemパッケージをインストールするのに使う。bundlerはrootユーザで使うため、ここでは`sudo`で実行する。なお、`--no-rdoc --no-ri`オプションはドキュメントのインストールを省略する。\n\n```\n[doshi@centos8 ~]$ sudo gem install bundler --no-rdoc --no-ri\nFetching: bundler-2.2.15.gem (100%)\nSuccessfully installed bundler-2.2.15\n```\n\n# ５．PostgreSQLの設定 \n## データベースクラスタの新規作成\n```\n[doshi@centos8 ~]$ sudo postgresql-setup initdb\n```\n\n## RedmineからPostgreSQLに接続するための設定を追加\n`/var/lib/pgsql/data/pg_hba.conf`を開き、\"Put your actual configuration here\"と書かれている箇所を探して以下のように設定を2行追加する。\n\n```:/var/lib/pgsql/data/pg_hba.conf\n# Put your actual configuration here\n# ----------------------------------\n#\n# If you want to allow non-local connections, you need to add more\n# \"host\" records.  In that case you will also need to make PostgreSQL\n# listen on a non-local interface via the listen_addresses\n# configuration parameter, or via the -i or -h command line switches.\nhost    redmine         redmine         127.0.0.1/32            md5\nhost    redmine         redmine         ::1/128                 md5\n```\n\n## PostgreSQLの起動および自動起動の設定\n```\n[doshi@centos8 ~]$ sudo systemctl start postgresql.service\n[doshi@centos8 ~]$ sudo systemctl enable postgresql.service\nCreated symlink /etc/systemd/system/multi-user.target.wants/postgresql.service → /usr/lib/systemd/system/postgresql.service.\n```\n## PostgreSQLのディレクトリに移動\n`/etc/sudoers`を開く。\n\n```\n[doshi@centos8 ~]$ sudo vi /etc/sudoers\n```\npostgresユーザを追加する。\n\n```:/etc/sudoers\npostgres        ALL=(ALL)       ALL\n```\n\npostgresユーザに切り替える。\n\n```\n[doshi@centos8 ~]$ su - postgres\n```\n`/var/lib/pgsql`ディレクトリに移動する。\n\n```\n[postgres@centos8 ~]$ cd /var/lib/pgsql\n```\n\n## Redmine用ユーザーの作成\n```\n[postgres@centos8 ~]$ sudo -u postgres createuser -P redmine\n```\n## Redmine用データベースの作成\n```\n[postgres@centos8 ~]$ sudo -u postgres createdb -E UTF-8 -l ja_JP.UTF-8 -O redmine -T template0 redmine\n```\n## PostgreSQLのディレクトリから元のディレクトリに戻る\n`exit`でpostgresユーザから一般ユーザに戻る。\n\n# ６．Redmineのインストール\nsvnコマンドを使ってインストールするため、subversionをインストールする。\n\n```\n[doshi@centos8 ~]$ sudo dnf install subversion\n```\nRedmine 4.1の最新ソースコード一式を、デプロイしたい`/var/lib/`直下のディレクトリ`redmine`にダウンロードする。\n\n```\n[doshi@centos8 ~]$ sudo svn co http://svn.redmine.org/redmine/branches/4.1-stable/ /var/lib/redmine\n```\n## データベースへの接続設定\nRedmineからデータベースへ接続するための設定ファイルを作成する。Redmineのインストールディレクトリ`/var/lib/redmine`に`config/database.yml`を作成する。\n\n```\n[doshi@centos8 ~]$ sudo vi /var/lib/redmine/config/database.yml\n```\n\n```:/var/lib/redmine/config/database.yml\nproduction:\n  adapter: postgresql\n  database: redmine\n  host: localhost\n  username: redmine\n  password: \"*******\"\n  encoding: utf8\n```\n## 設定ファイル config/configuration.yml の作成\nRedmineからメールサーバへ接続するための設定や日本語フォントファイルのパスを記述した設定ファイルを作成する。Redmineのインストールディレクトリ`/var/lib/redmine`に`config/configuration.yml`を作成する。\n\n```\n[doshi@centos8 ~]$ sudo vi /var/lib/redmine/config/database.yml\n```\n\n```:/var/lib/redmine/config/database.yml\nproduction:\n  email_delivery:\n    delivery_method: :smtp\n    smtp_settings:\n      enable_starttls_auto: true\n      address: \"smtp.gmail.com\"\n      port: 587\n      domain: \"smtp.gmail.com\"\n      authentication: :plain\n      user_name: \"**********@gmail.com\"\n      password: \"**********\"\n\nproduction:\n  rmagick_font_path: /usr/share/fonts/ipa-pgothic/ipagp.ttf\n```\n\n## Redmineのインストールディレクトリへ移動\n\nrootユーザに切り替える。\n\n```\n[doshi@centos8 ~]$ su -\n```\n`/var/lib/redmine`ディレクトリへ移動する。\n \n```\n[root@centos8 ~]# cd /var/lib/redmine\n```\n\n## gemパッケージのインストール\n\n```\n[root@centos8 ~]# bundle install --without development test --path vendor/bundle\n```\n\n# ７．Redmineの初期設定と初期データ登録\n\nRedmine動作に関する初期設定と初期データの登録を行う。Redmineのインストールディレクトリで実行する必要がある。\n\n## セッション改ざん防止用秘密鍵の作成\n```\n[root@centos8 redmine]# bundle exec rake generate_secret_token\n```\n## データベースのテーブル作成\n```\n[root@centos8 redmine]# RAILS_ENV=production bundle exec rake db:migrate\n```\n## デフォルトデータの登録\n作成したテーブルにデフォルトデータのロードを行う。この操作によりトラッカー、優先度、ステータス、ロール、ワークフローなどの初期値が登録される。\n\n```\n[root@centos8 redmine]# RAILS_ENV=production REDMINE_LANG=ja bundle exec rake redmine:load_default_data\nDefault configuration data loaded.\n```\n\n# ８．Passengerのインストール\nApache上でRedmineなどのRailsアプリケーションを実行するために使われるPhusion Passengerをインストールする。\n\n```\n[root@centos8 redmine]# gem install passenger -v 5.1.12 --no-rdoc --no-ri\n```\n## PassengerのApache用モジュールのインストール\nApache用のモジュールのビルドとインストールを行う。完了するまで時間がかかる。\n\n```\n[root@centos8 redmine]# passenger-install-apache2-module --auto --languages ruby\n```\n## Redmineのディレクトリから元のディレクトリに戻る\n`exit`でrootユーザから一般ユーザに戻る。\n\n# ９．Apacheの設定\n## Apache用設定内容の確認\n下記コマンドを実行するとApacheに追加すべき設定が表示される。\n\n```\n[doshi@centos8 ~]$ passenger-install-apache2-module --snippet\nLoadModule passenger_module /usr/local/share/gems/gems/passenger-5.1.12/buildout/apache2/mod_passenger.so\n<IfModule mod_passenger.c>\n  PassengerRoot /usr/local/share/gems/gems/passenger-5.1.12\n  PassengerDefaultRuby /usr/bin/ruby\n</IfModule>\n```\n## Apacheの設定ファイル作成\n`/etc/httpd/conf.d/redmine.conf`を開く。\n\n```\n[doshi@centos8 ~]$ sudo vi /etc/httpd/conf.d/redmine.conf\n```\nApacheの設定ファイルを以下の内容で作成する。\n\n```:/etc/httpd/conf.d/redmine.conf\n# サブディレクトリでRedmineを実行\nAlias /redmine /var/lib/redmine/public\n\n<Location /redmine>\n  PassengerBaseURI /redmine\n  PassengerAppRoot /var/lib/redmine\n</Location>\n\n# Redmineの画像ファイル・CSSファイル等へのアクセスを許可する設定\n<Directory \"/var/lib/redmine/public\">\n  Require all granted\n</Directory>\n\n# Passengerの基本設定\n# passenger-install-apache2-module --snippet で表示された設定を記述\nLoadModule passenger_module /usr/local/share/gems/gems/passenger-5.1.12/buildout/apache2/mod_passenger.so\n<IfModule mod_passenger.c>\n  PassengerRoot /usr/local/share/gems/gems/passenger-5.1.12\n  PassengerDefaultRuby /usr/bin/ruby\n</IfModule>\n```\n\n## Apacheの起動および自動起動の設定\n\n```\n[doshi@centos8 ~]$ sudo systemctl start httpd.service\n[doshi@centos8 ~]$ sudo systemctl enable httpd.service\nCreated symlink /etc/systemd/system/multi-user.target.wants/httpd.service → /usr/lib/systemd/system/httpd.service.\n```\n\n## Apache上のPassengerでRedmineを実行するための設定\nRedmineを配置したディレクトリ以下のファイルを、Apacheを実行するユーザー・グループ(CentOSの場合はいずれも\"apache\")で読み書きできるよう、オーナーを変更する。\n\n```\n[doshi@centos8 ~]$ sudo chown -R apache:apache /var/lib/redmine\n```\n\n# １０．運用\n\n## Redmineのログローテーション\n[production.logのローテート][production-log-rotate] を参考に、logroatedを使ってログローテーションを設定する。\n[production-log-rotate]: https://redmine.jp/faq/system_management/production-log-rotate/\n\n`/etc/logrotate.d/redmine`を開く。\n\n```\n[doshi@centos8 ~]$ sudo vi /etc/logrotate.d/redmine\n```\n`/etc/logrotate.d/redmine`の設定ファイルを以下の内容で作成する。\n\n```:/etc/logrotate.d/redmine\n/var/lib/redmine/log/*log {\n    missingok      # ファイルが存在しなくてもエラーににない\n    notifempty     # ファイルが空の場合はローテーションしない\n    copytruncate   # ログを別名でコピーした後、元のファイルの内容を空にする\n    compress       # 古いログを圧縮して保存する\n}\n```\n\n動作確認のため、ローテートする条件を満たしていなくても`-f`オプションで強制実行する。\n\n```\n[doshi@centos8 ~]$ sudo /usr/sbin/logrotate -f /etc/logrotate.d/redmine\n```\n\n圧縮ファイルが作成され、元ファイルのサイズが0となることを確認する。\n\n```\n[doshi@centos8 ~]$ sudo ls -ltr /var/lib/redmine/log/\n合計 12\n-rw-r--r-- 1 apache apache   32  3月 20 22:37 delete.me\n-rw-r--r-- 1 apache apache 8009  3月 27 17:57 production.log.1.gz\n-rw-r--r-- 1 apache apache    0  3月 27 18:08 production.log\n```\n\n## Redmineのバックアップとリストア\n[Redmineのバックアップとリストア][RedmineBackupRestore] を参考に、バックアップを取得する。リストアは、Redmineガイドになぜか記載がないため、公式サイトの [Restore][Restore] を参考にする。\n\n[RedmineBackupRestore]: http://guide.redmine.jp/RedmineBackupRestore/\n[Restore]: https://www.redmine.org/projects/redmine/wiki/RedmineBackupRestore\n\n## アップグレード\n\nRedmineガイドの [アップグレード][RedmineUpgrade] を参考にする。\n[RedmineUpgrade]: http://guide.redmine.jp/RedmineUpgrade/\n\n## ディレクトリ\nデータの蓄積するディレクトリは以下のとおり。\n\n| ディレクトリ | 用途 |\n|:--|:--|\n| /var/lib/pgsql/data | PostgreSQLのデータ一式が配置されるディレクトリ |\n| /var/lib/redmine/files | Redmineの添付ファイルがアップロードされるディレクトリ |\n\n# おわりに\nご指摘・アドバイス等あればご遠慮なくお願いいたします。\n\n## 参考文献\nこの記事は以下の情報を参考にした。\n\n* [Redmine公式サイト][www.redmine.org]\n* [Redmine.JP][redmine.jp]\n* [Redmine.JP Blog][blog.redmine.jp]\n* [Redmineガイド][guide.redmine.jp]\n\n[www.redmine.org]: https://www.redmine.org/\n[redmine.jp]: https://redmine.jp/\n[blog.redmine.jp]: http://blog.redmine.jp/\n[guide.redmine.jp]: http://guide.redmine.jp/\n","user":"Doshi","created_at":"2021-03-29T01:46:52+09:00","updated_at":"2021-03-29T02:21:19+09:00"},{"url":"https://qiita.com/ndj/items/9ec991af4ef40264ad6e","title":"【Gatsby.js】グローバル CSS を反映させたいときは、gatsby-browser.js に設定を記述する","body":"# Gatsby.js 製のサイトにグローバル CSS を使いたい\n\nこんにちは、@ndj です。\n表題の通りです。\nフォントの設定とか、margin や padding の初期設定をすべてのページ全体に反映させたいときにいちいちコンポーネントごとにスタイルを読み込んだりするのは面倒です。\n[Gatsby: Standard Styling with Global CSS Files](https://www.gatsbyjs.com/docs/how-to/styling/global-css/)を確認したところ、方法が見つかったので、備忘録として残しておきます。\n\n## 環境\n- Gatsby.js: v3.1.1\n- React.js: v17.0.1\n\n## 結論\n1. グローバル CSS ファイルを作成する\n2. gatsby-browser.js でグローバル CSS ファイルを読み込む記述を追加する\n\n\n## 手順\n\n### 1. グローバル CSS ファイルを作成する\n\nなにはともあれ、まずは CSS ファイルを作成します。\nテストがてら body 要素を真っ赤にしておきましょう。\n\n```global.css\nbody {\n    background-color: red;\n}\n```\n\n### 2. gatsby-browser.js にグローバル CSS ファイルを読み込む記述を追加する\n\n次は、gatsby-browser.js というファイルに、先ほど作成した global.css を読み込ませます。\n\nGatsby プロジェクトの root に gatsby-browser.js という名前のファイルを作成します。\nそして、以下の記述を追加します。\nglobal.css の場所は適宜確認してください。\n\n```gatsby-browser.js\nimport './global.css';\n\n//もしくは、\n//require('./global.css');\n```\n\nこれで OK です！\n\n#### 注意！\nもし開発サーバーが動いていたら、再起動が必要です。\n\n```\n1. Ctrl+C を押して停止\n2. gatsby develop を実行\n```\n\n#### gatsby-browser.js とは\n[Gatsby: Gatsby Browser APIs](https://www.gatsbyjs.com/docs/reference/config-files/gatsby-browser/)によると以下のような記述がありました。\n\n>Introduction\n>The file gatsby-browser.js lets you respond to actions within the browser, and wrap your site in additional components. The Gatsby Browser API gives you many options for interacting with the client-side of Gatsby.\n\nサイト全体をコンポーネントでラップできたりするらしいです。\nアナリティクスの API なんかはここに設定するみたいです（訳にあまり自信がないです…）。\nだがとりあえず、グローバル CSS を利用する際はあまり深く考える必要はないっぽい。\n\n> What is gatsby-browser.js? Don’t worry about this too much and for now, just know that gatsby-browser.js is one of a handful of special files that Gatsby looks for and uses (if they exist). Here, the naming of the file is important. If you do want to explore more now, check out the docs.\n[Gatsby: Introduction to Styling in Gatsby](https://www.gatsbyjs.com/docs/tutorial/part-two/)より\n\n## その他の方法\n共有レイアウトコンポーネントを作成する方法もあるみたいです。\n参考 [Gatsby: Standard Styling with Global CSS Files](https://www.gatsbyjs.com/docs/how-to/styling/global-css/)\n\n## 参考\n[Gatsby: Introduction to Styling in Gatsby](https://www.gatsbyjs.com/docs/tutorial/part-two/)\n[Gatsby: Standard Styling with Global CSS Files](https://www.gatsbyjs.com/docs/how-to/styling/global-css/)\n[Gatsby: Gatsby Browser APIs](https://www.gatsbyjs.com/docs/reference/config-files/gatsby-browser/)\n\n## さいごに\n今後は、gatsby-browser.js についてもっと深く調べた記事なども書いていきたいと思います。\n誤字脱字、間違いご指摘などありましたらコメントいただけますと幸いです。\nここまで読んでくださり、ありがとうございました。\n\n[Twitter: ndj](https://twitter.com/teqndj)\n","user":"ndj","created_at":"2021-03-29T01:46:35+09:00","updated_at":"2021-03-29T14:28:01+09:00"},{"url":"https://qiita.com/kusano_k/items/bc7e400aa0b9fd3c034b","title":"Google Code Jam Qualification Round 2021","body":"https://codingcompetitions.withgoogle.com/codejam/round/000000000043580a\n\nGoogle Code Jamはちょっと変わった問題があって面白い。全問解いて396位。\n\n他は、まあ公式解説そのままだけど、最後の問題でほぼ100%正解できるのは自慢なので読んでほしい。\n\n## Reversort\n\n[選択ソート](https://ja.wikipedia.org/wiki/%E9%81%B8%E6%8A%9E%E3%82%BD%E3%83%BC%E3%83%88)で、`A[i]`と`A[j]`をスワップする代わりに、`A[i..j]`を反転させることにしたと。なんでそんなことをするの？　で、案の定コストが掛かる。`A[i..j]`の反転には`j-i+1`。そのコストの合計を求めよという問題。`A[i..i]`の反転（？）でもコストが1かかる。ただし、最後の`A[N]`は処理しない。というのがちょっと変則的。制約は`N<=10`なので、素直に実装するだけ。\n\n```A.py\nT = int(input())\nfor t in range(T):\n  N = int(input())\n  L = list(map(int, input().split()))\n  ans = 0\n  for i in range(N-1):\n    j = i\n    for k in range(i+1, N):\n      if L[k]<L[j]:\n        j = k\n    L[i:j+1] = L[i:j+1][::-1]\n    ans += j-i+1\n  print(\"Case #%d: %d\"%(t+1, ans))\n```\n\n## Moons and Umbrellas\n\n`CJ?CC?`のような文字列が与えられ、`?`を`C`か`J`に書き換える。`CJ`が出現すると`X`のコストが、`JC`が出現すると`Y`のコストが掛かる。コストの合計の最小値は？　1個前の文字ごとにコストを覚えておいてのDP。\n\n最後のHidden Verdict以外はコストが正。正でも負でもやることは変わらないと思ったけど、公式解説を見たら、Visible Verdictは初手`?`を全部消して`CJ`と`JC`を数えるだけだった。なるほど。\n\n```B.py\nT = int(input())\nfor t in range(T):\n  X, Y, S = input().split()\n  X = int(X)\n  Y = int(Y)\n  oo = 1000000\n  C = [oo]*len(S)\n  J = [oo]*len(S)\n  if S[0]!=\"J\":\n    C[0] = 0\n  if S[0]!=\"C\":\n    J[0] = 0\n  for i in range(1, len(S)):\n    if S[i]!=\"J\":\n      C[i] = min(C[i-1], J[i-1]+Y)\n    if S[i]!=\"C\":\n      J[i] = min(J[i-1], C[i-1]+X)\n  print(\"Case #%d: %d\"%(t+1, min(C[-1], J[-1])))\n```\n\n## Reversort Engineering\n\n1問目とは逆に、コストが与えられてそのコストになるような文字列を返せという問題。後ろから順番に処理していけば、末尾から2番目では1か2のコストを選べる、末尾から3番目では1から3のコストを選べる……ということで、コストがN-1以上、2+3+...+N以下ならば達成可能。\n\n```C.py\nT = int(input())\nfor t in range(T):\n  N, C = map(int, input().split())\n  C -= N-1\n  if 0<=C<=(N-1)*N//2:\n    A = list(range(1, N+1))\n    for i in range(N-2, -1, -1):\n      c = min(N-1-i, C)\n      C -= c\n      A[i:i+c+1] = A[i:i+c+1][::-1]\n    ans = \" \".join(map(str, A))\n  else:\n    ans = \"IMPOSSIBLE\"\n  print(\"Case #%d: %s\"%(t+1, ans))\n```\n\n## Median Sort\n\nインタラクティブ問題。配列の要素を3個指定すると、そのうちどれが中央値かを返してくる。それを使って、配列をソートしろという問題。ただし、この条件では昇順か降順かは知りようがないので、どちらでも良い。難しいテストセットほど使える問い合わせ回数が減る。\n\n情報量の概念が重要である。最後のテストセットでは、`N=50`で、テストケース1個あたりの問い合わせ回数が170回。長さ50の配列は反転したものを同一視して、$\\frac{N!}{2}\\fallingdotseq 1.52\\times 10^{64}$個ある。一方、$2^{170}\\fallingdotseq 1.5\\times 10^{51}$。つまり、1回の問い合わせでYES/NOの1bitの情報しか使わないようなアルゴリズムでは無理ということ。中央値の問い合わせでは3通りの答えが返ってくる。これをフルに活用できるならば$\\frac{\\log(N!/2)}{\\log(3)}\\fallingdotseq 135$回の問い合わせで足りるということけっこうカツカツ。\n\nある要素`a`と`b`について`a<b`であることが分かっているならば、要素`c`を一緒に問い合わせることで、`c<a`、`a<c<b`、`b<c`のいずれであるかが分かる。これを使ってクイックソートの3分割版をする。\n\n分割したものを単純にソートしてしまうと、外側と昇順・降順が揃わなくなってしまうので、例えば`a`超過`b`未満の部分をソートするときには`a`を渡すようにした。これだと`a`未満の部分に`a`を渡すときに、素直に実装すると別処理になってしまって面倒。`a`を渡してソート結果を反転することで実装量を減らした。\n\n```D.py\nimport sys\n\nT, N, Q = map(int, input().split())\n\ndef query(*args):\n  print(*args)\n  sys.stdout.flush()\n  return int(input())\n\ndef f(l, V):\n  if len(V)<=1:\n    return V\n  a = query(l, V[0], V[1])\n  if a==V[0]:\n    b = V[1]\n  else:\n    b = V[0]\n  X, Y, Z = [], [], []\n  for v in V[2:]:\n    m = query(a, b, v)\n    if m==a:\n      X += [v]\n    elif m==v:\n      Y += [v]\n    elif m==b:\n      Z += [v]\n  return f(a, X)[::-1] + [a] + f(a, Y) + [b] + f(b, Z)\n\nfor t in range(T):\n  a = query(1, 2, 3)\n  b = a%3+1\n  X, Y, Z = [(a+1)%3+1], [], []\n  for i in range(4, N+1):\n    m = query(a, b, i)\n    if m==a:\n      X += [i]\n    elif m==i:\n      Y += [i]\n    elif m==b:\n      Z += [i]\n  ans = f(a, X)[::-1] + [a] + f(a, Y) + [b] + f(b, Z)\n  assert query(*ans)==1\n```\n\n## Cheating Detection\n\nプレイヤー100人と問題10,000問があって、それぞれに強さが決まっている。プレイヤーと問題の強さの差分に応じた確率で正解、不正解が決まる。プレイヤーの中には1人チーターがいて、そいつは1/2の確率で必ず正解する。「チーターは誰？」という問題。面白いのが、50個のテストケースのうち`P`%に正解すれば正解となること。難しいほうのテストケースでは`P=86`。つまり、43個のテストケースに正解すれば良い。\n\n「難しい問題に正解しているやつがチーターでしょ？」とか、「チーターは正解数のわりには簡単な問題も不正解になるはず」とかで80%くらいではいけたものの、微妙に足りなかった。\n\n難しい問題にも程度があり、とても難しい問題に正解しているほうが、ちょっと難しい問題に正解しているよりも、チーターっぽさが高いはず。簡単な問題も同様。この辺の話は[情報量](https://ja.wikipedia.org/wiki/%E6%83%85%E5%A0%B1%E9%87%8F)っぽい。ということで、情報量を求めてみた。要は、チーターは正解／不正解が不自然になる。不自然な結果というのは情報量が多いということ。\n\n各プレイヤーに対して、問題の強さは一様ランダムなので、プレイヤーの正答率から強さを推測できる。問題の強さも同様。強さが推測できれば、あるプレイヤーがある問題に正解する確率が分かる。確率が分かれば、正解／不正解でどれだけの情報量が得られたかも計算できる。プレイヤーごとに、正答率を横軸に、問題1問あたりの情報量を縦軸にプロットするとこうなる。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/25276/5ebfe0a7-8cd0-64a1-74a4-aaa6f5152eb9.png)\n\nあからさまに怪しいやつがいますねぇ。\n\nまあ、これはわかりやすい例で、チーターはたいてい正解率が高く、正解率が高いと分かりづらいのだけど。サンプル入力だとこんな感じ。右端がチーター。\n\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/25276/e0064e6e-8cda-f0b9-d4b8-568f08c90f5a.png)\n\nということで、この上に凸の曲線部分を除いてやる。この曲線はエントロピー関数である。そして一番値が高い人がチーター。\n\n公式解説の締めは、\n\n> Using this latest technique can get a solution above 90% accuracy.\n\nだけど、ランダムに生成した1000ケースで全問正解できた :v:\n\n```E.cpp\n#include <iostream>\n#include <vector>\n#include <string>\n#include <cmath>\nusing namespace std;\n\ndouble f(double x)\n{\n    return 1/(1+exp(-x));\n}\n\ndouble F(double x)\n{\n    return -log(1-f(x));\n}\n\ndouble skill(double p)\n{\n    double l = -3.;\n    double r = 3.;\n    for (int i=0; i<100; i++)\n    {\n        double m = (l+r)*.5;\n        //  (1/6)∫[-3<=x<=3](f(m-x))\n        //  = (1/6)(-F(m-x)[-3<=x<=3])\n        //  = (1/6)(-F(m-3)+F(m+3))\n        ((-F(m-3)+F(m+3))/6<p ? l : r) = m;\n    }\n    return l;\n}\n\nint main()\n{\n    int T;\n    cin>>T;\n    int P;\n    cin>>P;\n\n    for (int t=1; t<=T; t++)\n    {\n        vector<vector<int>> A(100, vector<int>(10000));\n        for (int i=0; i<100; i++)\n        {\n            string s;\n            cin>>s;\n            for (int j=0; j<10000; j++)\n                A[i][j] = s[j]-'0';\n        }\n\n        vector<double> S(100);\n        for (int i=0; i<100; i++)\n        {\n            int s = 0;\n            for (int j=0; j<10000; j++)\n                s += A[i][j];\n            S[i] = skill(s/10000.);\n        }\n\n        vector<double> Q(10000);\n        for (int i=0; i<10000; i++)\n        {\n            int s = 0;\n            for (int j=0; j<100; j++)\n                s += A[j][i];\n            Q[i] = -skill(s/100.);\n        }\n\n        vector<double> X(100);\n        for (int i=0; i<100; i++)\n        {\n            for (int j=0; j<10000; j++)\n                if (A[i][j]==0)\n                    X[i] += -log(1-f(S[i]-Q[j]));\n                else\n                    X[i] += -log(f(S[i]-Q[j]));\n            int s = 0;\n            for (int j=0; j<10000; j++)\n                s += A[i][j];\n            double p = s/10000.;\n            X[i] = X[i]/10000 - (-p*log(p)-(1-p)*log(1-p));\n        }\n\n        int ans = 0;\n        for (int i=1; i<100; i++)\n            if (X[i]>X[ans])\n                ans = i;\n        ans++;\n\n        cout<<\"Case #\"<<t<<\": \"<<ans<<endl;\n    }\n}\n```\n","user":"kusano_k","created_at":"2021-03-29T01:43:37+09:00","updated_at":"2021-03-29T01:43:37+09:00"},{"url":"https://qiita.com/a1k4r/items/893be1e90aea91830cfd","title":"unittestとpytestでそれぞれC1カバレッジ出力のコマンドを最小限に抑えてみました。","body":"Pythonでテストしてカバレッジを取得する時にあれこれコマンドが長くなるなぁと思いつつ特に気にせず作業していたんですけど、やっぱり長いのを打つのってけっこうめんどくさい。。ということで、テストコマンドを最小限に抑えるための設定ファイルの作り方を探った時のメモ的なものです。\n\n2021年3月時点で最新のunittestとpytestに対応しています。今回はテストのコマンドを短くすることに目的をおいているので、テストコードの例は省いています。\n\n## 環境\n\n- Windows10\n- Python3.9インストール済\n\n## 今回のディレクトリ構成\n\n```\nproj_unittest/\n  ├ src/\n  │   ├ app/\n  │   │   ├ __init__.py\n  │   │   └ main.py\n  │   ├ tests/\n  │   │   ├ __init__.py\n  │   │   └ test_app_main.py\n  │   └ __init__.py\n  └ .coveragerc\n\nproj_pytest/\n  ├ src/\n  │   ├ app/\n  │   │   ├ __init__.py\n  │   │   └ main.py\n  │   ├ tests/\n  │   │   ├ __init__.py\n  │   │   └ test_app_main.py\n  │   └ __init__.py\n  └ pytest.ini\n```\n\n## unittestの場合\n\n### 準備\n\n`.coveragerc`を準備します。\n\n今回はC1カバレッジ(判定条件網羅)を出力するために`branch = true`を書いています。テストコードでカバーできてない行をコマンド出力するために`show_missing = true`も追加しています。\n\n```:proj_unittest/.coveragerc\n[run]\nsource = src/app\nbranch = true\ncommand_line = -m unittest\n\n[report]\nshow_missing = true\n```\n\n`coverage`をインストールします。\n\n```bash\n$ pip install coverage\n```\n\n### テスト＆カバレッジ出力\n\n[Before]\n\n```bash\n$ coverage run --source=src/app --branch -m unittest  ← テスト\n$ coverage report -m                                  ← コマンド出力\n$ coverage html                                       ← HTML出力\n```\n\n[after]\n\n```bash\n$ coverage run\n$ coverage report\n$ coverage html\n```\n\nだいぶきれいになりました。\n\n\n## pytestの場合\n\n### 準備\n\n`pytest.ini`を準備します。\n\nC1カバレッジを出力するために`--cov-branch`を書いています。テストコードでカバーできてない行をコマンド出力するために`--cov-report=term-missing`、自動でHTMLを出力する機能もあるので`--cov-report=html`も追加しています。\n\n```:proj_pytest/pytest.ini\n[pytest]\naddopts=\n  --cov=src/app\n  --cov-branch\n  --cov-report=term-missing\n  --cov-report=html\n```\n\n`pytest`、`pytest-cov`をインストールします。\n\n```bash\n$ pip install pytest pytest-cov\n```\n\n### テスト＆カバレッジ出力\n\n[before]\n\n```bash\n$ pytest --cov=src/app --cov-branch --cov-report=term-missing --cov-report=html\n```\n\n[after]\n\n```bash\n$ pytest\n```\n\npytestの場合はこれでカバレッジ出力も自動でやってくれるからほんと便利です。\n\n\n## 参考\n\n- https://coverage.readthedocs.io/en/coverage-5.0/config.html\n- https://docs.pytest.org/en/stable/customize.html#pytest-ini\n","user":"a1k4r","created_at":"2021-03-29T01:41:25+09:00","updated_at":"2021-03-29T01:41:25+09:00"},{"url":"https://qiita.com/Doshi/items/7b69b0f12946b9de4cfe","title":"【CentOS8に最新バージョンのRedmineとGitLabを構築する】事前調査","body":"# はじめに\n\nRHEL8の仮想サーバを入手したため、RedmineとGitを構築し業務で活用したい。そこで、まずはCentOS8上で検証してみることにした。ここでは、事前に調査した内容をまとめておく。\n\n## 関連記事\n\n[【CentOS8に最新バージョンのRedmineとGitLabを構築する】Redmine構築][Redmine構築]\n[【CentOS8に最新バージョンのRedmineとGitLabを構築する】GitLab構築][GitLab構築]\n\n[Redmine構築]: https://qiita.com/Doshi/items/293442ef0ea3999010fb\n[GitLab構築]: https://qiita.com/Doshi/items/1ea1515e614ef8287096\n\n# １．コンテナで構築する場合を調べた\n勉強がてらコンテナで構築したいと思ったが、結論、早々に諦めた。ざっと調べたところ、RHEL8（正確にはRHEL 7.6以降）のコンテナエンジンにはPodmanが採用され、Dockerはサポート対象外となっている。Dockerを管理する`docker-compose`に対応したサードパーティ製の`podman-compose`が提供されているようだが、まだナレッジも少なく実用的ではない模様。\n\n# ２．Redmineについて調べた\nRedmineとは、OSSでWeb型のプロジェクト管理ツールである。\n[Redmine公式サイトのInstalling Redmine][RedmineInstall] から現時点（2021/3）の情報を抜粋する。\n\n## Redmineの最新リリース\n4.1.2 (2021-03-21)\n4.0.8 (2021-03-21)\n\nRedmineの代表的なプラグインは、4.1, 4.0のバージョンに対応している模様。\n\n## RedmineがサポートするRubyのバージョン\n| Redmineバージョン　 | Rubyバージョン | Railsバージョン　 |\n|:--|:--|:--|\n| 4.1 | Ruby 2.3, 2.4, 2.5, 2.6 | Rails 5.2 |は\n| 4.0 | Ruby 2.2.2, 2.3, 2.4, 2.5, 2.6　 | Rails 5.2 |\n\n## Redmineがサポートするデータベースとそのバージョン\n* MySQL 5.5 または 5.7（5.6 と MariaDB は問題あり）\n* PostgreSQL 9.2 以降\n\n# ３．Redmineの動作環境を、CentOS8上に構築できるのか調べた\n## CentOS8\nCentOS8のバージョンは現時点（2021/3）の最新版バージョンを利用する。なお、CentOS8は2021年でサポート終了のため、CentOS Streamへの移行が推奨されている。\n\n```\n[doshi@centos8 ~]$ cat /etc/redhat-release\nCentOS Linux release 8.3.2011\n[doshi@centos8 ~]$ uname -r\n4.18.0-240.el8.x86_64\n```\n\nCentOS8ではパッケージ管理ソフトyumが後継のdnfに変更された。有効なリポジトリを確認してみる。新たなAppStream含め、3つのリポジトリが有効化されていた。\n\n```\n[doshi@centos8 ~]$ dnf repolist\nrepo id                                                 repo の名前\nappstream                                               CentOS Linux 8 - AppStream\nbaseos                                                  CentOS Linux 8 - BaseOS\nextras                                                  CentOS Linux 8 - Extras\n```\n\n## Ruby\n[Rubyの公式サイト][www.ruby-lang.org] に、サポートする動作環境の明確な記載はない。最近のRubyは最近のLinux上で問題なく動く模様。なお、CentOS8のリポジトリにあるRubyバージョンは2.5。\n\n```\n[doshi@centos8 ~]$ dnf list --available ruby.x86_64\nruby.x86_64            2.5.5-106.module_el8.3.0+571+bab7c6bc            appstream\n```\n\nRedmineがサポートするRubyバージョンをCentOS8上に問題なく準備できそう。\n\n## データベース\n### MySQL 動作環境\n[MySQL公式サイト][www.mysql.com]  から現時点（2021/3）の情報を抜粋する。\n\n| Operating System | Architecture | MySQL |\n|:--|:--|:--|\n| Red Hat Enterprise Linux 8 / CentOS 8　 | x86_64, ARM 64　 | 8.0 |\n| Red Hat Enterprise Linux 7 / CentOS 7　 | ARM 64 |  8.0 |\n| Red Hat Enterprise Linux 7 / CentOS 7　 | x86_64 |  8.0, 5.7　  |\n\nRHEL8、CentOS8上ではMySQL 8.0がサポートされている。なお、CentOS8のリポジトリにあるMySQLバージョンも8.0。\n\n```\n[doshi@centos8 ~]$ sudo dnf list --available mysql.x86_64\nmysql.x86_64            8.0.21-1.module_el8.2.0+493+63b41e36            appstream\n```\nRedmineがMySQL8.0をサポートしていないので、データベースにMySQLは採用できない。\n\n### PostgreSQL 動作環境\n[PostgreSQL公式サイト][www.postgresql.org] に、サポートする動作環境の明確な記載はない。最近のPostgreSQLは最近のLinux上で問題なく動く模様。なお、CentOS8のリポジトリにあるPostgreSQLバージョンは10.15。\n\n```\n[doshi@centos8 ~]$ dnf list --available postgresql\npostgresql.x86_64            10.15-1.module_el8.3.0+619+dbc95fbc            appstream\n```\nRedmineがサポートするPostgreSQL 9.2以降をCentOS8上に問題なく準備できそう。\n\n# ４．Redmineの調査まとめ\nCentOS8上にRedmineを構築する場合、データベースにはPostgreSQLを採用する必要がある。なお、Redmineには、Bitnami Redmineというオールインパッケージが準備されているが、データベースにMySQLがバンドルされているため、今回は利用しない。そのため、各種ソフトウェアを個別にインストールし構築する必要がある。\n\n# ５．GitLabについて調べた\nGitとはOSSの分散型バージョン管理システムである。Gitには標準のGUIが存在しないので、Gitを便利に使えるようにしたWebサービスが複数存在し、今回は評判のよいGitLabを選定した。\n[GitLab Docs の Requirements][requirements] から現時点（2021/3）の情報を抜粋する。\n\n## Omnibus GitLabがサポートするOSバージョン\nGitLabには、Omnibus GitLabというオールインパッケージが準備されている。\n\n* Linuxディストリビューション\n * CentOS (7/8)\n * Red Hat Enterprise Linux (please use the CentOS packages and instructions)\n\n## Omnibus GitLabのバージョンの見方\n現時点（2021/3）で、[gitlab’s repos][packages.gitlab.com]での最新バージョンは`gitlab-ee-13.9.4-ee.0`の模様。\n[packages.gitlab.com]: https://packages.gitlab.com/gitlab\n\nOmnibus GitLab のバージョンの表記\n `MAJOR.MINOR.PATCH-EDITION.OMNIBUS_RELEASE`\n\n| Component | Meaning | Example |\n|:--|:--|:--|\n| MAJOR.MINOR.PATCH | 13.9.3 | GitLabのバージョン |\n| EDITION | ee | GitLabのエディション |\n| OMNIBUS_RELEASE | 0 | 同じGitLabでのビルドバージョン（基本 ０） |\n\n## Omnibus GitLabにバンドルされたソフトウェア\nOmnibus GitLabにバンドルされた各種ソフトウェアのバージョンは、インストールした後の　`/opt/gitlab/version-manifest.txt`で確認できる。\n\n未インストールの状態で、バンドルされたソフトウェアのバージョンを知りたい場合、[omnibus-gitlab][gitlab.com] のリポジトリを確認する必要がある。例として、Rubyバージョンを確認してみる。\n[gitlab.com]: https://gitlab.com/gitlab-org/omnibus-gitlab/-/tree/13-5-stable\n\n13-5-stable のブランチを選択する。\n> ![13-5-stable.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/242519/3e0350ec-229e-1465-1193-17582b87d2fe.png)\n\n`config/software/ruby.rb`の中を確認してみる。\n![Ruby.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/242519/f23bcc48-2763-6103-28e9-d573f6872d58.png)\n\n以下の記載を発見。Ruby 2.6.6 がバンドルされていることが分かった。\n`version('2.6.6') { source sha256: '364b143def360bac1b74eb56ed60b1a0dca6439b00157ae11ff77d5cd2e92291' }`\n\n## Omnibus GitLabの仕組み\nOmnibus GitLabの仕組みとして、以下の図でTCPの記載がない箇所は、Unix Domain Socketというプロセス間での通信を行う。例として、PostgresqlがTCP通信ではないため、デフォルトポート番号5432で起動している他のPostgreSQLと同一ホスト内で同居出来る。WebサーバのNginxはTCP通信であるため、他のWebサーバを同居させる場合はポート番号が競合しないように気をつける必要がある。\n![architecture_simplified.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/242519/405a47a7-d152-28e1-0227-b65254bb5720.png)\n\n# ６．GitLabの調査まとめ\nOmnibus GitLabというオールインワンパッケージでのインストールを行う。WebサーバのNginxとのポート番号競合には注意する必要があるが、その他は気にしないで大丈夫そう。Rubyも個別にインストールしたバージョンとは別管理となり、Omnibus GitLabは独立したものとして考えることができる。\n\n# おわりに\nご指摘・アドバイス等あればご遠慮なくお願いいたします。\n\n## 参考文献\nこの記事は以下の情報を参考にした。\n\n* Redmine\n * [Redmine公式サイト][www.redmine.org]\n * [Rubyの公式サイト][www.ruby-lang.org]\n * [MySQL公式サイト][www.mysql.com]\n * [PostgreSQL公式サイト][www.postgresql.org]\n\n* GitLab\n * [GitLab公式サイト][about.gitlab.com]\n\n\n[RedmineInstall]: https://www.redmine.org/projects/redmine/wiki/RedmineInstall\n[www.redmine.org]: https://www.redmine.org/\n[www.ruby-lang.org]: https://www.ruby-lang.org/en/\n[www.mysql.com]: https://www.mysql.com/jp/\n[www.postgresql.org]: https://www.postgresql.org/\n\n[requirements]: https://docs.gitlab.com/ee/install/requirements.html\n[about.gitlab.com]: https://about.gitlab.com/\n","user":"Doshi","created_at":"2021-03-29T01:40:58+09:00","updated_at":"2021-03-29T02:19:35+09:00"},{"url":"https://qiita.com/joney19860716/items/b1cfc1c9d034f7af6420","title":"Salesforce データセキュリティ","body":"#データセキュリティ\n##組織レベル\n###ユーザ作成\n要求：\n①ユーザ名：世界唯一\n②メール：パスワード通知またリセットする時送信対象アドレス、複数ユーザは同じ設定可能\n③ロール：作成する時、していしなくでも大丈夫です、ロール階層設定用\n④ユーザライセンス：該当ユーザ所属ライセンス（開発する時、お客様と確認）\n⑤プロファイル：該当ユーザの利用プロフィール指定（権限など関連）\n⑥パスワードをリセットしてユーザに通知する：事前作成のユーザは、このチェック外す、利用必要の時にパスワードリセットする。\n<font color=\"Red\">　↑パスワードリセットのメールのデフォルト有効期限は7日、変更できる期限は「1日」と「180日」</font>\n<font color=\"Red\">※ユーザ削除不可、退職ユーザは無効を設定すれば、ライセンス解放</font>\n・新規ユーザ\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/965ceb6a-538c-646c-a0b7-9930d5aff339.png)\n・複数ユーザを追加：同時10人まで追加可能\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/04ac4ed7-4c46-d946-d393-d8666a1153c1.png)\n###ログインIP制限設定（プロファイル別）\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/00be4d6a-db4b-5e77-9bd3-a9e1099b4bf4.png)\n###ログイン時間帯設定（プロファイル別）\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/f7beb551-fef4-d542-1e9d-483df957254a.png)\n###パスワードポリシーの設定\nパスワード有効期限、複雑さ、ログイン失敗によりロックするまでの回数、ログアウトの有効期間など設定可能\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/3133870a-b9f5-92e2-aed9-ba1e8ee9f77e.png)\n※代理管理者\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/d1fed191-fb8f-2aea-8254-f3f800a946cb.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/24d73e70-f6b2-ef9c-f376-8a713bcc0b56.png)\n##オブジェクトレベル\nプロファイルまたは権限セットを使用して設定できます。1 人のユーザには 1 つのプロファイルと複数の権限セットを設定できます。\n\n・ユーザのプロファイルによって、ユーザがアクセスできるオブジェクトと、オブジェクトレコードでユーザが実行できる操作 (作成、参照、編集、削除など) が決まります。\n・権限セットを使用すれば、ユーザに追加の権限を付与したり、アクセスを設定することができます。適用した特定のグループまたユーザに対して、プロファイルの補足の認識で大丈夫です。\n<font color=\"Red\">　※アクセス権限は縮小することができないので、プロファイルに応用対象ユーザの最小権限を設定する。\n　　一部のユーザの権限縮小したい場合、新しいプロファイル作成必要</font>\n###標準プロファイル\n標準プロファイルは下記のようなものがある、権限は既定ですので、変更不可\n・標準ユーザ（オブジェクトレベルのカスタムオブジェクトアクセスできない、ただし、項目レベルアクセス可能、統計関連標準オブジェクトのアクセス権限付いていない）\n・マーケティングユーザ\n・契約管理者\n・システム管理者（全オブジェクトの全権限がある）\n・最小アクセス - Salesforce\n\n###プロファイル作成\n　・プロファイルを作成する最も簡単な方法は、作成するプロファイルと似た既存のプロファイルをコピーし、それを変更することです。\n<font color=\"Red\">※[拡張プロファイルユーザインターフェース] が「有効化」に設定必要</font>\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/6ad7bf9a-d2ff-4a72-c47d-29a8bbc35a75.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/4f6527ba-afab-4198-3042-a2e4928375c8.png)\n\nコピー作成のプロファイルオブジェクトレベル権限設定可能（カスタム、標準両方）\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/f94fd86f-bb63-bef8-7a8b-88889cd8ca55.png)\n\n\n###権限セット作成\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/45056c88-2b0f-7c87-3514-0b168eea89ca.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/5e3b4458-d703-bd7f-c582-f69666525d65.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/0985d9c1-f79a-513d-984a-e96ec91751c4.png)\n\n##項目レベル\n###プロファイル\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/03397298-9bc3-d6b9-119a-a5d5489cc963.png)\n\n###権限セット\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/ea25132c-562e-2a9d-26e2-9eec6c9ed056.png)\n\n<font color=\"Red\">\n※オブジェクトレベルと項目レベルの区別：\nオブジェクトレベル：新規、削除、全表示、全編集の権限指定可能。\n　　　　　　　　　　読む、編集については実際の権限は項目レベルの権限です。\n項目レベル：項目表示また編集出来るかどうか指定する、画面表示用基準レベルの認識で宜しいです\n</font>\n\n##レコードレベルセキュリティ\n・組織の共有設定：相互のレコードに対するユーザのデフォルトのアクセスレベルを指定します。（プロファイル、権限セット）\n・ロール階層：マネージャには常にその部下と同じレコードへのアクセス権を付与します。階層の各・ロールは、ユーザまたはユーザグループが必要とするデータアクセスのレベルを表します。（ロール）\n・共有ルール：特定のユーザグループに対して組織の共有設定の例外を自動的に作成して、所有していないレコードや通常は参照できないレコードへのアクセス権を付与します。（グループ、キュー）\n・共有の直接設定：レコード所有者が、レコードへのアクセス権がないと思われるユーザに参照および編集権限を付与できるようにします。（レコード手動共有）\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/424429/0e368702-3bc5-7f46-ce4c-a2a03edf3468.png)\n\n\n","user":"joney19860716","created_at":"2021-03-29T01:36:56+09:00","updated_at":"2021-03-29T01:36:56+09:00"},{"url":"https://qiita.com/sakano/items/e38306a8204c531a40c1","title":"VContainer入門(2) - LifetimeScope","body":"# この記事について\n[前回](https://qiita.com/sakano/items/3a009019e279024fda19)に引き続きVContainerの説明をしていきます。\n\n今回はLifetimeScopeの基本的な使い方を説明します。\nLifetimeScopeを使うと前回紹介した`IContainerBuilder`と`IObjectResolver`を簡単に扱えます。\n\n\n# LifetimeScopeを試してみる\n## 動作確認用のクラスを作成\n今回もサンプルとして前回と全く同じクラスを使います。念のためそのまま載せてきます。\n\n```CSharp:Mock.cs\nusing UnityEngine;\nusing VContainer;\n\n// 先頭に[Logger]を付けてログ出力するクラス\npublic sealed class Logger\n{\n    public void Log(string message) => Debug.Log(\"[Logger] \" + message);\n}\n\n// 足し算するだけのクラス\npublic sealed class Calculator\n{\n    public int Add(int a, int b) => a + b;\n}\n\n// LoggerとCalculatorに依存するクラス\npublic sealed class HogeClass\n{\n    private readonly Logger logger;\n    private readonly Calculator calculator;\n\n    [Inject]\n    public HogeClass(Logger logger, Calculator calculator)\n    {\n        this.logger = logger;\n        this.calculator = calculator;\n    }\n\n    public void LoggerTest()\n    {\n        logger.Log(\"LoggerTest\");\n    }\n\n    public void CalculatorTest(int a, int b)\n    {\n        int result = calculator.Add(a, b);\n        logger.Log($\"{a} + {b} = {result}\");\n    }\n}\n```\n\n## LifetimeScopeを作成\nこれを使うLifetimeScopeは以下のようになります。\n\n```CSharp:TestLifetimeScope.cs\nusing VContainer;\nusing VContainer.Unity;\n\npublic sealed class TestLifetimeScope : LifetimeScope\n{\n    protected override void Configure(IContainerBuilder builder)\n    {\n        builder.Register<Logger>(Lifetime.Singleton);\n        builder.Register<Calculator>(Lifetime.Singleton);\n        builder.Register<HogeClass>(Lifetime.Singleton);\n    }\n}\n```\n\n前回、VContainerを使う流れとして次の説明をしました。\n\n> 1. IContainerBuilderを生成する。\n> 2. IContainerBuilderに使いたいクラスを登録する。\n> 3. IContainerBuilderからIObjectResolverを生成する。\n> 4. IObjectResolverを通して使いたいクラスを生成する。\n\n`LifetimeScope`クラスを継承すると、この1,2,3を自動的にやってくれます。\n\n2の段階で`Configure`というメソッドを呼び出してくれるのでこれをoverrideして好きなクラスを登録します。引数に渡された`IContainerBuilder`のRegisterを呼び出してください。\n\n## LifetimeScopeを使う\n`LifetimeScope`は`MonoBehaviour`を継承したクラスなのでGameObjectにアタッチして使います。\n\n下の画像はTestLifetimeScopeのインスペクタです。\n![TestLifetimeScopeのインスペクタ](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/31952/1482d49e-4de4-9d29-8324-8bf4149eb6bb.png)\nいくつか設定項目がありますが、ひとまずAutoRunにチェックが付いていることを確認してください。チェックが付いていればAwakeのタイミングで1～3をやってくれます。\n\n次にこのLifetimeScopeを使う`TestMonoBehaviour`クラスを作成します。\nこのクラスを`TestlifetimeScope`とおなじGameObjecctにアタッチすれば動きます。\n\n```CSharp:TestMonoBehaviour.cs\nusing UnityEngine;\nusing VContainer;\n\npublic sealed class TestMonoBehaviour : MonoBehaviour\n{\n    public void Start()\n    {\n        TestLifetimeScope testLifetimeScope = GetComponent<TestLifetimeScope>();\n\n        HogeClass hogeClass = testLifetimeScope.Container.Resolve<HogeClass>();\n        hogeClass.CalculatorTest(2, 3); // 2 + 3 = 5 と表示される\n    }\n}\n```\nLifetimeScopeが生成したIContainerBuilderは`Container`プロパティに入れられています。そこからHogeClassをResolveして使っているだけです。\n\n## ComponentにInjectする\n先ほどの例ではLifetimeScopeのContainerプロパティに直接アクセスしていましたが、もっと便利な方法があります。\nTestMonoBehaviour自体を登録して自動的にResolveしてもらいます。\n\nまずはLifetimeScopeでTestMonoBehaviourを登録します。\n\n```CSharp:TestLifetimeScope.cs\nusing UnityEngine;\nusing VContainer;\nusing VContainer.Unity;\n\npublic sealed class TestLifetimeScope : LifetimeScope\n{\n    // testMonoBehaviourをインスペクタで設定する\n    [SerializeField] private TestMonoBehaviour testMonoBehaviour;\n\n    protected override void Configure(IContainerBuilder builder)\n    {\n        builder.Register<Logger>(Lifetime.Singleton);\n        builder.Register<Calculator>(Lifetime.Singleton);\n        builder.Register<HogeClass>(Lifetime.Singleton);\n\n        // testMonoBehaviourのインスタンスを登録する\n        builder.RegisterComponent(testMonoBehaviour);\n    }\n}\n```\n`[SerializeField] private TestMonoBehaviour testMonoBehaviour;`と`builder.RegisterComponent(testMonoBehaviour);`の行を追加しました。\n\n`RegisterComponent`はMonoBehaviourを登録するためのメソッドです。[Inject]属性がついたメンバが存在すれば`IObjectResolver`を生成した直後にそのインスタンスにInjectしてくれます。\n\nTestMonoBehaviourもInjectできるように書き換えます。\n\n```CSharp:TestMonoBehaviour.cs\nusing UnityEngine;\nusing VContainer;\n\npublic sealed class TestMonoBehaviour : MonoBehaviour\n{\n    private HogeClass hogeClass;\n\n    [Inject]\n    public void Inject(HogeClass hogeClass)\n    {\n        this.hogeClass = hogeClass;\n    }\n\n    public void Start()\n    {\n        hogeClass.CalculatorTest(2, 3); // 2 + 3 = 5 と表示される\n    }\n}\n```\n\n`IObjectResolver`は[Inject]属性が付いたメソッドを発見して、登録されているものの中から合致するものを自動的にResolveして渡してくれます。\n\nこの形なら`TestMonoBehaviour`側はどこからHogeClassが渡されてくるかを気にせずに実装できます。\n\n# まとめ\n- `LifetimeScope`クラスを継承して必要なLifetimeScopeを実装します。\n- LifetimeScopeはAutoRunのチェックが付いていればAwakeのタイミングで以下のことをしてくれます。\n - IContainerBuilderを生成してConfigureに渡します。\n - IContainerBuilderからIObjectResolverを生成してContainerプロパティに保持します。\n- `RegisterComponent`でMonoBehaviourのインスタンスをわたしてInjectできます。\n\n\n次回はRegisterやRegsiterComponent以外の登録用メソッドを紹介する予定です。\n","user":"sakano","created_at":"2021-03-29T01:34:48+09:00","updated_at":"2021-03-29T01:34:48+09:00"},{"url":"https://qiita.com/Koshka/items/d33202bfb5a5c9a79981","title":"Google Colab Proでの開発に慣れないので，FloydHubに移行した話","body":"Google Colab Proを登録して色々と遊んではみたが，ipynb形式に慣れないのと，セッションの問題などが面倒で[FloydHub](https://www.floydhub.com/)に移行することにした．\n\n## FloydHubとは \nデータサイエンティスト用の廉価なクラウドサービス + ホスティングサービス．無料版もあるが学習時間の時間制限などの制約が厳しい．有料版でも9ドル/月と安いため，無料版を使ってみて良かったら有料版に移行したい．無料版(Beginner)と有料版(Data Scientist)の細かい差異(の一部分)は以下のとおり．\n\n![floyd.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/300536/ca594c98-5cf6-2e4c-8235-6b262595c670.png)\n\n## よいところ\n- 環境構築の手間がかからない\n- ローカルで書いたコードをCLIでサクッとGPU環境に流せる\n\n## 登録\n普通にSign Upすればよいが，無料版でもクレジットカードの入力が求められた．\n何もしていしないと無料版での登録となり，登録後に移動するページで\"Upgrade your plan\"に従うと有料版に移行できる．\n\n## 利用法\n実際にコードを動かしてみる．基本的には，[Quick Start](https://docs.floydhub.com/getstarted/quick_start/)に沿えばよい．\n\n**手順:**\n1). `floyd-cli`をローカルマシンにインストール\n    - `pip install -U floyd-cli`\n        - 私の場合，Python 3.6にしないとうまくいかなかった\n2). `floyd login` でログイン\n    - PowerShell等でこのコマンドを打つと，ブラウザが起動しログインできる\n3). プロジェクトの作成\nブラウザでFloydHubに入り，プロジェクト(\"test\"と命名)を作成する．ほぼGitHub. \n![floyd_project.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/300536/66213967-eeb1-731e-fa7b-e9c9a100abe0.png)\n\n4). \"quick-start repository\"を動かしてみる\n\nサンプルリポジトリ(CNNによるMNISTの分類)を落とす:\n\n``` sh\n$ git clone https://github.com/floydhub/quick-start.git\nCloning into 'quick-start'...\n...\n$ cd quick-start\n$ ls\neval.py  LICENSE  mnist_cnn.ipynb  README.md  train_and_eval.py  train.py\n```\n\n先ほど作ったプロジェクトの初期化:\n\n```sh\n$ floyd init test\n\nProject \"test\" initialized in current directory\n```\n\n実行:\n\n``` sh\nfloyd run --gpu --env tensorflow-1.3 \"python train_and_eval.py\"\n```\n\nジョブをリアルタイムで確認:\n\n```sh\nfloyd logs <ジョブ名> -f\n```\n\n出力:\n\n``` sh\n2021-03-28 09:04:13,348 INFO - Iter 192000, Minibatch Loss= 331.912109, Training Accuracy= 0.96094\n2021-03-28 09:04:13,509 INFO - Iter 193280, Minibatch Loss= 83.669022, Training Accuracy= 0.98438\n2021-03-28 09:04:13,671 INFO - Iter 194560, Minibatch Loss= 320.909058, Training Accuracy= 0.98438\n2021-03-28 09:04:13,832 INFO - Iter 195840, Minibatch Loss= 234.908890, Training Accuracy= 0.96875\n2021-03-28 09:04:13,993 INFO - Iter 197120, Minibatch Loss= 116.310966, Training Accuracy= 0.96875\n2021-03-28 09:04:14,154 INFO - Iter 198400, Minibatch Loss= 54.050278, Training Accuracy= 0.97656\n2021-03-28 09:04:14,315 INFO - Iter 199680, Minibatch Loss= 70.160957, Training Accuracy= 0.96094\n2021-03-28 09:04:14,346 INFO - Optimization Finished!\n2021-03-28 09:04:14,384 INFO - Testing Accuracy: 0.96875\n2021-03-28 09:04:15,150 INFO - \n################################################################################\n\n2021-03-28 09:04:15,150 INFO - Waiting for container to complete...\n2021-03-28 09:04:15,435 INFO - Persisting outputs...\n2021-03-28 09:04:15,787 INFO - Creating data module for output...\n2021-03-28 09:04:15,830 INFO - Data module created for output.\n2021-03-28 09:04:15,831 INFO - Persisting data in home...\n2021-03-28 09:04:16,085 INFO - Home data persisted.\n2021-03-28 09:04:16,086 INFO - [success] Finished execution\n```\n\n簡単．結果はブラウザ上でも確認できる．\n\n## 各種フレームワークへの対応\n上のコマンド`floyd run --gpu --env tensorflow-1.3 \"python train_and_eval.py\"` にある`--env`オプションには，TensorFlowやPyTorch等のフレームワークを指定することができ，バージョンもほぼ揃っているため自前で環境構築をする必要はない．**ここが一番うれしい**．\n\n## スマホから学習進捗の確認\nブラウザベースなのでスマホからもログを確認することができる.\n![CA919EEA-51B5-43C4-A3F9-49729937043C.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/300536/b4615678-df60-8d8f-03d7-b08f7cdf86ae.png)\n\n---\n\n他にも，JupyterLabをベースにしたIDEをブラウザ上で使えたりするので，ご興味がある方は[Core Concepts](https://docs.floydhub.com/getstarted/core_concepts/)を参照していただきたい．\n","user":"Koshka","created_at":"2021-03-29T01:28:04+09:00","updated_at":"2021-03-29T01:58:12+09:00"},{"url":"https://qiita.com/ysys_Ba/items/9a99c250c6cc7634a403","title":"～ MOD ～ チートシート","body":"#目次\n[1-割り算](#1-割り算)\n[2-コンビネーション（nCr）](#2-コンビネーション)\n\n[-1-割り算以外の四則演算](#-1-割り算以外の四則演算)\n[-2-べき乗](#-2-べき乗)　`pow(x,n,MOD)`\n\n#0-はじめに\n\nチートシートの扱いついては[ここ](https://qiita.com/ysys_Ba/items/d27282b888abbd1f43e7#%E3%83%81%E3%83%BC%E3%83%88%E3%82%B7%E3%83%BC%E3%83%88%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6)を読んでください\n\n#1-割り算\n\n```python:mod_1.py\nMOD = 1000000007\n\ndef div(a, b):\n  return ((a % MOD) * pow(b, MOD-2, MOD)) % MOD\n```\n\n#2-コンビネーション\n\n```python:mod_2.py\nMOD = 1000000007\n\ndef div(a, b):\n  return ((a % MOD) * pow(b, MOD-2, MOD)) % MOD\n\ndef Combination(n,r):\n  bunnshi = 1\n  bunnbo = 1\n  for i in range(r):\n    bunnshi = (bunnshi*(n-i))%MOD\n    bunnbo = (bunnbo*(i+1))%MOD\n  return div(bunnshi,bunnbo)\n```\n\n```math\nnCr = \\frac{n!}{r!(n-r)!} = \\frac{n(n-1)...(n-r+1)}{r(r-1)...1}\\\\\n```\nをMOD計算する\n割り算ができれば簡単に実装できる\n\n#-1-割り算以外の四則演算\n\n```python:mod_-1.py\nMOD = 1000000007\n\n(a + b) % MOD\n(a - b) % MOD\n(a * b) % MOD\n```\n\nまあ自明\npythonは負の整数に対しても余りを計算できるので、引き算の時に`(a - b + MOD) % MOD`としなくても正しく計算できる\n\n#-2-べき乗\n\n```python:mod_-2.py\nMOD = 1000000007\n\npow(x, n, MOD)\n```\n\n`x ** n % MOD`を早く正確に計算できる\n詳しくは[こちら](https://qiita.com/ysys_Ba/items/e422b6ab951853dc87d8#1-%E3%81%B9%E3%81%8D%E4%B9%97)\n","user":"ysys_Ba","created_at":"2021-03-29T01:18:42+09:00","updated_at":"2021-03-29T01:18:42+09:00"},{"url":"https://qiita.com/ayato077/items/7695b943d3ae26e48e88","title":"MQTT-BrokerとFluentdをminikubeにデプロイしてみた","body":"#目的と概要\n大学のロボットアームからデータを収集しよう！\nということでロボットに設置したRaspberry PiからMQTTでデータを送信して、データレイクに保存するまでの試験的な実装を考えました。\n\n###Kafkaにデータを送信しなければならない\nサーバー側の環境を確認したところ、入ってくるデータはKubernetes上のKafkaが管理しているとのこと。よってMQTTブローカーとKafkaブローカーをつなぐコネクターが必要なので、オープンソースであるFluentdを利用してコネクターを作成することにしました。エッジデバイス内へのMQTTブローカー設置も考えましたが、なるべく負荷を減らしたいのでこれもKubernetesにデプロイします。**デバイス => MQTT-Broker => Fluentd => Kafka** の流れでデータが移動します。\n\n###本稿の内容\nローカルでminikubeを利用して行なったことを次の順に説明していきます。\n\n1. MQTT-Brokerのデプロイメント\n2. Fluentdのプラグインの追加とDockerイメージの作成\n3. Fluentdのデプロイメント\n\n#開発環境\n- macOS Big Sur, version 11.2.1\n- [Docker](https://www.docker.com/), version 20.10.5\n- [minikube](https://minikube.sigs.k8s.io/docs/), v1.18.1\n- [eclipse-mosquitto](https://hub.docker.com/_/eclipse-mosquitto), v 2.0.9\n- [fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset), v1.12.0-debian-kafka2-1.2\n- [Fluent::Plugin::Mqtt::IO](https://github.com/toyokazu/fluent-plugin-mqtt-io)\n- [fluent-plugin-kafka](https://github.com/fluent/fluent-plugin-kafka)\n\n#事前の準備\nKubernetesのローカル開発環境としてminikubeを使用しました。minikubeはDockerやVirtual Boxなどの仮想マシンマネージャー上で動作します。今回はDockerを使用しました。\n\n1. [Docker](https://www.docker.com/)のインストール\n2. [minikube](https://minikube.sigs.k8s.io/docs/)のインストール\n\nを各ページの指示に従って行いました。動作確認をするためローカルに[mosquitto client](https://mosquitto.org/download/)のインストールもしておくと便利です。\n\n#MQTT-Brokerのデプロイメント\nここから本題に入ります。\n[eclipse-mosquitto](https://hub.docker.com/_/eclipse-mosquitto)を利用してブローカーをminikubeにデプロイしました。こちらはdockerイメージをそのまま使用するので、yamlファイルの作成から始めます。まずはデフォルトの`mosquitto.conf`ファイルを編集するためにConfigMapを作りました。\n###ConfigMapの作成\nConfigMapは設定情報を扱うためのリソースです。各アプリケーション用の設定をConfigMapとしてKubernetesに預けておけば、コンテナのデプロイ時にそれを使って設定ファイルの作成ができます。手元にmosquitto.confがある場合は`kubectl create configmap <your-map-name> --from-file=<your-source-flie>`のコマンドで作成できます。yamlファイルから作成する時は次のような記述をします。\n\n```\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: mosquitto-config-file\ndata:\n  mosquitto.conf: |\n    listener 1883\n    allow_anonymous false\n    password_file /mosquitto/secret/passwd\n```\ndataタグ下の記述はmosquitto.confという名前のファイルの中身が`|`（改行維持の表記）の後に続くテキストにマッピングされることを示しています。`allow_anonymous false`にしているのでブローカーの接続にはユーザー名とパスワードが必須になってます。パスワードファイルの保存先は`password_file /mosquitto/secret/passwd`で設定をしています。\n\n本来はSecretでパスワードファイルのマップを作成するべきですが、デプロイ時のエラーが解決できなかったのと、kafkaへのアクセスはsslを利用するのでひとまずconfigmapで作成しました。mosquittoのパスワードの暗号化は[こちらのサイト](http://www.steves-internet-guide.com/mqtt-username-password-example/)を参考にしました。\n\n###Deploymentの作成\n次のような記述をyamlファイルに追加します。（configmapと同じファイルに記述するときはセパレーター`---`を忘れずに！）\n\n```\napiVersion: apps/v1 \nkind: Deployment\nmetadata:\n  name: mqtt-broker\nspec:\n  selector:\n    matchLabels:\n      app: mqtt-broker\n  replicas: 1 # レプリカの数の指定\n  template:\n    metadata:\n      labels:\n        app: mqtt-broker\n    spec:\n      containers:\n        - name: mosquitto\n          image: eclipse-mosquitto #レジストリのホスト名を指定しない場合は、KubernetesはDockerパブリックレジストリを意味していると見なします。\n          ports:\n            - containerPort: 1883\n          volumeMounts: #　マウント先の指定\n            - name: mosquitto-config\n              mountPath: /mosquitto/config\n            - name: mosquitto-passwd\n              mountPath: /mosquitto/secret\n              readOnly: true\n      volumes: # マップのソースを指定\n        - name: mosquitto-config\n          configMap:\n            name: mosquitto-config-file  #ConfigMapの名前を指定\n        - name: mosquitto-passwd\n          configMap:\n            name: mqtt-passwd\n```\nDocker imageの取得レジストリ、設定のマッピング先などを指定してあげます。これでデプロイすれば新しいPodが作成されて、その中でコンテナが動作するようになりました。\n\n###Serviceの作成\n次にデバイスやFluentdがこのPodと通信できるようにサービスの記述もyamlに追加します。`kubectl expose`コマンドでも可能ですが、次回のデプロイ時にサービス名が違うと困るのでyamlに書きました。\n\n```\napiVersion: v1\nkind: Service\nmetadata:\n  name: mosquitto-service\n  labels:\n    name: mosquitto\nspec:\n  selector:\n    app: mqtt-broker\n  ports:\n  - port: 1883\n    name: mosquitto-port\n    protocol: TCP\n```\n\n### デプロイメント\nこれでyamlの記述は完了です。全体はこんな感じです。\n\n```\n# mosquitto.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: mosquitto-config-file\ndata:\n  mosquitto.conf: |\n    listener 1883\n    allow_anonymous false\n    password_file /mosquitto/secret/passwd\n#---\n## この部分はパスワードファイル用のマップです。記述せずにコマンドでsecretを作成するか、別ファイルからapplyすることをおすすめします\n#apiVersion: v1\n#kind: ConfigMap\n#metadata:\n#  name: mqtt-passwd\n#data:\n#  passwd: |\n#    <your-mosquitto-username>:<generated-password>   \n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mqtt-broker\nspec:\n  selector:\n    matchLabels:\n      app: mqtt-broker\n  replicas: 1 \n  template:\n    metadata:\n      labels:\n        app: mqtt-broker\n    spec:\n      containers:\n        - name: mosquitto\n          image: eclipse-mosquitto\n          ports:\n            - containerPort: 1883\n          volumeMounts:\n            - name: mosquitto-config\n              mountPath: /mosquitto/config\n            - name: mosquitto-passwd\n              mountPath: /mosquitto/secret\n              readOnly: true\n      volumes:\n        - name: mosquitto-config\n          configMap:\n            name: mosquitto-config-file\n        - name: mosquitto-passwd\n          configMap:\n            name: mqtt-passwd\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: mosquitto-service\n  labels:\n    name: mosquitto\nspec:\n  selector:\n    app: mqtt-broker\n  ports:\n  - port: 1883\n    name: mosquitto-port\n    protocol: TCP\n```\nDockerを起動して`minikube start`でクラスターを立ち上げたら、このyamlファイルを`kubectl apply -f ファイル`でデプロイします。`minikube dashboard`でダッシュボードを起動してデプロイが成功したか確認できます。注意点は、作成したサービスが外部からのアクセスポートを持っていないことです。投稿主のローカル環境では`NodePort`からのアクセスはできなかったので、ポートフォワードをしました。`kubectl port-forward svc/mosquitto-service 1883:1883`のコマンドで`ローカルポート:リモートポート`の間にtunnelを通します。これで`localhost:1883`からブローカーにアクセスできるようになりました。\n\n実際の環境では`LoadBalancer`または`NodePort`を使って外部IPを設けることになると思います。\n#Fluentdのデプロイメント\n続いてはFluentdの登場です。Fluentd向けに多数のプラグインが開発されていて、インストールもシンプルです。\n\n（余談ですがRaspberry PiでFluentdを導入した際に`bundle`と`Gemfile`の代わりに`fluentd-gem install`を使用したためエラーが出てしまったので、参考になればと思います。またmacにインストールしたtd-agentにプラグインを追加する場合は、通常の`fluentd-gem`ではインストールできませんでした。プラグインのインストールには`/opt/td-agent/embedded/bin/fluent-gem install <plugin-name>`を使用するようです。）\n\n###FluentdにMQTTプラグインを追加する\nfluentd-kubernetes-daemonsetの[debian-kafka2-fluent](https://github.com/fluent/fluentd-kubernetes-daemonset/tree/master/docker-image/v1.12/debian-kafka2)をダウンロードして編集しました。FluentdのDockerイメージの作成手順は以下の通りです。\n\n1. `Gemfile`に`fluent-plugin-mqtt-io`を追加します。\n2. 次に`docker build -t <name>:<tag> .`でイメージを作成して、`docker image push <image>`でDocker Hubにプッシュします。\n\n次は`fluent.conf`を編集しました。`<source>`タグ内に先ほど作成した`mosquitto-service`からデータを読み込むための設定を書きます。追加部分の例はこちらです。\n\n```\n<source>\n  @type mqtt\n  host \"#{ENV['FLUENT_MQTT_BROKER_HOST'] || 'mosquitto-service'}\"\n  port \"#{ENV['FLUENT_MQTT_BROKER_PORT'] || '1883'}\"\n  topic \"#{ENV['FLUENT_MQTT_SUB_TOPIC'] || 'topic'}\"\n  <security>\n     username \"#{ENV['FLUENT_MQTT_USER'] || 'user'}\"\n     password \"#{ENV['FLUENT_MQTT_PASSWORD'] || 'password'}\"\n  </security>\n  <parse>\n    @type \"#{ENV['FLUENT_MQTT_INPUT_FORMAT_TYPE'] || 'json'}\"\n  </parse>\n</source>\n```\nアドレス情報の他に、購読するトピックや入力タイプの指定ができます。その他設定については[Fluent::Plugin::Mqtt::IO](https://github.com/toyokazu/fluent-plugin-mqtt-io)を参照してください。\n\n###Kafkaプラグインの設定\n今回利用しているリポジトリのDockerfileはKafkaプラグインのインストールが設定済みとなっています。（Docker環境のみで利用する場合は、[FluentdのDocker Hub](https://hub.docker.com/r/fluent/fluentd/)にカスタマイズの方法が記載されています。）\nまた、confファイルに環境変数として定義されているものはyamlファイルから設定ができます。ここではさらにKafkaとの通信のためにTLS/SSLの設定を追加しました。\n\nクライアント認証ができるように、ルート証明書、クライアント証明書、クライアントキーを用意しました。今回は`kubectl create secret generic <secret-name> --from-file=ca_cert.pem --from-file=client_cert.pem --from-file=client_key.pem`でSecretを作成しました。\n\n次は`fluent.conf`の`@type kafka2`を含む`<match>`タグのエリアに\n\n```\nssl_ca_cert /fluentd/ssl/ca_cert.pem\nssl_client_cert /fluentd/ssl/client_cert.pem\nssl_client_cert_key /fluentd/ssl/client_cert_key.pem\n```\nの行を追加してクライアント認証を有効にします。（Kafka側には認証できるようにクライアント証明書のルート証明書を入れておきます）\n\n[fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset)のページのファイルを参考にFluentd-Kafka用のyamlファイルを作成します。secretのvolumes設定にsecretNameではなくnameを使ってコンソールに怒られました。\n\n```\nvolumes:\n- name: fluentd-config\n        configMap:\n            name: fluent-conf\n- name: fluentd-kafka-tls\n        secret:\n            secretName: tls-secret\n```\n\nこれで設定は完了です。あとは`kubectl apply -f`でデプロイして動作確認をしました。\n\n###動作の確認\nローカルのmosquittoからpublishしました。MosquittoからFluentdへのデータ送信については、`fluentd.conf`内のKafka用の`<match>`タグ内を`@stdout`のみに書き換えてデプロイした後、ターミナルかダッシュボードでログを確認しました。Kafka側の出力は既にGrafanaがあったので、ない場合はKafka-Consumer等でログが確認できると思います。\n\n今回の実装で行なったことは以上です。\n\n近いうちに**Kafka => telegraf/Fluentd => influxDB**のルートの実装も予定してるので、そちらに関しても投稿できればと思っています。\n\n#その他参考にしたもの\n[Kubernetesドキュメント](https://kubernetes.io/ja/docs/home/)\n[Kubernetes Fluentd](https://docs.fluentd.org/v/0.12/articles/kubernetes-fluentd)\n[Kubernetes ConfigMap and Secret as Kubernetes Volumes | Demo (youtube)](https://www.youtube.com/watch?v=FAnQTgr04mU&t=580s)\n\n\n\n","user":"ayato077","created_at":"2021-03-29T01:17:46+09:00","updated_at":"2021-03-29T01:17:46+09:00"},{"url":"https://qiita.com/greed_1998/items/8077ba8de6ac74deaa87","title":"ARC116 振り返りメモ(B問題まで)","body":"#結果\nAの1完で, レート変化は<font color=\"Maroon\">729</font>→<font color=\"Maroon\">713</font> (-16)\n\n#[A問題 ( Odd vs Even )](https://atcoder.jp/contests/arc116/tasks/arc116_a)\n###概要\n> N の約数のうち, 偶数のものと奇数のものの個数を比較する.\n\n###方針\nN を素因数分解することを考えると, \n\n```math\nN = 2^d \\times a　(aは奇数)\n```\nという風に素因数分解できるはずである.\nd = 0のときは, 奇数の約数しか持たないので, 当然奇数の約数の方が多い.\nd = 1のときは, 奇数と偶数の約数の個数は等しくなる.\nd > 2のときは, 偶数の約数の方が多くなる.\n\nまとめると, 4で割った余りが1または3のときは奇数の方が多くなり, 2のときは等しくなり, 0の時は偶数の方が多くなる.\n\nC++ での実装例は以下のようになる.\n\n```cpp:a.cpp\n#include <bits/stdc++.h>\nusing namespace std;\n#define rep(i,n) for (long long i = 0; i < (n); i++)\nusing ll = long long;\n\nint main() {\n    ll t; cin >> t;\n    rep(i, t) {\n        ll n; cin >> n;\n        if (n % 4 == 1 || n % 4 == 3) cout << \"Odd\" << endl;\n        if (n % 4 == 0) cout << \"Even\" << endl;\n        if (n % 4 == 2) cout << \"Same\" << endl;\n    }\n    return 0;\n} \n```\n\n#[B問題 ( Products of Min-Max )](https://atcoder.jp/contests/arc116/tasks/arc116_b) \n###概要\n> 長さNの整数列(A)の空でない全ての部分列(B)に対して, それぞれmax(B) * min(B) を計算し, その総和を求める.\n\n### 方針\nminの添字をi, maxの添字をjとすると, \nA[i] * A[j] * 2 ^ (j - i - 1) \nを全ての(i, j)の組について計算すれば良い.\nが, 愚直に計算するとO(N^2)となって計算が間に合わなくなってしまう.\nそのため, i を固定して, jをi+1~n まで動かす部分をまとめて計算する.\n\n\nC++ での実装例は以下のようになる.\n\n```cpp:b.cpp \n#include <bits/stdc++.h>\nusing namespace std;\n#define rep(i,n) for (long long i = 0; i < (n); i++)\nusing ll = long long;\n\nconst ll MOD = 998244353;\n\nint main() {\n    ll n; cin >> n;\n    vector<ll> a(n);\n    rep(i, n) cin >> a[i];\n    sort(a.begin(), a.end());\n    ll ans = 0;\n    // max と min が同じ値の場合の処理\n    rep(i, n) {\n        ans += a[i] * a[i] % MOD;\n    }\n    ll mx = 0;\n    for (ll i = 1; i < n; i++) {\n        mx = 2 * mx;\n        mx += a[n-i];\n        mx %= MOD;\n        ans += a[n-i-1] * mx % MOD;\n        ans %= MOD;\n    }\n    cout << ans << endl;\n    return 0;\n} \n```\n\n\n\n\n","user":"greed_1998","created_at":"2021-03-29T01:11:36+09:00","updated_at":"2021-03-29T01:11:36+09:00"},{"url":"https://qiita.com/wakiguchi/items/ae81ddd15d2dbb18d12c","title":"DoxygenとGraphvizでC++コードのドキュメントを作る","body":"#目次\n[０．doxygenとは](#doxygenとは)\n[１．環境構築](#環境構築)\n[２．ソースコード記述](#ソースコード記述)\n[３．プロジェクト作成](#プロジェクト作成)\n[４．ドキュメント出力](#ドキュメント出力)\n\n#doxygenとは\n**メリット**\n・コードに設計内容が埋め込まれているため、コードと設計書の乖離が軽減され保守性が向上する\n・コメントにDoxygenに対応したタグを埋め込むだけなので低コストで詳細設計書が作成可能である\n![ドキュメント生成の流れ-1024x423.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/803090/5886e2d7-e045-e5c9-55c8-1cca6714b36a.png)\n\n【引用】[【C/C++】ドキュメント作成(doxygen)まとめ](https://www.mathkuro.com/c-cpp/doxygen/) \n\n#環境構築\n・Doxygenのインストール\n・Graphvizのインストール\n\nこちらを参考に構築。環境変数のパスだけ気を付ける。\n【参考】[最近覚えた便利アプリ[doxygen]](https://qiita.com/wakaba130/items/faa6671bd5c954cb2d02) \n\n```terminal:consol\n>doxygen  -v\n1.9.1 (ef9b20ac7f8a8621fcfc299f8bd0b80422390f4b)\n>dot -V\ndot - graphviz version 2.47.0 (20210316.0004)\n\n```\n\n#ソースコード記述\n```c++:sample.cpp\n/*! @class Class1\n    @brief  クラスの説明\n*/\nclass Class1 {\npublic:\n    /*! メンバ1の説明 */\n    int member1;\n\n    int member2; /*!< メンバ2の説明を横につける */\n\n    /*! メソッド1の説明 */\n    int method1(int var1, int var2);\n\n    /*! メソッド2の説明。詳細説明\n        @param[out]     var1    var1の説明\n        @param[in]      var2    var2の説明\n        @param[in,out]  var3    var3の説明\n        @par            Refer\n        - 参照するグローバル変数 global_var1\n        - 参照するグローバル変数 global_var2\n        @par            Modify\n        - 変更するグローバル変数 global_var3\n        - 変更するグローバル変数 global_var4\n        @return         成功 0, 失敗 0 以外 など\n        @exception      例外。不要であればnoneを記述\n    */\n    int method2(int var1, int var2, int var3) {\n\n    }\n};\n/*! @class Class2\n    @brief  クラスの説明\n    クラスの詳細\n*/\nclass Class2 {\npublic:\n    /*! メンバ1の説明 */\n    Class1 class_obj1;\n};\n};\n```\n\n#プロジェクト作成\nDoxywizardを使ってプロジェクト作成。\nRUNボタンでHTMLが生成される。DoxyfileでConfigurationを直接編集もできる。\n<img width=\"300\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/803090/754d2f76-d9dd-c53c-0b4f-2678bbb5ad1e.png\">\n\n【参考】[Graphviz の設定](https://blog.cercopes-z.com/doxygen-diagrams-auto/) \n\n#ドキュメント出力\n![html.PNG](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/803090/d15e2c4d-ac72-4448-cf21-3695e15c7f0e.png)\n","user":"wakiguchi","created_at":"2021-03-29T01:10:29+09:00","updated_at":"2021-03-29T01:10:29+09:00"},{"url":"https://qiita.com/ZAKILOG1/items/9fca2ba0e52e2f7c904b","title":"ethreumアプリを作成してみた","body":"最近、仮想通貨の仕組みに興味がありまして、実際にブロックチェーンを用いたアプリケーションを作ってみようということにしてみました。dappsで一番主流と言われているethreumを使って、どんな感じか触ってみてます。\n\ndappsとは、実際の仮想通貨口座とアプリケーションを紐付けてやりとりができるアプリケーションだと認識してます。\n\nhttps://github.com/PaulRBerg/create-eth-app\n\n上記のlibraryを起動させれば簡単な手順でローカル開発環境を整えることができます。\n初期の状態でmetamaskとの連携ができるって感じですね。\n\nmy-eth-app\n├── README.md\n├── node_modules\n├── package.json\n├── .gitignore\n└── packages\n    ├── contracts\n    │   ├── README.json\n    │   ├── package.json\n    │   └── src\n    │       ├── abis\n    │       │   ├── erc20.json\n    │       │   └── ownable.json\n    │       ├── addresses.js\n    │       └── index.js\n    ├── react-app\n    │   ├── README.md\n    │   ├── package.json\n    │   ├── node_modules\n    │   ├── public\n    │   │   ├── favicon.ico\n    │   │   ├── index.html\n    │   │   └── manifest.json\n    │   └── src\n    │       ├── App.css\n    │       ├── App.js\n    │       ├── App.test.js\n    │       ├── ethereumLogo.svg\n    │       ├── index.css\n    │       ├── index.js\n    │       ├── serviceWorker.js\n    │       └── setupTests.js\n    └── subgraph\n        ├── README.md\n        ├── abis\n        │   └── erc20.json\n        ├── package.json\n        ├── schema.graphql\n        ├── src\n        │   └── mappings\n        │       ├── tokens.ts\n        │       └── transfers.ts\n        └── subgraph.yaml\n\n\n初期構成は、上記でしてreactアプリケーションとして構成されてます。metamaskとのやりとり以外は通常のアプリケーションと大層変わりがないようかなと感じてます。\npackages内のcontracts react-app subgraphの三つのディレクトリが根幹に関わってくるコントラクトとreactアプリケーションとgraphqlに似たapiかなって感じですね。\n500mb近いアプリケーションになっているので初期状態から結構重めだなって印象です。\n\n日本の記事は限りなく少ないので随時増やせていけたらなと思います。以上です！\n","user":"ZAKILOG1","created_at":"2021-03-29T01:08:06+09:00","updated_at":"2021-03-29T01:08:06+09:00"},{"url":"https://qiita.com/tk_ppp/items/2de68357844fd2efde5c","title":"Integromatを使ってアクセス制限つきGASを外部サービスのwebhookから実行する","body":"# 概要\n\n何かと便利なGAS(Goole Apps Script)はwebアプリケーションやAPIとして公開することもできます。\nしかし、G Suiteを利用していて組織外に公開できない場合などは外部サービスのwebhookなどとの連携にOAuth認証が必要となりやや複雑です。\n今回はIntegromatを用い、実行可能なGoogleアカウントが制限された状態でもGASで作成した実行可能APIを外部のwebhookから実行できる構成を試しました。\nなお、webhookの例としてChatworkを用います。\n\n※組織的に本当にAPIを外から叩けるようにするのが良いのかは各自のご判断でお願いします\n\n### 今回の目標\n* GASで作成したAPIを組織内のみに公開した状態で、ChatworkのwebhookからのデータをGASで受け取れるようにする\n* OAuthのアクセストークンのリフレッシュが自動で行われるようにする\n\n### 構成\n最終的な構成は以下のようなイメージです。\n![スクリーンショット 2021-03-29 0.58.17.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/d00da292-6353-1b42-2e61-c04851397463.png)\n\n### Integromatについて\nIFTTTやZapierのようなノーコードで複数のAPIを簡単に接続することができるサービスです。\n1000リクエスト/月までは無料で使うことができます。(21/3/27現在)\n\nhttps://www.integromat.com/\n\n# 実装\n以下のような流れで実装を推めていきます。\n1. [スクリプトの用意](スクリプトの用意)\n2. [実行可能API形式でGASを公開するためのGCP設定](実行可能API形式でGASを公開するためのGCP設定)\n3. [APIの公開](APIの公開)\n4. [IntegromatによるOAuth認証つきリクエストの作成](IntegromatによるOAuth認証つきリクエストの作成)\n5. [外部サービスのwebhookとの接続](#外部サービスのwebhookとの接続)\n\n### スクリプトの用意\n今回は、とりあえず適当なスプレッドシートにバインドした形で以下のようなスクリプトを用意しました。これをwebhookで呼び出せるようにします。\n\n```js\nfunction testFunc(param) {\n  return { \n      sheet_name : SpreadsheetApp.getActiveSheet().getName() // \"hogehoge\"\n    , param      : param\n  };\n}\n```\n\n### 実行可能API形式でGASを公開するためのGCP設定\n実行可能API形式で使用するにはいくつか下準備が必要になります。\n[公式ドキュメント](https://developers.google.com/apps-script/api/how-tos/execute#requirements)をざっくり要約すると、\n\n* GCPのプロジェクトと紐付けて適切なOAuthのスコープをクライアントに与えてね\n* GCPプロジェクトでGoogle Apps Script APIを有効化してね\n* 実行可能API形式でデプロイしてね\n\nという感じです。まずはGCP周りの設定を行います。\n\n#### プロジェクトの作成\nまずは[GCPにのダッシュボード](https://console.cloud.google.com/home/dashboard)にアクセスし、こんな感じでプロジェクトを作成します。\n![スクリーンショット 2021-03-27 22.04.36.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/989558a1-44d6-4700-8a1a-eb4c526fd25d.png)\n\nその後プロジェクト選択してダッシュボードに戻ると、プロジェクトIDが表示されるのでメモしておきます。\n![スクリーンショット 2021-03-27 22.05.49.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/60e758e4-fb8c-8b39-88b4-8f752b5fb605.png)\n\n#### APIの有効化\nプロジェクトを作成したら、メニューから「APIとサービス」に遷移し、「APIとサービスの有効化」を選択します。\n![スクリーンショット 2021-03-27 22.08.23.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/b9dec549-d2c5-5876-5c9e-a8e9561050e1.png)\n\nすると各種APIが検索できる画面に切り替わるので、実行に必要なAPIを探して有効化していきます。\n今回はApps Script APIと、スプレッドシートを利用するのでSheets APIを検索して有効化しました。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/a7f873d8-0c8a-9137-8ebd-077dd08e4640.png\" width=\"300\"/><img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/8da95f3c-597f-3cfb-1f2c-241eb6da70a9.png\" width=\"300\"/>\n\nなお、スクリプトが必要とするスコープはGASのエディタの概要から確認できます。\n![スクリーンショット 2021-03-27 22.25.47.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/d459fc71-de91-3097-3bc2-454046dbe57f.png)\n\n#### OAuth関連の設定\n次に、メニューから「APIとサービス」>「OAuth同意画面」へ遷移します。\nG Suiteユーザでは最初に公開範囲を確認されますが、「内部」を選択します。\n![スクリーンショット 2021-03-27 22.11.50.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/82580848-11e3-7a7c-00ec-10a07b4dda5a.png)\n\nその後の設定画面については、アプリ名とメールアドレスなどの必須項目だけ入力してあとは無視して進めます。\n\n同意画面の設定が終わったら、同じ「APIとサービス」から「認証情報」を開き、OAuthクライアント IDを発行します。\n![スクリーンショット 2021-03-27 22.16.52.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/111bdc79-67c0-6bb5-8b5c-124d65028a88.png)\n\n種類はwebアプリケーションを選び、リダイレクトURIはIntegromatでの認証のため「`https://www.integromat.com/oauth/cb/oauth2`」を入れます。\n![スクリーンショット 2021-03-27 22.18.17.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/8050d48b-52bf-1746-40c9-f01f39db0c48.png)\n\n作成を押下するとクライアントIDとクライアントシークレットが発行されるので、そちらをメモしておきます。\n\n最後にGASのエディタに戻り、設定から「プロジェクトを変更」を押下して先ほどコピーしたプロジェクトIDを入れます。\nこれでGCP周りの設定は完了です。\n![スクリーンショット 2021-03-27 22.00.38.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/d7136787-af64-9e68-0528-990943628b40.png)\n\n### APIの公開\nGCPの設定が終わったらAPIの公開です。\n画面右上のデプロイから「新しいデプロイ」に進み、その後出てくるウインドウにて、種類を「実行可能API」と設定します。(GCPの設定を先にしていないとここでエラーが出ます）\n\n![スクリーンショット 2021-03-27 22.36.59.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/9841a4e9-00bd-521b-d596-f206a247b7c0.png)\n\nこの時、G Suiteアカウントであれば「[組織名]内の全員」という選択があるので、それを選びます。\n個人利用でアクセス制限をかけたい場合は「自分のみ」にします。\n\n![スクリーンショット 2021-03-27 22.37.26.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/8ccdc495-5a08-0d6e-93e9-e2adce83807b.png)\n\nデプロイボタンを押すと「実行可能API」のURLが表示されるのでメモしておきます。\nなお、このURLはデプロイをするたびに変更になるので注意が必要です。\n![スクリーンショット 2021-03-28 2.44.42.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/14dad206-f012-1e9c-f56f-be810e025e63.png)\n\nこれでスクリプトを公開できました。\nただしアクセス制限があるので、試しにPostmanなどを使ってOAuth認証なしのリクエストを投げてみると認証エラーが返ってきます。\nwebhookで利用するにはアクセストークンを付加した継続的なリクエストが発行できる状態にする必要があります。\n\n```json\n{\n    \"error\": {\n        \"code\": 401,\n        \"message\": \"Request had invalid authentication credentials. Expected OAuth 2 access token, login cookie or other valid authentication credential. See https://developers.google.com/identity/sign-in/web/devconsole-project.\",\n        \"status\": \"UNAUTHENTICATED\"\n    }\n}\n```\n\n### IntegromatによるOAuth認証つきリクエストの作成\n継続的にOAuthのアクセストークンを含んだリクエストを送れるようにするために、[Integromat](https://www.integromat.com/\n)を設定していきます。\n\n#### シナリオの作成とOAuth設定\nIntegromatではシナリオ内に各種サービスの連携を定義するので、そのシナリオの作成です。\nなお、この辺りの設定は基本的に[Integromat公式チュートリアル](https://support.integromat.com/hc/en-us/articles/360008096679-Calling-Google-APIs-via-the-HTTP-Make-a-OAuth-2-0-request-module)(手順12以降)に結構詳細な説明があってその通りに進めるだけなので適度に割愛します。\n\nまずIntegromatにログインしたら、新規シナリオを作成します。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/b912852a-9fd3-1ed1-36a2-7643dbeb3b6b.png\" width=\"600\">\n\nサービスを選ぶ画面が表示されますが、まずは単純に先ほどのAPIを叩く部分だけ作れれば良いのでHTTPだけ選択して先に進みます。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/73aecb4a-2fab-5a49-2ce7-73ba86c4ec41.png\" width=\"300\">\n\nシナリオの編集画面に切り替わるので、右下のアイコンからOAuth2.0通信のリクエストを選択します、\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/9425d6b3-a5c4-00d0-2a27-85c9fa634415.png\" width=\"600\">\n\nHTTPモジュールのアイコンが画面上に追加されるのでそれをクリックして設定画面を開きます。\nすると各種情報を設定するウインドウが開くので、OAuth接続の情報を設定するために一番上のConnectionの「Add」を選択します。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/ce2fdbe7-3bc8-bb21-57c2-dbb6c72c7deb.png\" width=\"400\">\n\nするとOAuth認証用の情報を入力するウインドウが出てくるので、入力欄を埋めていきます。(URIなどはチュートリアルのページに文字で記載があるのでそれをコピペしてください。)\n補足としてはこんなところです。\n\n* ここでGCPのプロジェクト作成後にメモしておいたClient IdとClient Secretを使います。。\n* ウインドウ下部の「Show advanced settings」にチェックを入れないと全設定ができないので注意してください。\n* Scope separatorはデフォルトで`COMMA`になっているのでこちらも注意です。（GoogleのScope指定はスペース区切りらしい）\n* 私の環境では、チュートリアルにInformationとして記載している`prompt - consent`のペアをAuthorize parmetersに入れないと動きませんでした。\n\n![スクリーンショット 2021-03-27 22.28.26.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/a9534715-9942-b558-9752-5c994699b781.png)\n\n上記画像のように全て入力したあと「Continue」を押すと、GoogleのOAuth認証画面が開くので、APIを実行させたいアカウントで認証を進めてください。\n![スクリーンショット 2021-03-27 22.30.08.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/cb20100f-3eeb-059a-5245-1fc177607fe2.png)\n\nOAuth接続の画面が問題なく進めば、Integromatの画面でOAuthコネクションのウインドウが自動で閉じられます。\n\n#### APIへのリクエスト設定\nOAuthの設定が終わったら、あとはhttpリクエスト本体の設定をしていきます。\nURLには先に公開しておいたGASの実行可能APIのURLを入力します。\nリクエストボディの中身は[こちらのドキュメント](https://developers.google.com/apps-script/api/reference/rest/v1/scripts/run#request-body)を参照のうえ、入力してください。\n今回はパラメータが渡ってくることさえ確認できればいいので、こんな感じ。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/e477ccbc-7e06-e440-198e-36038a212b7c.png\" width=\"400\"/>\nここまで入力できたらOKを押して設定を完了させます。\n\n#### 接続確認\nここまで設定できたら、テスト実行をしてみます。\n\nテスト実行をするにはモジュールのアイコンを右クリックし、「Run this module only」を選択します。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/4f66de0f-ad3e-4297-a5c4-7ff2535a8f3f.png\" width=\"300\"/>\n\n実行が終わるとモジュールの右上に吹き出しが出るので、それをクリックすると通信の詳細が表示されます。\n今回はシート名と送ったパラメータ名をただ返すだけのAPIなので、このようなレスポンスが返ってくれば成功です。\nここでステータスコードが400などで返ってくる場合は認証周りなどがおかしいので設定を見直しましょう。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/6902f825-f0ff-aaa5-10c1-2732b768c02a.png\" width=\"500\"/>\n\nなお、Googleのアクセストークンは有効期限が1時間なので、初回の実行から1時間以上あけて再度実行した時にはリフレッシュトークンを用いたアクセストークンの自動更新が走ります。\n基本的にはこちらで何もしなくてもIntegromatの裏側で更新してくれるのですが、もし1時間後に実行してステータスコードが401になる場合は、OAuthの設定の見直しやクライアントの作り直しなどをすれば解決するかもしれません。\n\n以上でIntegromatでOAuth認証を含めてGASのAPIを実行する設定は完了です。\n画面下部のアイコンからシナリオを保存しておきます。\n\n### 外部サービスのwebhookとの接続\nここまできたら、あとは外部サービスのwebhookをIntegromatで拾って、その内容を先ほどのhttp通信のbodyに反映させられれば完成です。\n\n#### Integromat上でのwebhook受け口準備\n先ほどのシナリオ編集画面上で、下の画像のような「？」のアイコンが出ていると思います。\nこれを選択するとモジュール選択画面になるので、「Webhooks」を検索してその中の「Custom webhook」を選択します。\n※Chatwork専用のモジュールも存在しますが、あくまでサンプルなので今回は汎用的なWebhooksを使用しました\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/9994687e-ce3b-6801-e3b3-346fbcf95a19.png\" width=\"300\"/>\n\nWebhooksのモジュールが画面に表示されたら、httpの時と同じようにクリックして設定を開きます。\nWebhookの設定が空になっているので「Add」をクリックしてコネクション設定を追加します。\nここではwebhookの名前さえ入れておけば他は何も入力しなくても設定を勧められるのですが、今回はadvanced settingsの「JSON pass-through」にチェックを入れます。\nこれにチェックを入れると渡ってきたJSONを1つの文字列としてそのまま使用することができます。\n今回チェックを入れるのは、Integromat上でJSONの中身を見たりするのではなく、そのままGASに流したいので文字列のままの方が扱いやすいためです。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/d66e8f71-c848-7963-3eef-47458f5a9105.png\" width=\"300\"/>\n\n以上を設定して「Save」を押すと、webhookの欄が埋まるのと同時に、URLが表示されます。\nこれがIntegromatがwebhookを受付けるためのURLですので、こちらをコピーしておきます。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/2e1328e0-3ffe-8c84-a077-9afa73be8d5f.png\" width=\"400\"/>\n\nまた、同時に画面中央あたりに「Stop」というボタンが出ています。\nその上にある説明文の通りですが、これはwebhookでどんなデータ構造が送られてくるのかをチェックするために待機している状態です。\nこの状態で実際のwebhookを受け取ると、「このwebhookはこういうデータ構造なんだ」と解釈してくれますので、Chatwork側の設定を推めます。\n\n#### Chatwork側のwebhook設定\nここは本題ではないので簡単に。\n先ほどコピーしておいたIntegromatのURLをChatwork側のwebhookに設定します。\n今回は特定ルームへの投稿でキックされるwebhookとします。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/967cb7ce-f8a5-5178-ce2c-ee7782dda6e5.png\" width=\"400\"/>\n\n設定が終わったら、対象のルームで投稿してみます。\nすると、Integromatでの方で実行待ちしていた画面が切り替わるはずです。\n\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/9c6baede-7e47-ba3a-51b7-514c645ed715.png\" width=\"400\"/>\n\nこれでChatworkのwebhookからIntegromatでデータを受け取る準備はできました。\n\n#### webhookのデータをGASに流す設定\nIntegromatのシナリオ画面にて、webhooksモジュールの右側にカーソルを当てると現れる「+」から新たにJSONモジュールを繋ぎ、Aggregate to JSONを選択します。\n後にGASのAPIに投げるときのparametersに入れるJSONを生成するためです。\n\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/8d0c1511-767d-72b8-eb58-3d784e6519a2.png\" width=\"300\"/>\n\n先ほどの手順でwebhookのデータ構造がうまく定義できていれば、画像のように、テキストエリアにフォーカスを当てると、選択肢が出てきます。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/c98b28ec-f072-c749-88d0-ada8065163fb.png\" width=\"５00\"/>\n\nこの`value`と`chatwork_webhook_signature`をそのままJSONでGASに流したいので、データ構造と値を定義していきます。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/0f6b8691-e3c4-7d9b-e4f3-97dd75f98a08.png\" width=\"５00\"/>\n\nそして、最後に今作ったJSONモジュールと、最初に作ったGASのAPIにリクエストを投げるhttpモジュールを繋ぎ、リクエストボディのparametersの部分をJSONモジュールで作成した文字列に変えます。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/efb90066-4eb7-2d6c-6a2b-3b5983732080.png\" width=\"５00\"/>\n\nIntegromatの画面では最終的にこのような形になっているはずです。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/da577cf5-db91-f1ad-72c3-32bcbf2eaff8.png\" width=\"400\"/>\n\nシナリオを保存したら、最後に画面左上の「<-」ボタンを押して右上のアクティブ状態を「ON」にします。\n![スクリーンショット 2021-03-28 0.24.28.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/7802dda2-aef1-b357-16bd-b17168a0477a.png)\n\n以上で、webhookからGASのAPIにつなぐ設定は完了です。\n\n#### 動作確認\nChatworkの監視対象のルームに戻り、また適当な投稿をしてみます。\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/ba720834-3a7d-5b55-53d5-995afe4a6aa0.png\" width=\"300\"/>\n\nIntegromatのHISTORYタブに移動し、最新の実行ログのDetailsを確認していきます。\nHTTPを試しに実行した時のようにモジュールに吹き出しがついているはずなので、それをクリックして実際の通信状況について見てみると、webhooksで受け取ったjsonがそのままhttpのモジュールでGASに送信されていることがわかります。\n※valueの中身のJSONは文字列として受け取った関係でエスケープが入ってます\n\n<img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/035327d7-2a8c-72c6-eb45-5eac1e381dc4.png\" width=\"400\"/><img src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/86185/c715085c-7775-2b20-e578-7aec6a39892b.png\" width=\"400\"/>\n\nこれで全工程が完了です。\n今回はダミーのスクリプトでしたが、接続するサービスやスクリプトの内容を工夫すれば様々なタスクを自動化できそうです。\n\n# 最後に\n今回は外部サービスのwebhookをGASの実行可能APIで受け取るための構成を試してみました。\nIntegromatもGCPを用いたOAuth認証もほぼ触ったことなかったのでもしかすると非常に効率の悪いやり方をしてしまっているかもしれません。\nもし何かおかしな点があればご指摘いただけますと幸いです。\n\n","user":"tk_ppp","created_at":"2021-03-29T01:06:51+09:00","updated_at":"2021-03-29T01:06:51+09:00"},{"url":"https://qiita.com/Fin_Metis/items/9db4c9ccfd680317e35f","title":"機械学習による米雇用統計予測","body":"金融市場で最も注目度の高い経済指標の一つである米雇用統計を機械学習を用いて予測してみた。\n\n#米雇用統計とは\n非農業部門で働く就業者数を集計したもので、通常、毎月第一金曜日に発表される経済指標。\n米連邦準備理事会（FRB）は「雇用の最大化とインフレの安定」というデュアルマンデートを持っていることもあり、雇用情勢を図る上で非常に注目度は高いものとなっている。\n\n#データ\n2002年1月から2021年2月までのデータから、パンデミックによる外れ値（2020年3月から9月）を除いた223個を使用。非農業部門雇用者数変化（前月比）を目的変数とし、ADP雇用統計や新規失業保険申請件数、消費者信頼感指数の雇用見通し等、21個を特徴量として採用した。\n\n#特徴量エンジニアリング\n消費者信頼感の雇用見通しについて、\"positive - negative, positive/negative\"等、四則演算を用いてさらに特徴量を生成。日付データに三角関数を適用することで、月毎のシーズナリティも考慮した。\nまた、偽の特徴量を追加し、検定により特徴量を15個まで削減した(Boruta)。\n\n#アルゴリズム\nランダムフォレストを採用。LightGBMやXGBoostも試したが、データ数が少ないためか収束せず。\n\n#ハイパーパラメータチューニング\noptunaを用いて以下のハイパーパラメータをチューニングした。\n\n```python\nrf_max_depth = trial.suggest_int('rf_max_depth', 2, 32)\nn_estimators = trial.suggest_int('n_estimators', 10, 100, 10)\nmax_features = trial.suggest_loguniform('max_features', 1e-1, 1)\n```\n\n#結果\n絶対平均誤差（MAE）と決定係数（R2)を用いてモデルを評価した。誤差の単位は[千人]。\n\n|  | データ処理前 | 特徴量エンジニアリング後 | ハイパーパラメータチューニング後 |\n|:-----------|------------:|:------------:|:------------:|\n| MAE       | 86.6         | 76.8         | 73.7          |\n| R2     | 0.778      | 0.850      | 0.869           |\n\n<img width=\"400\" alt=\"predict_acctual.png\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1248754/e6c284d6-1807-94e8-aa67-0e447124fee4.png\">\n\n\n\n#終わりに\n毎月金曜日発表の非農業部門雇用者数は速報値であり、発表後二ヶ月に渡り遡及改定される。速報値と改定値の誤差と決定係数は以下の通りであり、このブレが雇用統計予測モデルの限界である。\n\n|  | 速報値と改定値 | \n|:-----------|------------:|\n| MAE       | 56.1         | \n| R2     | 0.886      |\n\n\n<img width=\"400\" alt=\"first_revision.png\" src=\"https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1248754/08c3022f-9581-278d-97df-38ee09e0a820.png\">\n\nまた、説明変数に用いたADP雇用統計は、雇用統計に合わせた年次改定を行っているため、上記のモデルではLeakageの影響が入ってしまっている。とはいえ、ADP雇用統計は、非農業部門雇用者数の予測をするために開発されたものであり、説明変数としては外せなかった。\n\n\n","user":"Fin_Metis","created_at":"2021-03-29T00:59:04+09:00","updated_at":"2021-03-29T00:59:04+09:00"},{"url":"https://qiita.com/yonahaty/items/08677a786a523e60357c","title":"【メモ】 JSON 概要 ","body":"JSONを初めて使用したので、概要だけまとめておく。\n\nおおむね、下記の3パターンを階層的に組み合わせていく。\n\n## オブジェクト型\n### json\n```\n{\n\t\"id\": \"001\",\n\t\"name\": \"taro\"\n}\n```\n\n### java\n```\n// マッピング\nJsonSampleBean bean = mapper.readValue(json, JsonSampleBean.class);\n\n// Beanの定義\npackage com.example.app.bean.json.request;\n\nimport lombok.Getter;\nimport lombok.Setter;\n\n/**\n * JSONマッピング用のオブジェクト。\n *\n * @author start\n */\npublic class JsonSampleBean {\n\n\t/** ID */\n\t@Getter\n\t@Setter\n\tprivate String id;\n\n\t/** 名称 */\n\t@Getter\n\t@Setter\n\tprivate String name;\n\n}\n```\n\n## リスト（配列）型\n### json\n```\n{\n\t\"sampleList\": [\n\t\t{\n\t\t\t\"id\": \"001\",\n\t\t\t\"name\": \"taro\"\n\t\t},\n\t\t{\n\t\t\t\"id\": \"002\",\n\t\t\t\"name\": \"jiro\"\n\t\t}\n\t]\n}\n```\n\n### java\n```\n// マッピング\nJsonSampleListBean list = mapper.readValue(listJson, JsonSampleListBean.class);\n\n// Beanの定義\npackage com.example.app.bean.json.request;\n\nimport java.util.List;\n\nimport lombok.Getter;\nimport lombok.Setter;\n\n/**\n * JSONマッピング用のオブジェクト。\n *\n * @author start\n */\npublic class JsonSampleListBean {\n\n\t/** ID */\n\t@Getter\n\t@Setter\n\tprivate List<JsonSampleBean> sampleList;\n\n}\n```\n\n## マップ型\n### json\n```\n{\n\t\"key1\": {\n\t\t\"id\": \"001\",\n\t\t\"name\": \"taro\"\n\t},\n\t\"key2\": {\n\t\t\"id\": \"002\",\n\t\t\"name\": \"jiro\"\n\t}\n}\n```\n\n### java\n```\n// マッピング\nMap<String, JsonSampleBean> map = mapper.readValue(mapJson, new TypeReference<LinkedHashMap<String,JsonSampleBean>>(){});\n\n// Beanの定義\n// 省略\n```\n","user":"yonahaty","created_at":"2021-03-29T00:52:36+09:00","updated_at":"2021-03-29T00:52:36+09:00"},{"url":"https://qiita.com/yoshi-heita/items/fe9ea7229ed8d04758c3","title":"ツイートデータのテキストマイニング","body":"<a href=\"https://qiita.com/yoshi-heita/items/344711b3831b92ddbbdb\" target=\"_blank\">前回</a>の続きです。\nツイッターで検索するワードは、<font color=\"Red\">**自動車メーカー3社（トヨタ・日産・ホンダ）の社名**</font>と合わせ、昨今話題の<font color=\"Red\">**「自動運転」**</font>が同時にツイートされているものを対象としました。\n\n# やりたいこと・処理の流れ\n* __概要__\n     * 収集したツイートデータを適宜整形・加工し、形態素解析を行う\n     * 品詞ごとの頻度集計を行い、ワードクラウドとしてプロットしてみる\n     * 単語間の係り方を図示すべく、n-gram集計(今回はn=2)し、<a href=\"https://khcoder.net/scr_3wnew.html#net\" target=\"_blank\">共起ネットワーク</a>を描いてみる \n\n* __前提__\n     * MeCabやimportする各種ライブラリのインストールが済んでいること\n     * PythonとMeCabの連携、Pythonバインディングのインストールが済んでいること\n     * お好みでシステム辞書の拡張(mecab-ipadic-neologd)、ユーザー辞書の作成・コンパイルが済んでいること\n\n* __完成イメージ__\n     * 日別推移  \n     ![日別推移.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/2817c77d-9139-1868-24b7-edda2d9db806.png)\n\n     * ワードクラウド\n     ![ワードクラウド.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/08e5ee74-82b9-c006-5f64-5ac2350d4461.png)\n\n     * 共起ネットワーク\n     ![共起ネットワーク.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/e6609a4f-4530-7bf5-4c52-02194a086df3.png)\n\n* __参考サイト__\n     * ワードクラウドの関数部分：<a href=\"https://www.takapy.work/entry/2019/01/14/142128\" target=\"_blank\">TF-IDFで見る評価の高いラーメン屋の口コミ傾向（自然言語処理, TF-IDF, Mecab, wordcloud, 形態素解析、分かち書き）</a>\n     * 共起ネットワークの関数部分：<a href=\"https://qiita.com/hanon/items/a2000da2f70d6c14ca5b\" target=\"_blank\">MeCabとnetworkXを使って共起ネットワークを書いたのでコードをメモっておく</a>\n\n# コードと出力結果\n* __前処理__\n     * 収集したツイートのうち、重複ツイートが存在する可能性があるためユニークにする<br>※単一ツイート内でトヨタ・日産・ホンダのいずれか2つ以上をツイートしたものは重複して取得しているため\n\n     ```python\n     # pickleファイルをロード\n     raw_tweetlog = pd.read_pickle('./raw_tweetlog.pkl')\n\n     # 同一ツイートを重複して取得しているため、ツイートidのユニークなDataFrameを作成（TARGET_WORDS（メーカー名）ごとのフラグも集約）\n     dupulicate_target = 'id'\n     uniqueflag_df = raw_tweetlog[raw_tweetlog.duplicated(subset=dupulicate_target, keep=False)].\\\n                     groupby(dupulicate_target).agg(\n                     {'トヨタ': lambda x: True if sum(x) > 0 else False,\n                     '日産': lambda x: True if sum(x) > 0 else False,\n                     'ホンダ': lambda x: True if sum(x) > 0 else False}).reset_index()\n\n     # ユニークなDataFrameを参照してツイートがあれば各TARGET_WORDのフラグを上書き、新たなDataFrameを作成\n     df = raw_tweetlog.merge(uniqueflag_df, on=[dupulicate_target], how='left', suffixes=('_',''))\n     target_word = ['トヨタ', '日産', 'ホンダ']\n     for target in target_word:\n         df[target] = df[target].fillna(df[target+'_'])\n         df = df.drop(target+'_', axis=1)\n\n     df.drop_duplicates(subset=dupulicate_target, inplace=True)\n     ```\n\n     * ツイート日時のフォーマット変換と、ツイート内のターゲットとなる社名数をカウント\n\n     ```python\n     df['created_at'] = pd.to_datetime(df['created_at'], format='%Y-%m-%d')\n     df['target_count'] = df.apply(lambda x: sum(x[['トヨタ', '日産', 'ホンダ']]), axis=1)\n     ```\n\n* __形態素解析__\n     * MeCabを使って解析\n\n     ```python\n     def mecab_list(sentence):\n         # ユーザー辞書とシステム辞書がある場合は指定\n         tagger = MeCab.Tagger('-Ochasen -u /usr/local/lib/mecab/dic/ipadic/user_dic.dic -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n         tagger.parse('')\n         node = tagger.parseToNode(str(sentence))\n         word_class = []\n         type_of_word_class = []\n         \n         # 除外ワードがある場合は指定する\n         stopwords = ['し', 'する', 'こと', 'てる', 'ん', 'の', 'て', 'なっ', 'れ', 'さ', 'なる', 'そう', 'い', 'さん',\\\n                      'co', 'https', 't', '思っ', 'いる', 'くる', 'ー', 'みたい', '見', '出', '方', '事', '何',\\\n                      '中', 'ある', 'とき', '人', '私', 'ため']\n         target_wclass = ['名詞', '動詞', '形容詞'] # 抽出したい品詞を指定する\n         \n         while node:\n             # sentenceから表層形と品詞情報の出力\n             word, wclass = node.surface, node.feature.split(',')[0]\n             # 対象外の表層形を除外、対象の品詞に絞り込み\n             if wclass != u'BOS/EOS' and \\\n                word not in stopwords and wclass in target_wclass:\n                 word_class.append(word)\n                 type_of_word_class.append(wclass)\n             node = node.next\n\n         return pd.Series({'morphene': word_class, 'morphene_type': type_of_word_class})\n\n     df = pd.concat([df, df['text'].apply(mecab_list)], axis=1)\n     df\n     ```\n\n     * 出力結果\n     ![ダウンロード.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/1caaab0a-2d48-10ea-a53f-d4cc2a8c0b4d.jpeg)\n\n* __日別推移__\n     * メーカーごとの日別推移を集計\n\n     ```python\n     def daily_tweet(title, data):\n         plt.figure(figsize=(8, 6))\n         temp_df = data.set_index(data['created_at'].map(lambda s: s.strftime('%m/%d'))).\\\n         groupby(level=0).size()\n         plt.bar(temp_df.index, temp_df.values)\n         plt.title(label='\"{}\" を含むツイート'.format(title))\n     \n         # ツイート総数\n         plt.text(x=temp_df.index[-1], y=max(temp_df.values)*0.95,\\\n                  s='ツイート総数:'+str(sum(temp_df.values))+'件', ha='center',\\\n                  bbox=dict(boxstyle='round', fc='white', alpha=0.3, ec='gray'))\n         # 日別件数\n         [plt.text(x=temp_df.index[i], y=temp_df.values[i], s=temp_df.values[i], ha='center')\\\n          for i in range(len(temp_df))]\n     \n         plt.show()\n\n     # メーカーごとのDataFrameを作成\n     toyota_df = df.loc[df['トヨタ']==True]\n     nissan_df = df.loc[df['日産']==True]\n     honda_df = df.loc[df['ホンダ']==True]\n     \n     for target, data in zip(target_word, [toyota_df, nissan_df, honda_df]):\n         daily_tweet(target, data)\n     ```\n\n     <div>\n<img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/2185d664-d038-a76e-d303-1e2da3f60afa.png width=50% height=50%>\n<img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/6c009baa-9198-4227-9eb3-fb880bf1292e.png width=50% height=50%>\n<img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/7b8dabb0-7fdb-022a-f46d-1c56514a42b7.png width=50% height=50%>\n     </div>\n\n     * ホンダ・レジェンド「自動運転で世界初レベル3」のニュースによって、3/24にツイート数が激増\n     * それに引っ張られる形でトヨタもツイートが増えている（ホンダと比較されている？）\n     * 日産にはほぼ影響を及ぼしておらず、なんなら3/26はツイート数ゼロ\n\n\n* __ワードクラウド__\n     * 同じくメーカーごとにワードクラウドとして描画\n\n     ```python\n     # 品詞ごとの頻度をカウント\n     def word_frequency(data):\n         documents = data['morphene']\n         dct = corpora.Dictionary(documents)\n         # コーパスの中で出現頻度の低すぎる単語と高すぎる単語は、文書間の違いを表せないので特徴語には不適切と考えて除去\n         dct.filter_extremes(no_below = 3, no_above = 0.8)\n     \n         word_freq = {x:dct.dfs[y] for x, y in dct.token2id.items()}\n         word_freq = dict(sorted(word_freq.items(), key=lambda x:x[1], reverse=True))\n         word_freq_df = pd.DataFrame(data=word_freq.values(), index=word_freq.keys(), columns=['freq']).head(100)\n              \n         return word_freq_df\n     \n     # ワードクラウドの描画\n     def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), \n                        title=None, title_size=60, title_color='gray', bg_color='white'):\n         \n         # 日本語に対応させるためにフォントのパスを指定\n         f_path = '/System/Library/Fonts/ヒラギノ角ゴシック W1.ttc'\n         \n         # wordcloudの生成\n         wordcloud = WordCloud(background_color=bg_color,\n                         font_path=f_path, #日本語対応\n                         max_words=max_words,\n                         max_font_size=max_font_size, \n                         width=800, \n                         height=400,\n                         mask=mask)\n         wordcloud.generate(str(text).replace(\"'\", \"\"))\n         \n         plt.figure(figsize=figure_size)\n         plt.imshow(wordcloud)\n         plt.title(title, fontdict={'size': title_size, \n                                    'color': title_color, \n                                    'verticalalignment': 'bottom'})\n         plt.axis('off')\n         plt.tight_layout()\n         \n     #　横棒グラフの描画\n     def plot_bar_horizontal(data, figure_size):\n         plt.figure(figsize=figure_size)\n         plt.barh(data.index, data.values)\n     \n     for company_df, title in zip([toyota_df, nissan_df, honda_df], target_word):\n         company_word_freq_df = word_frequency(company_df)\n         plot_wordcloud(list(company_word_freq_df.index), figure_size=(12, 6), title='')\n         plot_bar_horizontal(company_word_freq_df[:20][::-1]['freq'], figure_size=(8, 6))\n     ```\n\n * トヨタ\n<div>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/d7a5afa7-a93d-729b-364a-cf7b11fbbbf3.png width=60% height=60%>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/699b73c7-369f-469c-6264-fd857df8e02d.png width=60% height=60%>\n</div>\n\n * 日産\n<div>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/c5bd6416-ef83-c8dd-971e-09151e1b2b59.png width=60% height=60%>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/28e976e3-0ae6-11b3-a790-8ebd34aba146.png width=60% height=60%>\n</div>\n\n * ホンダ\n<div>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/88205b65-b31a-538e-abee-ac217ae3788c.png width=60% height=60%>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/fe5db763-40de-5f86-c7ed-aaa85757464c.png width=60% height=60%>\n</div>\n\n* __共起ネットワーク__\n     * メーカーごとの共起ネットワークを描画\n\n     ```python\n     def plot_co_occurrence_network(data_morphene, data_morphene_type, text=''):\n         \n         node_name = defaultdict(str)\n         node_idx = defaultdict(int)\n         node_type = defaultdict(list)\n         node_count = defaultdict(int)\n         edge_list = []\n         cnt = 0\n         \n         # DataFrameの形態素・品詞種類の各列からデータを読み込み\n         for morphene, morphene_type in zip(data_morphene, data_morphene_type):\n             node_prev = None\n     \n             for m, m_t in zip(morphene, morphene_type):\n                 # Nodeの処理\n                 if m not in node_name.values():\n                     node_name[cnt] = m\n                     node_idx[m] = cnt\n                     node_count[cnt] = 1\n                     node_type[m_t].append(node_idx[m])\n                     cnt += 1\n                 else:\n                     node_count[node_idx[m]] += 1\n     \n                 # edgeの処理\n                 if (node_prev is not None) & (node_prev != node_idx[m]): # 循環グラフ、有向グラフを回避\n                     edge = (min(node_prev, node_idx[m]), max(node_prev, node_idx[m]))\n                     edge_list.append(edge)\n                 node_prev = node_idx[m]\n     \n         edge_count = Counter(edge_list)\n     \n         # Networkxに格納\n         G = nx.Graph()\n         G.add_nodes_from([(idx, {'cnt': node_count[idx]}) for idx in node_name])\n         G.number_of_nodes(), len(node_name)\n         G.add_edges_from([(a, b, {'cnt': edge_count[(a, b)]}) for a, b in edge_list])\n     \n         # Node, Edgeを剪定\n         G2 = deepcopy(G)\n         # Node: cnt >= 5で剪定\n         # 破壊的操作なので、予め破壊用のグラフ(G2)と検索用グラフ(G)を分けておく\n         for n, attr in G.nodes().items():\n             if (attr['cnt'] < 5):\n                 G2.remove_edges_from(list(G.edges(n)))\n                 G2.remove_node(n)\n     \n         G3 = deepcopy(G2)\n         # Edge: cnt >= 2で剪定\n         # EdgeがなくなったNodeは一旦そのまま\n         for e, attr in G2.edges().items():\n             if attr['cnt'] < 2:\n                 G3.remove_edge(*e)\n     \n         G4 = deepcopy(G3)\n         # EdgeがなくなったNodeを削除\n         for n in list(G3.nodes()):\n             if len(G3[n]) == 0:\n                 G4.remove_node(n)\n     \n         G_result = deepcopy(G4)\n     \n         pos = nx.layout.spring_layout(G_result, k=0.7, seed=10) # 2次元平面上の座標を計算\n         labels = {n: node_name[n] for n in pos.keys()} # Nodeに日本語を描画するための辞書\n         # node_size = [np.log(node_count[n])*400 for n in pos.keys()] # 対数スケール\n         node_size = [node_count[n]*25 for n in pos.keys()]\n     \n         edge_alpha = [edge_count[e] for e in G_result.edges()]\n         edge_colors = [edge_count[e]*2.5 for e in G_result.edges()]\n         edge_width = [edge_count[e]*0.4 for e in G_result.edges()]\n     \n         node_dict = dict(zip(G_result.nodes(), node_size))\n     \n         # 描画\n         fig, ax = plt.subplots(figsize=(12,12))\n         # Nodeを色分けしたいときは、nodelistを使ってNodeのグループ毎に描画関数を繰り返し実行する\n         # nodelistはグループ毎のNode番号を指定するが、それ以外の引数(posやnode_sizeなど)は全てのNodeについての値を入れる\n         # 指定出来る色はmatplotlibのcolor exampleを参照\n         # https://matplotlib.org/examples/color/named_colors.html\n     \n         node_type_list = ['名詞', '動詞', '形容詞']\n         node_color_list = ['orange', 'yellowgreen', 'tomato']\n         \n         for n_t, n_c in zip(node_type_list, node_color_list):\n             nx.draw_networkx_nodes(G_result, pos, \n                                    nodelist=[n for n in G_result.nodes() if n in node_type[n_t]], \n                                    node_size=[val for key, val in node_dict.items() if key in \\\n                                              [n for n in G_result.nodes() if n in node_type[n_t]]], \n                                    node_color=n_c, alpha=0.6, ax=ax)\n             \n             # 凡例の出力準備\n             plt.scatter([], [], c=n_c, alpha=0.5, s=350, label=n_t)\n     \n         # edgeの色に濃淡をつけたいときは、edge_colorに数値のlistを代入してedge_cmapを使用\n         # Sequentialなカラーマップから好きなやつを選ぶ\n         # https://matplotlib.org/examples/color/colormaps_reference.html\n         # 色の濃淡の具合はedge_vmin, edge_vmaxで調整\n         nx.draw_networkx_edges(G_result, pos, alpha=0.6,\n                                width=edge_width, edge_color=edge_colors, \n                                edge_vmin=0, edge_vmax=10,\n                                edge_cmap=plt.cm.Blues,ax=ax)\n         # Nodeにラベルをつけたいときは、以下の関数を使う\n         # font_familyにPCに入っている日本語フォントを指定してあげると、日本語を描画してくれる\n         nx.draw_networkx_labels(G_result, pos, labels, font_size=10, font_family=\"Hiragino sans\", ax=ax)\n     \n         plt.title(text)\n         \n         # 凡例表示\n         plt.legend(scatterpoints=1, frameon=True,\n                labelspacing=1, title='品詞の種類')\n         \n         plt.axis('off')\n         # fig.patch.set_alpha(0.3)\n         fig.patch.set_facecolor('white')\n         plt.show()\n     \n     for company_df, text in zip([toyota_df, nissan_df, honda_df], target_word):\n         plot_co_occurrence_network(company_df['morphene'].tolist(),\\\n                                    company_df['morphene_type'].tolist(), text)\n\n     ```\n\n     * トヨタ\n<div>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/1b2b6386-39f5-c80e-957a-c74b3449633c.png>\n</div>\n\n     * 日産\n<div>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/e3053408-191d-9e69-1493-8b86ddf0505c.png>\n</div>\n\n     * ホンダ\n<div>\n     <img src=https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/fc95a772-368f-abae-db2f-e2819ba3e7a7.png>\n</div>\n\n* __おまけ__\n     * 同一ツイート内に複数の自動車メーカーを含んでいるもの\n\n     ```python\n     df.loc[df['target_count']>=2]\n     ```\n\n     ![ダウンロード.jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/172589/4a34bed7-88cd-5b41-2111-9402cc876ac7.jpeg)\n\n# まとめ\n* __日別推移__\n     * ホンダのレベル3のニュースでトヨタもツイート数爆上げ、日産に対しては限定的\n     * 自動運転のニュースをリリースするまでホンダは影が薄かったが、今回「やっぱり技術のホンダ」として世に知らしめた印象を受ける\n     \n* __ワードクラウド__\n     * トヨタ：「自動運転」のワードと同時に、別日にニュースとなった「小型商用分野で資本提携」のネタとも合わせてたくさんツイートされている\n     * 日産：他2社と比べると印象薄い。CMに対するツイート多い。なんかやっちゃえNISSAN!\n     * ホンダ：「世界初」「レベル3」「実用化」など、驚きとともにインパクトのあるニュースとして広まっている\n     \n* __共起ネットワーク__\n     * トヨタ：自動運転まわりだと、自動運転−燃料電池−資本提携や、自動運転−ユニコーン−Momenta(中国のユニコーン企業)なんかも\n     * 日産：特徴掴みきれず\n     * ホンダ：自動運転・レベル3は言わずもがな、枝葉にフォーカスすると、追い越せ−ウサギ−カメ、挑む−理由など、応援するツイートも多い\n     \n* __反省__\n     * ユーザー辞書の作り込みが甘く、「レベル3」「センシングエリート」などの固有名詞が分かち書きされてしまっていた\n     * 共起ネットワークを作成する際、Networkxライブラリの使用方法をきちんと押さえきれておらず、edge・nodeしきい値の最適解は道半ば\n     * 同様に、MeCabのstopwordのチューニングも試行錯誤が必要そう\n","user":"yoshi-heita","created_at":"2021-03-29T00:51:46+09:00","updated_at":"2021-03-29T00:51:46+09:00"},{"url":"https://qiita.com/noritsune/items/6c30e4498ffecc76e5aa","title":"Slackへ勤怠連絡を入力するAlexaスキルを作ってみた","body":"# 概要\n弊社は出勤や休憩などの勤怠連絡をSlackのチャンネルへのメッセージ送信で行っています\n毎日何度も行うことなので手入力は結構面倒です\nそこで、最近我が家にやってきたAmazon Echo Showに話しかけて勤怠連絡を行えるAlexaスキルを作りました！\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/9ec76584-08da-ed4f-8139-d3a2a473f531.png)\n\nちなみに、Echo Showが無くてもスマホのAlexaアプリでAlexaスキルを実行することはできます\n音声入力で色々なものを操作するのは魔法感があって楽しいのでAlexaスキル開発はおすすめです！\n\n# システム構成\n![勤怠入力スキル構成図 (2).jpg](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/0b8214ed-9921-5472-d822-715873c51e29.jpeg)\n\n# 手順\n手順は大きく分けて以下の4つです\n\n1. Alexaスキルセットアップ\n2. Slack連携\n3. Lambda関数セットアップ\n4. 配布\n\n## 1. Alexaスキルセットアップ\nまずは、ユーザーからの入力を受ける部分を作成します\n\n### 1.1 スキル作成\n[Alexaデベロッパーコンソール](https://developer.amazon.com/ja-JP/alexa)にアクセスしてAmazonアカウントでログインします\n\nその後、スキルの作成ボタンを押下して以下の設定でスキルを作成します\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/eca44c29-4a29-b690-db3e-65b9e4d885ae.png)\nバックエンドリソースは「ユーザー定義のプロビジョニング」にします\n「Alexa-hosted」にするとわざわざLambdaで関数を作成する必要がなくて楽ですが、テスト機能が不十分なのとデプロイが遅いので今回は使用しません\n\n今回は一から作成するのでテンプレートは使用せず、「スクラッチで作成」を選択します\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/7e35f518-36ae-5bce-b69d-48067b3fbe50.png)\n\n### 1.2 スキルの呼び出し方法について\nAlexaスキルの呼び出し方法は様々ありますが、今回は以下のような発話を使って勤怠連絡を入力しようと思います\n\n「<font color=\"SkyBlue\">アレクサ</font>、<font color=\"Orange\">勤怠入力</font>で<font color=\"YellowGreen\">出勤</font>して」\n\nこの発話を3つの部分に分けて解説します\n\n- <font color=\"SkyBlue\">アレクサ</font>\n    - ウェイクワード\n    - Alexaデバイスがユーザーの発話を聞き始めるトリガーとなる文言です\n    - Alexaデバイス毎に設定することができます。「アレクサ」がデフォルトですが、その他にも「Amazon」、「Computer」などがあります\n- <font color=\"Orange\">勤怠入力</font>\n    - 呼び出し名\n    - この文言でAlexaはスキルを判別します\n- <font color=\"YellowGreen\">出勤</font>\n    - スロット\n    - 同じ属性の文言を列挙型の様に定義できます\n    - 定義したスロットの文言が発話に含まれていると、それがスキルリクエストに含まれてLambdaに渡されます\n\n### 1.3 呼び出し名設定\nスキルのセットアップ画面に入り、左のメニュー一覧から「呼び出し名」を開きます。\nこの画面で呼び出し名を設定することができます\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/7d3864aa-cfe0-7cc9-7646-77cc0050aacb.png)\n\n呼び出し名は既存スキルと似たものにしてしまうと、うまく認識されません\nまた、2語以上を組み合わせた単語である必要があります([公式リファレンス](https://developer.amazon.com/ja-JP/docs/alexa/custom-skills/choose-the-invocation-name-for-a-custom-skill.html))\n\n今回は「勤怠連絡」を呼び出し名とします\n\n### 1.4 スロット作成\n「アセット」→「スロット」を開きます。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/87064dd5-4bde-0969-da4b-ce21188a8f91.png)\n\n「+スロットタイプ」ボタンを押下してスロットを追加します\nスロット名は「KintaiType」にします\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/06bc3052-12be-969e-3865-42551abb0b34.png)\n\n必要の種類は「出勤」、「退勤」、「休憩開始」、「休憩終了」の4つです\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/5a84b459-b5c5-5184-2f32-02e2ba267828.png)\n\n### 1.5 インテント作成\n「対話モデル」→「インテント」を開きます。\nAlexaスキルにおけるインテントとは、ユーザーの発話によって引き起こされるアクションのことです。([公式リファレンス](https://developer.amazon.com/ja-JP/docs/alexa/ask-overviews/alexa-skills-kit-glossary.html#i))\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/404907f1-788d-ba65-8d82-87e889d57362.png)\n\nインテント名が「Amazon」から始まるものは標準ビルトインインテントです\n「HelloWorldIntent」はサンプルなので削除します\n\nそれでは、「出勤して」などのコマンドを受け付けるためのインテントを作成するために「インテントを追加」ボタンを押下します\nインテント名は「KintaiIntent」にしました\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/867f3a4b-114d-6fce-bd6f-ec54a4e9c30b.png)\n\nインテントには以下2種類のサンプル発話を設定しました\nサンプル発話はなるべく多く登録した方が認識されやすいそうです\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/eca6e474-4590-063e-f338-5e3c4e0e527a.png)\nこのとき、「{kintaiType}」と「して」の間に半角スペースが入っていないと以降のビルドでエラーになるので気を付けましょう\n\n以上でインテントの設定は完了です\n\nそうしたらページ上部の「モデルをビルド」ボタンを押します\nこれでこのスキルが設定した発話を認識できるようになります\n\n### 1.6 発話テスト\nユーザーの発話がちゃんと認識されるかテストしてみましょう\nテスト方法は以下の2種類があります\n\n1. Echo端末やスマホからAlexaに話しかける\n2. デベロッパーコンソールのテスト機能を使う\n\n今回は2の方法でテストします。\nPCのみで完結しますし、認識された発話から生成されたスキルリクエストも確認できるのでおすすめです\n\nAlexa Developer Console上部の「テスト」タブを開きます\nそして画面左上のテキストボックスへ発話を入力するか、マイクボタンを長押ししながらPCのマイクへ発話します\nすると、それによって生成されたjson形式のスキルリクエストを確認することができます\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/5414a121-3953-4ade-ae43-c3d373253440.png)\n\n以上でAlexaスキルセットアップは一旦完了です！\n\n## 2. Slack連携\n今回作成するアプリはSlackへのメッセージ送信を行うため、この作業が必要です\n\n### 2.1 Slackアプリ作成\n[こちら](https://api.slack.com/apps)のページの「Create New App」ボタンから新しいアプリを作成します\nApp Nameは「勤怠連絡」、\nDevelopment Slack Workspaceは勤怠連絡を送信したいワークスペースを設定します\n\n作成ができたら編集ページに遷移します\n\n### 2.2 権限設定\nアプリからSlackを操作するには、使用するAPIに必要な権限を追加する必要があります。\n\n今回使用するAPIは[chat.postMessage](https://api.slack.com/methods/chat.postMessage)です\n今回はユーザーとしてこのAPIを使用するので、「ユーザースコープ」の「chat:write」権限が必要です\n\nアプリ編集ページのOAuth & Permissionsタブを開き、Scopes → User Token Scopes欄から以下の様に追加すればOKです\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/bbb58f19-7bba-0123-c9c6-7bcbe115da5f.png)\n\n### 2.3 ワークスペースへのインストール\nアプリを使用するためにはワークスペースへのインストールが必要です\nOAuth & Permissionsタブの上部の緑のボタンからインストールをします\n\n### 2.4 Alexaスキルとのアカウントリンク設定\nAlexaスキルを使用するユーザーが使用しているSlackアカウントとしてメッセージを送信するためには、Alexaスキルのアカウントリンク機能を使用します\n\nまずは、Slackアプリの編集ページ → Basic Information → App Credentials欄から「Client ID」と「Client Secret」をコピーしておきます\n\n次に、Alexa Developer Console → ツールタブ → アカウントリンクタブを開き、以下のように設定します\nWeb認証画面のURI: https://slack.com/oauth/authorize\nアクセストークンのURI: https://slack.com/api/oauth.access\nユーザーのクライアントID: 先程コピーしたClient ID\nクライアントのシークレット: 先程コピーしたClient Secret\nスコープ: chat:write:user\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/f90dffd6-d3d5-d92c-d5ec-d6b5ed07a45d.png)\nAlexaのリダイレクト先のURL欄は次の手順で使用するので3つともコピーしておきます\n\n先程コピーしたリダイレクト先のURLを以下の欄に全て登録します\nSlackアプリの編集ページ → OAuth & Permissions → Redirect URLs\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/4c712027-22d2-76ba-7b0f-74ca122fad16.png)\n\nこれで、Alexaアプリを使うためにはSlackアカウントとの連携が必要になりました\n\n### 2.5 Slack連携テスト\n実際にSlackとの連携ができるかテストしてみます\n\nスマホのAlexaアプリ下部のその他タブ → スキル・ゲームページを開きます\nそして、有効なスキルタブ → 開発タブ → 勤怠入力スキルへと進みます\n勤怠入力スキルページが開けたら上部の「設定」ボタンを押下してアカウントのリンクを行ってみます\n以下の様に表示されればOKです！\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/1758cadf-7f0b-1c3e-fc16-0b8264f8dd56.png)\n\n## 3. Lambda関数セットアップ\nそれではいよいよ、Alexaからのスキルリクエストを受け取って処理をするLambda関数を作ります\nAWSアカウントは作成済みの前提です\n\n### 3.1 関数作成\n[Serverless Application Repository](https://ap-northeast-1.console.aws.amazon.com/serverlessrepo/home)のページを開き、\n「利用可能なアプリケーション」→「alexa-skills-kit-nodejs-factskill」を選択します\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/cfe84aee-1525-e2ff-3880-49e480ccab5f.png)\nこれはアレクサスキル作成用のテンプレートのようなものです\n\nアプリケーション名を「KintaiRenraku」とし、「デプロイ」ボタンを押します\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/b684b548-2f8c-a07c-75e3-03b82440d66d.png)\nデプロイには数十秒かかりました\n\nデプロイが終了するとLambdaのアプリケーション一覧ページに遷移します\n遷移しなければ[こちら](https://ap-northeast-1.console.aws.amazon.com/lambda/home)から遷移できます\nアプリケーション一覧には先程作成したアプリケーションが「serverlessrepo-KintaiRenraku」という名前で存在しているので名前をクリックします。\n\nすると、このアプリケーション内に「alexaskillskitnodejsfactskill」というLabda関数が作成されていることが確認できます\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/13f83a82-782e-d14c-a470-d821fae420dc.png)\n関数名をクリックして編集画面に入りましょう\n\n以上でLambda関数の作成ができました！\n\n### 3.2 Lambda関数とAlexaスキルを接続\nこの関数がAlexaから呼ばれるためには以下の2つの作業が必要です\n\n- Labda関数のトリガーにAlexaスキルIDを設定\n- AlexaスキルのエンドポイントにLambda関数のARNを設定\n\nまずは、「Labda関数のトリガーにAlexaスキルIDを設定」から行います\n関数編集画面上部の「Alexa Skill Kit」トリガーをクリックします\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/5b1b0e93-a7eb-a50b-672c-ccbc0be8ef1c.png)\n\nすると、トリガー一覧画面に入ります\n既に追加済みのAlexa Skill Kitトリガーの説明欄に書いてあるとおり、追加済みのこのトリガーは削除し下さい\nそして、「トリガーを追加」ボタンから改めてAlexa Skill Kitを追加します\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/b792fd67-bb34-8c18-5022-f2792dffd657.png)\n\nAlexa Skill Kitトリガーを追加しようとするとこの様な画面でスキルIDを求められます\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/314cf40b-8fa4-d9f1-4b1a-a40b0878fe1e.png)\n\nスキルIDは、手順1.1で開いたAlexa Developer Consoleから確認できます\n作成したAlexaスキルの編集画面 → エンドポイントタブを開くとスキルIDが書いてあるのでコピーして先程のトリガー追加画面に入力します\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/9dac0c23-5827-52a4-460c-f66ea29f123a.png)\n\n続いて、「AlexaスキルのエンドポイントにLambda関数のARNを設定」を行います\nLambda関数の編集画面上部のボタンからARNをコピーします\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/b81596cf-3207-3a9f-a7e3-cf11403580bc.png)\n\n先程開いた、Alexaスキルの編集画面 → エンドポイントタブの「デフォルトの地域」欄にコピーしたARNを入力します\nそしてページ上部の「エンドポイントを保存」ボタンを押下すればOKです\n\nこれでAlexaからLambda関数が呼び出されるようになりました！\n\n試しにテストしてみましょう\n「勤怠連絡を開いて」と話しかけると豆知識を披露してくれました\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/1cd80a0b-294c-0107-f10c-9db9e8b7a659.png)\n今回使用したテンプレートは豆知識を披露してくれるスキルなので、これでAlexaスキルとLambda関数の接続が確認できました\n\n### 3.3 パッケージ追加\nSlackAPIを叩くには色々な方法がありますが、今回は簡単にコードを書くために、`@slack/web-api`パッケージを使用します\n\n以下の手順はローカル環境にnpmがインストールされていることが前提です\n\nnpmパッケージをインストールするためにはLambda関数の実行環境を一旦、ローカルに落としてくる必要があります\n作成したLambda関数の編集ページ上部の「アクション」プルダウン → 関数をエクスポート → デプロイパッケージをエクスポートをします\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/da1676eb-e50d-5821-1a4d-26adde19ed9f.png)\n\nするとzipファイルがDLされるので、任意のフォルダに解凍します\n次に、コマンドプロンプトを開いて解凍したフォルダに移動します\nそして`npm install @slack/web-api`コマンドを実行します\n\n解凍したフォルダ → 「node_modules」フォルダ内に@slack\\web-apiというディレクトリができていれば成功です\n\nアップロードするために、解凍したフォルダ内にあるファイルを全て選択してzip圧縮します\n\nLambda関数の編集ページを開き、コードソース → 「アップロード元」プルダウン → .zipファイルを選択し、先程作成したzipファイルをアップロードします\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/05a50aa4-7738-e160-c8a8-d2c0d07cdb34.png)\n\nアップロード後にコードソース欄の「Enviroment」タブがこの様になっていれば@slack/web-apiパッケージのインストールは完了です\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/1f2d44c9-8a83-58f1-a164-fc0ff1c1c5db.png)\n\n### 3.4 コーディング\n今回は以下の様なコードを作成しました。\nchannelId_Kintai変数には勤怠連絡先のチャンネルIDを指定して下さい\n詳細説明は割愛します\n\n``` index.js\n'use strict';\nconst Alexa = require('ask-sdk-core');\nconst { WebClient } = require('@slack/web-api');\n\n// 喋る内容\nconst HELP_MESSAGE = \"Slackの勤怠管理チャンネルで打刻します。\";\nconst HELP_REPROMPT = 'どうしますか？';\nconst STOP_MESSAGE = \"お疲れさまです\";\n\n// 打刻用の情報\nconst channelId_Kintai = \"hoge\";\nconst kanjiConversion = {\n  \"しゅっきん\": \"しゅっきん\",\n  \"出勤\": \"しゅっきん\",\n  \"きゅうけいかいし\": \"きゅうけいかいし\",\n  \"休憩開始\": \"きゅうけいかいし\",\n  \"きゅうけいしゅうりょう\": \"きゅうけいしゅうりょう\",\n  \"休憩終了\": \"きゅうけいしゅうりょう\",\n  \"たいきん\": \"たいきん\",\n  \"退勤\": \"たいきん\",\n};\nconst commandInfos = {\n  \"しゅっきん\": {\n    \"command\": \"in\",\n    \"msg\": \"今日もいちにちがんばるぞい\",\n  },\n  \"きゅうけいかいし\": {\n    \"command\": \"bi\",\n    \"msg\": \"ゆっくりやすんでくださいね\",\n  },\n  \"きゅうけいしゅうりょう\": {\n    \"command\": \"bo\",\n    \"msg\": \"残りもがんばりましょう\",\n  },\n  \"たいきん\": {\n    \"command\": \"out\",\n    \"msg\": \"今日も一日お疲れさまでした\",\n  },\n};\n\nconst KintaiHandler = {\n  canHandle(handlerInput) {\n    const request = handlerInput.requestEnvelope.request;\n    return request.type === 'IntentRequest' && request.intent.name === 'KintaiIntent';\n  },\n   async handle(handlerInput) {\n    // 勤怠チャンネルに打刻メッセージを送る\n    const intent = handlerInput.requestEnvelope.request.intent;\n    var commandInfo = commandInfos[kanjiConversion[intent.slots.kintaiType.value]];\n    if(!commandInfo) {\n      return handlerInput.responseBuilder\n        .speak(intent.slots.kintaiType.value + \"は存在しないコマンドです。使えるコマンドは「出勤」、「休憩開始」、「休憩終了」、「退勤」の4つです\")\n        .getResponse();\n    }\n    \n    const client = new WebClient(handlerInput.requestEnvelope.context.System.user.accessToken)\n    \n    var params = {\n      channel: channelId_Kintai,\n      as_user: true,\n      text: commandInfo[\"command\"],\n    };\n    \n    var msg;\n    try {\n      console.log(\"りくえすと(chat.postMessage): \" + JSON.stringify(params));\n      const response = await client.chat.postMessage(params);\n      console.log(\"れすぽんす(chat.postMessage): \" + JSON.stringify(response));\n      \n      msg = response.ok\n        ? \"打刻しました。\" + commandInfo[\"msg\"]\n        : \"打刻に失敗しました\";\n    } catch(e) {\n      console.log(\"エラー: \" + e);\n      msg = \"打刻に失敗しました\";\n    } finally {\n      return handlerInput.responseBuilder\n      .speak(msg)\n      .getResponse();\n    }\n  },\n};\n\nconst HelpHandler = {\n  canHandle(handlerInput) {\n    const request = handlerInput.requestEnvelope.request;\n    return request.type === 'LaunchRequest'\n      || (request.type === 'IntentRequest' && request.intent.name === 'AMAZON.HelpIntent');\n  },\n  handle(handlerInput) {\n    let msg = \"Slackの勤怠管理チャンネルで打刻します。使えるコマンドは「出勤」、「休憩開始」、「休憩終了」、「退勤」の4つです。「Alexa、勤怠で出勤して」と言ってみて下さい。\"; \n    \n    return handlerInput.responseBuilder\n      .speak(msg)\n      .reprompt(\"コマンドを発言して下さい\")\n      .getResponse();\n  },\n};\n\nconst ExitHandler = {\n  canHandle(handlerInput) {\n    const request = handlerInput.requestEnvelope.request;\n    return request.type === 'IntentRequest'\n      && (request.intent.name === 'AMAZON.CancelIntent'\n        || request.intent.name === 'AMAZON.StopIntent');\n  },\n  handle(handlerInput) {\n    return handlerInput.responseBuilder\n      .speak(\"お疲れさまです\")\n      .getResponse();\n  },\n};\n\nconst SessionEndedRequestHandler = {\n  canHandle(handlerInput) {\n    const request = handlerInput.requestEnvelope.request;\n    return request.type === 'SessionEndedRequest';\n  },\n  handle(handlerInput) {\n    console.log(`セッションが以下の理由で終了しました: ${handlerInput.requestEnvelope.request.reason}`);\n    return handlerInput.responseBuilder.getResponse();\n  },\n};\n\nconst skillBuilder = Alexa.SkillBuilders.custom();\n\nexports.handler = skillBuilder\n  .addRequestHandlers(\n    KintaiHandler,\n    HelpHandler,\n    ExitHandler,\n    SessionEndedRequestHandler,\n  )\n  .withCustomUserAgent('sample/basic-fact/v2')\n  .lambda();\n```\n\n### 3.5 関数のテスト\nリクエストが正しく処理されるかテストしてみましょう\nAlexaに話しかけるか、Alexa Developer Consoleの「テスト」タブから発話をしてみます\n無事、以下の様な返答が行われました\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/2c4e2457-3163-05b2-42d2-a9283c0a7f4f.png)\nまた、Slackへのメッセージ送信も行われています\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/e5cce5db-b32c-ef3e-0951-c7176e61abab.png)\n\n以上でAlexaスキルの作成は完了です！\n\n## 4. 配布\n折角なので、作成したスキルを同僚の皆さんに使ってもらいましょう\n\nAlexa Developer Consoleの「公開」タブ → 「公開範囲」タブを開きます\nベータテスト機能で配布するためには以下の作業を行う必要があるので全て済ませておきます\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/413932/051c753d-1d12-4624-7bef-34824caaffa2.png)\n\n必要な作業を全て済ませてから改めて「公開範囲」タブの「ベータテスト」欄を開くと、テスターのEメールアドレスを追加できるようになっています\nここに、アプリを配布したい方のメアドを追加すればその方へメールが飛び、今回作成したスキルを配布することができます\n\n# 所感\n便利なスキルを作れて楽しかったです。自分で毎日使っています\n作り方をまとめるのが意外に大変で驚きました。書き始め当初は、コードの説明も細かく書く予定でしたが後半は疲れたので止めました\nAlexaスキルの作り方の記事は古いものが多く、現在の開発環境の参考になる記事が見つけにくかった為、この様な記事を書きました\nこの記事を読んでAlexaスキルを作られた方も作り方をまとめて見られては如何でしょうか？\n\n# 参考にさせて頂いたページ\n- [Amazon EchoからSlackに通知を出してみた(Web API版)](https://nemuzuka.vss.jp.net/entry/2018/01/09/123510)\n","user":"noritsune","created_at":"2021-03-29T00:38:42+09:00","updated_at":"2021-03-29T00:38:42+09:00"},{"url":"https://qiita.com/yutaaaaka/items/df6f28f9f3ed444bc656","title":"【GLSL】ISFをTouchDesigner上で動かしてみた","body":"\n##■概要\nこの記事は**「[ISF](https://editor.isf.video/)」がまとめられたサイトにあるシェーダーのプログラムコードを、「TouchDesigner」というVJソフトの「GLSL」にぶち込んで動かそう！**ということを書いてます。\n\nISFとは*`「Interactive Shader Format」`*の略で、僕も知ったばかりで詳しくないのでググってみたところ、**「GLSLベースのシェーダフォーマット」**らしいです。\n\n\nTouchDesignerでGLSLを勉強していた時、[**TDSWのチュートリアル動画**](https://www.youtube.com/watch?v=YhhWQTBAp8E&list=PLjqkEfiud5LMWrH1rzNFRGMvfycjIOJcr&index=100&t=610s)から「ISF」なるものを知りました。この動画では触れられていない他のシェーダーもいじってみよう！ということで学んだことを試しにやってみることにしました。\n\n\n\n##■動作環境\n>\nMacOS：Big Sur ver.11.2.1\nTouchDesigner：099 2020 27390\n\n##■試してみる\nうまくいくとこんな感じに動きます\n![ezgif-6-398df4cf8a0c.gif](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/315671/574f5d1f-6499-8443-a391-c2e9c9942008.gif)\n\n（ちなみにこの画像は`「MINAMI MIYAJIMA」`というスクエアを延々と手書きで書きに書いてる人の作品です。いま`JITSUZAISEI`という[**ただいまクラウドファンディングで60万以上資金調達してるプロジェクト**](https://camp-fire.jp/projects/view/373174?list=projects_fresh)に関わってるんですが，よければ興味持ってください笑 こそっと宣伝です。笑）\n\nでは進めていきまする。\n\n###■ISF\nまずは、ISFのサイトを開きます。\n>\n*ISF (Dual Side Scroller And Flip.fs　by VIDVOX)*\nhttps://editor.isf.video/shaders/5e7a7f767c113618206dde08\n\n開くと、こういう画面が現れると思います。\n![スクリーンショット 2021-03-28 13.02.58.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/315671/7e19c575-14cb-66c2-e5f6-26b68d891361.png)\n\nそしたら左側にある**” </> ”**のマークを押してください。\n\nするとコードが出てくると思います。`これを全部コピー`してください。\nコメントアウトの部分も含めてコピーしてください。\n![スクリーンショット 2021-03-28 13.03.16.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/315671/ee739edf-ae90-5a5b-a2e5-f9c5947af064.png)\n\n###■TouchDesigner\nタッチデザイナーの方も開いていきます！\n開いたら、まず**MovieFileinTOP**を置きます。そこから右につないで**glslTOP**を置きます。\n\nとりあえずは以下の画像のように各オペレーターを配置してください。\n![スクリーンショット 2021-03-28 22.13.35.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/315671/af0f8ff7-a6ed-bb30-5722-23f36fb979dc.png)\n\nglslTOPの下に出てきた**glsl_pixel（DAT）**の**Edit**を押してください。\n\nそこにさっきISFのサイトからコピーしたプログラムをコピペします。\n\n```glsl\n// uniform float exampleUniform;\n\n一旦、この辺にコピペ！！！！\n\nout vec4 fragColor;\n```\n\n\n\n###●完成形！\nちなみに，最終的なコードは以下のようなものになります。\n\n```glsl\n/*{\n  \"CREDIT\": \"VIDVOX\",\n  \"DESCRIPTION\": \"Mirror slide the top, bottom, left and right sections of the input image. Based on side scroller and flip by Brian Chasalow.\",\n  \"CATEGORIES\": [\n    \"Geometry Adjustment\"\n  ],\n  \"INPUTS\": [\n    {\n      \"NAME\": \"inputImage\",\n      \"TYPE\": \"image\"\n    },\n    {\n      \"NAME\": \"slidetop\",\n      \"TYPE\": \"float\",\n      \"MIN\": 0,\n      \"MAX\": 2,\n      \"DEFAULT\": 0\n    },\n    {\n      \"NAME\": \"slideleft\",\n      \"TYPE\": \"float\",\n      \"MIN\": 0,\n      \"MAX\": 2,\n      \"DEFAULT\": 0\n    },\n    {\n      \"NAME\": \"mirrorHorizontaltop\",\n      \"TYPE\": \"bool\",\n      \"MIN\": false,\n      \"MAX\": true,\n      \"DEFAULT\": true\n    },\n    {\n      \"NAME\": \"mirrorVerticaltop\",\n      \"TYPE\": \"bool\",\n      \"MIN\": false,\n      \"MAX\": true,\n      \"DEFAULT\": true\n    },\n    {\n      \"NAME\": \"slidebot\",\n      \"TYPE\": \"float\",\n      \"MIN\": 0,\n      \"MAX\": 2,\n      \"DEFAULT\": 0\n    },\n    {\n      \"NAME\": \"slideright\",\n      \"TYPE\": \"float\",\n      \"MIN\": 0,\n      \"MAX\": 2,\n      \"DEFAULT\": 0\n    },\n    {\n      \"NAME\": \"mirrorHorizontalbot\",\n      \"TYPE\": \"bool\",\n      \"MIN\": false,\n      \"MAX\": true,\n      \"DEFAULT\": true\n    },\n    {\n      \"NAME\": \"mirrorVerticalbot\",\n      \"TYPE\": \"bool\",\n      \"MIN\": false,\n      \"MAX\": true,\n      \"DEFAULT\": true\n    }\n  ]\n}*/\n\n\n\nuniform float slidetop;\nuniform float slideleft;\nuniform bool mirrorHorizontaltop;\nuniform bool mirrorVerticaltop;\nuniform float slidebot;\nuniform float slideright;\nuniform bool mirrorHorizontalbot;\nuniform bool mirrorVerticalbot;\n\n\n\n\n\n\nout vec4 fragColor;\nvoid main()\n{\n\t// vec4 color = vec4(1.0);\n\n\tvec2 pt = vUV.st;\n\tfloat slide = (vUV.y > 0.5) ? slidetop : slidebot;\n\tfloat shift = (vUV.x < 0.5) ? slideleft : slideright;\n\n\tbool mirrorHorizontal = (vUV.y > 0.5) ? mirrorHorizontaltop : mirrorHorizontalbot;\n\tbool mirrorVertical = (vUV.x < 0.5) ? mirrorVerticaltop : mirrorVerticalbot;\n\tpt.x += slide;\n\tpt.y += shift;\n\tvec2 moddedRetard = mod(pt,1.0);\n\t\n\tif(mirrorHorizontal && pt.x >= 1.0 && pt.x <= 2.0)\n\t\tmoddedRetard = vec2(1.0-moddedRetard.x, moddedRetard.y);\n\tif(mirrorVertical && pt.y >= 1.0 && pt.y <= 2.0)\n\t\tmoddedRetard = vec2(moddedRetard.x, 1.0-moddedRetard.y);\n\t\n\tvec4 pixel = texture(sTD2DInputs[0], moddedRetard);\n\tfragColor = pixel;\n\n\t// fragColor = TDOutputSwizzle(color);\n}\n```\n\n\n---\n\n\n\n###●置き換えるコードは？\n**＊ここからはたぶんこの記事の肝になります。**\n\nisfからコピペしたコメントアウトのコード下にある**「void main(void){}」の中のプログラム**を，タッチのデフォルトで書かれてた\n\n```glsl\nout vec4 fragColor;\nvoid main()\n{\n\t// vec4 color = texture(sTD2DInputs[0], vUV.st);\n\tvec4 color = vec4(1.0);\n\tfragColor = TDOutputSwizzle(color);\n\n→→→この辺にコピペ！！！\n\n}\n```\n→→→この辺にコピペ！！！にコピペしときましょう\n\n###●Uniform\nタッチのglslでは，uniform変数を使っていろいろできるっぽいです。\n\n>\n*GLSLにはユニフォーム変数という概念があります。通常GLSLコードの中で定義された変数を変更するとGLSLプログラムは再度コンパイルしないと有効になりませんが、uniform 指定子をつけた変数に関してはGLSLプログラム外部から動的にパラメーターを変更できるようにする、という仕組みです。TouchDesignerでももちろんこの機能が使えます。*\n\nってことらしいです。笑\n\nここではisfからコピペしてきたコメントアウト部分を参考に**\"NAME\"**を**Uniform変数**に割り当てていきます。\n\nたとえば，\n\n```\n{\n      \"NAME\": \"slidetop\",\n      \"TYPE\": \"float\",\n      \"MIN\": 0,\n      \"MAX\": 2,\n      \"DEFAULT\": 0\n    },\n```\nこれだと，**\"TYPE\":\"float\"** で **\"NAME\":\"slidetop\"** なので， \n\n```glsl\nuniform float slidetop;\n```\nに置き換えられます。\n（\"DEFAULT\"の値はまた後で使います）\n\nこの作業をすると，\n\n```glsl\nuniform float slidetop;\nuniform float slideleft;\nuniform bool mirrorHorizontaltop;\nuniform bool mirrorVerticaltop;\nuniform float slidebot;\nuniform float slideright;\nuniform bool mirrorHorizontalbot;\nuniform bool mirrorVerticalbot;\n```\nが出来上がって，`glsl_info`に出ていたエラーもだいぶ減ったと思います。\n（エラーが着実に減ってくとほっとするよね。）\n\n他の置き換え部分は，\n**`「isf_FragNormCoord」`** → **`「vUV」`** \n**`「IMG_NORM_PIXEL」`** → **`「texture」`** \n**`「inputImage」`** → **`「sTD2DInputs[0]」`** \n**`「gl_FragColor」`** → **`「fragColor」`** \n\nです！！！笑\n\n***え？なんでそれを置き換えるってわかるの？***\n\nとなった私なので，これらを少し解説していきます。\n\n**「isf_FragNormCoord」**は，\n>*これは便利な変数であり、現在のフラグメントの正規化された座標を表します（[0,0]は左下、[1,1]は右上）*\n\nで，**「vUV」**は，\n>*uvは、画像の左下が (0, 0)、右上が (1, 1) になるような2次元の数字で、今どのピクセルを処理しているのかをシェーダー側で知ることのできる情報です。*\n\nってことで**[0,0][1,1]**って表記からわかるように，置き換えれそうですね！笑\n\n**「IMG_NORM_PIXEL」**は，\n>*シェーダーでのtexture2D（）またはtexture2DRect（）の呼び出しは、それぞれIMG_NORM_PIXEL（）またはIMG_PIXEL（）に置き換える必要があります。*\n\n**「texture」**は\n>*外部からの入力のテクスチャも簡単に扱えるようになっています。デフォルトで生成されるコードの vec4 color = texture(sTD2DInputs[0], vUV.st); の部分のコメントアウトを外せば1番目に接続されたテクスチャをそのまま表示する動作になります。*\n\nってところから，ともにテクスチャを扱うときのコードなんですかね？笑\n\n\n**「sTD2DInputs[0]」**は，glslTOPのオペレーターを繋ぐところ（今回ならmoviefileinTOPと繋がっている）が関係していて，3口あるので[0]〜[2]までできます。\n\n\nこのそれぞれの置き換えについて，記事にする身としてはちゃんと調べようと思って，この記事がすごく参考になりましたのでリンク共有しときます。\n\n>*映像音響処理概説 2018 第十七回 GLSLについて*\nhttp://satoruhiga.com/TDWS2018/day17/\n\n>*ISF Variables Reference | ISF Documentation*\nhttps://docs.isf.video/ref_variables.html#automatically-declared-variables\nhttps://docs.isf.video/ref_converting.html\n\n\n\nこれ一読するだけでもGLSLを理解しやすくなると思います！\n\n\nあとはデフォルトでタッチの方にあった\n\n```glsl\n// vec4 color = texture(sTD2DInputs[0], vUV.st);\nvec4 color = vec4(1.0);\nfragColor = TDOutputSwizzle(color);\n```\nはここではもう使わないので，コメントアウトするなり消すなりしておきましょう。\n\n\n\n最初はエラーを吐きまくっていたと思うのですが、\n最終的にはこのようにglsl_info(DAT)でエラーがなくなれば成功です！\n![スクリーンショット 2021-03-28 22.22.46.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/315671/e855b99a-a0c0-ed48-78fd-b9b08ae26fc1.png)\n\n\n####●glslTOP\nあともう一踏ん張りです！\n![スクリーンショット 2021-03-28 13.07.31.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/315671/dc7ea270-a1f1-46cc-24fc-1dcb0d272055.png)\n**`glslTOP/Load Umiform NamesのLoad`**（この画像の真ん中ら辺にあるボタン）を押してあげると，\n\n![スクリーンショット 2021-03-28 13.07.24.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/315671/39280b55-9baf-ee09-86a8-6553e0c3e25d.png)\nこんな感じで，**Uniform変数**がずらっと出てくるはずです。\nあとはあの`\"DEFAULT\"`の値を,`Vectors/Value/value x`に入れていけばOK！\n(名前が似ててややこしいから気をつけてね)\n\n```\n \"NAME\": \"DEFAULT\":\n\"slidetop\"  0\n\"slideleft\"  0\n\"mirrorHorizontaltop\" true（1）\n\"mirrorVerticaltop\" true(1)\n\"slidebot\" 0\n\"slideright\" 0\n\"mirrorHorizontalbot\" true(1)\n\"mirrorVerticalbot\" true(1)\n```\n(trueは１，falseは０なので，それで対応した数字を入れてます。)\n\n\n\n#ここまでお疲れ様でした！🎉\n無事にプログラムを実行できたことを祈っています！\n\nあとは自由に，TOPとかで画像を加工したり，LFO CHOPで動きを自動にしたり，画像を差し替てみたり，コードいじってみたり，違うISFのコードを試してみたり，いろいろ遊んでみてください！\n\n\n\n##■まとめ\n基本的にはエラーを読んで置き換えていく流れになると思います。\n\nこういう`プログラム言語の翻訳`みたいなことって，**「四角を書きたい」**という本質に対して「javaだったらこう書く」「htmlならこう書く」「glslならこう書く」みたいな感覚ってのがありますよね。\n\n以前にGoogleのColab上でTensorFlowを使って機械学習かじってた時に，これTouchDesigner上で動かせたら楽しそうだな，と思って試してみてたところ，NVIDIAのGPUじゃないと動かなかったり，なんでかわかんないけどライブラリが読み込めなかったり，今回やったような`プログラム言語の翻訳`みたいなことが全然できなくてうまくいかなかった経験があったので，今回はその翻訳がうまくいってよかった。**求めていれば，違う形で叶うことがある**って感じがした。\n\nそれも，師匠や正しい先生のような，今回ならTDSWのチュートリアル動画で解説されていた[**原田康さん**](https://twitter.com/chimanaco)がいてくれたこそできたことだなと痛感した。**こういったことを学ぼうと思うと、わりと図書館とか大学とかが必要だったのに，今ではそれが大きく変わったように思う。**解説とかチュートリアルって本当にありがたい。だからこそ自分も少しでもこう言った記事を通じてオープンサイエンスに貢献できればなと思う。\n\n\n\n\ntwitter:https://twitter.com/jp_dummy\ntwitter:https://twitter.com/JITSUZAISEI\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","user":"yutaaaaka","created_at":"2021-03-29T00:37:31+09:00","updated_at":"2021-03-29T00:37:31+09:00"},{"url":"https://qiita.com/ELIXIR/items/8a7a24f6aa64972ec819","title":"PlatformIOでRaspberry Pi Pico を動かす（Windows,Arduinoフレームワーク）","body":"(2021/03/27現在)公式からは対応されていないようですが、\n[こちら](https://github.com/Wiz-IO/wizio-pico)にある方法でビルド＆実行を確認できました。\n\n１．Platforms>Advanced Installation -> https://github.com/Wiz-IO/wizio-pico を入力してInstall\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/59911/e351632c-2563-261a-a9e3-39c2ad553cb2.png)\n\n２．Board:WizIO - Raspberry Pi Pico, Framework:Arduino で適当なプロジェクトを作成  \n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/59911/a1fe4272-f838-c124-0514-eb5ccbde07af.png)\n\n３．適当なプログラムを作成\n\n```\n#include <Arduino.h>\n\nvoid setup() {\n  // put your setup code here, to run once:\n  pinMode(2,OUTPUT);\n}\n\nvoid loop() {\n  // put your main code here, to run repeatedly:\n  digitalWrite(2,HIGH);\n  delay(100);\n  digitalWrite(2,LOW);\n  delay(400);\n}\n```\n\n４．ビルド＆アップロードで実行ファイル作成\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/59911/4c059584-63e0-115e-833d-21fc9f6dac1c.png)\n\n５．Raspberry Pi PicoのBOOTSELボタンを押しながらUSBを接続し、ARDUINO.uf2をドラッグ＆ドロップ\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/59911/d6cf8fc7-979d-f150-94d4-da8f2e13af83.png)\n\n６．Raspberry Pi Pico上で実行される\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/59911/24fd38f3-8427-fdcd-9b96-b852852d8ec2.png)\n[動画](https://youtu.be/ep9tdJ0jRW0)\n\n以上です。\n","user":"ELIXIR","created_at":"2021-03-29T00:30:24+09:00","updated_at":"2021-03-29T00:50:29+09:00"},{"url":"https://qiita.com/novelworks/items/f3bcba667be37f4e1219","title":"UnityからRekognitionを使ってみた","body":"##R&D成果発表会Vol.2\nこんにちは。ノベルワークスR＆Dチームのともやんです。\n今回はUnityと表情分析でうにゃうにゃした際の報告です。\nこの記事がVol.100くらいになるころには、なにかおもしろいものがお目見えしているかもしれません。\nそれでは早速！\n\n##Amazon Rekognitionとは\nAmazon　Rekognitionとは、AWSのサービスの一つで、画像や動画を投げると、顔比較や感情分析など高度なことを、簡単に行える便利なものです。今回はこのサービスを使って、感情分析を行っていきます。\n\n##AWS SDK for .Netについて\nunityでのAWSSDK導入方法については基本ここ参照。\nhttps://qiita.com/nshinya/items/0a71d4658e7f4a650844\n\nRekognitionを使いたいので、AWS SDK.Rekognition.dllを入れてください\n\n##やりかた\nやり方として\n####1.unityでwebカメラを使う\n####2.Rekognitionにwebカメラの画像を投げる\n####3.返ってきたJson風データから感情値を取り出す\nの三つで説明していきます\n\n##完成コード(雑です)\n\n```\nusing System;\nusing System.Linq;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing System.IO;\nusing System.Collections;\nusing System.Collections.Generic;\nusing UnityEngine;\nusing UnityEngine.UI;\nusing Amazon.Rekognition;\nusing Amazon.Rekognition.Model;\n\n\n\n\npublic class DetectFaces : MonoBehaviour\n{\n    public RawImage rawImage;\n\n    WebCamTexture webCamTexture;\n\n\n    //textureをtexture2dにする関数\n    public Texture2D ToTexture2D(Texture self)\n    {\n        var sw = self.width;\n        var sh = self.height;\n        var format = TextureFormat.RGBA32;\n        var result = new Texture2D(sw, sh, format, false);\n        var currentRT = RenderTexture.active;\n        var rt = new RenderTexture(sw, sh, 32);\n        Graphics.Blit(self, rt);\n        RenderTexture.active = rt;\n        var source = new Rect(0, 0, rt.width, rt.height);\n        result.ReadPixels(source, 0, 0);\n        result.Apply();\n        RenderTexture.active = currentRT;\n        return result;\n    }\n\n\n\n\n\n    //Amazon Rekognition\n    public async Task Example(Amazon.Rekognition.Model.DetectFacesRequest image)\n    {\n        //AmazonRekognitionClient\n        AmazonRekognitionClient rekognitionClient = new AmazonRekognitionClient(\"AWSのアクセスキー\", \"AWSのシークレットキー\");\n\n        var response = await rekognitionClient.DetectFacesAsync(image);\n        \n        \n        foreach(var i in response.FaceDetails[0].Emotions)\n        {\n            Debug.Log(i.Confidence);\n            Debug.Log(i.Type);\n        }\n    }\n\n    \n\n    //start\n    public void Start()\n    {\n        webCamTexture = new WebCamTexture();\n        rawImage.texture = webCamTexture;\n        webCamTexture.Play();\n    }\n\n    public async void UseReko()\n    {\n        var img2d = ToTexture2D(webCamTexture);\n        var img = img2d.EncodeToJPG();\n        var stream = new MemoryStream(img);\n        List<string> att = new List<string>() { \"ALL\" };\n        var rekoImg = new Amazon.Rekognition.Model.Image { Bytes = stream };\n        var reqImg = new DetectFacesRequest {Attributes=att, Image = rekoImg };\n\n        await Example(reqImg);\n        \n    }\n\n```\n\n\n##1.Webカメラ\nRawImageにwebカメラで取得した画像をはっつけます。顔見たいからです。別に顔を画面で見たくねえよって人はrawImageなんていりません。\n\n\n```\n\n略\n\npublic RawImage rawImage;\nWebCamTexture webCamTexture;\n\n略\n\n\n    public void Start(){\n        webCamTexture=new WebCamTexture();\n        rawImage.texture=webCamTexture;\n        webCamTexture.Play()\n    }\n}\n\n```\n\nんで、webCamTextreなんですが、これをそのままImageとしてRekognitionに投げるわけにはいきません。\nというのも、Amazon.Rekognition.Model.DetectFacesRequestクラスのImageを投げなきゃいけないのです。ということで、\nWebCamTexture>Texture2D>JPG形式>MemoryStream>DetectFacesRequestという順序で変換していきます。\n\n####WebCamTexture>Texture2D\nWebCamTextureは一見Texture2Dなんですが、残念ながら違うんです。WebCamTextureというクラスなんです。だから、いったんToTexture2D()をつかって変換します。\n\n```\nvar img2d = ToTexture2D(webCamTexture);\n```\n\n####Texture2D>JPG\nこれも関数一発ドーンってやつです\n\n```\nvar img = img2d.EncodeToJPG();\n```\n\n####JPG>MemoryStream\nDetectFacesRequestを作るには、Byte列としてMemoryStreamを作る必要があります。MemoryStreamがなんだかはよくわかっていません。これもドーンです。\n\n```\nvar stream = new MemoryStream(img);\n```\n####MemoryStream>DetectFacesRequest\nこれはnewするときの引き数にMemoryStreamを入れるだけです。\n\n```\nvar rekoImg = new Amazon.Rekognition.Model.Image { Bytes = stream };\n```\n\n\nこれで投げる画像はOKです。あと、どんな情報が返ってくるかの指定として、ALLを指定しておきます。ALLじゃないと感情値とかは返ってきません。\n\n```\nList<string> att = new List<string>() { \"ALL\" };\n```\n\nんで最後に\n\n```\nvar reqImg = new DetectFacesRequest {Attributes=att, Image = rekoImg };\n```\nというようにRekognitionに投げるものを作ってあげれば終了です。\n\n\n\n##RekognitionにWebカメラの画像を投げる\n\n```\nAmazonRekognitionClient rekognitionClient = new AmazonRekognitionClient(\"AWSのアクセスキー\", \"AWSのシークレットキー\");\n\n        var response = await rekognitionClient.DetectFacesAsync(image);\n\n```\nここで、DetectFacesAsync()をつかって投げています。ここで大事なのが、DetectFacesじゃなくてDetectFacesAsyncを使わなくちゃいけないということです。非同期なのでそこら辺のことも書き足さなきゃデス。\n\nAsynchronous operations (methods ending with Async) in the table below are for .NET 4.5 or higher. For .NET 3.5 the SDK follows the standard naming convention of BeginMethodName and EndMethodName to indicate asynchronous operations - these method pairs are not shown in the table below.\n（APIリファレンスにちっちゃく書いてある)\n\nきちんとリファレンス読むべきですね。(Asyncないとerrorとしてinaccesible due to のやつが出てきます)\n\n\n\n\n##返ってきたJson風データから感情値を取り出す\n返ってくるデータはこんな形です。\n\n```\n{\n   \"FaceDetails\": [ \n      { \n         \"AgeRange\": { \n            \"High\": number,\n            \"Low\": number\n         },\n         \"Beard\": { \n            \"Confidence\": number,\n            \"Value\": boolean\n         },\n         \"BoundingBox\": { \n            \"Height\": number,\n            \"Left\": number,\n            \"Top\": number,\n            \"Width\": number\n         },\n         \"Confidence\": number,\n         \"Emotions\": [ \n            { \n               \"Confidence\": number,\n               \"Type\": \"string\"\n            }\n         ],\n         \"Eyeglasses\": { \n            \"Confidence\": number,\n            \"Value\": boolean\n         },\n         \"EyesOpen\": { \n            \"Confidence\": number,\n            \"Value\": boolean\n         },\n         \"Gender\": { \n            \"Confidence\": number,\n            \"Value\": \"string\"\n         },\n         \"Landmarks\": [ \n            { \n               \"Type\": \"string\",\n               \"X\": number,\n               \"Y\": number\n            }\n         ],\n         \"MouthOpen\": { \n            \"Confidence\": number,\n            \"Value\": boolean\n         },\n         \"Mustache\": { \n            \"Confidence\": number,\n            \"Value\": boolean\n         },\n         \"Pose\": { \n            \"Pitch\": number,\n            \"Roll\": number,\n            \"Yaw\": number\n         },\n         \"Quality\": { \n            \"Brightness\": number,\n            \"Sharpness\": number\n         },\n         \"Smile\": { \n            \"Confidence\": number,\n            \"Value\": boolean\n         },\n         \"Sunglasses\": { \n            \"Confidence\": number,\n            \"Value\": boolean\n         }\n      }\n   ],\n   \"OrientationCorrection\": \"string\"\n}\n```\n\nさっき、返ってくるデータ指定したけれど、DefaultだとBoundingBox, Confidence, Pose, Quality, Landmarksだけ返ってきます。\nforeachでちょちょいと出してあげればOKです。\n\n以上、Rekognitionの簡単な使い方でした。感情値データを使えばいろいろなことができるので遊んでみてください。\nあと、動くけれどここのやり方違うとかあるかもなので、そこんところは教えてくれると嬉しいです。\n","user":"novelworks","created_at":"2021-03-29T00:28:50+09:00","updated_at":"2021-03-29T00:28:50+09:00"},{"url":"https://qiita.com/LittleGreenMen/items/902ef02fb7d3914e5562","title":"素人基盤エンジニアがDockerでDjango REST Frameworkとreactを触るシリーズ③：reactの導入","body":"\n[素人基盤エンジニアがDockerでDjango REST Frameworkとreactを触るシリーズ②：Django REST Framework](https://qiita.com/LittleGreenMen/items/1c09bb1e2241a5d750fa)のつづき。\n[①からみたい場合はこちら。素人基盤エンジニアがDockerでDjango REST Frameworkとreactを触るシリーズ①：Djangoの導入](https://qiita.com/LittleGreenMen/items/f60c5a8c5138ddaaed79)\n\n# reactの導入\n最終的には、S3上にreactのアプリを配置してCloudFront経由で表示させたいが、構築/テストまでは同じEC2上でreactとdocker上のDjango REST frameworkを動作させて連携させることとする。\n動作が確認出来たら、ビルドしS3に移行する。\n### node.jsの導入\nreactのビルド環境として、node.jsが必要なので、下記手順に従いインストールする。\nhttps://docs.aws.amazon.com/ja_jp/sdk-for-javascript/v2/developer-guide/setting-up-node-on-ec2-instance.html\n\n```shell\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash\n```\n```shell\n. ~/.nvm/nvm.sh\n```\n```shell\nnvm install node\n```\n```shell\nnode -e \"console.log('Running Node.js ' + process.version)\"\n```\nRunning Node.js v15.12.0\n↑のような形でバージョンが表示されたらインストールは完了。\n\n### create-react-app\n今回は、reactアプリを簡単に作成することができるツールであるcreate-react-appを利用する。\n（本格的にreactアプリを作成したい場合は自分で一から作成したほうが良いと思うが、今回はあくまでreactとDjango REST Frameworkを利用してとりあえず動くものを作るというところを目標とする。）\ndjangoのためのファイル群をbackendというディレクトリに作成したので、一旦/home/ec2-userまで戻り、下記コマンドを実行する。\n\n```shell\ncd /home/ec2-user\nnpm install -g yarn\nyarn global add create-react-app\ncreate-react-app frontend\n```\nしばらくすると、frontendというディレクトリが作成され、下記のような構成になっているはず。\n\n```text\nfrontend\n∟node_modules\n　∟パッケージ多数\n∟package.json\n∟public\n　∟favicon.ico\n　∟index.html\n　∟logo192.png\n　∟logo512.png\n　∟manifest.json\n　∟robots.txt\n∟README.md\n∟src\n　∟App.css\n　∟App.test.js\n　∟index.js\n　∟reportWebVitals.js\n　∟App.js\n　∟index.css\n　∟logo.svg\n　∟setupTests.js\n∟yarn.lock\n```\nまずはデフォルトの状態で、reactアプリを起動させてみる。\n\n```shell\ncd frontend\nyarn start\n```\nhttp://\\<ip-address>:3000\nにアクセスする。\n![DRF011.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/369619/8185a218-992a-358e-949e-44ea465c5c8b.png)\nreactアプリが動作していることがわかる。\nctrl+Cで一旦終了し、下記ソースを修正してみる。\n\n```html:public/index.html\n<!DOCTYPE html>\n<html lang=\"ja\">\n  <head>\n    <meta charset=\"utf-8\" />\n    <link rel=\"icon\" href=\"%PUBLIC_URL%/favicon.ico\" />\n    <link href=\"https://use.fontawesome.com/releases/v5.6.1/css/all.css\" rel=\"stylesheet\">\n    <title>ReactSampleApp</title>\n  </head>\n  <body>\n    <h1 class=\"title\">ToDo Apps(React+DjangoRestFramework)</h1>\n    <div id=\"root\"></div>\n  </body>\n</html>\n```\n\n```js:src/App.js\nimport React, { Component } from 'react';\nimport axios from 'axios';\n\nclass App extends Component {\n    constructor(props) {\n        super(props);\n        this.state = {\n            todos: [],\n            hostname: \"\"\n        };\n    }\n\n    componentDidMount() {\n        this.getTodos();\n        this.getHostname();\n    }\n\n    getTodos() {\n        axios\n            .get('http://<ip-address>:8000/api/todos/')\n            .then(res => {\n                this.setState({ todos: res.data });\n            })\n            .catch(err => {\n                console.log(err);\n            });\n    }\n\n    getHostname() {\n        axios\n            .get('http://<ip-address>:8000/api/hostname/')\n            .then(res => {\n                this.setState({ hostname: res.data });\n            })\n            .catch(err => {\n                console.log(err);\n            });\n    }\n\n    render() {\n        return (\n            <div>\n                {this.state.todos.map(item => (\n                    <div key={item.id}>\n                        <h2>{item.title}</h2>\n                        <p className=\"item_body\">{item.body}</p>\n                    </div>\n                ))}\n\n                <div className=\"box30\">\n                    <div className=\"box-title\">HOSTNAME</div>\n                    <p>{this.state.hostname.hostname}</p>\n                </div>\n            </div>\n        );\n    }\n}\n\nexport default App;\n```\n\\<ip-address>の部分を、EC2のIPアドレスにすることを忘れないように注意。\nここは、CloudFrontでの構成に移行すればIPアドレスを書かなくてもよくなる。\n\n```css:src/index.css\nbody {\n  margin: 0;\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen',\n    'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue',\n    sans-serif;\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\ncode {\n  font-family: source-code-pro, Menlo, Monaco, Consolas, 'Courier New',\n    monospace;\n}\n\nh1.title {\n  font-family: 'Segoe Print',sans-serif;\n  padding: 0.5em;\n  color: #494949;/*文字色*/\n  background: #fffaf4;/*背景色*/\n  border-left: solid 5px #ffaf58;/*左線（実線 太さ 色）*/\n}\n\n.box30 {\n    margin: 0 auto 0 20px;\n    width: 300px;\n    background: #f1f1f1;\n    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.22);\n}\n.box30 .box-title {\n    font-size: 1.2em;\n    background: #5fc2f5;\n    padding: 4px;\n    text-align: center;\n    color: #FFF;\n    font-weight: bold;\n    letter-spacing: 0.05em;\n}\n.box30 p {\n    text-align: center;\n    padding: 15px 20px;\n    margin: 0 0;\n}\n\nh2 {\n  position: relative;\n  padding: 8px 15px;\n  margin-left: 40px;\n  background: #def3ff;\n  border-radius: 20px;\n}\n\nh2:before {\n  font-family: \"Font Awesome 5 Free\";\n  content: \"\\f111\";\n  position: absolute;\n  font-size: 15px;\n  left: -40px;\n  bottom: 0;\n  color: #def3ff;\n}\n\nh2:after {\n  font-family: \"Font Awesome 5 Free\";\n  content: \"\\f111\";\n  position: absolute;\n  font-size: 23px;\n  left: -23px;\n  bottom: 0;\n  color: #def3ff;\n}\n\np.item_body {\n  font-family: 'Mv Boli',sans-serif;\n  margin-left: 80px;\n}\n```\nソース内で、axiosというパッケージを利用しているので、frontendディレクトリで下記コマンドを利用してパッケージを追加しておく。\n\n```shell\nyarn add axios\n```\n\n\nまた、Django側の設定も、別サイトからのクロスオリジンアクセスがあるため、下記のように書き換える。\n\n```python:backend/todo_project/settings.py\nMIDDLEWARE = [\n    'corsheaders.middleware.CorsMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.security.SecurityMiddleware',\n    'django.contrib.sessions.middleware.SessionMiddleware',\n    'django.middleware.common.CommonMiddleware',\n    'django.middleware.csrf.CsrfViewMiddleware',\n    'django.contrib.auth.middleware.AuthenticationMiddleware',\n    'django.contrib.messages.middleware.MessageMiddleware',\n    'django.middleware.clickjacking.XFrameOptionsMiddleware',\n]\n\nCORS_ORIGIN_ALLOW_ALL = True\n```\n一行目のcorsheaders～と最後のCORS_ORIGIN_ALLOW_ALLを追加。\n\ndocker-compose upでdbとdjangoのコンテナを起動する。\n（この後reactも起動したいのでバックエンドで起動する。）\n\n```shell\ncd backend\ndocker-compose up &\n```\n\nコンテナを起動させたまま、reactを起動。\n\n```shell\ncd ../frontend\nyarn start\n```\n\nhttp://\\<ip-address>:3000/\nにアクセスしてみる。\n![DRF012.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/369619/9afc086b-0891-891f-f5c5-ee3ea89e7747.png)\n\n無事、todoとhostnameが表示されていることがわかる。\n次回は、今回構築したreactアプリをビルドしS3へ配置して最終系であるCloudfrontの形に変更する。\n\nつづく\n","user":"LittleGreenMen","created_at":"2021-03-29T00:28:36+09:00","updated_at":"2021-03-29T00:32:41+09:00"},{"url":"https://qiita.com/moomim/items/e11471753ea7b7f907e6","title":"Windows資格情報のバックアップ/復元手順","body":"PC交換の時にいろいろ調べたので備忘録。\n\nWindowsの資格情報をバックアップ復元する手順\n　※Webのパスワードではなく、フォルダアクセス等のもののみ\n\nWindows8以降で利用可。\n\n#バックアップ手順\n①　スタートで以下を入力する。\n　　「資格情報マネージャー」\n\n②　[Windows資格情報]を押下する。\n\n③　[資格情報のバックアップ]を押下する。\n\n④　[バックアップの作成先]を指定し、次へを押下する。\n\n⑤　[Ctrl+Alt+Del]を押下する。\n\n⑥　パスワードの入力が求められるので、\n　　現在ログインしているユーザのログインパスを入力する。\n　　　※インポート時にも必要になります。\n\n#復元手順\n\n⑦　スタートで以下を入力する。\n　　「資格情報マネージャー」\n\n⑧　[Windows資格情報]を押下する。\n\n⑨　[資格情報の復元]を押下する。\n\n⑩　[バックアップファイルの場所]にて④のファイルを選択し、[次へ]を押下する。\n\n⑪　[Ctrl+Alt+Del]を押下する。\n\n⑫　パスワード入力が求められるので、\n　　⑥で入力したパスワードを入力する。\n　　　※インポートするユーザが違っても⑥で利用したパスワードになります。\n\n⑬　[F5]を押下し、ウィンドウを更新する。\n\n⑭　エクスポートと同じ資格情報があることを確認し、終了です。\n\n以上\n","user":"moomim","created_at":"2021-03-29T00:26:17+09:00","updated_at":"2021-03-29T00:26:17+09:00"},{"url":"https://qiita.com/cpcznksutbeoa/items/45f220c9b6f76e722640","title":"AtCoder、中一の間に青コーダーに","body":"なれませんでした。\n#精進量\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/963100/d226f2e8-29b4-fd45-4980-d2e087f01a44.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/963100/d776ca1c-4e31-922c-8b7d-b12d9c397ba2.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/963100/2db546bb-7388-424d-d074-7a53320f9093.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/963100/4ee602e2-dfdf-bc0d-8a66-d9c664514125.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/963100/7db3221e-fdf8-83c0-6cf0-e0e506160c3b.png)\n｢え、少な。よくこんなんで青コーダーになろうと思ったな。｣\n1500AC、水まで全埋め、青も7~80%は埋めてたかったなって思ってます。\n同期を見てても1500とか1700とかはACしてるので、それくらいはやっておきたかったかな\n#パフォーマンス・レーティング推移\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/963100/a178160b-4468-80ee-0ec4-34ba43f49ea6.png)\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/963100/78ae5701-904d-1e30-b2c4-175595f43a78.png)\n最後のゴタゴタなんや、いろいろ起きすぎやろ、ということであとで解説。\n#これまでの記録\n##2020年2月\nprocessing言語をちょっとやる。変数は理解したけど、配列理解できなくてやめた。\n##2020年5月\nクラスメイトがパ研の宣伝してたので入ってみる。\n5月28日にパ研に仮入部する。\n##2020年6月\n5月の終わりごろからAPG4bを読んだり過去問解いたりする。\n6月17日にコンテストにそろそろ出たいと思ったのでAtCoderのアカウントを作る。\n6月21日初コンテストABC171。3完で茶パフォだった\n##2020年8月\n精進してたらABC174で入茶した。当時646AC。\nC++始めてから2カ月ちょいで入茶したので、ここまでは割と順調(?)だと思う。同期に初回コンテストで入茶した人いるけど、そんな人のことは気にしません。\n8月22日に初水パフォ。ここら辺でさっき言った人と違う同期をライバル視したはず。\n##2020年9月\n9月13日、さっきの同期にあっさり抜かされる。\nこれ以降この同期には追い付いてないです。\n9月19日、JOI一次予選1回目。瞬殺した。スマホで15,6分台なので、まあまあ早いはず。\n##2020年10月\nARC105で入緑した。当時960AC。\n10月18日、JOI一次予選2回目。PCだったので6分台だったと思う。\n10月31日、1000ACを突破する。\nここら辺、文化祭準備で結構忙しかった。\n##2020年11月\n11月21日、JOI一次予選3回目。スマホで10分切った気がする。\n11月28日、入水する。自殺じゃない方のね。当時1081AC。\nこの時、青パフォ3連続で入水した。割とノってた時期。\n###余談\n入水って、勘違いされるから、寒色に入ったっていう意味で入寒とかの方がいいんじゃないかなって思う。みんなはどっちの方がいいんだろ、\n##2020年12月\nJOI対策めっちゃしてた。\n12月13日、JOI二次予選でボーダー188点で184点とって落ちた。詳しくはhttps://qiita.com/cpcznksutbeoa/items/f53a88d1c9d47ea58cd0 を見てください。\nここらへんでOTPCあった気がする。ずっと椅子温めてた。チームメイトの2人、ごめんなさい...。\n##2021年1月\nここらへんから伸びるスピードが落ちる。\n目標を中一の間に1400から1600(入青)に引き上げる。\n##2021年2月\nとくに何もなかった...。\n##2021年3月\n3月忙しかったのでいろいろ書く。\n3月7日、人生初の黄パフォをとる。この時点で1500に乗り、3月中に入青を確信する。\n3月11日、新入生プログラミングコンテストの開催が決定する。ここから作問をずっとやって精進をそんなにやらないようになる。みなさん、このコンテスト、出ましょう！3月31日に開催です！\nABC195,ARC114,ABC196で適正レートに戻される。\nARC115で2回目の黄パフォをとる。1510だったのでまだあると思った。\nここでネタ画像が生まれた。\n![image.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/963100/d99d6fbd-ccac-6172-11b9-3d94b4736541.png)\nなんやねんこのレートグラフ()\nABC197,ARC116で冷え、1500を切る。\n3月中にRatedコンテストが生えることはあり得ないので、中1青コーダーになれないことが確定する。\n今期中1で青になった経験がある人が4人いるので、今月中に青色になりたかった人生でした...。\n#来年の目標\nJOIで春に頑張っていきたいです。本選はマストかな、という感じ。\nAtCoderは2200台に乗っけたいです。\n#終わりに\n同期がプロすぎます。助けてください。(助けなくて結構です)\n日本語が前より変になっているかもしれません...\n青色目指してる人は、1500問とか1800問とか問題を解きましょう!\n最後まで読んでくださり、ありがとうございました！\n","user":"cpcznksutbeoa","created_at":"2021-03-29T00:21:34+09:00","updated_at":"2021-03-29T00:47:04+09:00"},{"url":"https://qiita.com/chocoshop/items/4d75f814b3bb9841c1d3","title":"Web API DOMとEvent Flowを理解する","body":"# はじめに\n\nふと、DOMとは何か理解したくなったので勉強してまとめたいと思います。\nDOM全体だとかなり長くなってしまうので、今回はよくある下記のようなコードがどのような仕組みで動いているのか理解したいと思います。\n\n```js\nlet element = document.getElementById('el');\nelement.addEventListener('click', function() {})\n```\n\n# DOM: Document Object Model\nDOMは、HTMLやXMLを操作するためのインターフェイスです。\nXMLに対してDOM操作って個人的には馴染みのないものですね。\n\nWebページを表現するHTMLは、あくまで\"文書\"です。\nDOMは、HTMLをオブジェクトとして操作・変更するためのインターフェイスであり、その操作を行う言語がJavaScriptです。\nDOM操作を主に使用される言語がJavaScriptなだけであり、DOM操作は他の言語でも可能です。\n例えばPHPには、DOM操作するためのクラスが用意されています。\nhttps://www.php.net/manual/ja/book.dom.php\n\n\n```php\n<?php\n$doc = new DOMDocument();\n$doc->loadHTML('<html><body id=\"test\">Test<br></body></html>');\necho $doc->getElementById('test')->tagName; // body\n?>\n```\n\n\n## DOMインターフェイス\nDOMで提供されるインターフェイスは様々なものがありますが、\nいくつか取り上げてまとめていきたいと思います。\n\n## EventTarget\nDOMを構成する基底のインターフェースです。\nイベントを登録したり、DOM操作の対象になるオブジェクトです。\nイベントを追加するaddEventListener()はEventTargetで実装されているメソッドです。\n\n## Node\nDOMを構成するインターフェースの1つです。EventTargetのメソッドとプロパティを継承しています。\nDOMのインターフェイスは、基本的にNodeを継承しています。\n\n例えば以下のものはNodeに含まれます。\n\n- HTMLElement\n- テキスト\n- コメント\n- 属性\n\nDOMは、HTML内のオブジェクトをNodeとして扱います。\n以下のようなHTMLを分類してみるとこのような感じになると思います。\n\n- html -> element node\n- body -> element node\n- h1 -> element node\n- メイン -> テキスト node\n- <!-- メイン --> -> コメント node\n\n```html\n<html>\n  <body>\n    <h1>タイトル</h1>\n    <!-- メイン -->\n  </body>\n</html>\n```\n\n\n## Document\n> DOM ツリーであるウェブページのコンテンツへのエントリーポイントとして働きます\nhttps://developer.mozilla.org/ja/docs/Web/API/Document\n\n`<html>`から始まるDOMツリーにアクセスするための、エントリポイントです。\nNodeを継承していて、ドキュメント全体の情報を検索したりすることができます。\n\n```html\n<html>\n  <body>\n    <h1>タイトル</h1>\n    <img src=\"hoge.jpg\" alt=\"\">\n  </body>\n</html>\n\n<script>\nlet images = document.images; // HTMLCollection[img]\n</script>\n```\n\n\n\nDocumentやWindowオブジェクトは、Nodeを継承していて、EventTargetで実装されているaddEventListenerといったメソッドにアクセスすることができます。\n\n\n# Event Flow\nインターフェイスを追っていくことで、addEventListenerが実装されている基底のインターフェイスまで学ぶことができました。\n次に、イベント処理がどのように行われるのかみてみたいと思います。\n\n\n## イベントとは\nそもそもイベントとは何か、簡単にまとめたいと思います。\nWebページで行われる状態の変化や操作全般を指しています。\nマウスカーソルの移動やボタンのクリック、動画の再生もイベントととして扱うことができます。\nどんなイベントがあるか、こちらからわかりやすく一覧でみることができます。量は大変多いです。\nWebVRに関連したイベントもありますね👀\nhttps://developer.mozilla.org/ja/docs/Web/Events\n\n\n\n## イベントフロー\n処理の流れを整理するためにイベントフローを理解するのが良さそうです。\n![Event Flow](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/323969/083ef66c-e29c-2e1d-9795-f1632b77621d.png)\n画像は、本記事の参考文献でもあるW3Cのページからお借りしました。\nhttps://www.w3.org/TR/DOM-Level-3-Events/\n\nイベントが発生してからEventListenerの処理が行われるまで3つのフェーズがあります。\n\n- capture phase\nWindowオブジェクトからターゲットとなるElementをツリー構造を下っていくように捕捉します。\n\n\n- target phase (at-target phase)\nターゲットを見つけたフェーズです。 イベントの種類をみてbubble phaseへ移すか判断します。\n\n\n- bubble phase\ncapure phaseとは逆に、イベントが起こったElementから親Nodeを辿ってイベントを伝搬させます。\nイベントハンドラは基本的にバブリングフェーズに登録されるので、ユーザーが定義したハンドラの実行もこのフェーズで行われます。\n\n伝播ということがどういうことかわかりづらかったので例に以下のようなコードを用意しました。\n`body`と`h1`には同じハンドラを登録しています。\n`h1`をクリックした時に、consoleに2回以下のようなログが記録されるはずです。\n`[object HTMLHeadingElement] clicked`\nこれはイベントのバブリングによってbodyに登録されたハンドラが実行されたことによります。\n`e.target`は、イベントが発生した要素を示すので、`body`がクリックされた訳ではなく、`h1`で発生したイベントが伝播したことがわかると思います。\n\n```html\n<html>\n  <body id=\"body\">\n    <h1 id=\"h1\">タイトル</h1>\n  </body>\n</html>\n\n<script>\n  function handler(e) {\n    console.log(`${e.target} clicked`);\n  }\n  document.getElementById('body').addEventListener('click', handler);\n  document.getElementById('h1').addEventListener('click', handler);\n</script>\n```\n\nなお、イベントの伝播をせずにターゲットのElementだけで処理をさせたいような場合には、`e.stopPropagation()`を書いて上げることで実現可能です。\n\n```js\nfunction handler(e) {\n  e.stopPropagation()\n  console.log(`${e.target} clicked`);\n}\n```\n\n# まとめ\n冒頭に紹介したコードを改めて読んでまとめとします。\n\n```js\nlet element = document.getElementById('el');\nelement.addEventListener('click', function() {})\n```\n\n####`el`がclickされた時の流れ\n\n- クリックイベントが発生する\n- イベントは、Windowオブジェクトから子Nodeに伝播する\n- ターゲットとなる`el`を見つける\n- バブリングフェーズに登録された匿名関数を実行する\n- (親Nodeへイベントが伝搬する)\n\n\n# 参考\nDOMの紹介\nhttps://developer.mozilla.org/ja/docs/Web/API/Document_Object_Model/Introduction\n\nDOM EventTarget\nhttps://developer.mozilla.org/ja/docs/Web/API/EventTarget\n\nDOM Node\nhttps://developer.mozilla.org/ja/docs/Web/API/Node\n\nブラウザの仕組み全般\nhttps://www.html5rocks.com/ja/tutorials/internals/howbrowserswork/#The_rendering_engine\n\nイベントフロー\nhttps://www.w3.org/TR/DOM-Level-3-Events/\n","user":"chocoshop","created_at":"2021-03-29T00:20:36+09:00","updated_at":"2021-03-29T00:23:49+09:00"},{"url":"https://qiita.com/k1mu0419/items/1ddb20c13f6c545df547","title":"昭和 VS 平成 ヒット曲の違いを分析【Spotify APIとPythonでデータ分析】","body":"\n今回は、<strong><a href=\"https://www.spotify.com/jp/\" target=\"_blank\" rel=\"noreferrer noopener\">Spotify</a></strong>の公式プレイリストである\n\n\n「<strong>昭和ポップス</strong>」\n\nhttps://open.spotify.com/embed/playlist/37i9dQZF1DX2QCBqV8Ylrq\n\n\n<p>と「<strong>平成ポップ<strong>ヒストリー</strong></strong>」</p>\n\nhttps://open.spotify.com/embed/playlist/37i9dQZF1DWYQelb54GZmT\n\n\nに含まれている曲のデータを比較・分析してみました！！\n\nでは、いってみよう！(๑˃̵ᴗ˂̵)و\n\n\n##はじめに\n\n\nはじめに、<strong>分析の方法</strong>を軽く説明します。\n\n\n\n<strong><a href=\"https://www.spotify.com/jp/\" target=\"_blank\" rel=\"noreferrer noopener\">Spotify</a></strong>は、配信している楽曲に\"<span class=\"bold-red\">AIで判定した曲の情報</span>\"を付与しています。\n\n\n\nこの\"<strong>情報</strong>\"には、「<strong>曲のキー</strong>」や「<strong>テンポ</strong>」などに加えて<strong>Spotify独自の評価項目</strong>も含まれます。\n\n\n\nたとえば、\"<strong>danceability</strong>\"は「<strong>踊りやすさ</strong>」の度合い示す項目になります。<br>(詳しくは、ドキュメント↓の<strong>Objects Index</strong>の項目あたりに書いてあります。)\n\n\nhttps://developer.spotify.com/documentation/web-api/reference/#objects-index\n\n\n\nそして、その\"<strong>情報</strong>\"は<strong><span class=\"marker\">Spotifyの</span><span class=\"marker\"><a href=\"https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%95%E3%82%A7%E3%83%BC%E3%82%B9\" target=\"_blank\" rel=\"noreferrer noopener\">API</a>を介して取得できます。</span></strong>\n\n\n「<strong><strong><a href=\"https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%95%E3%82%A7%E3%83%BC%E3%82%B9\" target=\"_blank\" rel=\"noreferrer noopener\">API</a></strong></strong>」は、<strong>ウェブサービス等が機能の一部を外部ユーザーにも使わせてくれる仕組み</strong>で、大雑把に言えば「<strong>プログラミング言語を使ってサービスの機能を使わせてもらうための受付窓口</strong>」みたいな概念だと思います。\n\n\nhttps://khufrudamonotes.com/spotify-api\n\n\n…というわけで今回の記事は、上記の2つのプレイリストの\"<strong>Spotifyが付与した情報</strong>\"を<strong><a href=\"https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%97%E3%83%AA%E3%82%B1%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%9F%E3%83%B3%E3%82%B0%E3%82%A4%E3%83%B3%E3%82%BF%E3%83%95%E3%82%A7%E3%83%BC%E3%82%B9\" target=\"_blank\" rel=\"noreferrer noopener\">API</a></strong>を介して取得し、主に<a href=\"https://www.python.org/\" target=\"_blank\" rel=\"noreferrer noopener\"><strong>python</strong></a>を使ってデータを比較・分析した結果になります。\n\n\n##昭和と平成 それぞれのデータの特徴を分析する。\n\n最初は、昭和と平成のプレイリストのデータを<strong>個別に分析</strong>してみます。\n\nどちらのプレイリストにも、それぞれ<span class=\"bold-red\">100曲分のデータ</span>が含まれています。\n\n\n###昭和ポップス\n\n\nまず、「<strong>昭和ポップス</strong>」に含まれる曲の<strong>リリース時期データ</strong>を見ます。\n\n<!-- wp:image {\"id\":13035,\"width\":470,\"height\":314,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large is-resized\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和ポップス-リリース時期.png\" alt=\"\" class=\"wp-image-13035\" width=\"470\" height=\"314\"/></figure>\n<!-- /wp:image -->\n\n\nすると、「<strong>昭和ポップス</strong>」と言いつつリリース時期が<strong>昭和(～1989年)の間に収まっていない</strong>のが分かります。\n\n\nつまり、「<strong>昭和ポップス</strong>」プレイリストには、リマスターやベストアルバムとして後日<span class=\"bold-red\">再リリース</span>された音源も多く含まれているようです。\n\n\n(「<strong>曲自体が作られた時期</strong>」と「<strong>他のデータとの関係性</strong>」を調べられないのは、少し残念ですね。)\n\n\n次に、各パラメーターの<span class=\"bold-red\">相関係数</span>を見てみます。\n\n<!-- wp:image {\"id\":13031,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和ポップス-相関係数-1024x274.png\" alt=\"\" class=\"wp-image-13031\"/></figure>\n<!-- /wp:image -->\n\n「<strong>loudness</strong>(ラウドネスの値)」と「<strong>energy</strong>(激しさの値)」の相関など、特に不思議ではない相関が多い印象です。\n\n\n\n###平成ポップヒストリー\n\n次は「<strong>平成ポップ<strong>ヒストリー</strong></strong>」のデータです。\n\n各パラメーターの<strong>相関係数</strong>を見てみます。\n\n\n<!-- wp:image {\"id\":13032,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/平成ポップス-相関係数-1024x275.png\" alt=\"\" class=\"wp-image-13032\"/></figure>\n<!-- /wp:image -->\n\n\nこちらも、あまり面白そうな特徴は見受けられません。\n\nあえて言うなら、「<strong>loudness</strong>(ラウドネスの値)」と「<strong>YearMonth</strong>(リリース時期)」との相関関係から<a href=\"https://ja.wikipedia.org/wiki/%E3%83%A9%E3%82%A6%E3%83%89%E3%83%8D%E3%82%B9%E3%83%BB%E3%82%A6%E3%82%A9%E3%83%BC\" target=\"_blank\" rel=\"noreferrer noopener\"><strong>音圧戦争</strong></a>の影響が具体的に分かりますね。</p>\n\n\nhttps://ja.wikipedia.org/wiki/%E3%83%A9%E3%82%A6%E3%83%89%E3%83%8D%E3%82%B9%E3%83%BB%E3%82%A6%E3%82%A9%E3%83%BC\n\n\n##昭和と平成との比較\n\nでは、いよいよ「<span class=\"bold-red\">昭和と平成の比較</span>」にいきましょう！\n\n###音圧\n\nまずは、<strong>音圧</strong>です。\n\n音圧に関しては、先ほど「<strong>平成ポップ<strong>ヒストリー</strong></strong>」個別の所見でも触れましたが…\n\n<!-- wp:image {\"id\":13033,\"width\":435,\"height\":379,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large is-resized\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和vs平成ポップス-リリース時期と音圧.png\" alt=\"\" class=\"wp-image-13033\" width=\"435\" height=\"379\"/></figure>\n<!-- /wp:image -->\n\n平成と昭和のデータを合算しても「<strong>loudness</strong>(ラウドネスの値)」と「<strong>リリース時期</strong>」には<span class=\"bold-red\">正の相関があります。</span>(計算した相関係数は<strong>約0.45</strong>)\n\nつまり、<strong><span class=\"marker\">昭和ヒット曲も再リリース時に音圧を上げた可能性が高い</span></strong>と伺えます。\n\nちなみに、<strong>散布図の右上</strong>の\"<strong>音圧がつよつよな曲</strong>\"は、<strong>DA PUMPの『U.S.A.』</strong>です。\n\n\n####DA PUMP / U.S.A.\n\nhttps://youtu.be/sr--GVIoluU\n\nYouTubeMVの再生画面を右クリックして「詳細統計情報」を見てみると、音圧が高すぎて音量を65％下げられているようです。\n\n(YouTubeやSpotifyなどの主要配信プラットフォームが<strong>ラウドネスノーマライゼーション</strong>を導入し、令和になって音圧戦争がやや落ち着いてきた印象もあります。)\n\n\n###キー\n\n<!-- wp:image {\"id\":13048,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和vs平成ポップス-キーの分布-1-1024x502.png\" alt=\"\" class=\"wp-image-13048\"/><figcaption>SpotifyのAIは転調を判別しません。付与されているキーの情報は恐らく曲の中で最も使用されている時間が長いキーだと思われます。</figcaption></figure>\n<!-- /wp:image -->\n\n<!-- wp:paragraph -->\n<p>「<strong>キーの違い</strong>」は<strong>ヴォーカルの音域</strong>の都合に拠る部分も多く、<span class=\"bold-red\">深い意味は無い</span>かもしれません。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>ただ、データを眺めて思うところはあります。…と言うのも、<strong>ヴォーカルの音域</strong>以外にも、\"<span class=\"bold-red\">キーの選択に影響を与える要素</span>\"はあると考えられます。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>それは、「<strong>楽器の演奏しやすさ</strong>」と「<strong>楽譜の読みやすさ</strong>」です。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>#がつく調号のキーは<strong>弦楽器</strong>、♭がつく調号のキーは<strong>管楽器</strong>が、<strong><span class=\"marker\">比較的演奏しやすいキー</span></strong>です。<br>そして、<strong>調号の(変化記号の)数が少ないキー</strong>の方が「<strong><span class=\"marker\">楽譜が読みやすい</span></strong>」と感じる人が多いはずです。</p>\n<!-- /wp:paragraph -->\n\n<span class=\"fz-12px\">詳しくはこちら↓</span>\n\nhttps://khufrudamonotes.com/music-key-decide\n\n\nキーの分布を見ると、昭和ヒット曲は「<strong>調号が少ないキー</strong>」、平成ヒット曲は「<strong>#がつく調号のキー</strong>」が比較的多い印象を受けます。\n\n調号の(変化記号の)数は、ある程度の読譜力を持つミュージシャンにはあまり関係無い気もするので、昭和に「<strong>調号が少ないキー</strong>」が多い理由はよく分かりません。\n\n一方、「<strong>平成ポップ<strong>ヒストリー</strong></strong>」に「<strong>#がつく調号のキー</strong>」が比較的多いのは、<span class=\"bold-red\">バンドの楽曲が多い</span>のと多少関係がありそうだと思いました。(弦楽器であるギターやベースが演奏しやすいキーが選ばれている。)\n\n###danceability\n\n<p><strong>danceability</strong>は「<strong>踊りやすさ</strong>」を示すSpotify独自の評価項目です。</p>\n\n<p>具体的にどのように「<strong>踊りやすさ</strong>」を判定しているかは分かりません。<br>ドキュメントでは以下の説明がされています。</p>\n\n\n<blockquote class=\"wp-block-quote\"><p>Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.</p><p>訳：テンポ、リズムの安定性、ビートの強さ、全体的な規則性などの音楽的要素の組み合わせに基づいて、トラックがどの程度ダンスに適しているかを説明します。値が0.0の場合は最もダンサブルではなく、1.0の場合は最もダンサブルです。</blockquote>\n\n\nhttps://developer.spotify.com/documentation/web-api/reference/#objects-index\n\n\n\n<!-- wp:image {\"id\":13049,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和vs平成ポップス-danceabilityの分布-1-1024x504.png\" alt=\"\" class=\"wp-image-13049\"/><figcaption>見やすさのためdanceabilityを100倍した値を四捨五入しています。</figcaption></figure>\n<!-- /wp:image -->\n\nこのデータを見ると、<strong>昭和のヒット曲の方が比較的ダンスに適している</strong>のが分かります。\n\n平成ヒット曲の\"<strong>バラード風味曲が多そうな印象</strong>\"とも合致します。\n\n###テンポ(BPM)\n\n<!-- wp:image {\"id\":13050,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和vs平成ポップス-BPMの分布-1-1024x502.png\" alt=\"\" class=\"wp-image-13050\"/><figcaption>BPMを100～200の間に収めるため、100以下の値を2倍、200より大きい値を1/2倍しています。</figcaption></figure>\n<!-- /wp:image -->\n\n<!-- wp:table -->\n<figure class=\"wp-block-table\"><table><tbody><tr><td></td><td><strong>昭和ポップス</strong></td><td><strong>平成ポップヒストリー</strong></td></tr><tr><td>頻出BPM：</td><td>130、146、148</td><td>111、123、124、174</td></tr><tr><td>BPMの平均値：</td><td>140</td><td>144</td></tr><tr><td>BPMの中央値：</td><td>138</td><td>138</td></tr><tr><td>BPMの最大値：</td><td>200</td><td>200</td></tr><tr><td>BPMの最小値：</td><td>102</td><td>100.5</td></tr></tbody></table></figure>\n\n\n昭和と平成を比較して、極端な偏りは感じられません。\n<strong>全体的に見るとBPM=120〜150辺り</strong>が多く、細かく見れば<strong>昭和はBPM=150</strong>辺り、<strong>平成はBPM=120</strong>辺りが多そうです。\n\nしばしば「<strong>最近の曲は昔の曲よりテンポが速い</strong>」みたいな感想を耳にします。\nしかし、実際はテンポよりも<span class=\"bold-red\">リズムの組み方</span>によって<strong>体感的な曲の速さ</strong>は大きく変わります。\n\n詳しくはこちら↓\n\nhttps://khufrudamonotes.com/rhythm-pattern-making\n\n\n\n本当に時代を追うごとに曲のテンポが速くなっていたら、そのうち人間が演奏ができなくなりますからね。笑　\nこのデータからも、その一端が伺えるのではないでしょうか。\n\n###曲の長さ\n\n<!-- wp:image {\"id\":13051,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和vs平成ポップス-曲の長さの分布-1-1024x502.png\" alt=\"\" class=\"wp-image-13051\"/></figure>\n<!-- /wp:image -->\n\n<!-- wp:paragraph -->\n<p><strong><span class=\"marker\">平成のヒット曲の方が、曲が長い</span></strong>傾向が分かります。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>平成では「平歌とサビを繰り返すシンプル曲構成」ではない<strong>凝った構成の曲</strong>が増えた分、曲が長くなったのかもしれません。また、平成にバラード系の曲が多いのとも関係がありそうです。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>ただ、ストリーミング配信が主流になってきた<strong>令和</strong>では<strong>また短い曲が増えそう</strong>です。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>そして、昭和と平成共通して大体<span class=\"bold-red\">3分前半～5分後半の間</span>に収まっています。<br>ポップスのヒット曲を作ろうと思う場合は、<strong>30秒の曲</strong>や<strong>10分の曲</strong>はあまり作らない方が良さそうですね。笑</p>\n<!-- /wp:paragraph -->\n\n###Acousticness\n\n<!-- wp:paragraph -->\n<p><strong>Acousticness</strong>は「<strong>アコースティック度</strong>」を示すSpotify独自の評価項目です。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:quote -->\n<blockquote class=\"wp-block-quote\"><p>A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.</p><p>訳：トラックがアコースティックであるかどうかの信頼度を 0.0 から 1.0 の範囲で表します。1.0 は、トラックがアコースティックであるという確信度が高いことを表します。</p><cite><a href=\"https://developer.spotify.com/documentation/web-api/reference/#objects-index\" target=\"_blank\" rel=\"noreferrer noopener\">https://developer.spotify.com/documentation/web-api/reference/#objects-index</a></cite></blockquote>\n<!-- /wp:quote -->\n\n<!-- wp:image {\"id\":13052,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和vs平成ポップス-Acousticnessの分布-1024x502.png\" alt=\"\" class=\"wp-image-13052\"/><figcaption>見やすさのためAcousticnessを100倍した値を四捨五入しています。</figcaption></figure>\n<!-- /wp:image -->\n\n<!-- wp:paragraph -->\n<p><strong>平成のヒット曲のAcousticnessが低い</strong>傾向が伺えます。</p>\n<!-- /wp:paragraph -->\n\n<!-- wp:paragraph -->\n<p>具体的な曲名を見てみましょう。</p>\n<!-- /wp:paragraph -->\n\n\nAcousticnessが高いトップ10はこちら\n\n<!-- wp:table -->\n<figure class=\"wp-block-table\"><table><tbody><tr><td><strong>list_name</strong></td><td><strong>Name</strong></td><td><strong>Artist</strong></td><td><strong>Acousticness</strong></td></tr><tr><td>平成ポップヒストリー</td><td>さくら - 独唱</td><td>Naotaro Moriyama</td><td>95</td></tr><tr><td>平成ポップヒストリー</td><td>ハナミズキ</td><td>Yo Hitoto</td><td>88</td></tr><tr><td>昭和ポップス</td><td>さよならの向う側</td><td>Momoe Yamaguchi</td><td>85</td></tr><tr><td>平成ポップヒストリー</td><td>真夏の果実</td><td>サザンオールスターズ</td><td>82</td></tr><tr><td>昭和ポップス</td><td>ノーサイド</td><td>Yumi Matsutoya</td><td>81</td></tr><tr><td>平成ポップヒストリー</td><td>長い間</td><td>Kiroro</td><td>81</td></tr><tr><td>昭和ポップス</td><td>ウエディング・ベル</td><td>Sugar</td><td>79</td></tr><tr><td>平成ポップヒストリー</td><td>栄光の架橋</td><td>Yuzu</td><td>78</td></tr><tr><td>昭和ポップス</td><td>魅せられて</td><td>Judy Ongg</td><td>76</td></tr><tr><td>昭和ポップス</td><td>いっそ セレナーデ - Remastered 2018</td><td>Yosui Inoue</td><td>75</td></tr></tbody></table></figure>\n<!-- /wp:table -->\n\n\nAcousticnessが低い曲10曲はこちら\n\n<!-- wp:table -->\n<figure class=\"wp-block-table\"><table><tbody><tr><td><strong>list_name</strong></td><td><strong>Name</strong></td><td><strong>Artist</strong></td><td><strong>Acousticness</strong></td></tr><tr><td>平成ポップヒストリー</td><td>シャングリラ</td><td>Chatmonchy</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>君はロックを聴かない</td><td>Aimyon</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>さよならエレジー</td><td>Masaki Suda</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>TRUE LOVE</td><td>Fumiya Fujii</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>愛のために</td><td>Tamio Okuda</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>ラブ・ストーリーは突然に</td><td>Kazumasa Oda</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>GLAMOROUS SKY</td><td>Nana starring Mika Nakashima</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>Rising Sun</td><td>EXILE</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>恋</td><td>Gen Hoshino</td><td>0</td></tr><tr><td>平成ポップヒストリー</td><td>Boys &amp; Girls</td><td>Ayumi Hamasaki</td><td>0</td></tr></tbody></table></figure>\n\n<strong>Acousticness</strong>\"をSpotify側が具体的にどう判定しているかは分かりません。\n\nただ、なんとなく<span class=\"bold-red\">ミックスのやり方や電子楽器の使用の有無</span>などが影響していると感じます。\n\n###valence\n\n<strong>valence</strong>は「<strong>音楽的なポジティブさ</strong>」を示すSpotify独自の評価項目です。\n\n<!-- wp:quote -->\n<blockquote class=\"wp-block-quote\"><p>A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).</p><p>訳：0.0～1.0の間で、トラックから伝わる音楽的なポジティブさを表す尺度です。値の高いトラックはよりポジティブに聞こえ（例：幸せ、陽気、多幸感）、値の低いトラックはよりネガティブに聞こえます（例：悲しい、落ち込んでいる、怒っている）。</p><cite><a href=\"https://developer.spotify.com/documentation/web-api/reference/#objects-index\" target=\"_blank\" rel=\"noreferrer noopener\">https://developer.spotify.com/documentation/web-api/reference/#objects-index</a></cite></blockquote>\n<!-- /wp:quote -->\n\n<!-- wp:image {\"id\":13055,\"sizeSlug\":\"large\",\"linkDestination\":\"none\"} -->\n<figure class=\"wp-block-image size-large\"><img src=\"https://khufrudamonotes.com/wp-content/uploads/2021/02/昭和vs平成ポップス-valenceの分布-1024x502.png\" alt=\"\" class=\"wp-image-13055\"/></figure>\n\nSpotifyのAIの判定方法が分からないので詳しくは分かりません。\nしかし、全体的な傾向で見ると、平成のポップスの方が<strong>ネガティブ傾向の曲</strong>が多めなようです。\n\n<strong>時流や世代間の価値観の違い</strong>などと関係があるのでしょうか。\n\n##まとめと感想\n\n\nデータ分析をしてみると<strong>直観では気付きにくい部分</strong>が具体的に見えて面白かったです。\nただ、どちらのプレイリストもたった100曲なので、もう少し大きな括りで見ると結果も変わってくると思います。\n\n\n\n\nよければ他の分析もどうぞ。\n\n\nhttps://khufrudamonotes.com/melodic-analysis\n\nhttps://khufrudamonotes.com/uverworld-analysis\n","user":"k1mu0419","created_at":"2021-03-29T00:20:30+09:00","updated_at":"2021-03-29T10:27:03+09:00"},{"url":"https://qiita.com/KotoriAniki/items/80ac89b35be4e6bed3d7","title":"【解説】AtCoder Beginner Contest 197【A~C問題】","body":"#はじめに\nｵｲｲｲｲｲｲｲｲｲｲｲｲｯｽ！どうも、歌うプログラマのことり兄貴(・8・)です！\n「AtCoder Beginner Contest 197」、お疲れさまでした～\n昨日はかなりやらかしました...\n\nレート-30...\nバタバタしてたので動画もないですｗ\nまあ2完でしたが、Cまで書いてみたいと思います。\n\n今回はJavaとPythonの両方で書いてみます。\n\n#目次\n[1.A - Rotate](#1-a---rotate)\n[2.B - Visibility](#2-b---visibility)\n[3.C - ORXOR](#3-c---orxor)\n[4.おわりに](#4-おわりに)\n\n#1. A - Rotate\n####問題\n長さ3の文字列Sが与えられます。\nSの先頭の文字を末尾に移動した文字列を出力してください。\n\n####制約\n・Sは英小文字のみからなる長さ3の文字列\n[A問題リンク](https://atcoder.jp/contests/abc197/tasks/abc197_a)\n\n####考察\n文字列のインデックス番号で考えます。\n\n3文字の文字列の元のインデックス番号は0, 1, 2とする\n↓\n先頭(0)を末尾に移動\n↓\n1, 2, 0の順で並ぶ\n\n####ことり兄貴(・8・)の解答(Java)\n```java:Java\nimport java.util.*;\n\nclass Main {\n    public static void main(String[] ktr) {\n        Scanner sc = new Scanner(System.in);\n        char[] c = sc.next().toCharArray();\n        System.out.println(new String(c, 1, 2) + c[0]);\n    }\n}\n```\nchar同士の足し算だと文字コードの和を出力してしまうので、インデックス1から2文字をStringに変換し文字列の足し算にしています。\n\n####ことり兄貴(・8・)の解答(Python)\n```python:Python\ns = input()\nprint(s[1:] + s[0])\n```\nPythonだとJavaでいうchar配列的な動き初めからができて、1:で1以降という表記ができるのが便利ですね。\n\n\n#2. B - Visibility\n####問題\n縦H行、横W列のマス目があり、いくつかのマスには障害物(#)が置かれています。\n障害物がないマスは.で表されます。\nH個の文字列(S[1]~s[H])が与えられます。この文字列の上からi行目、左からj行目\nをマスを(i, j)とします。現在地は(X, Y)です。\n現在地から見えるマスはいくつありますか。\n見えるとはXまたはYの座標が一致していて、現在地そのマスの間に障害物が\n存在しないことを意味します。\n\n####制約\n・1 <= H <= 100\n・1 <= W <= 100\n・1 <= X <= H\n・1 <= Y <= W\n・S[i]は.と#のみで構成される長さWの文字列\n・マス(X, Y)に障害物はない\n[B問題リンク](https://atcoder.jp/contests/abc197/tasks/abc197_b)\n\n####やらかした\nえー、筆者ここで盛大にやらかしました。\nこの問題においてXは縦の座標、Yは横の座標を示します。\n問題文をよく読まずに「Yは縦の座標で、Xは横の座標」という前提でコードを書いて、40分以上苦闘しました...ふと問題をよく見て「逆だったのかあああ...」ってなりましたｗ\n問題文はよく読みましょう(自戒)\n\n####考察\nまず、この系統の問題は外側を障害物(#)で囲んでおくのが無難です。\nなくても色々範囲とかに気を付ければ解けなくもないと思いますが、楽に行きましょう。\n囲んでしまうことで「障害物が見つかるまでループ」という条件がすべてのテストケースに対応できるようになります。\n囲んでからは\n・縦の座標を固定した状態で現在地から障害物の直前まで左に進む。\n　-->見つかったら折り返し始める。障害物のないマスを1つ通過するたびに答えを1増やす。\n・横の座標を固定した状態で現在地から障害物の直前まで上に進む。\n　-->見つかったら折り返し始める。障害物のないマスを1つ通過するたびに答えを1増やす。\nとすれば答えが出ます。\n\nただし、この数え方では初期のマス(X, Y)を2回数えてしまっているので出力の際は-1を忘れずに。\n\n####ことり兄貴(・8・)の解答(Java)\n```java:Java\nimport java.util.*;\n\nclass Main {\n    public static void main(String[] ktr) {\n        Scanner sc = new Scanner(System.in);\n        int h, w, x, y, ans, i;\n        h = sc.nextInt();\n        w = sc.nextInt();\n        x = sc.nextInt();\n        y = sc.nextInt();\n        ans = 0;\n        char[][] map = new char[h + 2][w + 2];\n        \n        Arrays.fill(map[0], '#');\n        for (i = 1; i <= h; i++) map[i] = ('#' + sc.next() + '#').toCharArray();\n        Arrays.fill(map[h + 1], '#');\n        \n        i = y;\n        while (map[x][i - 1] != '#') i--;\n        \n        while (map[x][i] != '#') {\n            ans++;\n            i++;\n        }\n        \n        i = x;\n        while (map[i - 1][y] != '#') i--;\n        \n        while (map[i][y] != '#') {\n            ans++;\n            i++;\n        }\n        \n        System.out.println(ans - 1);\n    }\n}\n```\nmapって名付けてる二次元配列がS[1]~S[H]を含む配列です。\nforやwhileで{}省略して横にくっつけてるのはご了承くだされ～\n\n####ことり兄貴(・8・)の解答(Python)\n```python:Python\nh, w, x, y = map(int, input().split())\nans = 0\ns = []\n\ns.append('#' * (w + 2))\nfor _ in range(h):\n    s.append('#' + input() + '#')\ns.append('#' * (w + 2))\n\ni = y\nwhile s[x][i - 1] != '#':\n    i -= 1\n\nwhile s[x][i] != '#':\n    ans += 1\n    i += 1\n\ni = x\nwhile s[i - 1][y] != '#':\n    i -= 1\n\nwhile s[i][y] != '#':\n    ans += 1\n    i += 1\n\nprint(ans - 1)\n```\n横にちょっと短くなるぐらいでJavaとそんなに変わりませんね。\n\n#3. C - ORXOR\n####問題\n長さNの数列Aが与えられます。\nこの数列を、1つ以上の空でない連続した区間に分けます。\nその後、分けた各区間で、区間内の数のビット単位ORを計算します。\nこうして得られたすべての値のビット単位XORとして考えられる最小値を求めてください。\n\n####制約\n・1 <= N <= 20\n・0 <= A[i] <= 2の30乗\n・入力に含まれる値は全て整数である\n\n[C問題リンク](https://atcoder.jp/contests/abc197/tasks/abc197_c)\n\n###考察\n制約の1つ目(1 <= N <= 20)は、「あ、ビット全探索っぽいな」ってなるやつで、2つ目(0 <= A[i] <= 2の30乗)は「32ビット型(Javaでいうint)に収まる値が入力されるんだなぁ」ってなるやつです。\n\n「1つ以上の空でない連続した区間に分ける」というのは\n1 2 3という数列があるなら\n※ここでは | を仕切りとして使います\n1 2 3\n1 2|3\n1|2 3\n1|2|3\nといったようにグループ分けするイメージですね。\nこの仕切りをビット全探索(後述)用いることによって再現します。\n\n####OR ? XOR?\n区間に分けることについては考えましたが、そもそも「ORとかXORってなに？」ってことについて軽く説明します。\nORは論理和、XORは排他的論理和と呼ばれるものです。\n#####OR\nA OR BとはAとBを2進数表記したときにAとBのどちらかに1がある桁は1、どちらも0の桁は0とするものです。\n例えば3 OR 5を考えると\n3 -> 011\n5 -> 101\n7 <- 111\nといった感じです。\n#####XOR\nA XOR BとはAとBを2進数表記したときにAとBの一方のみが1である桁は1、AとBに同じ数がある桁は0とするものです。\n例えば3 XOR 5を考えると\n3 -> 011\n5 -> 101\n6 <- 110\nといった感じです。\n\nただこれは式さえ書けばあとはプログラムが処理してくれるので、軽く「そうなんだ」ぐらいで大丈夫です。\nA OR BはA | B\nA XOR B は A ^ B\nと表現します。\n####ビット全探索?\nビット全探索は、ざっくりいうと「全部の組み合わせを試してみる」方法です。\nこの問題で言う、「仕切りの有無」をビットを用いて\n・その桁が0なら仕切りはない\n・その桁が1なら仕切りがある\nといった感じで表します。\n\n具体的には、\n1 2 3\n0 0\n\n1 2|3\n0 1\n \n1|2 3\n1 0\n\n1|2|3\n1 1\nといった感じです。\n\n今挙げた例では仕切りは2つ、組み合わせは4つでした。\nこのように組み合わせの数は仕切りをM個としたとき、\n2のM乗あります。\nコード中にある1 << (n - 1)は1を左にn - 1回移動した2進数を表しているのですが、\n1 << mは2のm乗に等しいです。\n\n2の2乗 = 4\n\n1 << 2\n100(2進数) = 4 + 0 + 0 = 4(10進数)\n\n####ことり兄貴(・8・)の解答(Java)\n```java:Java\nimport java.util.*;\n\nclass Main {\n    public static void main(String[] ktr) {\n        Scanner sc = new Scanner(System.in);\n        int n, a[], ans, i, j, xored, ored;\n        n = sc.nextInt();\n        a = new int[n];\n        ans = Integer.MAX_VALUE;\n        \n        for (i = 0; i < n; i++) a[i] = sc.nextInt();\n        \n        for (i = 0; i < 1 << (n - 1); i++) {\n            xored = 0;\n            ored = 0;\n            for (j = 0; j <= n; j++) {\n                if (j < n) ored |= a[j];\n                if (j == n || (i & 1 << j) > 0) {\n                    xored ^= ored;\n                    ored = 0;\n                }\n            }\n            \n            ans = Math.min(ans, xored);\n        }\n        \n        System.out.println(ans);\n    }\n}\n```\n\n####ことり兄貴(・8・)の解答(PyPy3)\n```python:PyPy3\nn = int(input())\na = list(map(int, input().split()))\nans = 2**32\n\nfor i in range(1 << (n - 1)):\n    xored = 0\n    ored = 0\n    for j in range(n + 1):\n        if j < n:\n            ored |= a[j]\n        if j == n or i & 1 << j:\n            xored ^= ored\n            ored = 0\n    ans = min(ans, xored)\n\nprint(ans)\n```\nPythonで提出するとTLEになってしまう様です。\nこの問題はPyPy3で提出しましょう。\n\n#4. おわりに\nいやぁ、やらかしました。XとY逆...改めて問題をじっくり読むことの大切さを実感しました。\nこの記事を見てる方の参考にもなれば幸いです！！\n","user":"KotoriAniki","created_at":"2021-03-29T00:19:32+09:00","updated_at":"2021-03-29T00:40:25+09:00"}]